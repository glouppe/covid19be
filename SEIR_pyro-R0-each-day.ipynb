{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppose 2 R0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters as stochastic function\n",
    "\n",
    "# deaths in hospitals / total deaths\n",
    "def frac_dh():\n",
    "    return torch.tensor(3470. / 7594.)\n",
    "\n",
    "# fraction of hospitalized \n",
    "def hh():\n",
    "    return torch.tensor(0.05)\n",
    "\n",
    "# inverse recovery time\n",
    "def gamma():\n",
    "    return torch.tensor(1. / 12.4)\n",
    "\n",
    "# inverse incubation time \n",
    "def epsilon():\n",
    "    return torch.tensor(1. / 5.2)\n",
    "\n",
    "# fatality rate in icu \n",
    "def dea():\n",
    "    return torch.tensor(.5)\n",
    "\n",
    "# population size\n",
    "def n0():\n",
    "    return torch.tensor(11000000.)\n",
    "\n",
    "# population en MR/MRS + personnel soignant\n",
    "def n0_MRS():\n",
    "    return torch.tensor(400000.)\n",
    "\n",
    "# e0 = i0 * factor\n",
    "def e0_factor():\n",
    "    return torch.tensor(37.)\n",
    "\n",
    "# e0_MRS = i0_MRS * factor\n",
    "def e0_MRS_factor():\n",
    "    return torch.tensor(20.)\n",
    "\n",
    "# size of the window for fitting Re's\n",
    "def window():\n",
    "    return torch.tensor(6.)\n",
    "\n",
    "def i0():\n",
    "    #return pyro.sample(\"i0\", dist.Poisson(10))\n",
    "    return torch.tensor(3.)\n",
    "\n",
    "def drea():\n",
    "    return dea()/ 5. \n",
    "    \n",
    "def rrea():\n",
    "    return (1 - dea())/20.\n",
    "    \n",
    "def hospi():\n",
    "    return torch.tensor(0.0)\n",
    "\n",
    "def gg():\n",
    "    return torch.tensor(.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEIR(r0):   \n",
    "    # Initial conditions\n",
    "    n = [n0()] # Population totale\n",
    "    i = [i0()] # Symptomatiques\n",
    "    e = [i[0] * e0_factor()] # Asymptomatiques\n",
    "    h = [torch.tensor(.0)] # Lits occupés hopital\n",
    "    l = [torch.tensor(.0)] # Lits occupés USI\n",
    "    r = [torch.tensor(.0)] # Immunisés\n",
    "    m = [torch.tensor(.0)] # Morts (totaux)\n",
    "    s = [n[-1] - e[-1] - i[-1] - r[-1]] # Sains\n",
    "    \n",
    "    # Simulate forward\n",
    "    n_days = len(r0)\n",
    "    \n",
    "    hospi = 0.\n",
    "    for day in range(n_days):\n",
    "        lam = gamma() * r0[day]\n",
    "        \n",
    "        if day == 14:\n",
    "            hospi = hh() / 7\n",
    "            \n",
    "        ds = -lam * (i[-1] / 2 + e[-1]) * s[-1] / n[-1]\n",
    "        de = lam * (i[-1] / 2 + e[-1]) * s[-1] / n[-1] - epsilon() * e[-1]\n",
    "        di = epsilon() * e[-1] - gamma() * i[-1] - hospi * i[-1]\n",
    "        dh = hospi * i[-1] - gg() * h[-1] / 7 - (1 - gg()) * h[-1] / (4. + 2 * torch.tanh((l[-1]-500.)/300.))\n",
    "        dl = (1 - gg()) * h[-1] / (4 + 2 * torch.tanh((l[-1]-500)/300)) - drea() * l[-1] - rrea() * l[-1]\n",
    "        dr = gamma() * i[-1] + rrea() * l[-1] + gg() * h[-1] / 7\n",
    "        dm = drea() * l[-1] \n",
    "        \n",
    "        s.append(s[-1] + ds)\n",
    "        e.append(e[-1] + de)\n",
    "        i.append(i[-1] + di)\n",
    "        h.append(h[-1] + dh)\n",
    "        l.append(l[-1] + dl)\n",
    "        if l[-1] > 1895:\n",
    "            dm = dm + (l[-1] - 1895)\n",
    "            l[-1] = torch.tensor(1895.)\n",
    "        r.append(r[-1] + dr)\n",
    "        m.append(m[-1] + dm)\n",
    "        n.append(s[-1] + e[-1] + i[-1] + h[-1] + l[-1] + r[-1])\n",
    "    return s, e, i, h, l, m, r\n",
    "def SEIR_MRS(r0_mrs, n_futures=0, window=6):    \n",
    "    # Smoothen and extend R0s\n",
    "    \n",
    "    # Initial conditions\n",
    "    alpha = torch.tensor(0.15 / 10)\n",
    "    lam = gamma() * 4.3\n",
    "    \n",
    "    n = [n0_MRS()]\n",
    "    i = [torch.tensor(1.)]\n",
    "    e = [i[-1] * e0_MRS_factor()]\n",
    "    r = [torch.tensor(0.0)]\n",
    "    s = [n[-1] - e[-1] - i[-1] - r[-1]]\n",
    "    m = [torch.tensor(0.0)]\n",
    "    \n",
    "    # Simulate forward\n",
    "    n_days = len(r0_mrs)\n",
    "    \n",
    "    for day in range(n_days):\n",
    "        lam = gamma() * r0_mrs[day]\n",
    "        \n",
    "        ds = -lam * (i[-1] / 2 + e[-1]) * s[-1] / n[-1]\n",
    "        de = lam * (i[-1] / 2 + e[-1]) * s[-1] / n[-1] - epsilon() * e[-1]\n",
    "        di = epsilon() * e[-1] - (gamma() + alpha) * i[-1]\n",
    "        dr = gamma() * i[-1]\n",
    "        dm = alpha * i[-1]\n",
    "        \n",
    "        s.append(s[-1] + ds)\n",
    "        e.append(e[-1] + de)\n",
    "        i.append(i[-1] + di)\n",
    "        r.append(r[-1] + dr)\n",
    "        m.append(m[-1] + dm)\n",
    "        n.append(s[-1] + e[-1] + i[-1] + r[-1])\n",
    "        \n",
    "    return s, e, i, m, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer.mcmc import MCMC, NUTS\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(source: [wikipedia covid-19 Belgique](https://fr.wikipedia.org/wiki/Pand%C3%A9mie_de_Covid-19_en_Belgique))\n",
    "- 11 Mars arrêt des visites en mrs. (13)\n",
    "- 16 Mars plus de cours. (18)\n",
    "- 18 Mars confinement. (20)\n",
    "- 20 avril magasin de bricolage et pépinieriste ouvrent à nouveau. (22)\n",
    "\n",
    "Nos données débutent au 28 février"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_r0_switch = 20\n",
    "date_r0_switch_mrs = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covid19be import load_data\n",
    "data_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hospitalized</th>\n",
       "      <th>n_hospitalized_in</th>\n",
       "      <th>n_hospitalized_out</th>\n",
       "      <th>n_icu</th>\n",
       "      <th>n_daily_deaths</th>\n",
       "      <th>date</th>\n",
       "      <th>n_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_hospitalized  n_hospitalized_in  n_hospitalized_out  n_icu  \\\n",
       "4               0                  0                   0      0   \n",
       "5               0                  0                   0      0   \n",
       "6               0                  0                   0      0   \n",
       "7               0                  0                   0      0   \n",
       "8               0                  0                   0      0   \n",
       "\n",
       "   n_daily_deaths       date  n_deaths  \n",
       "4               0 2020-03-02         0  \n",
       "5               0 2020-03-03         0  \n",
       "6               0 2020-03-04         0  \n",
       "7               0 2020-03-05         0  \n",
       "8               0 2020-03-06         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[3:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_days = len(data_df)\n",
    "n_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_dirty_data = 4\n",
    "n_useful_days = n_days - nb_dirty_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_useful_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unpredictable_days = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs = True\n",
    "noiser = lambda mu: dist.ZeroInflatedPoisson(torch.tensor(.0001), mu + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiser(mu):\n",
    "    #print(mu)\n",
    "    if mu <= 0:\n",
    "        print(mu)\n",
    "    return dist.ZeroInflatedPoisson(torch.tensor(.0001), mu + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEIR_full_model_bis(ret_data=False):    \n",
    "    n_futures=0\n",
    "    # Simulate\n",
    "    r0_1 = pyro.sample(\"r0_1\", dist.Uniform(torch.zeros(n_useful_days) + .2, \n",
    "                                            torch.ones(n_useful_days)*8.))\n",
    "    # R0 fluctuates around its means that are given by r0_1 and r0_2\n",
    "    r0 = dist.Uniform(r0_1 - .2, r0_1 + .2)()\n",
    "    s_T, e_T, i_T, h_T, l_T, m_T, r_T = SEIR(r0)\n",
    "    #print(r0)\n",
    "    if mrs:\n",
    "        r0_mrs_1 = pyro.sample(\"r0_mrs_1\", dist.Uniform(torch.zeros(n_useful_days) + .2, torch.ones(n_useful_days)*8.))\n",
    "        r0_mrs = dist.Uniform(r0_mrs_1 - .2, r0_mrs_1 + .2)()\n",
    "    \n",
    "        _, _, _, m_mrs_T, _ = SEIR_MRS(r0_mrs)\n",
    "    for idx in range(n_useful_days):\n",
    "        if idx > 16:\n",
    "            if h_T[idx] < 0:\n",
    "                print(h_T[idx])\n",
    "            pyro.sample(\"h_%d\" % idx, noiser(h_T[idx]))\n",
    "            pyro.sample(\"l_%d\" % idx, noiser(l_T[idx]))\n",
    "            pyro.sample(\"m_%d\" % idx, noiser(m_T[idx]))\n",
    "            if mrs:\n",
    "                pyro.sample(\"m_mrs_%d\" % idx, noiser(m_mrs_T[idx]))\n",
    "    if mrs and ret_data:\n",
    "        return s_T, e_T, i_T, h_T, l_T, m_T, m_mrs_T, r_T, r0, r0_mrs\n",
    "    if ret_data:\n",
    "        return s_T, e_T, i_T, h_T, l_T, m_T, r_T, r0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-995aa5173365>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data[\"m_%d\" % idx] = torch.tensor(m[idx]*frac_dh(), dtype=torch.float)\n",
      "<ipython-input-14-995aa5173365>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data[\"m_mrs_%d\" % idx] = torch.tensor(m[idx]*(1-frac_dh()))\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "hospi = data_df['n_hospitalized']\n",
    "l = data_df['n_icu']\n",
    "m = data_df['n_deaths']\n",
    "for idx in range(n_useful_days):\n",
    "    if idx > 16:\n",
    "        data[\"h_%d\" % idx] = torch.tensor(hospi[idx] - l[idx], dtype=torch.float)\n",
    "        data[\"l_%d\" % idx] = torch.tensor(l[idx], dtype=torch.float)\n",
    "        data[\"m_%d\" % idx] = torch.tensor(m[idx]*frac_dh(), dtype=torch.float)\n",
    "        if mrs:\n",
    "            data[\"m_mrs_%d\" % idx] = torch.tensor(m[idx]*(1-frac_dh()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r0_guide(ret_data=False):    \n",
    "    a_r0_1 = pyro.param(\"a_r0_1\", torch.ones(n_useful_days - n_unpredictable_days) * 4., constraint=constraints.positive)\n",
    "    b_r0_1 = pyro.param(\"b_r0_1\", torch.ones(n_useful_days - n_unpredictable_days) * 3., constraint=constraints.positive)\n",
    "    a_r0_1 = torch.cat((a_r0_1, torch.ones(n_unpredictable_days) * a_r0_1[-1]))\n",
    "    b_r0_1 = torch.cat((b_r0_1, torch.ones(n_unpredictable_days) * b_r0_1[-1]))\n",
    "\n",
    "    r0_1 = pyro.sample(\"r0_1\", dist.Uniform(a_r0_1, a_r0_1 + b_r0_1))\n",
    "    if mrs:\n",
    "        a_r0_mrs_1 = pyro.param(\"a_r0_mrs_1\", torch.ones(n_useful_days - n_unpredictable_days) * 2., constraint=constraints.positive)\n",
    "        b_r0_mrs_1 = pyro.param(\"b_r0_mrs_1\", torch.ones(n_useful_days - n_unpredictable_days) * 4., constraint=constraints.positive)\n",
    "        a_r0_mrs_1 = torch.cat((a_r0_mrs_1, torch.ones(n_unpredictable_days) * a_r0_mrs_1[-1]))\n",
    "        b_r0_mrs_1 = torch.cat((b_r0_mrs_1, torch.ones(n_unpredictable_days) * b_r0_mrs_1[-1]))\n",
    "        r0_mrs_1 = pyro.sample(\"r0_mrs_1\", dist.Uniform(a_r0_mrs_1, a_r0_mrs_1 + b_r0_mrs_1))\n",
    "\n",
    "    if ret_data:\n",
    "        # R0 fluctuates around its means that are given by r0_1 and r0_2\n",
    "        r0 = dist.Uniform(r0_1 - .2, r0_1 + .2)()\n",
    "\n",
    "        s_T, e_T, i_T, h_T, l_T, m_T, r_T = SEIR(r0)\n",
    "        #print(r0)\n",
    "        if mrs:\n",
    "            r0_mrs = dist.Uniform(r0_mrs_1 - .2, r0_mrs_1 + .2)()\n",
    "\n",
    "            _, _, _, m_mrs_T, _ = SEIR_MRS(r0_mrs)\n",
    "        for idx in range(n_useful_days):\n",
    "            if idx > 16:\n",
    "                pyro.sample(\"h_%d\" % idx, noiser(h_T[idx]))\n",
    "                pyro.sample(\"l_%d\" % idx, noiser(l_T[idx]))\n",
    "                pyro.sample(\"m_%d\" % idx, noiser(m_T[idx]))\n",
    "                if mrs:\n",
    "                    pyro.sample(\"m_mrs_%d\" % idx, noiser(m_mrs_T[idx]))\n",
    "        if mrs and ret_data:\n",
    "            return s_T, e_T, i_T, h_T, l_T, m_T, m_mrs_T, r_T, r0, r0_mrs\n",
    "        if ret_data:\n",
    "            return s_T, e_T, i_T, h_T, l_T, m_T, r_T, r0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "# setup the optimizer\n",
    "adam_params = {\"lr\": 0.001, \"betas\": (0.90, 0.999)}\n",
    "optimizer = pyro.optim.Adam(adam_params)\n",
    "svi = pyro.infer.SVI(model=pyro.condition(SEIR_full_model_bis, data=data),\n",
    "                     guide=r0_guide,\n",
    "                     optim=optimizer,\n",
    "                     loss=pyro.infer.Trace_ELBO())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960,\n",
      "        3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960,\n",
      "        3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960,\n",
      "        3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960,\n",
      "        3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960,\n",
      "        3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960, 3.9960,\n",
      "        3.9960], grad_fn=<AddBackward0>) tensor([6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930,\n",
      "        6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930,\n",
      "        6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930,\n",
      "        6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930,\n",
      "        6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930,\n",
      "        6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9930, 6.9990, 6.9930,\n",
      "        6.9930], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980,\n",
      "        1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980,\n",
      "        1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980,\n",
      "        1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980,\n",
      "        1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980,\n",
      "        1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980, 1.9980,\n",
      "        1.9980], grad_fn=<AddBackward0>) tensor([5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940,\n",
      "        5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940,\n",
      "        5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940,\n",
      "        5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940,\n",
      "        5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940,\n",
      "        5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940, 5.9940,\n",
      "        5.9940], grad_fn=<AddBackward0>)\n",
      "3435439.285803795\n",
      "r0 before lock-down  tensor([3.6191, 3.6210, 3.6218, 3.6197, 3.6220, 3.6203, 3.6222, 3.6216, 3.6217,\n",
      "        3.6211, 3.6218, 3.6210, 3.6207, 3.6201, 3.6204, 3.6230, 3.6210, 3.6216,\n",
      "        3.6192, 3.6213, 3.6206, 3.6213, 3.6195, 3.6203, 3.6209, 3.6224, 3.6192,\n",
      "        3.6197, 3.6189, 3.6196, 3.6189, 3.6157, 3.6150, 3.6131, 3.6110, 3.6069,\n",
      "        3.6020, 3.5988, 3.5925, 3.5870, 3.5808, 3.5749, 3.5695, 3.5639, 3.5604,\n",
      "        3.5568, 3.5537, 3.5522, 3.5506, 3.5497, 3.5484, 3.5483, 3.5481, 3.5483,\n",
      "        3.5484], grad_fn=<AddBackward0>) tensor([6.3744, 6.3593, 6.3610, 6.3692, 6.3624, 6.3708, 6.3675, 6.3663, 6.3732,\n",
      "        6.3680, 6.3667, 6.3706, 6.3673, 6.3747, 6.3789, 6.3547, 6.3691, 6.3603,\n",
      "        6.3718, 6.3682, 6.3691, 6.3672, 6.3766, 6.3728, 6.3631, 6.3615, 6.3753,\n",
      "        6.3632, 6.3644, 6.3562, 6.3654, 6.3697, 6.3628, 6.3562, 6.3454, 6.3588,\n",
      "        6.3515, 6.3264, 6.3269, 6.2994, 6.3027, 6.3046, 6.2802, 6.2657, 6.2716,\n",
      "        6.2626, 6.2631, 6.2595, 6.2618, 6.2554, 6.2545, 6.2597, 6.2665, 6.2581,\n",
      "        6.2466], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.8407, 1.8383, 1.8403, 1.8408, 1.8400, 1.8390, 1.8409, 1.8408, 1.8403,\n",
      "        1.8413, 1.8416, 1.8401, 1.8393, 1.8391, 1.8396, 1.8403, 1.8401, 1.8396,\n",
      "        1.8383, 1.8391, 1.8407, 1.8394, 1.8378, 1.8399, 1.8380, 1.8384, 1.8365,\n",
      "        1.8396, 1.8357, 1.8379, 1.8362, 1.8357, 1.8358, 1.8342, 1.8324, 1.8330,\n",
      "        1.8316, 1.8307, 1.8289, 1.8282, 1.8264, 1.8255, 1.8252, 1.8221, 1.8209,\n",
      "        1.8183, 1.8173, 1.8153, 1.8143, 1.8121, 1.8108, 1.8096, 1.8081, 1.8074,\n",
      "        1.8066], grad_fn=<AddBackward0>) tensor([5.5542, 5.5715, 5.5617, 5.5568, 5.5547, 5.5618, 5.5604, 5.5421, 5.5521,\n",
      "        5.5573, 5.5420, 5.5380, 5.5631, 5.5679, 5.5627, 5.5585, 5.5526, 5.5535,\n",
      "        5.5598, 5.5585, 5.5362, 5.5406, 5.5500, 5.5486, 5.5538, 5.5415, 5.5530,\n",
      "        5.5212, 5.5610, 5.5331, 5.5311, 5.5408, 5.5344, 5.5357, 5.5395, 5.5186,\n",
      "        5.5516, 5.5309, 5.5329, 5.5169, 5.5143, 5.5052, 5.5005, 5.5083, 5.4920,\n",
      "        5.5049, 5.4907, 5.4961, 5.4876, 5.4696, 5.4835, 5.4722, 5.4906, 5.4644,\n",
      "        5.4667], grad_fn=<AddBackward0>)\n",
      "2478137.1323764324\n",
      "r0 before lock-down  tensor([3.3020, 3.3019, 3.3042, 3.3039, 3.3055, 3.3059, 3.3071, 3.3060, 3.3065,\n",
      "        3.3039, 3.3066, 3.3043, 3.3053, 3.3045, 3.3069, 3.3060, 3.3050, 3.3042,\n",
      "        3.3053, 3.3049, 3.3057, 3.3061, 3.3047, 3.3053, 3.3043, 3.3038, 3.3043,\n",
      "        3.3015, 3.3006, 3.2976, 3.2972, 3.2919, 3.2875, 3.2825, 3.2745, 3.2657,\n",
      "        3.2537, 3.2397, 3.2246, 3.2071, 3.1869, 3.1669, 3.1471, 3.1274, 3.1088,\n",
      "        3.0930, 3.0784, 3.0670, 3.0568, 3.0498, 3.0431, 3.0385, 3.0335, 3.0316,\n",
      "        3.0293], grad_fn=<AddBackward0>) tensor([5.8558, 5.8528, 5.8391, 5.8376, 5.8350, 5.8409, 5.8331, 5.8386, 5.8438,\n",
      "        5.8486, 5.8363, 5.8464, 5.8365, 5.8502, 5.8379, 5.8272, 5.8437, 5.8403,\n",
      "        5.8316, 5.8408, 5.8264, 5.8326, 5.8341, 5.8344, 5.8292, 5.8384, 5.8263,\n",
      "        5.8261, 5.8197, 5.8287, 5.8201, 5.8256, 5.8182, 5.7979, 5.7888, 5.7882,\n",
      "        5.7639, 5.7333, 5.6984, 5.6516, 5.6424, 5.6209, 5.5670, 5.5238, 5.5381,\n",
      "        5.4913, 5.4641, 5.4291, 5.4248, 5.4166, 5.4264, 5.4088, 5.3873, 5.3851,\n",
      "        5.3578], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.7640, 1.7608, 1.7653, 1.7643, 1.7639, 1.7621, 1.7640, 1.7641, 1.7621,\n",
      "        1.7645, 1.7651, 1.7608, 1.7601, 1.7623, 1.7609, 1.7625, 1.7614, 1.7601,\n",
      "        1.7585, 1.7596, 1.7619, 1.7585, 1.7546, 1.7588, 1.7562, 1.7544, 1.7514,\n",
      "        1.7539, 1.7490, 1.7496, 1.7480, 1.7443, 1.7445, 1.7414, 1.7371, 1.7358,\n",
      "        1.7332, 1.7288, 1.7279, 1.7233, 1.7187, 1.7158, 1.7129, 1.7067, 1.7012,\n",
      "        1.6952, 1.6909, 1.6851, 1.6797, 1.6732, 1.6667, 1.6616, 1.6552, 1.6490,\n",
      "        1.6429], grad_fn=<AddBackward0>) tensor([5.3338, 5.3610, 5.3246, 5.3328, 5.3223, 5.3409, 5.3409, 5.3154, 5.3404,\n",
      "        5.3323, 5.3121, 5.3327, 5.3615, 5.3388, 5.3523, 5.3292, 5.3271, 5.3360,\n",
      "        5.3369, 5.3292, 5.2892, 5.3093, 5.3334, 5.3067, 5.3058, 5.3023, 5.3187,\n",
      "        5.2733, 5.3139, 5.2853, 5.2681, 5.2900, 5.2691, 5.2665, 5.2765, 5.2484,\n",
      "        5.2796, 5.2684, 5.2160, 5.2208, 5.2188, 5.1935, 5.1711, 5.1773, 5.1722,\n",
      "        5.1811, 5.1420, 5.1231, 5.1058, 5.0782, 5.1024, 5.0474, 5.0324, 5.0475,\n",
      "        5.0020], grad_fn=<AddBackward0>)\n",
      "1241974.731199503\n",
      "r0 before lock-down  tensor([3.0688, 3.0672, 3.0700, 3.0698, 3.0716, 3.0741, 3.0737, 3.0737, 3.0748,\n",
      "        3.0713, 3.0742, 3.0704, 3.0733, 3.0740, 3.0736, 3.0732, 3.0721, 3.0703,\n",
      "        3.0712, 3.0700, 3.0701, 3.0709, 3.0701, 3.0696, 3.0694, 3.0676, 3.0674,\n",
      "        3.0628, 3.0616, 3.0598, 3.0554, 3.0497, 3.0422, 3.0359, 3.0241, 3.0115,\n",
      "        2.9932, 2.9725, 2.9494, 2.9230, 2.8921, 2.8613, 2.8272, 2.7929, 2.7617,\n",
      "        2.7296, 2.6990, 2.6715, 2.6450, 2.6231, 2.6013, 2.5828, 2.5651, 2.5514,\n",
      "        2.5371], grad_fn=<AddBackward0>) tensor([5.4623, 5.4719, 5.4509, 5.4503, 5.4446, 5.4379, 5.4446, 5.4405, 5.4420,\n",
      "        5.4552, 5.4383, 5.4568, 5.4342, 5.4359, 5.4441, 5.4278, 5.4465, 5.4476,\n",
      "        5.4403, 5.4508, 5.4323, 5.4419, 5.4296, 5.4404, 5.4243, 5.4407, 5.4305,\n",
      "        5.4342, 5.4204, 5.4104, 5.4188, 5.4148, 5.4087, 5.3710, 5.3630, 5.3488,\n",
      "        5.3253, 5.2846, 5.2334, 5.1723, 5.1451, 5.1015, 5.0372, 4.9748, 4.9394,\n",
      "        4.8779, 4.8121, 4.7621, 4.7251, 4.7038, 4.6720, 4.6283, 4.5901, 4.5673,\n",
      "        4.5210], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.7443, 1.7412, 1.7452, 1.7438, 1.7442, 1.7407, 1.7436, 1.7437, 1.7413,\n",
      "        1.7445, 1.7444, 1.7387, 1.7390, 1.7399, 1.7376, 1.7389, 1.7384, 1.7362,\n",
      "        1.7342, 1.7338, 1.7353, 1.7308, 1.7258, 1.7293, 1.7249, 1.7213, 1.7173,\n",
      "        1.7181, 1.7119, 1.7100, 1.7073, 1.6999, 1.6988, 1.6936, 1.6878, 1.6824,\n",
      "        1.6796, 1.6722, 1.6694, 1.6613, 1.6543, 1.6484, 1.6433, 1.6334, 1.6236,\n",
      "        1.6152, 1.6073, 1.5972, 1.5873, 1.5765, 1.5663, 1.5572, 1.5457, 1.5348,\n",
      "        1.5233], grad_fn=<AddBackward0>) tensor([5.2624, 5.2889, 5.2572, 5.2686, 5.2466, 5.2842, 5.2692, 5.2413, 5.2715,\n",
      "        5.2514, 5.2346, 5.2689, 5.2831, 5.2707, 5.2900, 5.2601, 5.2458, 5.2554,\n",
      "        5.2511, 5.2503, 5.2064, 5.2232, 5.2470, 5.2121, 5.2117, 5.2089, 5.2163,\n",
      "        5.1657, 5.1977, 5.1742, 5.1420, 5.1787, 5.1457, 5.1399, 5.1328, 5.1190,\n",
      "        5.1233, 5.1111, 5.0402, 5.0513, 5.0351, 5.0014, 4.9588, 4.9629, 4.9695,\n",
      "        4.9479, 4.8889, 4.8696, 4.8455, 4.8275, 4.8277, 4.7440, 4.7209, 4.7471,\n",
      "        4.6760], grad_fn=<AddBackward0>)\n",
      "530837.1295442581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([2.9180, 2.9179, 2.9198, 2.9195, 2.9221, 2.9247, 2.9237, 2.9244, 2.9243,\n",
      "        2.9223, 2.9250, 2.9198, 2.9243, 2.9241, 2.9251, 2.9224, 2.9210, 2.9198,\n",
      "        2.9205, 2.9179, 2.9181, 2.9191, 2.9170, 2.9148, 2.9152, 2.9126, 2.9115,\n",
      "        2.9044, 2.9035, 2.9000, 2.8965, 2.8876, 2.8792, 2.8700, 2.8565, 2.8412,\n",
      "        2.8198, 2.7954, 2.7662, 2.7349, 2.6971, 2.6600, 2.6177, 2.5757, 2.5342,\n",
      "        2.4925, 2.4513, 2.4118, 2.3741, 2.3402, 2.3064, 2.2751, 2.2458, 2.2198,\n",
      "        2.1911], grad_fn=<AddBackward0>) tensor([5.2168, 5.2181, 5.2022, 5.2040, 5.1883, 5.1836, 5.1961, 5.1861, 5.1954,\n",
      "        5.1977, 5.1821, 5.2077, 5.1743, 5.1812, 5.1769, 5.1726, 5.1943, 5.1878,\n",
      "        5.1786, 5.1965, 5.1699, 5.1741, 5.1647, 5.1870, 5.1604, 5.1750, 5.1665,\n",
      "        5.1762, 5.1524, 5.1434, 5.1358, 5.1440, 5.1294, 5.0932, 5.0763, 5.0592,\n",
      "        5.0277, 4.9753, 4.9287, 4.8514, 4.8185, 4.7552, 4.6827, 4.5968, 4.5513,\n",
      "        4.4653, 4.3797, 4.3346, 4.2703, 4.2274, 4.1795, 4.1224, 4.0523, 3.9892,\n",
      "        3.9160], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.7320, 1.7285, 1.7332, 1.7308, 1.7318, 1.7270, 1.7300, 1.7305, 1.7266,\n",
      "        1.7304, 1.7303, 1.7242, 1.7238, 1.7246, 1.7224, 1.7232, 1.7218, 1.7199,\n",
      "        1.7168, 1.7150, 1.7146, 1.7093, 1.7031, 1.7050, 1.6989, 1.6941, 1.6887,\n",
      "        1.6869, 1.6792, 1.6753, 1.6710, 1.6608, 1.6572, 1.6504, 1.6409, 1.6331,\n",
      "        1.6291, 1.6202, 1.6146, 1.6039, 1.5945, 1.5852, 1.5774, 1.5656, 1.5522,\n",
      "        1.5413, 1.5310, 1.5174, 1.5050, 1.4903, 1.4773, 1.4644, 1.4493, 1.4347,\n",
      "        1.4192], grad_fn=<AddBackward0>) tensor([5.2095, 5.2440, 5.2015, 5.2228, 5.1912, 5.2434, 5.2260, 5.1905, 5.2369,\n",
      "        5.2070, 5.1846, 5.2201, 5.2374, 5.2219, 5.2338, 5.1994, 5.1893, 5.1868,\n",
      "        5.1832, 5.1861, 5.1508, 5.1578, 5.1786, 5.1437, 5.1387, 5.1267, 5.1260,\n",
      "        5.0792, 5.1014, 5.0702, 5.0257, 5.0642, 5.0271, 5.0078, 5.0120, 4.9914,\n",
      "        4.9776, 4.9449, 4.8695, 4.8787, 4.8555, 4.8296, 4.7831, 4.7702, 4.7868,\n",
      "        4.7548, 4.6759, 4.6555, 4.6011, 4.5937, 4.5686, 4.4654, 4.4464, 4.4735,\n",
      "        4.3722], grad_fn=<AddBackward0>)\n",
      "434207.4331037998\n",
      "r0 before lock-down  tensor([2.8249, 2.8258, 2.8275, 2.8269, 2.8287, 2.8321, 2.8312, 2.8324, 2.8318,\n",
      "        2.8296, 2.8332, 2.8262, 2.8312, 2.8304, 2.8319, 2.8281, 2.8271, 2.8243,\n",
      "        2.8255, 2.8221, 2.8211, 2.8226, 2.8185, 2.8163, 2.8153, 2.8115, 2.8104,\n",
      "        2.8007, 2.7988, 2.7945, 2.7896, 2.7791, 2.7702, 2.7585, 2.7438, 2.7259,\n",
      "        2.7023, 2.6752, 2.6431, 2.6080, 2.5665, 2.5254, 2.4782, 2.4319, 2.3848,\n",
      "        2.3373, 2.2892, 2.2440, 2.1994, 2.1588, 2.1163, 2.0789, 2.0412, 2.0073,\n",
      "        1.9693], grad_fn=<AddBackward0>) tensor([5.0633, 5.0587, 5.0416, 5.0478, 5.0363, 5.0276, 5.0394, 5.0248, 5.0379,\n",
      "        5.0426, 5.0182, 5.0572, 5.0172, 5.0267, 5.0150, 5.0149, 5.0309, 5.0319,\n",
      "        5.0139, 5.0321, 5.0068, 5.0007, 5.0002, 5.0129, 4.9888, 5.0020, 4.9852,\n",
      "        5.0024, 4.9773, 4.9627, 4.9513, 4.9605, 4.9367, 4.9054, 4.8783, 4.8636,\n",
      "        4.8246, 4.7695, 4.7178, 4.6353, 4.5992, 4.5275, 4.4501, 4.3484, 4.2931,\n",
      "        4.2010, 4.1132, 4.0501, 3.9727, 3.9086, 3.8766, 3.7733, 3.7047, 3.6292,\n",
      "        3.5313], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.7639, 1.7584, 1.7641, 1.7606, 1.7623, 1.7577, 1.7620, 1.7615, 1.7567,\n",
      "        1.7593, 1.7595, 1.7530, 1.7526, 1.7522, 1.7493, 1.7504, 1.7474, 1.7452,\n",
      "        1.7398, 1.7371, 1.7346, 1.7288, 1.7209, 1.7197, 1.7121, 1.7051, 1.6959,\n",
      "        1.6916, 1.6810, 1.6739, 1.6668, 1.6537, 1.6488, 1.6373, 1.6254, 1.6148,\n",
      "        1.6068, 1.5960, 1.5870, 1.5727, 1.5609, 1.5486, 1.5387, 1.5244, 1.5082,\n",
      "        1.4941, 1.4815, 1.4651, 1.4495, 1.4325, 1.4167, 1.4011, 1.3833, 1.3665,\n",
      "        1.3473], grad_fn=<AddBackward0>) tensor([5.2741, 5.3263, 5.2695, 5.3017, 5.2625, 5.3119, 5.2740, 5.2486, 5.2994,\n",
      "        5.2793, 5.2473, 5.2833, 5.2934, 5.2842, 5.2939, 5.2467, 5.2423, 5.2279,\n",
      "        5.2334, 5.2296, 5.1961, 5.1869, 5.2030, 5.1729, 5.1524, 5.1316, 5.1407,\n",
      "        5.0856, 5.1004, 5.0682, 5.0107, 5.0405, 4.9748, 4.9689, 4.9547, 4.9260,\n",
      "        4.9171, 4.8602, 4.7831, 4.7968, 4.7610, 4.7316, 4.6649, 4.6403, 4.6504,\n",
      "        4.6188, 4.5198, 4.4951, 4.4403, 4.4231, 4.3931, 4.2797, 4.2564, 4.2663,\n",
      "        4.1904], grad_fn=<AddBackward0>)\n",
      "319958.95775032043\n",
      "r0 before lock-down  tensor([2.7681, 2.7694, 2.7702, 2.7697, 2.7721, 2.7754, 2.7745, 2.7755, 2.7748,\n",
      "        2.7727, 2.7765, 2.7692, 2.7740, 2.7728, 2.7737, 2.7693, 2.7684, 2.7647,\n",
      "        2.7654, 2.7605, 2.7583, 2.7588, 2.7541, 2.7507, 2.7486, 2.7433, 2.7411,\n",
      "        2.7297, 2.7263, 2.7211, 2.7147, 2.7026, 2.6927, 2.6789, 2.6630, 2.6434,\n",
      "        2.6172, 2.5884, 2.5539, 2.5165, 2.4721, 2.4289, 2.3783, 2.3284, 2.2783,\n",
      "        2.2264, 2.1743, 2.1254, 2.0768, 2.0313, 1.9840, 1.9421, 1.8997, 1.8602,\n",
      "        1.8164], grad_fn=<AddBackward0>) tensor([4.9665, 4.9597, 4.9479, 4.9544, 4.9370, 4.9301, 4.9410, 4.9273, 4.9406,\n",
      "        4.9449, 4.9174, 4.9574, 4.9161, 4.9271, 4.9155, 4.9144, 4.9239, 4.9274,\n",
      "        4.9064, 4.9273, 4.9034, 4.8961, 4.8898, 4.9012, 4.8751, 4.8859, 4.8672,\n",
      "        4.8852, 4.8583, 4.8363, 4.8237, 4.8322, 4.8019, 4.7707, 4.7366, 4.7195,\n",
      "        4.6835, 4.6214, 4.5679, 4.4775, 4.4405, 4.3565, 4.2775, 4.1736, 4.1065,\n",
      "        4.0150, 3.9223, 3.8493, 3.7578, 3.6870, 3.6535, 3.5302, 3.4532, 3.3794,\n",
      "        3.2589], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.7752, 1.7691, 1.7757, 1.7733, 1.7730, 1.7687, 1.7711, 1.7716, 1.7666,\n",
      "        1.7676, 1.7686, 1.7623, 1.7603, 1.7607, 1.7568, 1.7582, 1.7521, 1.7504,\n",
      "        1.7431, 1.7394, 1.7359, 1.7288, 1.7184, 1.7153, 1.7061, 1.6965, 1.6857,\n",
      "        1.6781, 1.6649, 1.6545, 1.6459, 1.6302, 1.6215, 1.6072, 1.5940, 1.5793,\n",
      "        1.5698, 1.5562, 1.5446, 1.5281, 1.5146, 1.5000, 1.4878, 1.4718, 1.4539,\n",
      "        1.4380, 1.4241, 1.4052, 1.3878, 1.3696, 1.3522, 1.3344, 1.3151, 1.2969,\n",
      "        1.2754], grad_fn=<AddBackward0>) tensor([5.2878, 5.3447, 5.2767, 5.2936, 5.2746, 5.3212, 5.2998, 5.2636, 5.3115,\n",
      "        5.3045, 5.2606, 5.2882, 5.3106, 5.2868, 5.2975, 5.2365, 5.2553, 5.2194,\n",
      "        5.2331, 5.2218, 5.1796, 5.1626, 5.1838, 5.1474, 5.1171, 5.0938, 5.0879,\n",
      "        5.0337, 5.0420, 5.0120, 4.9307, 4.9510, 4.8917, 4.8798, 4.8403, 4.8259,\n",
      "        4.7984, 4.7409, 4.6611, 4.6704, 4.6238, 4.5905, 4.5251, 4.4943, 4.4967,\n",
      "        4.4569, 4.3420, 4.3314, 4.2753, 4.2410, 4.2061, 4.0943, 4.0682, 4.0617,\n",
      "        3.9899], grad_fn=<AddBackward0>)\n",
      "278946.029753685\n",
      "r0 before lock-down  tensor([2.7291, 2.7304, 2.7311, 2.7307, 2.7325, 2.7356, 2.7353, 2.7362, 2.7351,\n",
      "        2.7333, 2.7367, 2.7295, 2.7341, 2.7326, 2.7330, 2.7278, 2.7262, 2.7217,\n",
      "        2.7213, 2.7157, 2.7118, 2.7115, 2.7055, 2.7012, 2.6975, 2.6911, 2.6874,\n",
      "        2.6741, 2.6690, 2.6625, 2.6547, 2.6409, 2.6296, 2.6142, 2.5970, 2.5758,\n",
      "        2.5471, 2.5170, 2.4802, 2.4412, 2.3947, 2.3493, 2.2963, 2.2435, 2.1909,\n",
      "        2.1367, 2.0820, 2.0307, 1.9787, 1.9304, 1.8810, 1.8354, 1.7901, 1.7480,\n",
      "        1.7002], grad_fn=<AddBackward0>) tensor([4.8971, 4.8895, 4.8774, 4.8841, 4.8706, 4.8660, 4.8724, 4.8588, 4.8741,\n",
      "        4.8762, 4.8496, 4.8876, 4.8446, 4.8536, 4.8412, 4.8416, 4.8508, 4.8535,\n",
      "        4.8321, 4.8503, 4.8283, 4.8177, 4.8092, 4.8162, 4.7893, 4.7936, 4.7731,\n",
      "        4.7916, 4.7625, 4.7350, 4.7206, 4.7263, 4.6919, 4.6564, 4.6174, 4.5969,\n",
      "        4.5648, 4.4954, 4.4414, 4.3441, 4.3045, 4.2161, 4.1351, 4.0318, 3.9596,\n",
      "        3.8609, 3.7645, 3.6827, 3.5945, 3.5156, 3.4666, 3.3446, 3.2666, 3.1818,\n",
      "        3.0619], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.7992, 1.7941, 1.8009, 1.7971, 1.7955, 1.7924, 1.7948, 1.7943, 1.7889,\n",
      "        1.7887, 1.7903, 1.7843, 1.7800, 1.7806, 1.7756, 1.7786, 1.7713, 1.7666,\n",
      "        1.7571, 1.7531, 1.7488, 1.7402, 1.7262, 1.7211, 1.7104, 1.6978, 1.6848,\n",
      "        1.6739, 1.6583, 1.6445, 1.6329, 1.6144, 1.6041, 1.5848, 1.5694, 1.5520,\n",
      "        1.5400, 1.5241, 1.5095, 1.4920, 1.4759, 1.4592, 1.4459, 1.4275, 1.4079,\n",
      "        1.3906, 1.3753, 1.3549, 1.3364, 1.3167, 1.2988, 1.2790, 1.2593, 1.2395,\n",
      "        1.2166], grad_fn=<AddBackward0>) tensor([5.3320, 5.3758, 5.3013, 5.3345, 5.3282, 5.3572, 5.3327, 5.3059, 5.3554,\n",
      "        5.3550, 5.2977, 5.3183, 5.3588, 5.3292, 5.3371, 5.2499, 5.2669, 5.2497,\n",
      "        5.2678, 5.2415, 5.1840, 5.1595, 5.1956, 5.1516, 5.1048, 5.0838, 5.0646,\n",
      "        5.0104, 5.0044, 4.9749, 4.8846, 4.8970, 4.8129, 4.8231, 4.7668, 4.7484,\n",
      "        4.7137, 4.6443, 4.5677, 4.5532, 4.5054, 4.4683, 4.3856, 4.3606, 4.3633,\n",
      "        4.3233, 4.1999, 4.1938, 4.1273, 4.0972, 4.0433, 3.9434, 3.8937, 3.8944,\n",
      "        3.8257], grad_fn=<AddBackward0>)\n",
      "190480.15582370758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([2.7094, 2.7106, 2.7113, 2.7108, 2.7125, 2.7155, 2.7155, 2.7163, 2.7151,\n",
      "        2.7133, 2.7168, 2.7089, 2.7132, 2.7112, 2.7112, 2.7052, 2.7028, 2.6975,\n",
      "        2.6960, 2.6893, 2.6842, 2.6824, 2.6745, 2.6692, 2.6642, 2.6556, 2.6501,\n",
      "        2.6346, 2.6282, 2.6196, 2.6100, 2.5949, 2.5817, 2.5646, 2.5460, 2.5228,\n",
      "        2.4923, 2.4609, 2.4220, 2.3812, 2.3337, 2.2862, 2.2312, 2.1764, 2.1223,\n",
      "        2.0665, 2.0093, 1.9564, 1.9027, 1.8518, 1.8007, 1.7530, 1.7058, 1.6618,\n",
      "        1.6120], grad_fn=<AddBackward0>) tensor([4.8604, 4.8537, 4.8418, 4.8490, 4.8359, 4.8316, 4.8353, 4.8224, 4.8379,\n",
      "        4.8390, 4.8108, 4.8515, 4.8070, 4.8150, 4.8008, 4.8006, 4.8085, 4.8098,\n",
      "        4.7876, 4.8036, 4.7787, 4.7660, 4.7587, 4.7602, 4.7272, 4.7319, 4.7091,\n",
      "        4.7274, 4.6909, 4.6617, 4.6442, 4.6441, 4.6086, 4.5701, 4.5252, 4.5052,\n",
      "        4.4719, 4.3963, 4.3446, 4.2438, 4.1959, 4.1057, 4.0251, 3.9198, 3.8393,\n",
      "        3.7346, 3.6405, 3.5513, 3.4551, 3.3796, 3.3227, 3.1987, 3.1241, 3.0358,\n",
      "        2.9104], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.8152, 1.8112, 1.8178, 1.8113, 1.8113, 1.8067, 1.8083, 1.8073, 1.8033,\n",
      "        1.8023, 1.8036, 1.7978, 1.7928, 1.7930, 1.7864, 1.7889, 1.7812, 1.7753,\n",
      "        1.7648, 1.7584, 1.7528, 1.7415, 1.7268, 1.7187, 1.7064, 1.6916, 1.6769,\n",
      "        1.6610, 1.6440, 1.6268, 1.6130, 1.5922, 1.5786, 1.5558, 1.5391, 1.5190,\n",
      "        1.5051, 1.4872, 1.4700, 1.4504, 1.4333, 1.4148, 1.4001, 1.3799, 1.3596,\n",
      "        1.3413, 1.3242, 1.3030, 1.2837, 1.2629, 1.2441, 1.2236, 1.2026, 1.1824,\n",
      "        1.1586], grad_fn=<AddBackward0>) tensor([5.3479, 5.3782, 5.3061, 5.3658, 5.3384, 5.3862, 5.3644, 5.3439, 5.3711,\n",
      "        5.3731, 5.3154, 5.3298, 5.3704, 5.3345, 5.3513, 5.2598, 5.2691, 5.2531,\n",
      "        5.2630, 5.2450, 5.1789, 5.1640, 5.1791, 5.1429, 5.0789, 5.0486, 5.0125,\n",
      "        4.9796, 4.9501, 4.9202, 4.8143, 4.8161, 4.7342, 4.7500, 4.6707, 4.6506,\n",
      "        4.6060, 4.5271, 4.4543, 4.4415, 4.3787, 4.3398, 4.2509, 4.2319, 4.2209,\n",
      "        4.1712, 4.0577, 4.0424, 3.9702, 3.9382, 3.8780, 3.7751, 3.7382, 3.7349,\n",
      "        3.6739], grad_fn=<AddBackward0>)\n",
      "180252.28471779823\n",
      "r0 before lock-down  tensor([2.7073, 2.7084, 2.7093, 2.7089, 2.7105, 2.7133, 2.7134, 2.7139, 2.7128,\n",
      "        2.7109, 2.7143, 2.7061, 2.7100, 2.7072, 2.7066, 2.6999, 2.6963, 2.6899,\n",
      "        2.6871, 2.6792, 2.6727, 2.6693, 2.6597, 2.6522, 2.6454, 2.6349, 2.6273,\n",
      "        2.6096, 2.6010, 2.5904, 2.5787, 2.5621, 2.5470, 2.5278, 2.5072, 2.4822,\n",
      "        2.4500, 2.4174, 2.3763, 2.3339, 2.2854, 2.2360, 2.1797, 2.1231, 2.0676,\n",
      "        2.0100, 1.9515, 1.8971, 1.8419, 1.7892, 1.7369, 1.6876, 1.6385, 1.5933,\n",
      "        1.5418], grad_fn=<AddBackward0>) tensor([4.8556, 4.8501, 4.8364, 4.8429, 4.8297, 4.8266, 4.8287, 4.8182, 4.8317,\n",
      "        4.8332, 4.8032, 4.8442, 4.7989, 4.8068, 4.7913, 4.7885, 4.7958, 4.7961,\n",
      "        4.7728, 4.7850, 4.7568, 4.7421, 4.7319, 4.7324, 4.6954, 4.6950, 4.6686,\n",
      "        4.6848, 4.6448, 4.6118, 4.5909, 4.5852, 4.5462, 4.5063, 4.4594, 4.4372,\n",
      "        4.4009, 4.3184, 4.2687, 4.1651, 4.1098, 4.0195, 3.9344, 3.8289, 3.7432,\n",
      "        3.6377, 3.5402, 3.4469, 3.3470, 3.2712, 3.2044, 3.0794, 3.0112, 2.9156,\n",
      "        2.7852], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.8454, 1.8420, 1.8474, 1.8414, 1.8416, 1.8378, 1.8387, 1.8367, 1.8315,\n",
      "        1.8321, 1.8318, 1.8261, 1.8186, 1.8202, 1.8120, 1.8131, 1.8060, 1.7985,\n",
      "        1.7860, 1.7770, 1.7703, 1.7570, 1.7397, 1.7302, 1.7142, 1.6974, 1.6794,\n",
      "        1.6592, 1.6408, 1.6203, 1.6035, 1.5799, 1.5619, 1.5375, 1.5174, 1.4952,\n",
      "        1.4792, 1.4582, 1.4391, 1.4173, 1.3992, 1.3791, 1.3629, 1.3410, 1.3199,\n",
      "        1.3000, 1.2826, 1.2601, 1.2401, 1.2182, 1.1989, 1.1771, 1.1556, 1.1348,\n",
      "        1.1102], grad_fn=<AddBackward0>) tensor([5.4127, 5.4334, 5.3748, 5.4251, 5.3905, 5.4327, 5.4135, 5.4005, 5.4374,\n",
      "        5.4164, 5.3688, 5.3794, 5.4383, 5.3789, 5.4002, 5.3142, 5.3012, 5.2861,\n",
      "        5.2958, 5.2871, 5.2106, 5.1912, 5.2045, 5.1487, 5.0910, 5.0448, 5.0072,\n",
      "        4.9825, 4.9239, 4.8892, 4.7722, 4.7643, 4.6924, 4.6832, 4.6081, 4.5745,\n",
      "        4.5197, 4.4462, 4.3665, 4.3554, 4.2744, 4.2322, 4.1395, 4.1269, 4.1070,\n",
      "        4.0620, 3.9230, 3.9154, 3.8310, 3.8056, 3.7320, 3.6423, 3.6004, 3.5978,\n",
      "        3.5451], grad_fn=<AddBackward0>)\n",
      "216608.19449281693\n",
      "r0 before lock-down  tensor([2.7086, 2.7095, 2.7104, 2.7101, 2.7117, 2.7144, 2.7146, 2.7150, 2.7137,\n",
      "        2.7116, 2.7147, 2.7063, 2.7097, 2.7063, 2.7048, 2.6974, 2.6927, 2.6851,\n",
      "        2.6809, 2.6718, 2.6634, 2.6582, 2.6470, 2.6373, 2.6285, 2.6159, 2.6061,\n",
      "        2.5860, 2.5751, 2.5625, 2.5485, 2.5299, 2.5130, 2.4919, 2.4694, 2.4426,\n",
      "        2.4085, 2.3749, 2.3321, 2.2875, 2.2380, 2.1873, 2.1297, 2.0719, 2.0150,\n",
      "        1.9559, 1.8965, 1.8411, 1.7844, 1.7307, 1.6776, 1.6268, 1.5769, 1.5310,\n",
      "        1.4783], grad_fn=<AddBackward0>) tensor([4.8559, 4.8514, 4.8375, 4.8423, 4.8303, 4.8276, 4.8287, 4.8177, 4.8318,\n",
      "        4.8334, 4.8035, 4.8438, 4.7972, 4.8040, 4.7874, 4.7822, 4.7886, 4.7877,\n",
      "        4.7616, 4.7696, 4.7421, 4.7238, 4.7082, 4.7074, 4.6662, 4.6611, 4.6311,\n",
      "        4.6441, 4.6007, 4.5627, 4.5391, 4.5295, 4.4864, 4.4428, 4.3936, 4.3696,\n",
      "        4.3327, 4.2397, 4.1910, 4.0901, 4.0288, 3.9333, 3.8472, 3.7378, 3.6500,\n",
      "        3.5460, 3.4446, 3.3462, 3.2489, 3.1685, 3.0939, 2.9746, 2.9058, 2.8037,\n",
      "        2.6776], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.8977, 1.8953, 1.8983, 1.8931, 1.8922, 1.8892, 1.8878, 1.8874, 1.8804,\n",
      "        1.8823, 1.8802, 1.8743, 1.8656, 1.8680, 1.8585, 1.8594, 1.8487, 1.8405,\n",
      "        1.8246, 1.8168, 1.8065, 1.7903, 1.7715, 1.7579, 1.7403, 1.7190, 1.6973,\n",
      "        1.6733, 1.6525, 1.6268, 1.6066, 1.5802, 1.5578, 1.5299, 1.5072, 1.4818,\n",
      "        1.4628, 1.4398, 1.4177, 1.3933, 1.3739, 1.3520, 1.3342, 1.3104, 1.2890,\n",
      "        1.2677, 1.2491, 1.2262, 1.2052, 1.1824, 1.1623, 1.1404, 1.1180, 1.0968,\n",
      "        1.0712], grad_fn=<AddBackward0>) tensor([5.5246, 5.5372, 5.4989, 5.5385, 5.5127, 5.5430, 5.5449, 5.5119, 5.5636,\n",
      "        5.5205, 5.4872, 5.4952, 5.5533, 5.4790, 5.5020, 5.4035, 5.4112, 5.3852,\n",
      "        5.4084, 5.3569, 5.2907, 5.2717, 5.2682, 5.2150, 5.1343, 5.0920, 5.0456,\n",
      "        5.0115, 4.9291, 4.9032, 4.7701, 4.7443, 4.6745, 4.6574, 4.5622, 4.5252,\n",
      "        4.4649, 4.3750, 4.3016, 4.2919, 4.1955, 4.1507, 4.0551, 4.0479, 4.0080,\n",
      "        3.9688, 3.8299, 3.8111, 3.7299, 3.7128, 3.6384, 3.5311, 3.4941, 3.4803,\n",
      "        3.4478], grad_fn=<AddBackward0>)\n",
      "175207.12069106102\n",
      "r0 before lock-down  tensor([2.7166, 2.7177, 2.7186, 2.7183, 2.7198, 2.7225, 2.7227, 2.7229, 2.7215,\n",
      "        2.7193, 2.7221, 2.7132, 2.7163, 2.7122, 2.7098, 2.7014, 2.6956, 2.6865,\n",
      "        2.6811, 2.6702, 2.6600, 2.6529, 2.6396, 2.6276, 2.6166, 2.6016, 2.5894,\n",
      "        2.5670, 2.5534, 2.5384, 2.5221, 2.5015, 2.4826, 2.4595, 2.4351, 2.4063,\n",
      "        2.3703, 2.3356, 2.2914, 2.2452, 2.1943, 2.1427, 2.0839, 2.0248, 1.9672,\n",
      "        1.9070, 1.8469, 1.7906, 1.7330, 1.6785, 1.6249, 1.5733, 1.5232, 1.4765,\n",
      "        1.4231], grad_fn=<AddBackward0>) tensor([4.8695, 4.8635, 4.8498, 4.8549, 4.8429, 4.8393, 4.8405, 4.8297, 4.8435,\n",
      "        4.8445, 4.8150, 4.8552, 4.8068, 4.8125, 4.7953, 4.7876, 4.7918, 4.7894,\n",
      "        4.7597, 4.7657, 4.7345, 4.7136, 4.6939, 4.6900, 4.6440, 4.6353, 4.6011,\n",
      "        4.6086, 4.5635, 4.5205, 4.4939, 4.4791, 4.4313, 4.3859, 4.3333, 4.3082,\n",
      "        4.2709, 4.1714, 4.1193, 4.0185, 3.9554, 3.8545, 3.7670, 3.6589, 3.5654,\n",
      "        3.4622, 3.3576, 3.2575, 3.1612, 3.0801, 3.0005, 2.8829, 2.8073, 2.7089,\n",
      "        2.5849], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.9189, 1.9173, 1.9199, 1.9138, 1.9119, 1.9103, 1.9084, 1.9077, 1.8986,\n",
      "        1.9011, 1.8983, 1.8923, 1.8838, 1.8839, 1.8744, 1.8764, 1.8633, 1.8528,\n",
      "        1.8360, 1.8249, 1.8129, 1.7952, 1.7739, 1.7590, 1.7386, 1.7126, 1.6902,\n",
      "        1.6624, 1.6392, 1.6104, 1.5879, 1.5581, 1.5325, 1.5031, 1.4783, 1.4490,\n",
      "        1.4299, 1.4053, 1.3810, 1.3569, 1.3360, 1.3123, 1.2938, 1.2705, 1.2482,\n",
      "        1.2262, 1.2074, 1.1839, 1.1634, 1.1399, 1.1200, 1.0977, 1.0756, 1.0540,\n",
      "        1.0283], grad_fn=<AddBackward0>) tensor([5.5490, 5.5538, 5.5139, 5.5644, 5.5472, 5.5619, 5.5631, 5.5321, 5.6016,\n",
      "        5.5484, 5.5150, 5.5205, 5.5627, 5.5093, 5.5203, 5.3996, 5.4160, 5.3975,\n",
      "        5.4133, 5.3761, 5.3003, 5.2733, 5.2655, 5.1908, 5.1079, 5.0801, 5.0007,\n",
      "        4.9690, 4.8728, 4.8410, 4.6920, 4.6704, 4.6027, 4.5684, 4.4668, 4.4511,\n",
      "        4.3615, 4.2702, 4.2064, 4.1666, 4.0736, 4.0432, 3.9470, 3.9198, 3.8860,\n",
      "        3.8485, 3.7059, 3.6973, 3.5936, 3.5948, 3.5149, 3.4145, 3.3675, 3.3607,\n",
      "        3.3240], grad_fn=<AddBackward0>)\n",
      "171536.57069396973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([2.7269, 2.7282, 2.7291, 2.7289, 2.7302, 2.7331, 2.7329, 2.7332, 2.7316,\n",
      "        2.7292, 2.7318, 2.7225, 2.7253, 2.7203, 2.7167, 2.7074, 2.7002, 2.6897,\n",
      "        2.6829, 2.6701, 2.6581, 2.6487, 2.6331, 2.6187, 2.6054, 2.5876, 2.5729,\n",
      "        2.5480, 2.5318, 2.5142, 2.4959, 2.4728, 2.4519, 2.4268, 2.4003, 2.3700,\n",
      "        2.3321, 2.2964, 2.2506, 2.2029, 2.1508, 2.0983, 2.0386, 1.9785, 1.9200,\n",
      "        1.8590, 1.7983, 1.7414, 1.6835, 1.6282, 1.5742, 1.5224, 1.4718, 1.4250,\n",
      "        1.3715], grad_fn=<AddBackward0>) tensor([4.8874, 4.8793, 4.8655, 4.8693, 4.8589, 4.8534, 4.8567, 4.8455, 4.8599,\n",
      "        4.8607, 4.8303, 4.8702, 4.8185, 4.8238, 4.8065, 4.7963, 4.7984, 4.7938,\n",
      "        4.7600, 4.7637, 4.7292, 4.7054, 4.6824, 4.6748, 4.6223, 4.6115, 4.5719,\n",
      "        4.5749, 4.5262, 4.4796, 4.4460, 4.4304, 4.3778, 4.3285, 4.2752, 4.2442,\n",
      "        4.2076, 4.1004, 4.0493, 3.9460, 3.8827, 3.7759, 3.6844, 3.5773, 3.4803,\n",
      "        3.3784, 3.2714, 3.1703, 3.0709, 2.9909, 2.9108, 2.7905, 2.7193, 2.6225,\n",
      "        2.4978], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.9486, 1.9456, 1.9475, 1.9408, 1.9400, 1.9378, 1.9363, 1.9350, 1.9247,\n",
      "        1.9292, 1.9243, 1.9191, 1.9086, 1.9086, 1.8989, 1.8987, 1.8853, 1.8753,\n",
      "        1.8552, 1.8414, 1.8273, 1.8078, 1.7826, 1.7672, 1.7424, 1.7143, 1.6878,\n",
      "        1.6572, 1.6310, 1.5995, 1.5742, 1.5411, 1.5125, 1.4797, 1.4542, 1.4220,\n",
      "        1.4020, 1.3750, 1.3494, 1.3246, 1.3019, 1.2777, 1.2582, 1.2341, 1.2114,\n",
      "        1.1891, 1.1701, 1.1461, 1.1257, 1.1020, 1.0820, 1.0597, 1.0375, 1.0161,\n",
      "        0.9904], grad_fn=<AddBackward0>) tensor([5.5920, 5.6076, 5.5766, 5.6316, 5.6008, 5.6157, 5.6105, 5.5823, 5.6602,\n",
      "        5.5779, 5.5631, 5.5560, 5.6093, 5.5505, 5.5461, 5.4421, 5.4431, 5.4021,\n",
      "        5.4270, 5.3968, 5.3164, 5.2795, 5.2813, 5.1780, 5.1063, 5.0641, 4.9862,\n",
      "        4.9443, 4.8439, 4.7938, 4.6384, 4.6134, 4.5435, 4.5168, 4.3859, 4.3803,\n",
      "        4.2657, 4.1831, 4.1095, 4.0570, 3.9728, 3.9347, 3.8408, 3.8147, 3.7804,\n",
      "        3.7364, 3.5924, 3.5871, 3.4781, 3.4821, 3.4001, 3.3041, 3.2638, 3.2505,\n",
      "        3.2251], grad_fn=<AddBackward0>)\n",
      "171678.90077280998\n",
      "r0 before lock-down  tensor([2.7474, 2.7487, 2.7497, 2.7494, 2.7507, 2.7538, 2.7530, 2.7535, 2.7516,\n",
      "        2.7491, 2.7516, 2.7417, 2.7439, 2.7376, 2.7333, 2.7229, 2.7141, 2.7020,\n",
      "        2.6932, 2.6785, 2.6642, 2.6523, 2.6342, 2.6171, 2.6012, 2.5803, 2.5629,\n",
      "        2.5350, 2.5158, 2.4958, 2.4748, 2.4493, 2.4262, 2.3991, 2.3704, 2.3382,\n",
      "        2.2989, 2.2614, 2.2144, 2.1654, 2.1121, 2.0586, 1.9982, 1.9369, 1.8779,\n",
      "        1.8164, 1.7553, 1.6977, 1.6396, 1.5837, 1.5297, 1.4776, 1.4268, 1.3800,\n",
      "        1.3263], grad_fn=<AddBackward0>) tensor([4.9201, 4.9119, 4.8975, 4.9024, 4.8917, 4.8836, 4.8908, 4.8769, 4.8921,\n",
      "        4.8918, 4.8606, 4.9011, 4.8481, 4.8543, 4.8326, 4.8190, 4.8200, 4.8119,\n",
      "        4.7766, 4.7761, 4.7383, 4.7105, 4.6838, 4.6716, 4.6129, 4.5995, 4.5530,\n",
      "        4.5514, 4.4994, 4.4459, 4.4090, 4.3901, 4.3336, 4.2787, 4.2233, 4.1909,\n",
      "        4.1494, 4.0411, 3.9862, 3.8798, 3.8154, 3.7055, 3.6114, 3.5066, 3.4066,\n",
      "        3.3014, 3.1950, 3.0954, 2.9928, 2.9152, 2.8296, 2.7095, 2.6409, 2.5442,\n",
      "        2.4210], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.9956, 1.9928, 1.9941, 1.9848, 1.9871, 1.9840, 1.9823, 1.9803, 1.9709,\n",
      "        1.9741, 1.9663, 1.9624, 1.9497, 1.9517, 1.9378, 1.9390, 1.9231, 1.9100,\n",
      "        1.8907, 1.8744, 1.8559, 1.8353, 1.8072, 1.7897, 1.7595, 1.7276, 1.6986,\n",
      "        1.6644, 1.6345, 1.5989, 1.5701, 1.5337, 1.5020, 1.4670, 1.4380, 1.4034,\n",
      "        1.3816, 1.3523, 1.3254, 1.2989, 1.2749, 1.2501, 1.2296, 1.2042, 1.1810,\n",
      "        1.1589, 1.1392, 1.1149, 1.0945, 1.0705, 1.0504, 1.0281, 1.0057, 0.9843,\n",
      "        0.9584], grad_fn=<AddBackward0>) tensor([5.6809, 5.6956, 5.6643, 5.7445, 5.6802, 5.7040, 5.6926, 5.6698, 5.7340,\n",
      "        5.6571, 5.6682, 5.6392, 5.7039, 5.6169, 5.6415, 5.5081, 5.5173, 5.4896,\n",
      "        5.4778, 5.4486, 5.3805, 5.3242, 5.3222, 5.1975, 5.1409, 5.0932, 4.9926,\n",
      "        4.9430, 4.8332, 4.7828, 4.6169, 4.5812, 4.5046, 4.4602, 4.3282, 4.3197,\n",
      "        4.1912, 4.1091, 4.0267, 3.9777, 3.8901, 3.8440, 3.7505, 3.7375, 3.7032,\n",
      "        3.6421, 3.5026, 3.4984, 3.3823, 3.3960, 3.3084, 3.2108, 3.1736, 3.1540,\n",
      "        3.1434], grad_fn=<AddBackward0>)\n",
      "167119.56255626678\n",
      "r0 before lock-down  tensor([2.7701, 2.7714, 2.7724, 2.7721, 2.7734, 2.7765, 2.7756, 2.7760, 2.7742,\n",
      "        2.7712, 2.7734, 2.7631, 2.7645, 2.7570, 2.7518, 2.7401, 2.7296, 2.7156,\n",
      "        2.7049, 2.6879, 2.6712, 2.6569, 2.6362, 2.6160, 2.5972, 2.5733, 2.5529,\n",
      "        2.5221, 2.4998, 2.4770, 2.4530, 2.4254, 2.4000, 2.3706, 2.3397, 2.3061,\n",
      "        2.2653, 2.2262, 2.1778, 2.1278, 2.0733, 2.0189, 1.9580, 1.8961, 1.8365,\n",
      "        1.7747, 1.7134, 1.6554, 1.5974, 1.5414, 1.4875, 1.4353, 1.3849, 1.3381,\n",
      "        1.2846], grad_fn=<AddBackward0>) tensor([4.9568, 4.9494, 4.9343, 4.9388, 4.9286, 4.9194, 4.9265, 4.9135, 4.9265,\n",
      "        4.9273, 4.8950, 4.9340, 4.8808, 4.8870, 4.8617, 4.8448, 4.8446, 4.8339,\n",
      "        4.7947, 4.7904, 4.7494, 4.7167, 4.6842, 4.6694, 4.6044, 4.5866, 4.5334,\n",
      "        4.5269, 4.4708, 4.4129, 4.3737, 4.3472, 4.2868, 4.2302, 4.1723, 4.1332,\n",
      "        4.0892, 3.9799, 3.9227, 3.8133, 3.7494, 3.6368, 3.5396, 3.4346, 3.3340,\n",
      "        3.2281, 3.1212, 3.0240, 2.9194, 2.8434, 2.7554, 2.6376, 2.5663, 2.4707,\n",
      "        2.3492], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([1.9980, 1.9955, 1.9963, 1.9860, 1.9892, 1.9841, 1.9831, 1.9817, 1.9727,\n",
      "        1.9749, 1.9660, 1.9627, 1.9489, 1.9525, 1.9343, 1.9359, 1.9205, 1.9050,\n",
      "        1.8853, 1.8677, 1.8465, 1.8250, 1.7929, 1.7747, 1.7415, 1.7084, 1.6767,\n",
      "        1.6414, 1.6079, 1.5723, 1.5402, 1.5017, 1.4691, 1.4319, 1.4020, 1.3673,\n",
      "        1.3453, 1.3145, 1.2873, 1.2603, 1.2369, 1.2120, 1.1918, 1.1665, 1.1435,\n",
      "        1.1218, 1.1026, 1.0785, 1.0583, 1.0346, 1.0150, 0.9929, 0.9707, 0.9497,\n",
      "        0.9240], grad_fn=<AddBackward0>) tensor([5.6560, 5.6667, 5.6376, 5.7286, 5.6499, 5.6954, 5.6739, 5.6442, 5.6967,\n",
      "        5.6262, 5.6472, 5.6042, 5.6766, 5.5675, 5.6252, 5.4781, 5.4700, 5.4506,\n",
      "        5.4273, 5.3944, 5.3322, 5.2639, 5.2796, 5.1338, 5.0808, 5.0168, 4.9166,\n",
      "        4.8490, 4.7499, 4.6730, 4.5198, 4.4830, 4.3982, 4.3660, 4.2296, 4.2069,\n",
      "        4.0696, 4.0017, 3.9242, 3.8783, 3.7754, 3.7314, 3.6408, 3.6307, 3.5961,\n",
      "        3.5305, 3.3856, 3.3868, 3.2752, 3.2880, 3.1977, 3.1001, 3.0742, 3.0454,\n",
      "        3.0561], grad_fn=<AddBackward0>)\n",
      "211928.37609386444\n",
      "r0 before lock-down  tensor([2.7915, 2.7928, 2.7936, 2.7932, 2.7946, 2.7978, 2.7968, 2.7969, 2.7950,\n",
      "        2.7916, 2.7936, 2.7830, 2.7836, 2.7747, 2.7685, 2.7555, 2.7430, 2.7272,\n",
      "        2.7143, 2.6951, 2.6760, 2.6588, 2.6355, 2.6120, 2.5903, 2.5632, 2.5398,\n",
      "        2.5059, 2.4806, 2.4549, 2.4285, 2.3982, 2.3708, 2.3393, 2.3064, 2.2710,\n",
      "        2.2293, 2.1884, 2.1387, 2.0880, 2.0327, 1.9775, 1.9163, 1.8541, 1.7941,\n",
      "        1.7321, 1.6706, 1.6130, 1.5550, 1.4991, 1.4457, 1.3936, 1.3434, 1.2972,\n",
      "        1.2440], grad_fn=<AddBackward0>) tensor([4.9898, 4.9822, 4.9684, 4.9734, 4.9617, 4.9515, 4.9592, 4.9465, 4.9594,\n",
      "        4.9607, 4.9279, 4.9641, 4.9102, 4.9168, 4.8870, 4.8680, 4.8660, 4.8508,\n",
      "        4.8093, 4.8002, 4.7541, 4.7182, 4.6794, 4.6616, 4.5910, 4.5680, 4.5093,\n",
      "        4.4979, 4.4365, 4.3746, 4.3301, 4.3007, 4.2353, 4.1752, 4.1150, 4.0746,\n",
      "        4.0228, 3.9167, 3.8579, 3.7442, 3.6784, 3.5670, 3.4654, 3.3582, 3.2583,\n",
      "        3.1535, 3.0491, 2.9487, 2.8455, 2.7710, 2.6765, 2.5653, 2.4973, 2.3958,\n",
      "        2.2809], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.0296, 2.0272, 2.0273, 2.0152, 2.0204, 2.0141, 2.0136, 2.0116, 2.0021,\n",
      "        2.0036, 1.9954, 1.9921, 1.9757, 1.9802, 1.9601, 1.9612, 1.9435, 1.9289,\n",
      "        1.9056, 1.8866, 1.8627, 1.8408, 1.8050, 1.7832, 1.7479, 1.7130, 1.6769,\n",
      "        1.6391, 1.6005, 1.5637, 1.5282, 1.4866, 1.4528, 1.4135, 1.3814, 1.3455,\n",
      "        1.3211, 1.2898, 1.2612, 1.2341, 1.2094, 1.1843, 1.1639, 1.1385, 1.1154,\n",
      "        1.0935, 1.0746, 1.0503, 1.0303, 1.0070, 0.9874, 0.9656, 0.9436, 0.9227,\n",
      "        0.8969], grad_fn=<AddBackward0>) tensor([5.7066, 5.7164, 5.6927, 5.8000, 5.6990, 5.7559, 5.7230, 5.7011, 5.7522,\n",
      "        5.6830, 5.6913, 5.6392, 5.7349, 5.6090, 5.6708, 5.5137, 5.5143, 5.4677,\n",
      "        5.4628, 5.4167, 5.3568, 5.2594, 5.2838, 5.1415, 5.0746, 4.9891, 4.8982,\n",
      "        4.8159, 4.7386, 4.6356, 4.4844, 4.4493, 4.3389, 4.3017, 4.1621, 4.1301,\n",
      "        4.0028, 3.9218, 3.8520, 3.7921, 3.7003, 3.6521, 3.5590, 3.5471, 3.5145,\n",
      "        3.4555, 3.3048, 3.3130, 3.1999, 3.2116, 3.1250, 3.0240, 2.9914, 2.9623,\n",
      "        2.9963], grad_fn=<AddBackward0>)\n",
      "160373.42479228973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([2.8260, 2.8276, 2.8288, 2.8280, 2.8296, 2.8322, 2.8316, 2.8312, 2.8291,\n",
      "        2.8253, 2.8271, 2.8164, 2.8157, 2.8057, 2.7978, 2.7833, 2.7683, 2.7507,\n",
      "        2.7352, 2.7132, 2.6916, 2.6712, 2.6446, 2.6175, 2.5923, 2.5613, 2.5346,\n",
      "        2.4973, 2.4686, 2.4397, 2.4105, 2.3775, 2.3475, 2.3139, 2.2788, 2.2415,\n",
      "        2.1983, 2.1560, 2.1050, 2.0534, 1.9971, 1.9410, 1.8796, 1.8168, 1.7564,\n",
      "        1.6944, 1.6329, 1.5753, 1.5174, 1.4617, 1.4085, 1.3565, 1.3066, 1.2609,\n",
      "        1.2079], grad_fn=<AddBackward0>) tensor([5.0474, 5.0370, 5.0212, 5.0275, 5.0148, 5.0089, 5.0132, 5.0018, 5.0157,\n",
      "        5.0164, 4.9815, 5.0132, 4.9615, 4.9651, 4.9346, 4.9113, 4.9100, 4.8884,\n",
      "        4.8442, 4.8306, 4.7774, 4.7362, 4.6917, 4.6699, 4.5919, 4.5659, 4.4987,\n",
      "        4.4807, 4.4149, 4.3478, 4.2972, 4.2637, 4.1952, 4.1286, 4.0665, 4.0239,\n",
      "        3.9686, 3.8583, 3.7992, 3.6816, 3.6160, 3.5060, 3.3991, 3.2941, 3.1937,\n",
      "        3.0882, 2.9827, 2.8820, 2.7790, 2.7025, 2.6076, 2.4998, 2.4331, 2.3273,\n",
      "        2.2183], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.0693, 2.0639, 2.0633, 2.0503, 2.0590, 2.0499, 2.0509, 2.0487, 2.0395,\n",
      "        2.0384, 2.0296, 2.0264, 2.0083, 2.0102, 1.9931, 1.9931, 1.9712, 1.9569,\n",
      "        1.9329, 1.9098, 1.8844, 1.8620, 1.8217, 1.7961, 1.7585, 1.7194, 1.6814,\n",
      "        1.6395, 1.5977, 1.5586, 1.5201, 1.4760, 1.4390, 1.3983, 1.3640, 1.3266,\n",
      "        1.3008, 1.2680, 1.2381, 1.2109, 1.1850, 1.1594, 1.1384, 1.1129, 1.0896,\n",
      "        1.0676, 1.0485, 1.0243, 1.0043, 0.9811, 0.9615, 0.9399, 0.9182, 0.8972,\n",
      "        0.8716], grad_fn=<AddBackward0>) tensor([5.7509, 5.7892, 5.7702, 5.8823, 5.7460, 5.8267, 5.7742, 5.7569, 5.7974,\n",
      "        5.7505, 5.7572, 5.6999, 5.8001, 5.6947, 5.7123, 5.5567, 5.5846, 5.5141,\n",
      "        5.4963, 5.4674, 5.3927, 5.2718, 5.3062, 5.1699, 5.0870, 5.0082, 4.8930,\n",
      "        4.8209, 4.7301, 4.6115, 4.4566, 4.4134, 4.3065, 4.2536, 4.1117, 4.0728,\n",
      "        3.9394, 3.8613, 3.7904, 3.7127, 3.6290, 3.5787, 3.4878, 3.4718, 3.4396,\n",
      "        3.3757, 3.2295, 3.2367, 3.1219, 3.1349, 3.0548, 2.9514, 2.9142, 2.8902,\n",
      "        2.9462], grad_fn=<AddBackward0>)\n",
      "154881.8662059307\n",
      "r0 before lock-down  tensor([2.8517, 2.8528, 2.8540, 2.8536, 2.8547, 2.8576, 2.8570, 2.8564, 2.8542,\n",
      "        2.8499, 2.8515, 2.8403, 2.8384, 2.8273, 2.8178, 2.8018, 2.7848, 2.7649,\n",
      "        2.7469, 2.7220, 2.6979, 2.6742, 2.6442, 2.6137, 2.5854, 2.5508, 2.5208,\n",
      "        2.4803, 2.4479, 2.4163, 2.3841, 2.3490, 2.3169, 2.2813, 2.2443, 2.2055,\n",
      "        2.1609, 2.1176, 2.0658, 2.0132, 1.9565, 1.8999, 1.8384, 1.7756, 1.7154,\n",
      "        1.6535, 1.5923, 1.5350, 1.4775, 1.4224, 1.3697, 1.3181, 1.2687, 1.2235,\n",
      "        1.1712], grad_fn=<AddBackward0>) tensor([5.0863, 5.0785, 5.0624, 5.0661, 5.0570, 5.0477, 5.0515, 5.0415, 5.0535,\n",
      "        5.0550, 5.0180, 5.0482, 4.9981, 4.9975, 4.9658, 4.9383, 4.9338, 4.9088,\n",
      "        4.8610, 4.8451, 4.7837, 4.7378, 4.6893, 4.6624, 4.5759, 4.5454, 4.4711,\n",
      "        4.4469, 4.3804, 4.3061, 4.2539, 4.2138, 4.1404, 4.0706, 4.0076, 3.9610,\n",
      "        3.9039, 3.7912, 3.7301, 3.6142, 3.5459, 3.4370, 3.3285, 3.2233, 3.1222,\n",
      "        3.0155, 2.9120, 2.8141, 2.7093, 2.6295, 2.5357, 2.4298, 2.3658, 2.2620,\n",
      "        2.1541], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.1119, 2.1065, 2.1037, 2.0881, 2.0987, 2.0906, 2.0915, 2.0910, 2.0775,\n",
      "        2.0778, 2.0676, 2.0649, 2.0458, 2.0456, 2.0276, 2.0259, 2.0049, 1.9881,\n",
      "        1.9625, 1.9380, 1.9067, 1.8845, 1.8405, 1.8114, 1.7711, 1.7278, 1.6870,\n",
      "        1.6437, 1.5956, 1.5554, 1.5133, 1.4659, 1.4266, 1.3846, 1.3478, 1.3092,\n",
      "        1.2816, 1.2477, 1.2171, 1.1888, 1.1623, 1.1361, 1.1148, 1.0895, 1.0658,\n",
      "        1.0437, 1.0247, 1.0006, 0.9807, 0.9573, 0.9380, 0.9165, 0.8951, 0.8741,\n",
      "        0.8489], grad_fn=<AddBackward0>) tensor([5.8053, 5.8426, 5.8442, 5.9754, 5.8240, 5.8855, 5.8329, 5.7978, 5.8734,\n",
      "        5.8073, 5.8191, 5.7531, 5.8457, 5.7632, 5.7765, 5.6224, 5.6250, 5.5598,\n",
      "        5.5348, 5.4934, 5.4523, 5.2950, 5.3319, 5.1934, 5.0983, 5.0269, 4.8954,\n",
      "        4.7931, 4.7326, 4.5836, 4.4289, 4.3858, 4.2721, 4.2039, 4.0651, 4.0127,\n",
      "        3.8823, 3.8003, 3.7243, 3.6502, 3.5641, 3.5164, 3.4223, 3.3989, 3.3729,\n",
      "        3.3068, 3.1554, 3.1603, 3.0471, 3.0700, 2.9870, 2.8841, 2.8429, 2.8289,\n",
      "        2.9014], grad_fn=<AddBackward0>)\n",
      "146733.09737873077\n",
      "r0 before lock-down  tensor([2.8815, 2.8823, 2.8836, 2.8836, 2.8849, 2.8870, 2.8863, 2.8858, 2.8836,\n",
      "        2.8787, 2.8801, 2.8680, 2.8650, 2.8527, 2.8418, 2.8236, 2.8047, 2.7824,\n",
      "        2.7618, 2.7337, 2.7065, 2.6796, 2.6458, 2.6117, 2.5797, 2.5415, 2.5080,\n",
      "        2.4641, 2.4283, 2.3937, 2.3584, 2.3212, 2.2869, 2.2491, 2.2103, 2.1701,\n",
      "        2.1241, 2.0803, 2.0275, 1.9739, 1.9170, 1.8603, 1.7989, 1.7359, 1.6758,\n",
      "        1.6145, 1.5536, 1.4966, 1.4398, 1.3852, 1.3330, 1.2821, 1.2334, 1.1889,\n",
      "        1.1373], grad_fn=<AddBackward0>) tensor([5.1337, 5.1272, 5.1109, 5.1106, 5.1009, 5.0956, 5.0992, 5.0872, 5.0977,\n",
      "        5.1006, 5.0621, 5.0926, 5.0414, 5.0379, 5.0006, 4.9732, 4.9632, 4.9344,\n",
      "        4.8817, 4.8616, 4.7945, 4.7427, 4.6905, 4.6573, 4.5649, 4.5279, 4.4458,\n",
      "        4.4160, 4.3460, 4.2651, 4.2111, 4.1633, 4.0859, 4.0144, 3.9502, 3.9018,\n",
      "        3.8435, 3.7241, 3.6636, 3.5494, 3.4795, 3.3665, 3.2579, 3.1549, 3.0535,\n",
      "        2.9447, 2.8433, 2.7484, 2.6426, 2.5630, 2.4726, 2.3662, 2.3021, 2.1993,\n",
      "        2.0957], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.1204, 2.1144, 2.1124, 2.0978, 2.1088, 2.0992, 2.1018, 2.1011, 2.0833,\n",
      "        2.0849, 2.0741, 2.0709, 2.0532, 2.0523, 2.0361, 2.0294, 2.0065, 1.9906,\n",
      "        1.9638, 1.9379, 1.9034, 1.8804, 1.8321, 1.8037, 1.7619, 1.7139, 1.6707,\n",
      "        1.6257, 1.5745, 1.5331, 1.4896, 1.4403, 1.4001, 1.3565, 1.3186, 1.2797,\n",
      "        1.2514, 1.2164, 1.1872, 1.1581, 1.1314, 1.1054, 1.0844, 1.0599, 1.0368,\n",
      "        1.0148, 0.9958, 0.9725, 0.9529, 0.9303, 0.9112, 0.8903, 0.8693, 0.8485,\n",
      "        0.8238], grad_fn=<AddBackward0>) tensor([5.8120, 5.8528, 5.8474, 5.9653, 5.8066, 5.8836, 5.8135, 5.7786, 5.8896,\n",
      "        5.8071, 5.8240, 5.7537, 5.8285, 5.7476, 5.7329, 5.6182, 5.6281, 5.5390,\n",
      "        5.5036, 5.4587, 5.4290, 5.2540, 5.3130, 5.1385, 5.0310, 4.9812, 4.8457,\n",
      "        4.7276, 4.6816, 4.5130, 4.3484, 4.3042, 4.1790, 4.1186, 3.9803, 3.9215,\n",
      "        3.7928, 3.7249, 3.6195, 3.5594, 3.4776, 3.4331, 3.3352, 3.3023, 3.2723,\n",
      "        3.2162, 3.0816, 3.0807, 2.9719, 2.9910, 2.9102, 2.8018, 2.7647, 2.7587,\n",
      "        2.8387], grad_fn=<AddBackward0>)\n",
      "135446.64167881012\n",
      "r0 before lock-down  tensor([2.9129, 2.9137, 2.9149, 2.9153, 2.9169, 2.9182, 2.9176, 2.9168, 2.9147,\n",
      "        2.9092, 2.9107, 2.8973, 2.8929, 2.8796, 2.8665, 2.8469, 2.8254, 2.8007,\n",
      "        2.7770, 2.7456, 2.7151, 2.6847, 2.6475, 2.6094, 2.5733, 2.5313, 2.4944,\n",
      "        2.4468, 2.4073, 2.3696, 2.3318, 2.2923, 2.2558, 2.2157, 2.1755, 2.1340,\n",
      "        2.0869, 2.0422, 1.9887, 1.9345, 1.8774, 1.8206, 1.7594, 1.6964, 1.6367,\n",
      "        1.5758, 1.5157, 1.4591, 1.4031, 1.3490, 1.2976, 1.2475, 1.1995, 1.1556,\n",
      "        1.1049], grad_fn=<AddBackward0>) tensor([5.1830, 5.1772, 5.1606, 5.1570, 5.1458, 5.1451, 5.1475, 5.1369, 5.1438,\n",
      "        5.1476, 5.1051, 5.1392, 5.0887, 5.0797, 5.0415, 5.0068, 4.9937, 4.9595,\n",
      "        4.9037, 4.8795, 4.8071, 4.7483, 4.6878, 4.6494, 4.5533, 4.5089, 4.4173,\n",
      "        4.3826, 4.3096, 4.2243, 4.1631, 4.1102, 4.0292, 3.9580, 3.8886, 3.8387,\n",
      "        3.7785, 3.6569, 3.5952, 3.4822, 3.4109, 3.2971, 3.1866, 3.0871, 2.9861,\n",
      "        2.8784, 2.7761, 2.6841, 2.5775, 2.5012, 2.4088, 2.3015, 2.2397, 2.1406,\n",
      "        2.0381], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.1380, 2.1326, 2.1304, 2.1145, 2.1254, 2.1169, 2.1203, 2.1174, 2.1011,\n",
      "        2.1004, 2.0903, 2.0874, 2.0659, 2.0661, 2.0498, 2.0413, 2.0178, 2.0014,\n",
      "        1.9715, 1.9442, 1.9074, 1.8821, 1.8327, 1.8015, 1.7583, 1.7058, 1.6614,\n",
      "        1.6132, 1.5606, 1.5173, 1.4703, 1.4202, 1.3777, 1.3336, 1.2946, 1.2545,\n",
      "        1.2260, 1.1899, 1.1608, 1.1317, 1.1044, 1.0785, 1.0577, 1.0336, 1.0106,\n",
      "        0.9887, 0.9700, 0.9472, 0.9281, 0.9058, 0.8871, 0.8667, 0.8459, 0.8257,\n",
      "        0.8012], grad_fn=<AddBackward0>) tensor([5.8281, 5.8600, 5.8578, 5.9828, 5.8284, 5.8900, 5.8097, 5.7979, 5.8883,\n",
      "        5.8226, 5.8304, 5.7511, 5.8497, 5.7593, 5.7313, 5.6223, 5.6257, 5.5302,\n",
      "        5.5052, 5.4560, 5.4230, 5.2518, 5.2869, 5.1174, 4.9942, 4.9592, 4.8042,\n",
      "        4.6898, 4.6345, 4.4515, 4.3043, 4.2431, 4.1280, 4.0498, 3.9076, 3.8522,\n",
      "        3.7120, 3.6523, 3.5369, 3.4727, 3.3972, 3.3533, 3.2528, 3.2162, 3.1899,\n",
      "        3.1416, 3.0102, 3.0062, 2.8959, 2.9218, 2.8436, 2.7353, 2.7030, 2.6858,\n",
      "        2.7898], grad_fn=<AddBackward0>)\n",
      "122903.57218074799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([2.9508, 2.9512, 2.9525, 2.9532, 2.9549, 2.9558, 2.9552, 2.9548, 2.9523,\n",
      "        2.9456, 2.9471, 2.9327, 2.9274, 2.9119, 2.8974, 2.8756, 2.8515, 2.8234,\n",
      "        2.7965, 2.7616, 2.7275, 2.6934, 2.6519, 2.6103, 2.5696, 2.5232, 2.4826,\n",
      "        2.4308, 2.3882, 2.3470, 2.3064, 2.2645, 2.2258, 2.1838, 2.1419, 2.0992,\n",
      "        2.0508, 2.0053, 1.9512, 1.8967, 1.8394, 1.7823, 1.7216, 1.6586, 1.5994,\n",
      "        1.5390, 1.4794, 1.4235, 1.3683, 1.3150, 1.2643, 1.2148, 1.1678, 1.1246,\n",
      "        1.0748], grad_fn=<AddBackward0>) tensor([5.2409, 5.2381, 5.2210, 5.2143, 5.2022, 5.2034, 5.2049, 5.1910, 5.1980,\n",
      "        5.2065, 5.1606, 5.1951, 5.1412, 5.1319, 5.0859, 5.0492, 5.0318, 4.9952,\n",
      "        4.9347, 4.9048, 4.8263, 4.7592, 4.6934, 4.6432, 4.5429, 4.4953, 4.3939,\n",
      "        4.3564, 4.2746, 4.1858, 4.1195, 4.0613, 3.9770, 3.9013, 3.8297, 3.7761,\n",
      "        3.7160, 3.5918, 3.5287, 3.4144, 3.3427, 3.2312, 3.1170, 3.0224, 2.9194,\n",
      "        2.8137, 2.7125, 2.6232, 2.5159, 2.4395, 2.3483, 2.2478, 2.1816, 2.0849,\n",
      "        1.9836], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.1595, 2.1515, 2.1496, 2.1382, 2.1424, 2.1358, 2.1371, 2.1369, 2.1199,\n",
      "        2.1200, 2.1094, 2.1034, 2.0810, 2.0829, 2.0636, 2.0561, 2.0303, 2.0123,\n",
      "        1.9831, 1.9521, 1.9138, 1.8871, 1.8321, 1.8012, 1.7540, 1.6994, 1.6525,\n",
      "        1.6024, 1.5480, 1.5018, 1.4541, 1.4018, 1.3574, 1.3120, 1.2721, 1.2310,\n",
      "        1.2023, 1.1656, 1.1361, 1.1069, 1.0794, 1.0538, 1.0330, 1.0094, 0.9867,\n",
      "        0.9650, 0.9466, 0.9243, 0.9054, 0.8838, 0.8652, 0.8451, 0.8246, 0.8047,\n",
      "        0.7807], grad_fn=<AddBackward0>) tensor([5.8279, 5.8862, 5.8737, 5.9530, 5.8659, 5.9064, 5.8438, 5.8060, 5.8969,\n",
      "        5.8181, 5.8267, 5.7733, 5.8732, 5.7553, 5.7500, 5.6189, 5.6328, 5.5371,\n",
      "        5.4880, 5.4546, 5.4115, 5.2270, 5.2967, 5.0947, 4.9775, 4.9368, 4.7737,\n",
      "        4.6494, 4.5798, 4.4050, 4.2348, 4.1738, 4.0605, 3.9791, 3.8325, 3.7774,\n",
      "        3.6267, 3.5699, 3.4603, 3.3984, 3.3268, 3.2805, 3.1858, 3.1433, 3.1197,\n",
      "        3.0750, 2.9453, 2.9380, 2.8313, 2.8462, 2.7732, 2.6676, 2.6380, 2.6250,\n",
      "        2.7496], grad_fn=<AddBackward0>)\n",
      "112877.62625813484\n",
      "r0 before lock-down  tensor([2.9905, 2.9905, 2.9923, 2.9933, 2.9949, 2.9953, 2.9946, 2.9939, 2.9919,\n",
      "        2.9842, 2.9853, 2.9700, 2.9639, 2.9455, 2.9296, 2.9053, 2.8781, 2.8468,\n",
      "        2.8167, 2.7782, 2.7401, 2.7019, 2.6560, 2.6100, 2.5649, 2.5143, 2.4699,\n",
      "        2.4141, 2.3677, 2.3236, 2.2802, 2.2356, 2.1949, 2.1509, 2.1076, 2.0637,\n",
      "        2.0142, 1.9681, 1.9134, 1.8587, 1.8014, 1.7443, 1.6839, 1.6214, 1.5625,\n",
      "        1.5028, 1.4440, 1.3888, 1.3345, 1.2819, 1.2320, 1.1833, 1.1373, 1.0948,\n",
      "        1.0459], grad_fn=<AddBackward0>) tensor([5.3028, 5.3024, 5.2816, 5.2726, 5.2610, 5.2650, 5.2665, 5.2528, 5.2551,\n",
      "        5.2666, 5.2197, 5.2535, 5.1928, 5.1897, 5.1350, 5.0944, 5.0752, 5.0334,\n",
      "        4.9649, 4.9282, 4.8431, 4.7686, 4.6969, 4.6392, 4.5332, 4.4773, 4.3680,\n",
      "        4.3247, 4.2387, 4.1426, 4.0711, 4.0103, 3.9208, 3.8443, 3.7702, 3.7134,\n",
      "        3.6537, 3.5276, 3.4652, 3.3478, 3.2748, 3.1642, 3.0498, 2.9560, 2.8546,\n",
      "        2.7501, 2.6494, 2.5594, 2.4528, 2.3793, 2.2925, 2.1940, 2.1249, 2.0333,\n",
      "        1.9348], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.1836, 2.1717, 2.1726, 2.1642, 2.1647, 2.1564, 2.1577, 2.1586, 2.1403,\n",
      "        2.1400, 2.1310, 2.1230, 2.1013, 2.1019, 2.0796, 2.0705, 2.0474, 2.0251,\n",
      "        1.9964, 1.9640, 1.9222, 1.8943, 1.8352, 1.8024, 1.7536, 1.6975, 1.6466,\n",
      "        1.5951, 1.5381, 1.4897, 1.4406, 1.3858, 1.3407, 1.2938, 1.2530, 1.2111,\n",
      "        1.1814, 1.1449, 1.1148, 1.0856, 1.0582, 1.0323, 1.0117, 0.9884, 0.9660,\n",
      "        0.9443, 0.9265, 0.9043, 0.8856, 0.8646, 0.8461, 0.8265, 0.8064, 0.7866,\n",
      "        0.7631], grad_fn=<AddBackward0>) tensor([5.8314, 5.9208, 5.8781, 5.9315, 5.8797, 5.9289, 5.8668, 5.8196, 5.9124,\n",
      "        5.8371, 5.8284, 5.7885, 5.8735, 5.7616, 5.7755, 5.6488, 5.6244, 5.5567,\n",
      "        5.4813, 5.4432, 5.4109, 5.2154, 5.2985, 5.0882, 4.9569, 4.8972, 4.7494,\n",
      "        4.6069, 4.5362, 4.3605, 4.1785, 4.1317, 4.0031, 3.9230, 3.7774, 3.7184,\n",
      "        3.5727, 3.5016, 3.3983, 3.3331, 3.2629, 3.2208, 3.1233, 3.0804, 3.0540,\n",
      "        3.0172, 2.8791, 2.8801, 2.7759, 2.7868, 2.7226, 2.6147, 2.5811, 2.5730,\n",
      "        2.7158], grad_fn=<AddBackward0>)\n",
      "130379.07128572464\n",
      "r0 before lock-down  tensor([3.0289, 3.0286, 3.0311, 3.0314, 3.0336, 3.0336, 3.0325, 3.0315, 3.0292,\n",
      "        3.0212, 3.0219, 3.0059, 2.9985, 2.9776, 2.9594, 2.9328, 2.9026, 2.8681,\n",
      "        2.8344, 2.7921, 2.7499, 2.7073, 2.6571, 2.6063, 2.5571, 2.5022, 2.4539,\n",
      "        2.3943, 2.3443, 2.2973, 2.2513, 2.2043, 2.1615, 2.1161, 2.0713, 2.0266,\n",
      "        1.9764, 1.9295, 1.8746, 1.8199, 1.7628, 1.7058, 1.6459, 1.5841, 1.5258,\n",
      "        1.4668, 1.4089, 1.3545, 1.3012, 1.2493, 1.2003, 1.1524, 1.1074, 1.0657,\n",
      "        1.0178], grad_fn=<AddBackward0>) tensor([5.3626, 5.3646, 5.3377, 5.3331, 5.3180, 5.3241, 5.3263, 5.3131, 5.3151,\n",
      "        5.3265, 5.2765, 5.3072, 5.2448, 5.2428, 5.1858, 5.1382, 5.1149, 5.0669,\n",
      "        4.9927, 4.9484, 4.8572, 4.7755, 4.6958, 4.6338, 4.5168, 4.4554, 4.3376,\n",
      "        4.2888, 4.1977, 4.0954, 4.0196, 3.9549, 3.8629, 3.7831, 3.7092, 3.6464,\n",
      "        3.5872, 3.4615, 3.3993, 3.2800, 3.2059, 3.0987, 2.9847, 2.8890, 2.7898,\n",
      "        2.6880, 2.5869, 2.4999, 2.3917, 2.3207, 2.2337, 2.1394, 2.0712, 1.9802,\n",
      "        1.8877], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.2339, 2.2206, 2.2218, 2.2119, 2.2110, 2.2033, 2.2012, 2.2057, 2.1844,\n",
      "        2.1846, 2.1731, 2.1688, 2.1458, 2.1449, 2.1206, 2.1103, 2.0886, 2.0602,\n",
      "        2.0331, 1.9972, 1.9537, 1.9214, 1.8575, 1.8240, 1.7709, 1.7121, 1.6586,\n",
      "        1.6022, 1.5427, 1.4906, 1.4390, 1.3815, 1.3345, 1.2849, 1.2427, 1.1996,\n",
      "        1.1688, 1.1308, 1.1001, 1.0698, 1.0419, 1.0156, 0.9953, 0.9713, 0.9491,\n",
      "        0.9273, 0.9097, 0.8875, 0.8688, 0.8482, 0.8298, 0.8103, 0.7904, 0.7708,\n",
      "        0.7474], grad_fn=<AddBackward0>) tensor([5.8962, 5.9899, 5.9438, 6.0096, 5.9692, 6.0079, 5.9741, 5.8979, 6.0091,\n",
      "        5.9250, 5.9340, 5.8533, 5.9378, 5.8329, 5.8553, 5.7249, 5.6664, 5.6439,\n",
      "        5.5222, 5.4941, 5.4472, 5.2682, 5.3565, 5.1164, 4.9895, 4.9132, 4.7483,\n",
      "        4.6183, 4.5296, 4.3589, 4.1683, 4.1144, 3.9752, 3.9029, 3.7448, 3.6770,\n",
      "        3.5253, 3.4583, 3.3472, 3.2880, 3.2192, 3.1738, 3.0652, 3.0342, 3.0034,\n",
      "        2.9685, 2.8262, 2.8293, 2.7288, 2.7361, 2.6728, 2.5676, 2.5349, 2.5261,\n",
      "        2.6989], grad_fn=<AddBackward0>)\n",
      "103772.2622795105\n",
      "r0 before lock-down  tensor([3.0702, 3.0692, 3.0723, 3.0725, 3.0752, 3.0748, 3.0739, 3.0723, 3.0695,\n",
      "        3.0612, 3.0619, 3.0440, 3.0354, 3.0127, 2.9918, 2.9627, 2.9287, 2.8909,\n",
      "        2.8535, 2.8069, 2.7602, 2.7131, 2.6586, 2.6029, 2.5493, 2.4900, 2.4373,\n",
      "        2.3741, 2.3207, 2.2702, 2.2218, 2.1726, 2.1278, 2.0811, 2.0351, 1.9897,\n",
      "        1.9387, 1.8914, 1.8363, 1.7820, 1.7248, 1.6686, 1.6091, 1.5480, 1.4904,\n",
      "        1.4323, 1.3752, 1.3218, 1.2692, 1.2186, 1.1704, 1.1233, 1.0792, 1.0384,\n",
      "        0.9915], grad_fn=<AddBackward0>) tensor([5.4264, 5.4322, 5.4019, 5.3974, 5.3795, 5.3862, 5.3864, 5.3757, 5.3797,\n",
      "        5.3877, 5.3339, 5.3699, 5.3031, 5.2955, 5.2369, 5.1849, 5.1595, 5.1029,\n",
      "        5.0220, 4.9718, 4.8739, 4.7855, 4.6936, 4.6254, 4.4999, 4.4309, 4.3082,\n",
      "        4.2514, 4.1537, 4.0498, 3.9677, 3.8996, 3.8059, 3.7222, 3.6468, 3.5810,\n",
      "        3.5231, 3.3972, 3.3352, 3.2131, 3.1437, 3.0301, 2.9201, 2.8265, 2.7277,\n",
      "        2.6264, 2.5286, 2.4404, 2.3370, 2.2621, 2.1778, 2.0871, 2.0217, 1.9307,\n",
      "        1.8405], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.2204, 2.2072, 2.2099, 2.1998, 2.1991, 2.1910, 2.1876, 2.1904, 2.1710,\n",
      "        2.1726, 2.1589, 2.1528, 2.1316, 2.1296, 2.1056, 2.0974, 2.0710, 2.0420,\n",
      "        2.0146, 1.9770, 1.9306, 1.9011, 1.8334, 1.7984, 1.7445, 1.6841, 1.6303,\n",
      "        1.5736, 1.5141, 1.4603, 1.4078, 1.3509, 1.3033, 1.2534, 1.2118, 1.1689,\n",
      "        1.1388, 1.1003, 1.0706, 1.0413, 1.0139, 0.9886, 0.9686, 0.9454, 0.9240,\n",
      "        0.9029, 0.8860, 0.8643, 0.8462, 0.8263, 0.8083, 0.7894, 0.7700, 0.7510,\n",
      "        0.7279], grad_fn=<AddBackward0>) tensor([5.8318, 5.9227, 5.8643, 5.9272, 5.8842, 5.9214, 5.9085, 5.8409, 5.9344,\n",
      "        5.8326, 5.8585, 5.7972, 5.8616, 5.7597, 5.7712, 5.6177, 5.5976, 5.5752,\n",
      "        5.4488, 5.4205, 5.3925, 5.1732, 5.2851, 5.0494, 4.9117, 4.8382, 4.6656,\n",
      "        4.5225, 4.4235, 4.2621, 4.0810, 4.0112, 3.8783, 3.8108, 3.6458, 3.5846,\n",
      "        3.4264, 3.3842, 3.2663, 3.1997, 3.1365, 3.0861, 2.9899, 2.9578, 2.9277,\n",
      "        2.8935, 2.7519, 2.7624, 2.6641, 2.6693, 2.6096, 2.5028, 2.4723, 2.4561,\n",
      "        2.6632], grad_fn=<AddBackward0>)\n",
      "107696.0664665699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([3.0958, 3.0949, 3.0981, 3.0979, 3.1015, 3.1007, 3.0993, 3.0976, 3.0945,\n",
      "        3.0856, 3.0863, 3.0674, 3.0571, 3.0327, 3.0095, 2.9775, 2.9407, 2.8992,\n",
      "        2.8581, 2.8078, 2.7570, 2.7056, 2.6464, 2.5868, 2.5285, 2.4656, 2.4096,\n",
      "        2.3433, 2.2868, 2.2338, 2.1840, 2.1326, 2.0867, 2.0390, 1.9922, 1.9466,\n",
      "        1.8954, 1.8481, 1.7933, 1.7394, 1.6830, 1.6275, 1.5687, 1.5087, 1.4522,\n",
      "        1.3951, 1.3392, 1.2870, 1.2355, 1.1861, 1.1388, 1.0929, 1.0499, 1.0101,\n",
      "        0.9645], grad_fn=<AddBackward0>) tensor([5.4666, 5.4712, 5.4399, 5.4388, 5.4141, 5.4216, 5.4248, 5.4133, 5.4172,\n",
      "        5.4256, 5.3682, 5.4024, 5.3357, 5.3238, 5.2601, 5.2056, 5.1732, 5.1141,\n",
      "        5.0267, 4.9693, 4.8643, 4.7691, 4.6725, 4.5955, 4.4677, 4.3896, 4.2588,\n",
      "        4.1945, 4.0959, 3.9878, 3.8968, 3.8322, 3.7339, 3.6485, 3.5737, 3.5042,\n",
      "        3.4465, 3.3223, 3.2592, 3.1395, 3.0678, 2.9575, 2.8505, 2.7585, 2.6589,\n",
      "        2.5587, 2.4658, 2.3765, 2.2755, 2.2014, 2.1210, 2.0330, 1.9686, 1.8818,\n",
      "        1.7928], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.2608, 2.2426, 2.2475, 2.2396, 2.2355, 2.2266, 2.2239, 2.2278, 2.2107,\n",
      "        2.2088, 2.1973, 2.1880, 2.1692, 2.1636, 2.1387, 2.1320, 2.1022, 2.0716,\n",
      "        2.0416, 2.0040, 1.9529, 1.9223, 1.8514, 1.8125, 1.7577, 1.6932, 1.6349,\n",
      "        1.5775, 1.5153, 1.4571, 1.4032, 1.3435, 1.2951, 1.2435, 1.2003, 1.1563,\n",
      "        1.1252, 1.0862, 1.0557, 1.0261, 0.9980, 0.9727, 0.9528, 0.9294, 0.9081,\n",
      "        0.8869, 0.8702, 0.8486, 0.8307, 0.8110, 0.7932, 0.7745, 0.7552, 0.7364,\n",
      "        0.7136], grad_fn=<AddBackward0>) tensor([5.8813, 6.0128, 5.9312, 5.9760, 5.9577, 6.0027, 5.9816, 5.8993, 5.9686,\n",
      "        5.8952, 5.8938, 5.8547, 5.8925, 5.8138, 5.8232, 5.6389, 5.6406, 5.6124,\n",
      "        5.4926, 5.4412, 5.4277, 5.1936, 5.3002, 5.0734, 4.9091, 4.8400, 4.6784,\n",
      "        4.5039, 4.3994, 4.2562, 4.0577, 3.9961, 3.8412, 3.7717, 3.6071, 3.5442,\n",
      "        3.3860, 3.3379, 3.2246, 3.1539, 3.0980, 3.0412, 2.9405, 2.9069, 2.8760,\n",
      "        2.8446, 2.7015, 2.7167, 2.6157, 2.6204, 2.5622, 2.4565, 2.4271, 2.4147,\n",
      "        2.6492], grad_fn=<AddBackward0>)\n",
      "97275.57943153381\n",
      "r0 before lock-down  tensor([3.1354, 3.1345, 3.1371, 3.1373, 3.1406, 3.1393, 3.1392, 3.1362, 3.1327,\n",
      "        3.1231, 3.1242, 3.1040, 3.0915, 3.0653, 3.0392, 3.0039, 2.9639, 2.9181,\n",
      "        2.8733, 2.8181, 2.7629, 2.7067, 2.6427, 2.5781, 2.5153, 2.4480, 2.3879,\n",
      "        2.3177, 2.2582, 2.2024, 2.1505, 2.0972, 2.0501, 2.0011, 1.9535, 1.9076,\n",
      "        1.8560, 1.8088, 1.7543, 1.7006, 1.6447, 1.5899, 1.5320, 1.4731, 1.4173,\n",
      "        1.3613, 1.3067, 1.2555, 1.2050, 1.1566, 1.1103, 1.0655, 1.0234, 0.9845,\n",
      "        0.9399], grad_fn=<AddBackward0>) tensor([5.5267, 5.5295, 5.5023, 5.4984, 5.4756, 5.4868, 5.4791, 5.4739, 5.4789,\n",
      "        5.4872, 5.4216, 5.4554, 5.3913, 5.3702, 5.3050, 5.2466, 5.2070, 5.1444,\n",
      "        5.0469, 4.9849, 4.8702, 4.7659, 4.6615, 4.5782, 4.4422, 4.3567, 4.2193,\n",
      "        4.1513, 4.0463, 3.9351, 3.8375, 3.7705, 3.6682, 3.5822, 3.5065, 3.4338,\n",
      "        3.3786, 3.2533, 3.1889, 3.0714, 3.0016, 2.8934, 2.7862, 2.6944, 2.5999,\n",
      "        2.5012, 2.4058, 2.3187, 2.2193, 2.1477, 2.0691, 1.9822, 1.9194, 1.8348,\n",
      "        1.7507], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.3005, 2.2819, 2.2877, 2.2762, 2.2753, 2.2678, 2.2606, 2.2661, 2.2461,\n",
      "        2.2482, 2.2344, 2.2252, 2.2052, 2.1966, 2.1706, 2.1671, 2.1354, 2.1010,\n",
      "        2.0714, 2.0316, 1.9760, 1.9424, 1.8705, 1.8275, 1.7693, 1.7026, 1.6415,\n",
      "        1.5800, 1.5157, 1.4550, 1.3988, 1.3362, 1.2871, 1.2337, 1.1884, 1.1439,\n",
      "        1.1113, 1.0717, 1.0412, 1.0107, 0.9827, 0.9570, 0.9374, 0.9138, 0.8925,\n",
      "        0.8715, 0.8549, 0.8336, 0.8158, 0.7964, 0.7789, 0.7604, 0.7414, 0.7228,\n",
      "        0.7003], grad_fn=<AddBackward0>) tensor([5.9403, 6.0719, 5.9779, 6.0594, 6.0084, 6.0385, 6.0542, 5.9600, 6.0438,\n",
      "        5.9328, 5.9489, 5.9006, 5.9398, 5.8836, 5.8904, 5.6669, 5.6730, 5.6590,\n",
      "        5.5137, 5.4588, 5.4624, 5.2292, 5.3083, 5.0880, 4.9232, 4.8405, 4.6675,\n",
      "        4.5025, 4.3812, 4.2371, 4.0299, 3.9721, 3.7995, 3.7294, 3.5738, 3.4985,\n",
      "        3.3488, 3.2992, 3.1705, 3.1103, 3.0478, 2.9947, 2.8849, 2.8551, 2.8294,\n",
      "        2.7965, 2.6565, 2.6688, 2.5742, 2.5777, 2.5214, 2.4176, 2.3862, 2.3757,\n",
      "        2.6402], grad_fn=<AddBackward0>)\n",
      "124759.00504422188\n",
      "r0 before lock-down  tensor([3.1843, 3.1828, 3.1855, 3.1856, 3.1888, 3.1869, 3.1875, 3.1841, 3.1807,\n",
      "        3.1703, 3.1695, 3.1490, 3.1351, 3.1061, 3.0767, 3.0377, 2.9937, 2.9441,\n",
      "        2.8947, 2.8345, 2.7736, 2.7122, 2.6427, 2.5731, 2.5052, 2.4331, 2.3687,\n",
      "        2.2946, 2.2318, 2.1731, 2.1188, 2.0640, 2.0154, 1.9652, 1.9169, 1.8706,\n",
      "        1.8185, 1.7711, 1.7172, 1.6638, 1.6087, 1.5544, 1.4972, 1.4391, 1.3846,\n",
      "        1.3295, 1.2759, 1.2260, 1.1763, 1.1290, 1.0837, 1.0399, 0.9987, 0.9606,\n",
      "        0.9170], grad_fn=<AddBackward0>) tensor([5.5967, 5.6037, 5.5767, 5.5727, 5.5509, 5.5628, 5.5506, 5.5454, 5.5476,\n",
      "        5.5565, 5.4988, 5.5242, 5.4536, 5.4299, 5.3629, 5.3006, 5.2554, 5.1807,\n",
      "        5.0755, 5.0042, 4.8862, 4.7718, 4.6596, 4.5660, 4.4212, 4.3289, 4.1846,\n",
      "        4.1116, 3.9989, 3.8849, 3.7839, 3.7107, 3.6053, 3.5202, 3.4416, 3.3667,\n",
      "        3.3135, 3.1897, 3.1212, 3.0067, 2.9348, 2.8294, 2.7251, 2.6370, 2.5396,\n",
      "        2.4447, 2.3522, 2.2631, 2.1703, 2.0985, 2.0211, 1.9341, 1.8728, 1.7913,\n",
      "        1.7104], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.3235, 2.3067, 2.3122, 2.3017, 2.2995, 2.2928, 2.2859, 2.2910, 2.2698,\n",
      "        2.2712, 2.2576, 2.2476, 2.2256, 2.2154, 2.1885, 2.1853, 2.1555, 2.1185,\n",
      "        2.0872, 2.0478, 1.9871, 1.9512, 1.8759, 1.8325, 1.7707, 1.7031, 1.6395,\n",
      "        1.5756, 1.5079, 1.4464, 1.3872, 1.3239, 1.2724, 1.2187, 1.1725, 1.1273,\n",
      "        1.0946, 1.0543, 1.0235, 0.9929, 0.9649, 0.9392, 0.9195, 0.8965, 0.8754,\n",
      "        0.8547, 0.8383, 0.8172, 0.7997, 0.7808, 0.7635, 0.7454, 0.7267, 0.7083,\n",
      "        0.6863], grad_fn=<AddBackward0>) tensor([5.9836, 6.0961, 6.0022, 6.0766, 6.0337, 6.0571, 6.0679, 5.9754, 6.0672,\n",
      "        5.9562, 5.9678, 5.9193, 5.9728, 5.9218, 5.9293, 5.6924, 5.6726, 5.6661,\n",
      "        5.5194, 5.4455, 5.4680, 5.2353, 5.3218, 5.0671, 4.9156, 4.8083, 4.6292,\n",
      "        4.4627, 4.3544, 4.1874, 3.9957, 3.9196, 3.7638, 3.6776, 3.5209, 3.4443,\n",
      "        3.2859, 3.2460, 3.1179, 3.0559, 2.9935, 2.9467, 2.8386, 2.8000, 2.7738,\n",
      "        2.7397, 2.6008, 2.6181, 2.5270, 2.5281, 2.4744, 2.3722, 2.3429, 2.3400,\n",
      "        2.6329], grad_fn=<AddBackward0>)\n",
      "104528.41811275482\n",
      "r0 before lock-down  tensor([3.2423, 3.2399, 3.2432, 3.2435, 3.2462, 3.2439, 3.2446, 3.2406, 3.2376,\n",
      "        3.2259, 3.2247, 3.2029, 3.1865, 3.1552, 3.1219, 3.0789, 3.0308, 2.9771,\n",
      "        2.9213, 2.8556, 2.7892, 2.7216, 2.6470, 2.5706, 2.4979, 2.4209, 2.3516,\n",
      "        2.2735, 2.2071, 2.1457, 2.0888, 2.0321, 1.9822, 1.9309, 1.8816, 1.8348,\n",
      "        1.7827, 1.7354, 1.6818, 1.6288, 1.5739, 1.5204, 1.4642, 1.4071, 1.3534,\n",
      "        1.2994, 1.2469, 1.1979, 1.1494, 1.1031, 1.0588, 1.0160, 0.9758, 0.9385,\n",
      "        0.8960], grad_fn=<AddBackward0>) tensor([5.6817, 5.6920, 5.6635, 5.6565, 5.6379, 5.6521, 5.6376, 5.6336, 5.6300,\n",
      "        5.6427, 5.5812, 5.6042, 5.5328, 5.5009, 5.4321, 5.3651, 5.3094, 5.2211,\n",
      "        5.1159, 5.0352, 4.9064, 4.7858, 4.6590, 4.5641, 4.4046, 4.3024, 4.1528,\n",
      "        4.0734, 3.9559, 3.8348, 3.7320, 3.6558, 3.5464, 3.4578, 3.3801, 3.3044,\n",
      "        3.2497, 3.1251, 3.0548, 2.9413, 2.8747, 2.7706, 2.6656, 2.5787, 2.4841,\n",
      "        2.3912, 2.2997, 2.2141, 2.1230, 2.0527, 1.9766, 1.8917, 1.8321, 1.7531,\n",
      "        1.6742], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.3596, 2.3472, 2.3537, 2.3405, 2.3402, 2.3365, 2.3265, 2.3267, 2.3065,\n",
      "        2.3069, 2.2967, 2.2842, 2.2637, 2.2514, 2.2222, 2.2183, 2.1889, 2.1471,\n",
      "        2.1153, 2.0752, 2.0115, 1.9738, 1.8938, 1.8496, 1.7847, 1.7127, 1.6463,\n",
      "        1.5790, 1.5093, 1.4460, 1.3844, 1.3188, 1.2668, 1.2107, 1.1635, 1.1171,\n",
      "        1.0835, 1.0428, 1.0115, 0.9804, 0.9523, 0.9263, 0.9067, 0.8836, 0.8628,\n",
      "        0.8418, 0.8255, 0.8045, 0.7874, 0.7687, 0.7515, 0.7335, 0.7150, 0.6968,\n",
      "        0.6751], grad_fn=<AddBackward0>) tensor([6.0675, 6.1387, 6.0342, 6.1321, 6.0724, 6.0658, 6.0992, 6.0496, 6.1257,\n",
      "        6.0181, 6.0028, 5.9640, 5.9988, 5.9552, 5.9742, 5.7374, 5.7013, 5.7132,\n",
      "        5.5533, 5.4668, 5.4886, 5.2461, 5.3440, 5.0649, 4.9108, 4.8187, 4.6340,\n",
      "        4.4674, 4.3519, 4.1707, 3.9744, 3.9005, 3.7220, 3.6513, 3.4875, 3.4149,\n",
      "        3.2555, 3.2093, 3.0807, 3.0200, 2.9557, 2.9125, 2.7983, 2.7613, 2.7281,\n",
      "        2.7052, 2.5683, 2.5900, 2.4880, 2.4871, 2.4384, 2.3376, 2.3077, 2.3099,\n",
      "        2.6371], grad_fn=<AddBackward0>)\n",
      "108803.19436645508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([3.2756, 3.2729, 3.2766, 3.2766, 3.2791, 3.2769, 3.2780, 3.2728, 3.2705,\n",
      "        3.2569, 3.2563, 3.2331, 3.2144, 3.1807, 3.1445, 3.0976, 3.0457, 2.9875,\n",
      "        2.9261, 2.8560, 2.7845, 2.7125, 2.6329, 2.5516, 2.4743, 2.3931, 2.3205,\n",
      "        2.2393, 2.1706, 2.1071, 2.0488, 1.9907, 1.9407, 1.8889, 1.8391, 1.7928,\n",
      "        1.7408, 1.6940, 1.6414, 1.5892, 1.5352, 1.4829, 1.4279, 1.3720, 1.3196,\n",
      "        1.2669, 1.2156, 1.1680, 1.1206, 1.0756, 1.0324, 0.9907, 0.9516, 0.9154,\n",
      "        0.8740], grad_fn=<AddBackward0>) tensor([5.7295, 5.7402, 5.7096, 5.7048, 5.6863, 5.6986, 5.6827, 5.6820, 5.6724,\n",
      "        5.6920, 5.6225, 5.6439, 5.5721, 5.5333, 5.4587, 5.3893, 5.3256, 5.2316,\n",
      "        5.1255, 5.0337, 4.8985, 4.7640, 4.6295, 4.5283, 4.3616, 4.2534, 4.0966,\n",
      "        4.0137, 3.8895, 3.7676, 3.6595, 3.5872, 3.4683, 3.3821, 3.3076, 3.2276,\n",
      "        3.1767, 3.0530, 2.9817, 2.8724, 2.8064, 2.7019, 2.5996, 2.5164, 2.4220,\n",
      "        2.3321, 2.2460, 2.1597, 2.0719, 2.0019, 1.9291, 1.8470, 1.7884, 1.7112,\n",
      "        1.6347], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.3586, 2.3501, 2.3560, 2.3471, 2.3438, 2.3416, 2.3312, 2.3306, 2.3087,\n",
      "        2.3096, 2.3000, 2.2859, 2.2662, 2.2536, 2.2237, 2.2167, 2.1870, 2.1434,\n",
      "        2.1129, 2.0726, 2.0061, 1.9677, 1.8845, 1.8420, 1.7745, 1.7006, 1.6319,\n",
      "        1.5624, 1.4928, 1.4293, 1.3662, 1.2987, 1.2473, 1.1903, 1.1436, 1.0971,\n",
      "        1.0633, 1.0229, 0.9919, 0.9609, 0.9334, 0.9076, 0.8887, 0.8655, 0.8455,\n",
      "        0.8247, 0.8089, 0.7882, 0.7716, 0.7533, 0.7366, 0.7188, 0.7008, 0.6829,\n",
      "        0.6615], grad_fn=<AddBackward0>) tensor([6.0818, 6.1161, 6.0169, 6.0736, 6.0434, 6.0214, 6.0594, 6.0108, 6.1037,\n",
      "        5.9866, 5.9668, 5.9369, 5.9634, 5.9166, 5.9392, 5.7219, 5.6767, 5.7001,\n",
      "        5.5145, 5.4167, 5.4487, 5.2010, 5.3104, 4.9956, 4.8504, 4.7606, 4.5826,\n",
      "        4.4219, 4.2926, 4.0941, 3.9093, 3.8575, 3.6605, 3.6041, 3.4278, 3.3542,\n",
      "        3.1991, 3.1549, 3.0236, 2.9686, 2.8968, 2.8592, 2.7387, 2.7121, 2.6703,\n",
      "        2.6596, 2.5226, 2.5471, 2.4434, 2.4433, 2.3921, 2.2965, 2.2640, 2.2696,\n",
      "        2.6393], grad_fn=<AddBackward0>)\n",
      "85913.20187115669\n",
      "r0 before lock-down  tensor([3.3243, 3.3213, 3.3257, 3.3259, 3.3269, 3.3254, 3.3258, 3.3209, 3.3183,\n",
      "        3.3034, 3.3033, 3.2785, 3.2574, 3.2209, 3.1809, 3.1292, 3.0729, 3.0097,\n",
      "        2.9430, 2.8667, 2.7900, 2.7118, 2.6268, 2.5403, 2.4579, 2.3719, 2.2955,\n",
      "        2.2109, 2.1392, 2.0736, 2.0137, 1.9543, 1.9032, 1.8510, 1.8008, 1.7546,\n",
      "        1.7033, 1.6569, 1.6048, 1.5534, 1.5005, 1.4491, 1.3951, 1.3403, 1.2891,\n",
      "        1.2375, 1.1874, 1.1409, 1.0947, 1.0507, 1.0087, 0.9678, 0.9297, 0.8943,\n",
      "        0.8540], grad_fn=<AddBackward0>) tensor([5.8024, 5.8143, 5.7804, 5.7735, 5.7629, 5.7712, 5.7577, 5.7532, 5.7421,\n",
      "        5.7633, 5.6864, 5.7070, 5.6329, 5.5880, 5.5090, 5.4385, 5.3658, 5.2650,\n",
      "        5.1495, 5.0516, 4.9023, 4.7613, 4.6152, 4.5045, 4.3302, 4.2163, 4.0513,\n",
      "        3.9639, 3.8368, 3.7091, 3.5972, 3.5231, 3.4068, 3.3186, 3.2453, 3.1643,\n",
      "        3.1100, 2.9873, 2.9186, 2.8097, 2.7427, 2.6416, 2.5407, 2.4614, 2.3685,\n",
      "        2.2785, 2.1952, 2.1116, 2.0248, 1.9571, 1.8831, 1.8066, 1.7470, 1.6738,\n",
      "        1.5985], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.3869, 2.3760, 2.3834, 2.3736, 2.3715, 2.3713, 2.3562, 2.3581, 2.3331,\n",
      "        2.3325, 2.3253, 2.3080, 2.2873, 2.2774, 2.2460, 2.2351, 2.2097, 2.1634,\n",
      "        2.1300, 2.0893, 2.0210, 1.9793, 1.8940, 1.8490, 1.7806, 1.7035, 1.6322,\n",
      "        1.5611, 1.4889, 1.4236, 1.3595, 1.2898, 1.2373, 1.1793, 1.1319, 1.0849,\n",
      "        1.0505, 1.0095, 0.9783, 0.9469, 0.9194, 0.8936, 0.8747, 0.8515, 0.8317,\n",
      "        0.8111, 0.7954, 0.7751, 0.7586, 0.7405, 0.7240, 0.7065, 0.6887, 0.6710,\n",
      "        0.6499], grad_fn=<AddBackward0>) tensor([6.0980, 6.1493, 6.0384, 6.1000, 6.0609, 6.0199, 6.0968, 6.0266, 6.1406,\n",
      "        6.0326, 5.9883, 5.9838, 6.0122, 5.9383, 5.9647, 5.7745, 5.6844, 5.7143,\n",
      "        5.5398, 5.4269, 5.4553, 5.2153, 5.3209, 5.0061, 4.8397, 4.7604, 4.5788,\n",
      "        4.4065, 4.2797, 4.0758, 3.8807, 3.8377, 3.6350, 3.5752, 3.3934, 3.3117,\n",
      "        3.1577, 3.1138, 2.9793, 2.9294, 2.8563, 2.8168, 2.6974, 2.6747, 2.6304,\n",
      "        2.6173, 2.4829, 2.5047, 2.4061, 2.4073, 2.3554, 2.2591, 2.2286, 2.2344,\n",
      "        2.6435], grad_fn=<AddBackward0>)\n",
      "83865.97078943253\n",
      "r0 before lock-down  tensor([3.3762, 3.3718, 3.3771, 3.3772, 3.3779, 3.3769, 3.3776, 3.3721, 3.3679,\n",
      "        3.3525, 3.3525, 3.3260, 3.3025, 3.2623, 3.2182, 3.1621, 3.1014, 3.0330,\n",
      "        2.9606, 2.8779, 2.7953, 2.7107, 2.6197, 2.5280, 2.4406, 2.3499, 2.2694,\n",
      "        2.1816, 2.1073, 2.0394, 1.9783, 1.9176, 1.8659, 1.8132, 1.7631, 1.7168,\n",
      "        1.6658, 1.6202, 1.5685, 1.5180, 1.4661, 1.4158, 1.3630, 1.3093, 1.2594,\n",
      "        1.2089, 1.1600, 1.1146, 1.0696, 1.0267, 0.9857, 0.9459, 0.9087, 0.8741,\n",
      "        0.8349], grad_fn=<AddBackward0>) tensor([5.8779, 5.8966, 5.8582, 5.8524, 5.8429, 5.8458, 5.8295, 5.8265, 5.8226,\n",
      "        5.8407, 5.7571, 5.7771, 5.6998, 5.6512, 5.5686, 5.4902, 5.4058, 5.2963,\n",
      "        5.1702, 5.0664, 4.9057, 4.7554, 4.6013, 4.4785, 4.2955, 4.1748, 4.0058,\n",
      "        3.9117, 3.7794, 3.6505, 3.5334, 3.4592, 3.3396, 3.2509, 3.1775, 3.0975,\n",
      "        3.0463, 2.9207, 2.8568, 2.7471, 2.6820, 2.5820, 2.4812, 2.4045, 2.3127,\n",
      "        2.2281, 2.1466, 2.0653, 1.9798, 1.9123, 1.8401, 1.7652, 1.7091, 1.6378,\n",
      "        1.5657], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.3918, 2.3843, 2.3932, 2.3824, 2.3787, 2.3770, 2.3637, 2.3641, 2.3428,\n",
      "        2.3424, 2.3340, 2.3141, 2.2930, 2.2817, 2.2510, 2.2379, 2.2159, 2.1681,\n",
      "        2.1301, 2.0912, 2.0208, 1.9787, 1.8913, 1.8430, 1.7730, 1.6944, 1.6222,\n",
      "        1.5495, 1.4767, 1.4097, 1.3444, 1.2756, 1.2214, 1.1630, 1.1160, 1.0680,\n",
      "        1.0335, 0.9930, 0.9620, 0.9306, 0.9035, 0.8778, 0.8590, 0.8364, 0.8167,\n",
      "        0.7967, 0.7811, 0.7612, 0.7450, 0.7272, 0.7110, 0.6938, 0.6764, 0.6588,\n",
      "        0.6382], grad_fn=<AddBackward0>) tensor([6.1079, 6.1311, 6.0088, 6.0816, 6.0520, 6.0220, 6.0811, 6.0233, 6.1040,\n",
      "        5.9914, 5.9601, 5.9675, 5.9983, 5.9331, 5.9485, 5.7714, 5.6470, 5.6774,\n",
      "        5.5342, 5.3909, 5.4182, 5.1730, 5.2806, 4.9785, 4.8187, 4.7329, 4.5403,\n",
      "        4.3677, 4.2331, 4.0380, 3.8423, 3.7712, 3.5873, 3.5272, 3.3343, 3.2693,\n",
      "        3.1162, 3.0671, 2.9303, 2.8817, 2.8043, 2.7710, 2.6556, 2.6279, 2.5893,\n",
      "        2.5678, 2.4391, 2.4617, 2.3632, 2.3639, 2.3168, 2.2204, 2.1890, 2.2037,\n",
      "        2.6425], grad_fn=<AddBackward0>)\n",
      "85194.99909090996\n",
      "r0 before lock-down  tensor([3.4227, 3.4171, 3.4230, 3.4231, 3.4246, 3.4225, 3.4233, 3.4176, 3.4125,\n",
      "        3.3963, 3.3962, 3.3678, 3.3416, 3.2978, 3.2503, 3.1895, 3.1238, 3.0500,\n",
      "        2.9722, 2.8833, 2.7949, 2.7039, 2.6074, 2.5105, 2.4183, 2.3234, 2.2392,\n",
      "        2.1486, 2.0722, 2.0025, 1.9399, 1.8785, 1.8267, 1.7738, 1.7238, 1.6780,\n",
      "        1.6276, 1.5826, 1.5319, 1.4824, 1.4317, 1.3826, 1.3309, 1.2785, 1.2299,\n",
      "        1.1807, 1.1331, 1.0888, 1.0450, 1.0033, 0.9634, 0.9244, 0.8882, 0.8547,\n",
      "        0.8164], grad_fn=<AddBackward0>) tensor([5.9402, 5.9662, 5.9226, 5.9185, 5.9030, 5.9124, 5.8940, 5.8895, 5.8884,\n",
      "        5.9039, 5.8158, 5.8346, 5.7565, 5.7048, 5.6124, 5.5291, 5.4356, 5.3165,\n",
      "        5.1808, 5.0672, 4.8975, 4.7409, 4.5767, 4.4439, 4.2536, 4.1255, 3.9514,\n",
      "        3.8528, 3.7141, 3.5825, 3.4658, 3.3926, 3.2679, 3.1814, 3.1091, 3.0275,\n",
      "        2.9790, 2.8555, 2.7926, 2.6839, 2.6195, 2.5227, 2.4258, 2.3515, 2.2607,\n",
      "        2.1777, 2.0986, 2.0191, 1.9347, 1.8682, 1.7969, 1.7278, 1.6733, 1.6015,\n",
      "        1.5334], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.4372, 2.4305, 2.4399, 2.4289, 2.4256, 2.4215, 2.4064, 2.4078, 2.3896,\n",
      "        2.3877, 2.3810, 2.3595, 2.3377, 2.3251, 2.2943, 2.2767, 2.2560, 2.2056,\n",
      "        2.1646, 2.1234, 2.0510, 2.0049, 1.9148, 1.8653, 1.7921, 1.7106, 1.6338,\n",
      "        1.5565, 1.4830, 1.4133, 1.3458, 1.2752, 1.2182, 1.1589, 1.1101, 1.0611,\n",
      "        1.0256, 0.9842, 0.9530, 0.9211, 0.8935, 0.8674, 0.8486, 0.8259, 0.8063,\n",
      "        0.7863, 0.7708, 0.7510, 0.7348, 0.7174, 0.7013, 0.6842, 0.6669, 0.6496,\n",
      "        0.6291], grad_fn=<AddBackward0>) tensor([6.1875, 6.2082, 6.0775, 6.1508, 6.1181, 6.1026, 6.1778, 6.1053, 6.1572,\n",
      "        6.0506, 6.0043, 6.0132, 6.0446, 5.9855, 5.9912, 5.8399, 5.6934, 5.7274,\n",
      "        5.5899, 5.4453, 5.4605, 5.2261, 5.3249, 5.0013, 4.8339, 4.7382, 4.5590,\n",
      "        4.4011, 4.2368, 4.0362, 3.8321, 3.7518, 3.5775, 3.5019, 3.3132, 3.2453,\n",
      "        3.0883, 3.0379, 2.8932, 2.8457, 2.7743, 2.7447, 2.6259, 2.6011, 2.5602,\n",
      "        2.5399, 2.4100, 2.4330, 2.3394, 2.3333, 2.2876, 2.1954, 2.1654, 2.1772,\n",
      "        2.6674], grad_fn=<AddBackward0>)\n",
      "75307.25393748283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([3.4647, 3.4576, 3.4651, 3.4649, 3.4662, 3.4646, 3.4647, 3.4585, 3.4544,\n",
      "        3.4363, 3.4352, 3.4061, 3.3767, 3.3294, 3.2776, 3.2124, 3.1409, 3.0625,\n",
      "        2.9786, 2.8837, 2.7891, 2.6926, 2.5906, 2.4892, 2.3921, 2.2932, 2.2057,\n",
      "        2.1127, 2.0344, 1.9633, 1.9001, 1.8383, 1.7862, 1.7336, 1.6840, 1.6388,\n",
      "        1.5892, 1.5452, 1.4953, 1.4468, 1.3974, 1.3497, 1.2993, 1.2482, 1.2010,\n",
      "        1.1530, 1.1066, 1.0637, 1.0211, 0.9805, 0.9417, 0.9037, 0.8685, 0.8358,\n",
      "        0.7985], grad_fn=<AddBackward0>) tensor([5.9986, 6.0313, 5.9787, 5.9773, 5.9618, 5.9655, 5.9508, 5.9472, 5.9373,\n",
      "        5.9571, 5.8705, 5.8829, 5.8051, 5.7470, 5.6505, 5.5598, 5.4615, 5.3293,\n",
      "        5.1880, 5.0639, 4.8860, 4.7176, 4.5449, 4.3990, 4.2041, 4.0717, 3.8936,\n",
      "        3.7896, 3.6473, 3.5154, 3.3943, 3.3198, 3.1974, 3.1084, 3.0370, 2.9571,\n",
      "        2.9089, 2.7863, 2.7281, 2.6236, 2.5606, 2.4610, 2.3689, 2.2987, 2.2092,\n",
      "        2.1294, 2.0534, 1.9741, 1.8927, 1.8269, 1.7565, 1.6887, 1.6368, 1.5669,\n",
      "        1.5014], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.4361, 2.4333, 2.4398, 2.4309, 2.4249, 2.4224, 2.4068, 2.4055, 2.3916,\n",
      "        2.3863, 2.3810, 2.3586, 2.3374, 2.3239, 2.2926, 2.2739, 2.2538, 2.2002,\n",
      "        2.1596, 2.1174, 2.0458, 1.9951, 1.9081, 1.8562, 1.7799, 1.6982, 1.6198,\n",
      "        1.5419, 1.4683, 1.3959, 1.3295, 1.2586, 1.2008, 1.1409, 1.0927, 1.0438,\n",
      "        1.0079, 0.9675, 0.9361, 0.9046, 0.8773, 0.8517, 0.8331, 0.8107, 0.7916,\n",
      "        0.7720, 0.7568, 0.7375, 0.7216, 0.7047, 0.6889, 0.6722, 0.6551, 0.6382,\n",
      "        0.6180], grad_fn=<AddBackward0>) tensor([6.1608, 6.1519, 6.0438, 6.1006, 6.0915, 6.0612, 6.1391, 6.0902, 6.1034,\n",
      "        6.0206, 5.9647, 5.9738, 6.0020, 5.9463, 5.9530, 5.8100, 5.6534, 5.7028,\n",
      "        5.5533, 5.4114, 5.4067, 5.2042, 5.2581, 4.9474, 4.7981, 4.6891, 4.5154,\n",
      "        4.3528, 4.1760, 4.0025, 3.7760, 3.6944, 3.5275, 3.4610, 3.2604, 3.1925,\n",
      "        3.0477, 2.9806, 2.8438, 2.7950, 2.7238, 2.6907, 2.5802, 2.5568, 2.5155,\n",
      "        2.4988, 2.3709, 2.3941, 2.3056, 2.2955, 2.2531, 2.1591, 2.1341, 2.1418,\n",
      "        2.6755], grad_fn=<AddBackward0>)\n",
      "72186.02683138847\n",
      "r0 before lock-down  tensor([3.5175, 3.5096, 3.5165, 3.5162, 3.5173, 3.5160, 3.5150, 3.5083, 3.5052,\n",
      "        3.4851, 3.4839, 3.4537, 3.4210, 3.3698, 3.3138, 3.2429, 3.1662, 3.0821,\n",
      "        2.9906, 2.8894, 2.7881, 2.6857, 2.5778, 2.4709, 2.3690, 2.2660, 2.1754,\n",
      "        2.0796, 1.9996, 1.9270, 1.8629, 1.8006, 1.7483, 1.6957, 1.6465, 1.6020,\n",
      "        1.5529, 1.5100, 1.4611, 1.4135, 1.3653, 1.3187, 1.2699, 1.2198, 1.1739,\n",
      "        1.1272, 1.0821, 1.0402, 0.9987, 0.9592, 0.9214, 0.8843, 0.8500, 0.8182,\n",
      "        0.7819], grad_fn=<AddBackward0>) tensor([6.0674, 6.1038, 6.0555, 6.0538, 6.0397, 6.0406, 6.0307, 6.0265, 6.0092,\n",
      "        6.0329, 5.9411, 5.9463, 5.8667, 5.8047, 5.6995, 5.6038, 5.4938, 5.3497,\n",
      "        5.2067, 5.0702, 4.8836, 4.7024, 4.5204, 4.3651, 4.1641, 4.0239, 3.8387,\n",
      "        3.7319, 3.5842, 3.4504, 3.3274, 3.2541, 3.1313, 3.0423, 2.9718, 2.8922,\n",
      "        2.8475, 2.7235, 2.6673, 2.5661, 2.5043, 2.4083, 2.3147, 2.2487, 2.1605,\n",
      "        2.0837, 2.0092, 1.9312, 1.8520, 1.7866, 1.7186, 1.6547, 1.6047, 1.5349,\n",
      "        1.4730], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.4707, 2.4671, 2.4760, 2.4657, 2.4629, 2.4594, 2.4426, 2.4396, 2.4273,\n",
      "        2.4223, 2.4152, 2.3932, 2.3715, 2.3568, 2.3219, 2.3046, 2.2814, 2.2261,\n",
      "        2.1837, 2.1410, 2.0689, 2.0152, 1.9266, 1.8707, 1.7915, 1.7085, 1.6267,\n",
      "        1.5464, 1.4704, 1.3955, 1.3277, 1.2546, 1.1958, 1.1345, 1.0850, 1.0351,\n",
      "        0.9992, 0.9582, 0.9265, 0.8944, 0.8666, 0.8413, 0.8225, 0.8001, 0.7810,\n",
      "        0.7616, 0.7464, 0.7274, 0.7116, 0.6948, 0.6791, 0.6626, 0.6458, 0.6290,\n",
      "        0.6090], grad_fn=<AddBackward0>) tensor([6.2176, 6.2158, 6.0858, 6.1542, 6.1161, 6.0982, 6.1775, 6.1401, 6.1415,\n",
      "        6.0448, 6.0024, 6.0044, 6.0323, 5.9807, 6.0084, 5.8429, 5.7025, 5.7519,\n",
      "        5.5993, 5.4428, 5.4177, 5.2209, 5.2567, 4.9586, 4.8104, 4.6797, 4.5090,\n",
      "        4.3446, 4.1661, 3.9934, 3.7574, 3.6850, 3.5037, 3.4398, 3.2417, 3.1795,\n",
      "        3.0147, 2.9464, 2.8090, 2.7635, 2.7032, 2.6549, 2.5471, 2.5284, 2.4849,\n",
      "        2.4654, 2.3397, 2.3597, 2.2753, 2.2660, 2.2275, 2.1347, 2.1064, 2.1194,\n",
      "        2.7014], grad_fn=<AddBackward0>)\n",
      "64419.70193648338\n",
      "r0 before lock-down  tensor([3.5713, 3.5630, 3.5706, 3.5700, 3.5710, 3.5685, 3.5671, 3.5618, 3.5586,\n",
      "        3.5367, 3.5350, 3.5019, 3.4669, 3.4132, 3.3505, 3.2750, 3.1921, 3.1016,\n",
      "        3.0036, 2.8952, 2.7865, 2.6785, 2.5639, 2.4515, 2.3449, 2.2380, 2.1444,\n",
      "        2.0459, 1.9645, 1.8905, 1.8258, 1.7634, 1.7110, 1.6584, 1.6098, 1.5661,\n",
      "        1.5177, 1.4758, 1.4280, 1.3814, 1.3343, 1.2890, 1.2413, 1.1925, 1.1479,\n",
      "        1.1024, 1.0585, 1.0177, 0.9772, 0.9389, 0.9020, 0.8658, 0.8324, 0.8014,\n",
      "        0.7660], grad_fn=<AddBackward0>) tensor([6.1451, 6.1831, 6.1319, 6.1301, 6.1181, 6.1240, 6.1154, 6.0997, 6.0799,\n",
      "        6.1068, 6.0114, 6.0189, 5.9307, 5.8547, 5.7543, 5.6450, 5.5270, 5.3719,\n",
      "        5.2186, 5.0725, 4.8806, 4.6824, 4.4965, 4.3332, 4.1215, 3.9749, 3.7829,\n",
      "        3.6752, 3.5204, 3.3883, 3.2628, 3.1874, 3.0663, 2.9811, 2.9090, 2.8281,\n",
      "        2.7860, 2.6627, 2.6088, 2.5104, 2.4511, 2.3549, 2.2649, 2.2015, 2.1126,\n",
      "        2.0384, 1.9666, 1.8903, 1.8138, 1.7489, 1.6842, 1.6212, 1.5730, 1.5036,\n",
      "        1.4463], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.4932, 2.4904, 2.5009, 2.4904, 2.4880, 2.4848, 2.4673, 2.4597, 2.4534,\n",
      "        2.4487, 2.4366, 2.4194, 2.3921, 2.3808, 2.3431, 2.3226, 2.2985, 2.2417,\n",
      "        2.1995, 2.1543, 2.0817, 2.0278, 1.9372, 1.8762, 1.7960, 1.7111, 1.6269,\n",
      "        1.5460, 1.4672, 1.3904, 1.3202, 1.2463, 1.1870, 1.1247, 1.0744, 1.0235,\n",
      "        0.9874, 0.9468, 0.9148, 0.8823, 0.8546, 0.8291, 0.8105, 0.7883, 0.7695,\n",
      "        0.7502, 0.7352, 0.7165, 0.7008, 0.6842, 0.6689, 0.6526, 0.6360, 0.6193,\n",
      "        0.5996], grad_fn=<AddBackward0>) tensor([6.2529, 6.2461, 6.1038, 6.1718, 6.1300, 6.1053, 6.1903, 6.1876, 6.1397,\n",
      "        6.0370, 6.0301, 5.9892, 6.0587, 5.9767, 6.0198, 5.8765, 5.7313, 5.7747,\n",
      "        5.6116, 5.4628, 5.4208, 5.2001, 5.2357, 4.9639, 4.8019, 4.6626, 4.4882,\n",
      "        4.3040, 4.1339, 3.9595, 3.7406, 3.6557, 3.4650, 3.4031, 3.2020, 3.1508,\n",
      "        2.9802, 2.8956, 2.7635, 2.7263, 2.6653, 2.6262, 2.5162, 2.4933, 2.4502,\n",
      "        2.4293, 2.3066, 2.3257, 2.2457, 2.2388, 2.1943, 2.1040, 2.0755, 2.0930,\n",
      "        2.7265], grad_fn=<AddBackward0>)\n",
      "63050.156752586365\n",
      "r0 before lock-down  tensor([3.6302, 3.6218, 3.6297, 3.6278, 3.6280, 3.6257, 3.6242, 3.6197, 3.6155,\n",
      "        3.5933, 3.5896, 3.5546, 3.5186, 3.4586, 3.3910, 3.3092, 3.2203, 3.1221,\n",
      "        3.0177, 2.9024, 2.7861, 2.6707, 2.5506, 2.4322, 2.3208, 2.2102, 2.1131,\n",
      "        2.0126, 1.9296, 1.8542, 1.7889, 1.7270, 1.6740, 1.6219, 1.5738, 1.5308,\n",
      "        1.4834, 1.4423, 1.3957, 1.3501, 1.3042, 1.2602, 1.2137, 1.1662, 1.1228,\n",
      "        1.0785, 1.0358, 0.9961, 0.9567, 0.9194, 0.8834, 0.8482, 0.8156, 0.7855,\n",
      "        0.7509], grad_fn=<AddBackward0>) tensor([6.2224, 6.2591, 6.2073, 6.2117, 6.2050, 6.2085, 6.1990, 6.1761, 6.1585,\n",
      "        6.1780, 6.0854, 6.0891, 5.9872, 5.9148, 5.8049, 5.6906, 5.5601, 5.4011,\n",
      "        5.2312, 5.0713, 4.8721, 4.6679, 4.4656, 4.2975, 4.0780, 3.9229, 3.7307,\n",
      "        3.6151, 3.4565, 3.3275, 3.1997, 3.1169, 3.0022, 2.9172, 2.8469, 2.7684,\n",
      "        2.7241, 2.6038, 2.5507, 2.4543, 2.3974, 2.3025, 2.2166, 2.1559, 2.0678,\n",
      "        1.9954, 1.9251, 1.8514, 1.7768, 1.7131, 1.6506, 1.5884, 1.5433, 1.4746,\n",
      "        1.4216], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.5041, 2.5020, 2.5128, 2.4998, 2.5040, 2.4973, 2.4768, 2.4701, 2.4649,\n",
      "        2.4600, 2.4467, 2.4310, 2.4008, 2.3889, 2.3506, 2.3301, 2.3061, 2.2489,\n",
      "        2.2045, 2.1579, 2.0861, 2.0303, 1.9380, 1.8762, 1.7924, 1.7062, 1.6196,\n",
      "        1.5384, 1.4595, 1.3797, 1.3089, 1.2352, 1.1741, 1.1122, 1.0612, 1.0102,\n",
      "        0.9739, 0.9332, 0.9009, 0.8687, 0.8409, 0.8158, 0.7972, 0.7752, 0.7565,\n",
      "        0.7375, 0.7228, 0.7043, 0.6888, 0.6725, 0.6575, 0.6415, 0.6251, 0.6087,\n",
      "        0.5894], grad_fn=<AddBackward0>) tensor([6.2530, 6.2394, 6.0958, 6.1798, 6.0878, 6.0899, 6.1986, 6.1879, 6.1294,\n",
      "        6.0253, 6.0255, 5.9695, 6.0596, 5.9819, 6.0266, 5.8732, 5.7219, 5.7582,\n",
      "        5.6033, 5.4591, 5.3901, 5.1748, 5.2081, 4.9287, 4.7833, 4.6405, 4.4736,\n",
      "        4.2790, 4.0883, 3.9401, 3.7108, 3.6145, 3.4382, 3.3574, 3.1681, 3.1092,\n",
      "        2.9377, 2.8510, 2.7287, 2.6840, 2.6234, 2.5832, 2.4730, 2.4508, 2.4130,\n",
      "        2.3892, 2.2661, 2.2844, 2.2069, 2.1998, 2.1591, 2.0697, 2.0442, 2.0643,\n",
      "        2.7526], grad_fn=<AddBackward0>)\n",
      "70033.88549304008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([3.6639, 3.6548, 3.6618, 3.6610, 3.6610, 3.6592, 3.6584, 3.6522, 3.6469,\n",
      "        3.6243, 3.6198, 3.5825, 3.5448, 3.4799, 3.4081, 3.3210, 3.2279, 3.1225,\n",
      "        3.0109, 2.8911, 2.7683, 2.6467, 2.5222, 2.3997, 2.2848, 2.1718, 2.0726,\n",
      "        1.9710, 1.8872, 1.8119, 1.7468, 1.6852, 1.6331, 1.5818, 1.5347, 1.4930,\n",
      "        1.4466, 1.4067, 1.3615, 1.3172, 1.2728, 1.2300, 1.1849, 1.1389, 1.0969,\n",
      "        1.0538, 1.0124, 0.9739, 0.9356, 0.8994, 0.8644, 0.8302, 0.7985, 0.7692,\n",
      "        0.7356], grad_fn=<AddBackward0>) tensor([6.2600, 6.2984, 6.2534, 6.2497, 6.2449, 6.2429, 6.2283, 6.2142, 6.1994,\n",
      "        6.2147, 6.1204, 6.1250, 6.0120, 5.9395, 5.8210, 5.7016, 5.5517, 5.3930,\n",
      "        5.2208, 5.0409, 4.8378, 4.6308, 4.4160, 4.2405, 4.0148, 3.8545, 3.6612,\n",
      "        3.5445, 3.3864, 3.2526, 3.1259, 3.0470, 2.9290, 2.8461, 2.7783, 2.6988,\n",
      "        2.6598, 2.5403, 2.4884, 2.3953, 2.3416, 2.2501, 2.1659, 2.1065, 2.0219,\n",
      "        1.9519, 1.8823, 1.8102, 1.7392, 1.6775, 1.6169, 1.5553, 1.5122, 1.4452,\n",
      "        1.3955], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.5087, 2.5100, 2.5149, 2.5070, 2.5092, 2.5001, 2.4763, 2.4722, 2.4687,\n",
      "        2.4653, 2.4506, 2.4358, 2.4060, 2.3924, 2.3550, 2.3326, 2.3088, 2.2502,\n",
      "        2.2041, 2.1566, 2.0852, 2.0264, 1.9320, 1.8714, 1.7852, 1.6990, 1.6098,\n",
      "        1.5275, 1.4488, 1.3676, 1.2952, 1.2213, 1.1596, 1.0977, 1.0469, 0.9958,\n",
      "        0.9593, 0.9184, 0.8866, 0.8544, 0.8269, 0.8021, 0.7837, 0.7620, 0.7437,\n",
      "        0.7249, 0.7106, 0.6923, 0.6773, 0.6613, 0.6467, 0.6308, 0.6148, 0.5987,\n",
      "        0.5796], grad_fn=<AddBackward0>) tensor([6.2394, 6.1966, 6.0992, 6.1403, 6.0660, 6.0830, 6.2221, 6.1887, 6.1166,\n",
      "        6.0007, 6.0105, 5.9440, 6.0255, 5.9635, 5.9908, 5.8494, 5.6890, 5.7304,\n",
      "        5.5855, 5.4359, 5.3514, 5.1518, 5.1943, 4.8847, 4.7490, 4.5918, 4.4343,\n",
      "        4.2435, 4.0339, 3.8928, 3.6739, 3.5713, 3.3995, 3.3134, 3.1157, 3.0563,\n",
      "        2.8932, 2.8119, 2.6815, 2.6423, 2.5816, 2.5420, 2.4324, 2.4100, 2.3718,\n",
      "        2.3531, 2.2270, 2.2538, 2.1725, 2.1690, 2.1257, 2.0381, 2.0164, 2.0331,\n",
      "        2.7759], grad_fn=<AddBackward0>)\n",
      "52616.72824501991\n",
      "r0 before lock-down  tensor([3.7322, 3.7224, 3.7305, 3.7297, 3.7285, 3.7289, 3.7275, 3.7229, 3.7141,\n",
      "        3.6904, 3.6840, 3.6444, 3.6046, 3.5334, 3.4558, 3.3624, 3.2624, 3.1484,\n",
      "        3.0293, 2.9008, 2.7704, 2.6412, 2.5102, 2.3819, 2.2622, 2.1454, 2.0428,\n",
      "        1.9394, 1.8540, 1.7774, 1.7123, 1.6505, 1.5986, 1.5477, 1.5012, 1.4602,\n",
      "        1.4149, 1.3759, 1.3316, 1.2884, 1.2451, 1.2035, 1.1594, 1.1149, 1.0738,\n",
      "        1.0319, 0.9917, 0.9542, 0.9169, 0.8816, 0.8475, 0.8142, 0.7832, 0.7546,\n",
      "        0.7219], grad_fn=<AddBackward0>) tensor([6.3632, 6.4038, 6.3531, 6.3480, 6.3486, 6.3352, 6.3212, 6.2958, 6.2972,\n",
      "        6.3082, 6.2158, 6.2180, 6.0933, 6.0186, 5.8888, 5.7600, 5.5938, 5.4294,\n",
      "        5.2412, 5.0520, 4.8358, 4.6179, 4.3920, 4.2077, 3.9748, 3.8060, 3.6126,\n",
      "        3.4870, 3.3276, 3.1976, 3.0640, 2.9862, 2.8698, 2.7877, 2.7208, 2.6405,\n",
      "        2.6010, 2.4824, 2.4357, 2.3430, 2.2912, 2.2020, 2.1243, 2.0615, 1.9808,\n",
      "        1.9118, 1.8448, 1.7751, 1.7057, 1.6451, 1.5857, 1.5248, 1.4848, 1.4192,\n",
      "        1.3714], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.5161, 2.5195, 2.5197, 2.5157, 2.5156, 2.5082, 2.4831, 2.4801, 2.4765,\n",
      "        2.4696, 2.4588, 2.4457, 2.4110, 2.3978, 2.3621, 2.3373, 2.3102, 2.2529,\n",
      "        2.2029, 2.1591, 2.0846, 2.0253, 1.9308, 1.8659, 1.7800, 1.6915, 1.6027,\n",
      "        1.5174, 1.4379, 1.3565, 1.2833, 1.2080, 1.1463, 1.0846, 1.0333, 0.9824,\n",
      "        0.9457, 0.9050, 0.8731, 0.8409, 0.8137, 0.7892, 0.7711, 0.7495, 0.7316,\n",
      "        0.7133, 0.6992, 0.6811, 0.6664, 0.6508, 0.6363, 0.6208, 0.6051, 0.5891,\n",
      "        0.5704], grad_fn=<AddBackward0>) tensor([6.2166, 6.1592, 6.1003, 6.1072, 6.0519, 6.0553, 6.1966, 6.1578, 6.0891,\n",
      "        5.9994, 5.9778, 5.8937, 6.0097, 5.9411, 5.9505, 5.8195, 5.6871, 5.7072,\n",
      "        5.5914, 5.3969, 5.3284, 5.1210, 5.1463, 4.8642, 4.7100, 4.5627, 4.3824,\n",
      "        4.2120, 4.0009, 3.8460, 3.6295, 3.5411, 3.3575, 3.2648, 3.0722, 3.0060,\n",
      "        2.8479, 2.7623, 2.6384, 2.6056, 2.5442, 2.5034, 2.3913, 2.3778, 2.3357,\n",
      "        2.3154, 2.1905, 2.2218, 2.1419, 2.1358, 2.1001, 2.0102, 1.9846, 2.0080,\n",
      "        2.8054], grad_fn=<AddBackward0>)\n",
      "59530.9533059597\n",
      "r0 before lock-down  tensor([3.7957, 3.7841, 3.7950, 3.7934, 3.7935, 3.7931, 3.7890, 3.7867, 3.7752,\n",
      "        3.7526, 3.7451, 3.7013, 3.6577, 3.5807, 3.4983, 3.3981, 3.2901, 3.1688,\n",
      "        3.0417, 2.9055, 2.7663, 2.6309, 2.4937, 2.3600, 2.2355, 2.1154, 2.0099,\n",
      "        1.9051, 1.8186, 1.7420, 1.6760, 1.6147, 1.5635, 1.5130, 1.4672, 1.4269,\n",
      "        1.3829, 1.3447, 1.3016, 1.2596, 1.2176, 1.1771, 1.1342, 1.0910, 1.0511,\n",
      "        1.0103, 0.9712, 0.9347, 0.8985, 0.8642, 0.8309, 0.7985, 0.7683, 0.7404,\n",
      "        0.7084], grad_fn=<AddBackward0>) tensor([6.4511, 6.5022, 6.4364, 6.4336, 6.4314, 6.4164, 6.4159, 6.3756, 6.3886,\n",
      "        6.3850, 6.2903, 6.2974, 6.1713, 6.0904, 5.9425, 5.8054, 5.6311, 5.4506,\n",
      "        5.2520, 5.0473, 4.8284, 4.5946, 4.3575, 4.1651, 3.9277, 3.7523, 3.5589,\n",
      "        3.4267, 3.2653, 3.1288, 3.0039, 2.9222, 2.8037, 2.7261, 2.6609, 2.5836,\n",
      "        2.5408, 2.4280, 2.3809, 2.2904, 2.2403, 2.1535, 2.0791, 2.0174, 1.9399,\n",
      "        1.8744, 1.8076, 1.7408, 1.6729, 1.6113, 1.5559, 1.4961, 1.4572, 1.3934,\n",
      "        1.3476], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.5479, 2.5534, 2.5518, 2.5479, 2.5463, 2.5421, 2.5165, 2.5120, 2.5056,\n",
      "        2.5045, 2.4907, 2.4770, 2.4410, 2.4291, 2.3902, 2.3654, 2.3366, 2.2794,\n",
      "        2.2284, 2.1814, 2.1034, 2.0443, 1.9479, 1.8784, 1.7909, 1.7016, 1.6104,\n",
      "        1.5209, 1.4415, 1.3575, 1.2828, 1.2055, 1.1428, 1.0807, 1.0277, 0.9762,\n",
      "        0.9394, 0.8978, 0.8654, 0.8330, 0.8057, 0.7812, 0.7628, 0.7412, 0.7234,\n",
      "        0.7050, 0.6910, 0.6731, 0.6584, 0.6431, 0.6286, 0.6133, 0.5977, 0.5819,\n",
      "        0.5633], grad_fn=<AddBackward0>) tensor([6.2560, 6.1875, 6.1390, 6.1424, 6.0968, 6.0779, 6.2173, 6.1852, 6.1391,\n",
      "        6.0041, 6.0054, 5.9197, 6.0405, 5.9586, 5.9870, 5.8449, 5.7157, 5.7247,\n",
      "        5.6015, 5.4205, 5.3609, 5.1333, 5.1520, 4.8863, 4.7230, 4.5588, 4.3717,\n",
      "        4.2259, 3.9845, 3.8354, 3.6121, 3.5345, 3.3428, 3.2376, 3.0574, 2.9861,\n",
      "        2.8156, 2.7421, 2.6158, 2.5841, 2.5175, 2.4717, 2.3683, 2.3528, 2.3065,\n",
      "        2.2934, 2.1649, 2.1978, 2.1222, 2.1082, 2.0785, 1.9919, 1.9637, 1.9888,\n",
      "        2.8630], grad_fn=<AddBackward0>)\n",
      "68463.3184068203\n",
      "r0 before lock-down  tensor([3.8359, 3.8230, 3.8353, 3.8331, 3.8333, 3.8333, 3.8294, 3.8257, 3.8130,\n",
      "        3.7877, 3.7818, 3.7359, 3.6894, 3.6066, 3.5196, 3.4124, 3.2979, 3.1698,\n",
      "        3.0363, 2.8929, 2.7477, 2.6064, 2.4649, 2.3270, 2.1995, 2.0779, 1.9701,\n",
      "        1.8647, 1.7777, 1.7021, 1.6363, 1.5758, 1.5255, 1.4759, 1.4313, 1.3921,\n",
      "        1.3495, 1.3126, 1.2708, 1.2300, 1.1893, 1.1503, 1.1088, 1.0667, 1.0281,\n",
      "        0.9886, 0.9507, 0.9153, 0.8800, 0.8467, 0.8144, 0.7828, 0.7534, 0.7263,\n",
      "        0.6952], grad_fn=<AddBackward0>) tensor([6.5008, 6.5579, 6.4857, 6.4865, 6.4835, 6.4637, 6.4611, 6.4265, 6.4427,\n",
      "        6.4470, 6.3350, 6.3391, 6.2077, 6.1246, 5.9632, 5.8232, 5.6400, 5.4485,\n",
      "        5.2390, 5.0248, 4.7935, 4.5529, 4.3053, 4.1082, 3.8648, 3.6787, 3.4930,\n",
      "        3.3571, 3.1998, 3.0550, 2.9345, 2.8536, 2.7365, 2.6614, 2.5972, 2.5228,\n",
      "        2.4801, 2.3696, 2.3255, 2.2381, 2.1909, 2.1043, 2.0321, 1.9757, 1.8989,\n",
      "        1.8351, 1.7709, 1.7042, 1.6408, 1.5805, 1.5271, 1.4676, 1.4309, 1.3683,\n",
      "        1.3263], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.5822, 2.5847, 2.5833, 2.5799, 2.5766, 2.5766, 2.5482, 2.5428, 2.5376,\n",
      "        2.5370, 2.5238, 2.5093, 2.4700, 2.4608, 2.4203, 2.3928, 2.3603, 2.3027,\n",
      "        2.2524, 2.2042, 2.1218, 2.0633, 1.9651, 1.8914, 1.8025, 1.7107, 1.6178,\n",
      "        1.5258, 1.4446, 1.3587, 1.2821, 1.2032, 1.1399, 1.0762, 1.0221, 0.9697,\n",
      "        0.9324, 0.8904, 0.8576, 0.8248, 0.7977, 0.7727, 0.7543, 0.7327, 0.7148,\n",
      "        0.6965, 0.6826, 0.6647, 0.6502, 0.6351, 0.6206, 0.6055, 0.5900, 0.5744,\n",
      "        0.5559], grad_fn=<AddBackward0>) tensor([6.2776, 6.2354, 6.1832, 6.1815, 6.1484, 6.0966, 6.2536, 6.2274, 6.1734,\n",
      "        6.0304, 6.0241, 5.9424, 6.0809, 5.9772, 6.0117, 5.8824, 5.7736, 5.7747,\n",
      "        5.6317, 5.4446, 5.4046, 5.1479, 5.1611, 4.9077, 4.7317, 4.5663, 4.3669,\n",
      "        4.2231, 3.9711, 3.8174, 3.5992, 3.5161, 3.3137, 3.2142, 3.0385, 2.9688,\n",
      "        2.7938, 2.7160, 2.5932, 2.5611, 2.4855, 2.4455, 2.3433, 2.3281, 2.2812,\n",
      "        2.2682, 2.1397, 2.1748, 2.0980, 2.0777, 2.0567, 1.9666, 1.9456, 1.9668,\n",
      "        2.9087], grad_fn=<AddBackward0>)\n",
      "59330.07664299011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([3.8712, 3.8561, 3.8699, 3.8689, 3.8678, 3.8680, 3.8633, 3.8598, 3.8454,\n",
      "        3.8213, 3.8130, 3.7649, 3.7156, 3.6275, 3.5362, 3.4214, 3.3019, 3.1662,\n",
      "        3.0259, 2.8767, 2.7252, 2.5784, 2.4329, 2.2915, 2.1611, 2.0378, 1.9293,\n",
      "        1.8234, 1.7362, 1.6613, 1.5963, 1.5368, 1.4877, 1.4395, 1.3958, 1.3580,\n",
      "        1.3166, 1.2809, 1.2406, 1.2012, 1.1618, 1.1240, 1.0839, 1.0431, 1.0058,\n",
      "        0.9675, 0.9307, 0.8964, 0.8622, 0.8298, 0.7984, 0.7677, 0.7391, 0.7127,\n",
      "        0.6824], grad_fn=<AddBackward0>) tensor([6.5396, 6.6058, 6.5282, 6.5215, 6.5247, 6.5020, 6.5006, 6.4650, 6.4871,\n",
      "        6.4787, 6.3711, 6.3725, 6.2340, 6.1481, 5.9728, 5.8336, 5.6304, 5.4360,\n",
      "        5.2177, 4.9898, 4.7509, 4.5048, 4.2453, 4.0417, 3.7983, 3.6085, 3.4173,\n",
      "        3.2853, 3.1308, 2.9864, 2.8648, 2.7871, 2.6697, 2.5948, 2.5367, 2.4622,\n",
      "        2.4226, 2.3134, 2.2709, 2.1860, 2.1412, 2.0580, 1.9877, 1.9326, 1.8587,\n",
      "        1.7968, 1.7352, 1.6693, 1.6083, 1.5496, 1.4972, 1.4403, 1.4049, 1.3437,\n",
      "        1.3044], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.5902, 2.5932, 2.5927, 2.5866, 2.5820, 2.5838, 2.5570, 2.5496, 2.5444,\n",
      "        2.5437, 2.5326, 2.5146, 2.4781, 2.4674, 2.4295, 2.3980, 2.3659, 2.3072,\n",
      "        2.2545, 2.2063, 2.1239, 2.0624, 1.9652, 1.8892, 1.7986, 1.7053, 1.6130,\n",
      "        1.5197, 1.4370, 1.3495, 1.2720, 1.1929, 1.1286, 1.0655, 1.0110, 0.9586,\n",
      "        0.9207, 0.8792, 0.8464, 0.8136, 0.7863, 0.7617, 0.7434, 0.7221, 0.7044,\n",
      "        0.6863, 0.6725, 0.6548, 0.6407, 0.6259, 0.6116, 0.5966, 0.5813, 0.5659,\n",
      "        0.5478], grad_fn=<AddBackward0>) tensor([6.2614, 6.2166, 6.1574, 6.1765, 6.1521, 6.0850, 6.2303, 6.2193, 6.1628,\n",
      "        6.0219, 5.9974, 5.9380, 6.0527, 5.9612, 5.9716, 5.8694, 5.7530, 5.7553,\n",
      "        5.6255, 5.4307, 5.3773, 5.1362, 5.1300, 4.8820, 4.7054, 4.5431, 4.3233,\n",
      "        4.1772, 3.9294, 3.7871, 3.5730, 3.4845, 3.2926, 3.1715, 3.0000, 2.9279,\n",
      "        2.7660, 2.6789, 2.5556, 2.5240, 2.4605, 2.4167, 2.3112, 2.2939, 2.2459,\n",
      "        2.2354, 2.1128, 2.1501, 2.0697, 2.0493, 2.0274, 1.9423, 1.9227, 1.9471,\n",
      "        2.9473], grad_fn=<AddBackward0>)\n",
      "49218.49629664421\n",
      "r0 before lock-down  tensor([3.9217, 3.9067, 3.9207, 3.9201, 3.9174, 3.9183, 3.9135, 3.9091, 3.8952,\n",
      "        3.8687, 3.8595, 3.8083, 3.7578, 3.6607, 3.5659, 3.4425, 3.3163, 3.1734,\n",
      "        3.0249, 2.8688, 2.7101, 2.5572, 2.4063, 2.2613, 2.1281, 2.0019, 1.8926,\n",
      "        1.7860, 1.6989, 1.6241, 1.5596, 1.5008, 1.4529, 1.4055, 1.3631, 1.3262,\n",
      "        1.2861, 1.2517, 1.2125, 1.1744, 1.1362, 1.0996, 1.0607, 1.0213, 0.9850,\n",
      "        0.9479, 0.9121, 0.8789, 0.8456, 0.8141, 0.7835, 0.7535, 0.7257, 0.6999,\n",
      "        0.6704], grad_fn=<AddBackward0>) tensor([6.6064, 6.6687, 6.5911, 6.5843, 6.5950, 6.5666, 6.5642, 6.5305, 6.5477,\n",
      "        6.5425, 6.4311, 6.4314, 6.2762, 6.2024, 6.0024, 5.8639, 5.6452, 5.4365,\n",
      "        5.2092, 4.9676, 4.7188, 4.4665, 4.2003, 3.9866, 3.7353, 3.5501, 3.3514,\n",
      "        3.2203, 3.0637, 2.9214, 2.8021, 2.7267, 2.6063, 2.5362, 2.4760, 2.4045,\n",
      "        2.3688, 2.2602, 2.2206, 2.1379, 2.0944, 2.0152, 1.9490, 1.8927, 1.8227,\n",
      "        1.7608, 1.7021, 1.6369, 1.5775, 1.5209, 1.4702, 1.4139, 1.3791, 1.3209,\n",
      "        1.2844], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.6193, 2.6242, 2.6230, 2.6184, 2.6127, 2.6171, 2.5888, 2.5836, 2.5778,\n",
      "        2.5741, 2.5641, 2.5470, 2.5075, 2.4958, 2.4602, 2.4278, 2.3923, 2.3350,\n",
      "        2.2779, 2.2285, 2.1471, 2.0814, 1.9817, 1.9049, 1.8105, 1.7169, 1.6210,\n",
      "        1.5266, 1.4415, 1.3516, 1.2727, 1.1924, 1.1269, 1.0624, 1.0074, 0.9541,\n",
      "        0.9155, 0.8733, 0.8403, 0.8072, 0.7795, 0.7546, 0.7362, 0.7149, 0.6970,\n",
      "        0.6790, 0.6653, 0.6476, 0.6336, 0.6187, 0.6046, 0.5898, 0.5746, 0.5593,\n",
      "        0.5414], grad_fn=<AddBackward0>) tensor([6.3284, 6.2633, 6.2099, 6.2212, 6.1989, 6.1122, 6.2682, 6.2371, 6.1874,\n",
      "        6.0641, 6.0310, 5.9617, 6.0925, 6.0048, 5.9928, 5.8861, 5.7892, 5.7687,\n",
      "        5.6631, 5.4657, 5.3849, 5.1597, 5.1590, 4.8889, 4.7263, 4.5428, 4.3359,\n",
      "        4.1724, 3.9266, 3.7877, 3.5726, 3.4754, 3.2800, 3.1637, 2.9821, 2.9119,\n",
      "        2.7484, 2.6611, 2.5323, 2.5018, 2.4379, 2.3961, 2.2891, 2.2682, 2.2240,\n",
      "        2.2144, 2.0901, 2.1272, 2.0460, 2.0313, 2.0048, 1.9216, 1.9082, 1.9311,\n",
      "        3.0162], grad_fn=<AddBackward0>)\n",
      "50851.07790184021\n",
      "r0 before lock-down  tensor([3.9833, 3.9655, 3.9825, 3.9815, 3.9767, 3.9789, 3.9741, 3.9696, 3.9514,\n",
      "        3.9250, 3.9158, 3.8635, 3.8086, 3.7034, 3.6036, 3.4709, 3.3371, 3.1851,\n",
      "        3.0295, 2.8647, 2.6982, 2.5393, 2.3830, 2.2340, 2.0968, 1.9689, 1.8582,\n",
      "        1.7509, 1.6636, 1.5889, 1.5249, 1.4670, 1.4197, 1.3734, 1.3321, 1.2962,\n",
      "        1.2573, 1.2238, 1.1858, 1.1490, 1.1120, 1.0765, 1.0388, 1.0006, 0.9654,\n",
      "        0.9293, 0.8945, 0.8622, 0.8299, 0.7992, 0.7693, 0.7402, 0.7130, 0.6879,\n",
      "        0.6591], grad_fn=<AddBackward0>) tensor([6.6795, 6.7562, 6.6636, 6.6596, 6.6789, 6.6417, 6.6379, 6.6032, 6.6365,\n",
      "        6.6238, 6.5027, 6.4921, 6.3319, 6.2573, 6.0390, 5.8998, 5.6670, 5.4513,\n",
      "        5.2020, 4.9534, 4.6957, 4.4310, 4.1550, 3.9320, 3.6828, 3.4892, 3.2876,\n",
      "        3.1560, 3.0002, 2.8593, 2.7413, 2.6650, 2.5504, 2.4797, 2.4219, 2.3493,\n",
      "        2.3154, 2.2118, 2.1741, 2.0932, 2.0517, 1.9752, 1.9103, 1.8545, 1.7877,\n",
      "        1.7280, 1.6700, 1.6079, 1.5477, 1.4946, 1.4448, 1.3896, 1.3551, 1.2996,\n",
      "        1.2658], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.6255, 2.6307, 2.6280, 2.6268, 2.6169, 2.6248, 2.5965, 2.5912, 2.5865,\n",
      "        2.5812, 2.5696, 2.5517, 2.5163, 2.5038, 2.4656, 2.4326, 2.3988, 2.3405,\n",
      "        2.2824, 2.2277, 2.1475, 2.0811, 1.9794, 1.9037, 1.8090, 1.7109, 1.6144,\n",
      "        1.5179, 1.4339, 1.3428, 1.2633, 1.1827, 1.1161, 1.0518, 0.9967, 0.9428,\n",
      "        0.9044, 0.8624, 0.8294, 0.7958, 0.7688, 0.7438, 0.7257, 0.7046, 0.6868,\n",
      "        0.6691, 0.6557, 0.6383, 0.6244, 0.6098, 0.5960, 0.5814, 0.5664, 0.5512,\n",
      "        0.5336], grad_fn=<AddBackward0>) tensor([6.3154, 6.2455, 6.2073, 6.1911, 6.1983, 6.0856, 6.2430, 6.2123, 6.1532,\n",
      "        6.0396, 6.0190, 5.9560, 6.0489, 5.9717, 5.9716, 5.8633, 5.7476, 5.7334,\n",
      "        5.6275, 5.4667, 5.3640, 5.1353, 5.1421, 4.8454, 4.6710, 4.5237, 4.3131,\n",
      "        4.1626, 3.8880, 3.7554, 3.5415, 3.4358, 3.2539, 3.1269, 2.9410, 2.8803,\n",
      "        2.7106, 2.6197, 2.4895, 2.4739, 2.3987, 2.3664, 2.2567, 2.2365, 2.1972,\n",
      "        2.1832, 2.0571, 2.0986, 2.0205, 2.0083, 1.9765, 1.8982, 1.8835, 1.9107,\n",
      "        3.0809], grad_fn=<AddBackward0>)\n",
      "58825.0058927536\n",
      "r0 before lock-down  tensor([4.0457, 4.0293, 4.0476, 4.0443, 4.0380, 4.0394, 4.0371, 4.0307, 4.0133,\n",
      "        3.9848, 3.9743, 3.9172, 3.8599, 3.7475, 3.6420, 3.5012, 3.3586, 3.1959,\n",
      "        3.0346, 2.8597, 2.6860, 2.5209, 2.3598, 2.2063, 2.0654, 1.9361, 1.8237,\n",
      "        1.7162, 1.6289, 1.5545, 1.4908, 1.4340, 1.3877, 1.3423, 1.3020, 1.2671,\n",
      "        1.2293, 1.1970, 1.1601, 1.1243, 1.0886, 1.0543, 1.0177, 0.9806, 0.9465,\n",
      "        0.9114, 0.8777, 0.8462, 0.8148, 0.7849, 0.7558, 0.7274, 0.7009, 0.6764,\n",
      "        0.6483], grad_fn=<AddBackward0>) tensor([6.7596, 6.8287, 6.7309, 6.7400, 6.7635, 6.7300, 6.7084, 6.6829, 6.7063,\n",
      "        6.6970, 6.5720, 6.5708, 6.3944, 6.3126, 6.0767, 5.9293, 5.6863, 5.4694,\n",
      "        5.1895, 4.9419, 4.6712, 4.3954, 4.1073, 3.8795, 3.6314, 3.4280, 3.2301,\n",
      "        3.0952, 2.9395, 2.7987, 2.6860, 2.6073, 2.4928, 2.4243, 2.3682, 2.2982,\n",
      "        2.2646, 2.1637, 2.1286, 2.0507, 2.0094, 1.9359, 1.8713, 1.8205, 1.7529,\n",
      "        1.6957, 1.6390, 1.5800, 1.5204, 1.4694, 1.4204, 1.3658, 1.3328, 1.2791,\n",
      "        1.2493], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.6371, 2.6402, 2.6364, 2.6389, 2.6241, 2.6341, 2.6078, 2.6007, 2.5934,\n",
      "        2.5894, 2.5771, 2.5609, 2.5269, 2.5106, 2.4735, 2.4404, 2.4047, 2.3470,\n",
      "        2.2846, 2.2301, 2.1501, 2.0832, 1.9810, 1.9038, 1.8073, 1.7068, 1.6097,\n",
      "        1.5128, 1.4271, 1.3362, 1.2544, 1.1736, 1.1076, 1.0423, 0.9869, 0.9330,\n",
      "        0.8945, 0.8520, 0.8193, 0.7858, 0.7590, 0.7340, 0.7161, 0.6952, 0.6774,\n",
      "        0.6598, 0.6467, 0.6296, 0.6158, 0.6014, 0.5878, 0.5735, 0.5586, 0.5436,\n",
      "        0.5262], grad_fn=<AddBackward0>) tensor([6.2825, 6.2307, 6.2023, 6.1537, 6.2012, 6.0710, 6.2133, 6.1919, 6.1533,\n",
      "        6.0283, 6.0116, 5.9383, 6.0162, 5.9685, 5.9535, 5.8427, 5.7381, 5.7108,\n",
      "        5.6319, 5.4619, 5.3471, 5.1131, 5.1072, 4.8138, 4.6430, 4.5060, 4.2852,\n",
      "        4.1262, 3.8613, 3.7133, 3.5244, 3.4080, 3.2129, 3.0959, 2.9110, 2.8492,\n",
      "        2.6796, 2.6005, 2.4640, 2.4457, 2.3647, 2.3363, 2.2268, 2.2016, 2.1703,\n",
      "        2.1588, 2.0308, 2.0671, 1.9940, 1.9799, 1.9538, 1.8751, 1.8628, 1.8949,\n",
      "        3.1434], grad_fn=<AddBackward0>)\n",
      "41632.84846878052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([4.0735, 4.0584, 4.0771, 4.0728, 4.0671, 4.0671, 4.0654, 4.0584, 4.0404,\n",
      "        4.0122, 3.9992, 3.9405, 3.8784, 3.7625, 3.6494, 3.5041, 3.3529, 3.1855,\n",
      "        3.0173, 2.8351, 2.6568, 2.4870, 2.3225, 2.1669, 2.0246, 1.8951, 1.7826,\n",
      "        1.6758, 1.5890, 1.5160, 1.4535, 1.3983, 1.3530, 1.3089, 1.2700, 1.2365,\n",
      "        1.1999, 1.1690, 1.1333, 1.0989, 1.0645, 1.0313, 0.9960, 0.9600, 0.9271,\n",
      "        0.8930, 0.8604, 0.8298, 0.7994, 0.7703, 0.7420, 0.7144, 0.6885, 0.6647,\n",
      "        0.6372], grad_fn=<AddBackward0>) tensor([6.7956, 6.8570, 6.7579, 6.7715, 6.7935, 6.7639, 6.7373, 6.7138, 6.7359,\n",
      "        6.7180, 6.5981, 6.5900, 6.4172, 6.3177, 6.0844, 5.9176, 5.6774, 5.4365,\n",
      "        5.1496, 4.8997, 4.6150, 4.3355, 4.0424, 3.8114, 3.5613, 3.3532, 3.1578,\n",
      "        3.0233, 2.8732, 2.7324, 2.6205, 2.5419, 2.4315, 2.3675, 2.3106, 2.2432,\n",
      "        2.2130, 2.1121, 2.0823, 2.0043, 1.9651, 1.8953, 1.8329, 1.7835, 1.7174,\n",
      "        1.6631, 1.6073, 1.5513, 1.4917, 1.4433, 1.3948, 1.3410, 1.3104, 1.2575,\n",
      "        1.2311], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.6609, 2.6560, 2.6547, 2.6598, 2.6458, 2.6539, 2.6288, 2.6180, 2.6140,\n",
      "        2.6095, 2.5968, 2.5809, 2.5470, 2.5285, 2.4932, 2.4554, 2.4167, 2.3612,\n",
      "        2.2987, 2.2430, 2.1623, 2.0945, 1.9904, 1.9106, 1.8137, 1.7111, 1.6113,\n",
      "        1.5134, 1.4265, 1.3336, 1.2512, 1.1699, 1.1027, 1.0367, 0.9809, 0.9263,\n",
      "        0.8875, 0.8453, 0.8125, 0.7785, 0.7515, 0.7266, 0.7087, 0.6879, 0.6700,\n",
      "        0.6525, 0.6394, 0.6224, 0.6088, 0.5945, 0.5811, 0.5668, 0.5520, 0.5371,\n",
      "        0.5199], grad_fn=<AddBackward0>) tensor([6.2589, 6.2682, 6.2247, 6.1542, 6.1904, 6.0793, 6.2084, 6.2164, 6.1508,\n",
      "        6.0255, 6.0116, 5.9333, 6.0043, 5.9728, 5.9417, 5.8660, 5.7733, 5.7244,\n",
      "        5.6336, 5.4612, 5.3342, 5.0911, 5.0861, 4.8009, 4.6128, 4.4804, 4.2686,\n",
      "        4.1048, 3.8342, 3.7008, 3.5057, 3.3779, 3.1944, 3.0761, 2.8924, 2.8369,\n",
      "        2.6676, 2.5741, 2.4347, 2.4271, 2.3510, 2.3155, 2.2052, 2.1778, 2.1490,\n",
      "        2.1370, 2.0082, 2.0453, 1.9705, 1.9609, 1.9298, 1.8537, 1.8445, 1.8770,\n",
      "        3.2195], grad_fn=<AddBackward0>)\n",
      "39909.15837740898\n",
      "r0 before lock-down  tensor([4.1393, 4.1250, 4.1443, 4.1396, 4.1322, 4.1324, 4.1334, 4.1215, 4.1050,\n",
      "        4.0749, 4.0596, 3.9989, 3.9318, 3.8078, 3.6900, 3.5349, 3.3748, 3.1981,\n",
      "        3.0203, 2.8301, 2.6440, 2.4687, 2.2987, 2.1389, 1.9939, 1.8627, 1.7493,\n",
      "        1.6427, 1.5560, 1.4834, 1.4217, 1.3673, 1.3228, 1.2797, 1.2420, 1.2094,\n",
      "        1.1739, 1.1439, 1.1094, 1.0760, 1.0428, 1.0107, 0.9764, 0.9415, 0.9095,\n",
      "        0.8765, 0.8447, 0.8150, 0.7854, 0.7570, 0.7295, 0.7025, 0.6773, 0.6540,\n",
      "        0.6272], grad_fn=<AddBackward0>) tensor([6.8827, 6.9358, 6.8372, 6.8525, 6.8823, 6.8498, 6.8097, 6.8043, 6.8167,\n",
      "        6.7991, 6.6799, 6.6635, 6.4897, 6.3842, 6.1237, 5.9532, 5.6985, 5.4475,\n",
      "        5.1494, 4.8850, 4.5907, 4.2948, 3.9967, 3.7612, 3.5093, 3.2997, 3.1010,\n",
      "        2.9619, 2.8146, 2.6739, 2.5625, 2.4863, 2.3793, 2.3162, 2.2595, 2.1939,\n",
      "        2.1651, 2.0682, 2.0402, 1.9641, 1.9238, 1.8576, 1.7958, 1.7509, 1.6853,\n",
      "        1.6324, 1.5791, 1.5239, 1.4668, 1.4191, 1.3726, 1.3205, 1.2894, 1.2371,\n",
      "        1.2146], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.6836, 2.6762, 2.6776, 2.6830, 2.6667, 2.6733, 2.6525, 2.6402, 2.6376,\n",
      "        2.6314, 2.6158, 2.6046, 2.5689, 2.5475, 2.5115, 2.4758, 2.4361, 2.3793,\n",
      "        2.3161, 2.2552, 2.1767, 2.1078, 2.0011, 1.9184, 1.8209, 1.7164, 1.6144,\n",
      "        1.5154, 1.4269, 1.3332, 1.2496, 1.1665, 1.0991, 1.0326, 0.9757, 0.9212,\n",
      "        0.8814, 0.8389, 0.8057, 0.7716, 0.7447, 0.7194, 0.7015, 0.6807, 0.6630,\n",
      "        0.6455, 0.6324, 0.6155, 0.6019, 0.5878, 0.5745, 0.5603, 0.5457, 0.5309,\n",
      "        0.5138], grad_fn=<AddBackward0>) tensor([6.2677, 6.2948, 6.2324, 6.1635, 6.2115, 6.1076, 6.2102, 6.2251, 6.1444,\n",
      "        6.0350, 6.0401, 5.9233, 6.0038, 5.9960, 5.9617, 5.8646, 5.7705, 5.7252,\n",
      "        5.6301, 5.4921, 5.3307, 5.0855, 5.0856, 4.8112, 4.6119, 4.4781, 4.2726,\n",
      "        4.1010, 3.8338, 3.6868, 3.4925, 3.3745, 3.1767, 3.0513, 2.8720, 2.8047,\n",
      "        2.6494, 2.5560, 2.4160, 2.4083, 2.3232, 2.2988, 2.1875, 2.1568, 2.1256,\n",
      "        2.1135, 1.9883, 2.0262, 1.9525, 1.9401, 1.9090, 1.8379, 1.8295, 1.8612,\n",
      "        3.3104], grad_fn=<AddBackward0>)\n",
      "37317.01927661896\n",
      "r0 before lock-down  tensor([4.1748, 4.1586, 4.1819, 4.1742, 4.1671, 4.1662, 4.1660, 4.1533, 4.1388,\n",
      "        4.1069, 4.0923, 4.0268, 3.9560, 3.8275, 3.7046, 3.5398, 3.3732, 3.1895,\n",
      "        3.0034, 2.8080, 2.6158, 2.4364, 2.2637, 2.1012, 1.9551, 1.8236, 1.7108,\n",
      "        1.6046, 1.5189, 1.4476, 1.3871, 1.3340, 1.2908, 1.2491, 1.2127, 1.1812,\n",
      "        1.1470, 1.1181, 1.0849, 1.0528, 1.0208, 0.9897, 0.9566, 0.9227, 0.8919,\n",
      "        0.8598, 0.8289, 0.8002, 0.7713, 0.7438, 0.7169, 0.6906, 0.6661, 0.6434,\n",
      "        0.6172], grad_fn=<AddBackward0>) tensor([6.9177, 6.9781, 6.8617, 6.8904, 6.9194, 6.8917, 6.8564, 6.8491, 6.8516,\n",
      "        6.8341, 6.7036, 6.6957, 6.5163, 6.3973, 6.1191, 5.9543, 5.6849, 5.4217,\n",
      "        5.1223, 4.8401, 4.5428, 4.2390, 3.9313, 3.6985, 3.4448, 3.2333, 3.0306,\n",
      "        2.8965, 2.7520, 2.6121, 2.5009, 2.4281, 2.3225, 2.2607, 2.2054, 2.1429,\n",
      "        2.1184, 2.0237, 1.9962, 1.9215, 1.8836, 1.8207, 1.7618, 1.7172, 1.6524,\n",
      "        1.6008, 1.5509, 1.4971, 1.4415, 1.3947, 1.3495, 1.2986, 1.2687, 1.2170,\n",
      "        1.1995], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.6724, 2.6696, 2.6714, 2.6729, 2.6583, 2.6684, 2.6437, 2.6316, 2.6289,\n",
      "        2.6238, 2.6074, 2.5980, 2.5619, 2.5390, 2.5030, 2.4693, 2.4278, 2.3717,\n",
      "        2.3065, 2.2473, 2.1679, 2.0978, 1.9917, 1.9080, 1.8075, 1.7054, 1.6021,\n",
      "        1.5033, 1.4141, 1.3197, 1.2359, 1.1536, 1.0859, 1.0198, 0.9632, 0.9084,\n",
      "        0.8688, 0.8267, 0.7937, 0.7600, 0.7334, 0.7082, 0.6905, 0.6702, 0.6526,\n",
      "        0.6354, 0.6226, 0.6060, 0.5927, 0.5788, 0.5658, 0.5518, 0.5374, 0.5229,\n",
      "        0.5061], grad_fn=<AddBackward0>) tensor([6.2470, 6.2384, 6.1764, 6.1384, 6.1725, 6.0473, 6.1744, 6.1877, 6.1095,\n",
      "        5.9907, 5.9989, 5.8713, 5.9535, 5.9568, 5.9250, 5.8057, 5.7246, 5.6749,\n",
      "        5.5891, 5.4369, 5.2796, 5.0358, 5.0321, 4.7577, 4.5842, 4.4247, 4.2241,\n",
      "        4.0470, 3.7856, 3.6474, 3.4583, 3.3300, 3.1341, 3.0052, 2.8281, 2.7715,\n",
      "        2.6139, 2.5198, 2.3821, 2.3728, 2.2847, 2.2643, 2.1585, 2.1198, 2.0912,\n",
      "        2.0811, 1.9565, 1.9993, 1.9238, 1.9148, 1.8824, 1.8156, 1.8066, 1.8428,\n",
      "        3.3703], grad_fn=<AddBackward0>)\n",
      "31348.012029647827\n",
      "r0 before lock-down  tensor([4.2609, 4.2434, 4.2694, 4.2617, 4.2499, 4.2534, 4.2519, 4.2395, 4.2233,\n",
      "        4.1878, 4.1732, 4.1042, 4.0294, 3.8899, 3.7595, 3.5834, 3.4078, 3.2125,\n",
      "        3.0174, 2.8112, 2.6101, 2.4242, 2.2455, 2.0783, 1.9297, 1.7963, 1.6824,\n",
      "        1.5757, 1.4899, 1.4190, 1.3589, 1.3067, 1.2644, 1.2233, 1.1878, 1.1573,\n",
      "        1.1241, 1.0960, 1.0639, 1.0327, 1.0016, 0.9715, 0.9393, 0.9064, 0.8763,\n",
      "        0.8452, 0.8151, 0.7871, 0.7589, 0.7321, 0.7058, 0.6800, 0.6561, 0.6339,\n",
      "        0.6082], grad_fn=<AddBackward0>) tensor([7.0313, 7.0966, 6.9709, 6.9985, 7.0486, 6.9956, 6.9672, 6.9560, 6.9597,\n",
      "        6.9493, 6.8069, 6.7953, 6.6001, 6.4839, 6.1866, 6.0148, 5.7226, 5.4494,\n",
      "        5.1266, 4.8394, 4.5312, 4.2105, 3.8968, 3.6619, 3.3977, 3.1840, 2.9796,\n",
      "        2.8444, 2.7037, 2.5625, 2.4525, 2.3799, 2.2735, 2.2184, 2.1626, 2.1016,\n",
      "        2.0767, 1.9863, 1.9595, 1.8862, 1.8511, 1.7888, 1.7304, 1.6869, 1.6246,\n",
      "        1.5738, 1.5259, 1.4732, 1.4191, 1.3726, 1.3292, 1.2795, 1.2502, 1.2003,\n",
      "        1.1862], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.7208, 2.7216, 2.7227, 2.7229, 2.7099, 2.7137, 2.6945, 2.6792, 2.6767,\n",
      "        2.6701, 2.6530, 2.6444, 2.6073, 2.5874, 2.5446, 2.5144, 2.4692, 2.4157,\n",
      "        2.3451, 2.2852, 2.2033, 2.1309, 2.0204, 1.9347, 1.8315, 1.7275, 1.6210,\n",
      "        1.5199, 1.4274, 1.3308, 1.2440, 1.1601, 1.0907, 1.0233, 0.9654, 0.9091,\n",
      "        0.8686, 0.8255, 0.7919, 0.7577, 0.7304, 0.7047, 0.6867, 0.6661, 0.6482,\n",
      "        0.6310, 0.6179, 0.6013, 0.5880, 0.5740, 0.5611, 0.5470, 0.5327, 0.5181,\n",
      "        0.5014], grad_fn=<AddBackward0>) tensor([6.3229, 6.2885, 6.2292, 6.2043, 6.2194, 6.1431, 6.2293, 6.2612, 6.1811,\n",
      "        6.0692, 6.0814, 5.9441, 6.0288, 6.0076, 6.0186, 5.8635, 5.7964, 5.7119,\n",
      "        5.6537, 5.4897, 5.3297, 5.0843, 5.0924, 4.8042, 4.6238, 4.4501, 4.2467,\n",
      "        4.0588, 3.8051, 3.6591, 3.4795, 3.3410, 3.1403, 3.0032, 2.8216, 2.7729,\n",
      "        2.6058, 2.5179, 2.3710, 2.3561, 2.2724, 2.2553, 2.1465, 2.1061, 2.0787,\n",
      "        2.0657, 1.9453, 1.9848, 1.9108, 1.9047, 1.8696, 1.8048, 1.7924, 1.8359,\n",
      "        3.4780], grad_fn=<AddBackward0>)\n",
      "30562.301915884018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([4.3075, 4.2895, 4.3162, 4.3068, 4.2948, 4.2985, 4.2979, 4.2832, 4.2684,\n",
      "        4.2300, 4.2146, 4.1453, 4.0643, 3.9158, 3.7805, 3.5953, 3.4120, 3.2078,\n",
      "        3.0054, 2.7935, 2.5855, 2.3951, 2.2128, 2.0438, 1.8939, 1.7600, 1.6469,\n",
      "        1.5411, 1.4559, 1.3861, 1.3272, 1.2763, 1.2352, 1.1952, 1.1609, 1.1315,\n",
      "        1.0995, 1.0725, 1.0415, 1.0115, 0.9814, 0.9523, 0.9212, 0.8894, 0.8602,\n",
      "        0.8299, 0.8007, 0.7734, 0.7461, 0.7199, 0.6943, 0.6692, 0.6458, 0.6240,\n",
      "        0.5990], grad_fn=<AddBackward0>) tensor([7.0829, 7.1487, 7.0211, 7.0567, 7.1046, 7.0507, 7.0161, 7.0103, 7.0074,\n",
      "        7.0020, 6.8538, 6.8278, 6.6353, 6.5236, 6.2043, 6.0268, 5.7189, 5.4398,\n",
      "        5.1017, 4.7980, 4.4892, 4.1595, 3.8427, 3.6019, 3.3368, 3.1251, 2.9156,\n",
      "        2.7788, 2.6434, 2.5047, 2.3979, 2.3261, 2.2217, 2.1689, 2.1146, 2.0569,\n",
      "        2.0329, 1.9438, 1.9195, 1.8487, 1.8145, 1.7550, 1.6974, 1.6555, 1.5950,\n",
      "        1.5472, 1.5001, 1.4486, 1.3947, 1.3506, 1.3073, 1.2589, 1.2304, 1.1825,\n",
      "        1.1728], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.7222, 2.7216, 2.7233, 2.7246, 2.7077, 2.7119, 2.6967, 2.6806, 2.6771,\n",
      "        2.6683, 2.6558, 2.6465, 2.6092, 2.5872, 2.5429, 2.5119, 2.4670, 2.4131,\n",
      "        2.3445, 2.2846, 2.2025, 2.1271, 2.0165, 1.9298, 1.8239, 1.7204, 1.6139,\n",
      "        1.5120, 1.4188, 1.3211, 1.2342, 1.1502, 1.0807, 1.0134, 0.9555, 0.8987,\n",
      "        0.8580, 0.8155, 0.7819, 0.7478, 0.7205, 0.6948, 0.6771, 0.6566, 0.6390,\n",
      "        0.6220, 0.6091, 0.5928, 0.5796, 0.5658, 0.5531, 0.5393, 0.5252, 0.5107,\n",
      "        0.4942], grad_fn=<AddBackward0>) tensor([6.2868, 6.2637, 6.1977, 6.1662, 6.2125, 6.1330, 6.1887, 6.2221, 6.1514,\n",
      "        6.0519, 6.0326, 5.8989, 5.9852, 5.9805, 5.9989, 5.8514, 5.7786, 5.6947,\n",
      "        5.6125, 5.4409, 5.2790, 5.0529, 5.0575, 4.7655, 4.6096, 4.4203, 4.2057,\n",
      "        4.0206, 3.7666, 3.6348, 3.4508, 3.3071, 3.1046, 2.9627, 2.7808, 2.7415,\n",
      "        2.5783, 2.4797, 2.3356, 2.3193, 2.2426, 2.2313, 2.1153, 2.0781, 2.0481,\n",
      "        2.0388, 1.9156, 1.9533, 1.8825, 1.8828, 1.8495, 1.7821, 1.7692, 1.8156,\n",
      "        3.5575], grad_fn=<AddBackward0>)\n",
      "66136.94013118744\n",
      "r0 before lock-down  tensor([4.3597, 4.3389, 4.3631, 4.3560, 4.3454, 4.3478, 4.3454, 4.3283, 4.3146,\n",
      "        4.2754, 4.2570, 4.1857, 4.1002, 3.9463, 3.8020, 3.6093, 3.4180, 3.2054,\n",
      "        2.9939, 2.7762, 2.5612, 2.3672, 2.1808, 2.0102, 1.8588, 1.7248, 1.6124,\n",
      "        1.5074, 1.4233, 1.3544, 1.2968, 1.2472, 1.2073, 1.1685, 1.1352, 1.1070,\n",
      "        1.0760, 1.0502, 1.0202, 0.9912, 0.9623, 0.9341, 0.9041, 0.8732, 0.8449,\n",
      "        0.8155, 0.7871, 0.7606, 0.7339, 0.7085, 0.6835, 0.6589, 0.6361, 0.6149,\n",
      "        0.5904], grad_fn=<AddBackward0>) tensor([7.1122, 7.1873, 7.0734, 7.0941, 7.1397, 7.0875, 7.0591, 7.0634, 7.0549,\n",
      "        7.0414, 6.8971, 6.8630, 6.6676, 6.5385, 6.2193, 6.0279, 5.7028, 5.4143,\n",
      "        5.0743, 4.7540, 4.4441, 4.1019, 3.7847, 3.5394, 3.2782, 3.0655, 2.8534,\n",
      "        2.7203, 2.5832, 2.4512, 2.3442, 2.2733, 2.1707, 2.1209, 2.0698, 2.0120,\n",
      "        1.9929, 1.9038, 1.8826, 1.8121, 1.7806, 1.7220, 1.6652, 1.6253, 1.5676,\n",
      "        1.5220, 1.4752, 1.4260, 1.3726, 1.3293, 1.2877, 1.2403, 1.2128, 1.1658,\n",
      "        1.1600], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.7313, 2.7321, 2.7323, 2.7340, 2.7150, 2.7189, 2.7042, 2.6887, 2.6849,\n",
      "        2.6745, 2.6620, 2.6541, 2.6172, 2.5942, 2.5514, 2.5203, 2.4739, 2.4178,\n",
      "        2.3520, 2.2904, 2.2068, 2.1307, 2.0202, 1.9277, 1.8229, 1.7188, 1.6123,\n",
      "        1.5085, 1.4156, 1.3168, 1.2287, 1.1442, 1.0742, 1.0068, 0.9491, 0.8915,\n",
      "        0.8507, 0.8085, 0.7747, 0.7404, 0.7131, 0.6874, 0.6698, 0.6491, 0.6318,\n",
      "        0.6147, 0.6020, 0.5858, 0.5727, 0.5591, 0.5465, 0.5327, 0.5187, 0.5043,\n",
      "        0.4880], grad_fn=<AddBackward0>) tensor([6.2606, 6.2339, 6.1735, 6.1458, 6.2014, 6.1256, 6.1786, 6.2081, 6.1379,\n",
      "        6.0510, 6.0282, 5.8830, 5.9667, 5.9648, 5.9694, 5.8248, 5.7571, 5.6878,\n",
      "        5.5770, 5.4095, 5.2564, 5.0292, 5.0236, 4.7758, 4.5967, 4.4025, 4.1751,\n",
      "        4.0056, 3.7385, 3.6070, 3.4361, 3.2954, 3.0941, 2.9457, 2.7554, 2.7297,\n",
      "        2.5639, 2.4553, 2.3063, 2.2992, 2.2213, 2.2131, 2.0921, 2.0625, 2.0231,\n",
      "        2.0173, 1.8920, 1.9350, 1.8634, 1.8603, 1.8276, 1.7650, 1.7531, 1.8003,\n",
      "        3.6223], grad_fn=<AddBackward0>)\n",
      "32660.885251045227\n",
      "r0 before lock-down  tensor([4.3998, 4.3782, 4.4032, 4.3970, 4.3856, 4.3896, 4.3843, 4.3682, 4.3501,\n",
      "        4.3082, 4.2918, 4.2183, 4.1294, 3.9692, 3.8177, 3.6165, 3.4161, 3.1969,\n",
      "        2.9793, 2.7552, 2.5340, 2.3357, 2.1472, 1.9748, 1.8232, 1.6893, 1.5775,\n",
      "        1.4738, 1.3909, 1.3232, 1.2667, 1.2186, 1.1799, 1.1423, 1.1102, 1.0829,\n",
      "        1.0532, 1.0284, 0.9995, 0.9716, 0.9437, 0.9166, 0.8874, 0.8575, 0.8300,\n",
      "        0.8015, 0.7739, 0.7482, 0.7222, 0.6974, 0.6730, 0.6490, 0.6267, 0.6060,\n",
      "        0.5821], grad_fn=<AddBackward0>) tensor([7.1468, 7.2260, 7.1077, 7.1274, 7.1766, 7.1130, 7.0934, 7.0953, 7.1001,\n",
      "        7.0924, 6.9310, 6.8930, 6.6873, 6.5494, 6.2226, 6.0244, 5.6959, 5.3882,\n",
      "        5.0314, 4.7046, 4.3939, 4.0496, 3.7247, 3.4810, 3.2167, 3.0043, 2.7945,\n",
      "        2.6598, 2.5264, 2.3970, 2.2939, 2.2231, 2.1213, 2.0735, 2.0242, 1.9708,\n",
      "        1.9525, 1.8662, 1.8459, 1.7770, 1.7475, 1.6893, 1.6363, 1.5968, 1.5412,\n",
      "        1.4976, 1.4514, 1.4042, 1.3514, 1.3083, 1.2689, 1.2225, 1.1954, 1.1500,\n",
      "        1.1475], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.7784, 2.7814, 2.7822, 2.7788, 2.7599, 2.7660, 2.7490, 2.7358, 2.7306,\n",
      "        2.7213, 2.7078, 2.6991, 2.6625, 2.6383, 2.5946, 2.5642, 2.5151, 2.4591,\n",
      "        2.3906, 2.3279, 2.2430, 2.1628, 2.0513, 1.9539, 1.8464, 1.7404, 1.6321,\n",
      "        1.5254, 1.4296, 1.3282, 1.2383, 1.1522, 1.0797, 1.0113, 0.9524, 0.8937,\n",
      "        0.8517, 0.8089, 0.7745, 0.7392, 0.7114, 0.6853, 0.6673, 0.6464, 0.6289,\n",
      "        0.6115, 0.5986, 0.5822, 0.5691, 0.5554, 0.5427, 0.5288, 0.5148, 0.5003,\n",
      "        0.4841], grad_fn=<AddBackward0>) tensor([6.3240, 6.2870, 6.2182, 6.2288, 6.2814, 6.1895, 6.2569, 6.2692, 6.2087,\n",
      "        6.1078, 6.0951, 5.9483, 6.0254, 6.0305, 6.0332, 5.8741, 5.8180, 5.7363,\n",
      "        5.6325, 5.4563, 5.2943, 5.0786, 5.0545, 4.8241, 4.6400, 4.4382, 4.1899,\n",
      "        4.0225, 3.7591, 3.6272, 3.4499, 3.3013, 3.1143, 2.9522, 2.7590, 2.7293,\n",
      "        2.5665, 2.4500, 2.2994, 2.3019, 2.2202, 2.2094, 2.0900, 2.0544, 2.0154,\n",
      "        2.0121, 1.8873, 1.9257, 1.8491, 1.8470, 1.8150, 1.7585, 1.7456, 1.7964,\n",
      "        3.7657], grad_fn=<AddBackward0>)\n",
      "29973.73808979988\n",
      "r0 before lock-down  tensor([4.4910, 4.4729, 4.4975, 4.4917, 4.4791, 4.4820, 4.4778, 4.4579, 4.4414,\n",
      "        4.3978, 4.3816, 4.3022, 4.2076, 4.0367, 3.8765, 3.6614, 3.4512, 3.2211,\n",
      "        2.9917, 2.7586, 2.5275, 2.3225, 2.1292, 1.9529, 1.7989, 1.6633, 1.5512,\n",
      "        1.4472, 1.3646, 1.2973, 1.2415, 1.1943, 1.1562, 1.1194, 1.0881, 1.0618,\n",
      "        1.0329, 1.0088, 0.9809, 0.9538, 0.9267, 0.9004, 0.8722, 0.8430, 0.8163,\n",
      "        0.7885, 0.7617, 0.7366, 0.7113, 0.6871, 0.6632, 0.6398, 0.6179, 0.5976,\n",
      "        0.5742], grad_fn=<AddBackward0>) tensor([7.2777, 7.3403, 7.2242, 7.2438, 7.2985, 7.2344, 7.2074, 7.2245, 7.2154,\n",
      "        7.2034, 7.0335, 6.9956, 6.7825, 6.6388, 6.2899, 6.0907, 5.7385, 5.4092,\n",
      "        5.0431, 4.6964, 4.3824, 4.0265, 3.6891, 3.4414, 3.1706, 2.9589, 2.7435,\n",
      "        2.6123, 2.4814, 2.3511, 2.2506, 2.1774, 2.0785, 2.0332, 1.9866, 1.9323,\n",
      "        1.9157, 1.8325, 1.8108, 1.7461, 1.7162, 1.6603, 1.6076, 1.5703, 1.5168,\n",
      "        1.4726, 1.4295, 1.3833, 1.3319, 1.2894, 1.2508, 1.2053, 1.1793, 1.1350,\n",
      "        1.1363], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.7614, 2.7659, 2.7687, 2.7591, 2.7472, 2.7505, 2.7343, 2.7200, 2.7154,\n",
      "        2.7070, 2.6913, 2.6844, 2.6473, 2.6252, 2.5795, 2.5484, 2.5011, 2.4429,\n",
      "        2.3746, 2.3129, 2.2273, 2.1477, 2.0355, 1.9400, 1.8294, 1.7260, 1.6172,\n",
      "        1.5108, 1.4139, 1.3141, 1.2243, 1.1388, 1.0663, 0.9981, 0.9394, 0.8811,\n",
      "        0.8394, 0.7968, 0.7625, 0.7277, 0.7004, 0.6744, 0.6566, 0.6363, 0.6189,\n",
      "        0.6016, 0.5891, 0.5731, 0.5601, 0.5467, 0.5343, 0.5207, 0.5069, 0.4927,\n",
      "        0.4767], grad_fn=<AddBackward0>) tensor([6.2692, 6.2191, 6.1400, 6.1925, 6.1942, 6.1268, 6.1875, 6.2093, 6.1461,\n",
      "        6.0387, 6.0406, 5.8836, 5.9615, 5.9531, 5.9720, 5.8243, 5.7488, 5.6930,\n",
      "        5.5867, 5.4049, 5.2473, 5.0287, 5.0097, 4.7615, 4.6124, 4.3860, 4.1454,\n",
      "        3.9742, 3.7284, 3.5799, 3.4026, 3.2501, 3.0670, 2.9078, 2.7164, 2.6873,\n",
      "        2.5246, 2.4118, 2.2696, 2.2705, 2.1818, 2.1762, 2.0596, 2.0157, 1.9807,\n",
      "        1.9833, 1.8571, 1.8941, 1.8255, 1.8241, 1.7915, 1.7363, 1.7254, 1.7758,\n",
      "        3.8600], grad_fn=<AddBackward0>)\n",
      "23955.859045267105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([4.4985, 4.4773, 4.5007, 4.4967, 4.4850, 4.4867, 4.4830, 4.4592, 4.4452,\n",
      "        4.4025, 4.3819, 4.3023, 4.2042, 4.0250, 3.8622, 3.6424, 3.4245, 3.1905,\n",
      "        2.9560, 2.7190, 2.4866, 2.2794, 2.0857, 1.9100, 1.7575, 1.6232, 1.5125,\n",
      "        1.4107, 1.3298, 1.2645, 1.2103, 1.1647, 1.1281, 1.0928, 1.0628, 1.0375,\n",
      "        1.0100, 0.9869, 0.9603, 0.9342, 0.9082, 0.8829, 0.8557, 0.8275, 0.8017,\n",
      "        0.7748, 0.7487, 0.7243, 0.6998, 0.6762, 0.6529, 0.6301, 0.6088, 0.5889,\n",
      "        0.5661], grad_fn=<AddBackward0>) tensor([7.2544, 7.3286, 7.2177, 7.2295, 7.2782, 7.2194, 7.1895, 7.2239, 7.1997,\n",
      "        7.1762, 7.0188, 6.9714, 6.7582, 6.6241, 6.2532, 6.0418, 5.6922, 5.3493,\n",
      "        4.9789, 4.6282, 4.3024, 3.9509, 3.6136, 3.3682, 3.0935, 2.8868, 2.6794,\n",
      "        2.5463, 2.4213, 2.2929, 2.1959, 2.1234, 2.0291, 1.9840, 1.9410, 1.8908,\n",
      "        1.8736, 1.7945, 1.7729, 1.7118, 1.6827, 1.6298, 1.5782, 1.5417, 1.4902,\n",
      "        1.4479, 1.4069, 1.3619, 1.3106, 1.2692, 1.2322, 1.1871, 1.1628, 1.1197,\n",
      "        1.1252], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.7664, 2.7651, 2.7710, 2.7612, 2.7491, 2.7514, 2.7378, 2.7201, 2.7146,\n",
      "        2.7074, 2.6913, 2.6879, 2.6480, 2.6259, 2.5803, 2.5521, 2.5033, 2.4430,\n",
      "        2.3743, 2.3128, 2.2264, 2.1457, 2.0324, 1.9370, 1.8251, 1.7225, 1.6123,\n",
      "        1.5046, 1.4076, 1.3082, 1.2174, 1.1315, 1.0584, 0.9902, 0.9314, 0.8733,\n",
      "        0.8315, 0.7890, 0.7543, 0.7198, 0.6923, 0.6665, 0.6487, 0.6285, 0.6112,\n",
      "        0.5940, 0.5817, 0.5660, 0.5529, 0.5399, 0.5276, 0.5141, 0.5005, 0.4863,\n",
      "        0.4706], grad_fn=<AddBackward0>) tensor([6.2216, 6.2119, 6.1118, 6.1631, 6.1667, 6.1057, 6.1495, 6.1956, 6.1404,\n",
      "        6.0222, 6.0280, 5.8468, 5.9407, 5.9315, 5.9506, 5.7821, 5.7167, 5.6713,\n",
      "        5.5652, 5.3796, 5.2224, 5.0083, 4.9960, 4.7378, 4.5921, 4.3538, 4.1211,\n",
      "        3.9562, 3.7053, 3.5447, 3.3774, 3.2255, 3.0500, 2.8874, 2.6972, 2.6610,\n",
      "        2.4988, 2.3810, 2.2471, 2.2431, 2.1585, 2.1514, 2.0351, 1.9914, 1.9585,\n",
      "        1.9674, 1.8349, 1.8668, 1.8102, 1.8014, 1.7707, 1.7188, 1.7097, 1.7635,\n",
      "        3.9630], grad_fn=<AddBackward0>)\n",
      "35452.01892352104\n",
      "r0 before lock-down  tensor([4.5684, 4.5458, 4.5698, 4.5649, 4.5526, 4.5514, 4.5520, 4.5244, 4.5091,\n",
      "        4.4646, 4.4438, 4.3606, 4.2573, 4.0683, 3.8972, 3.6678, 3.4429, 3.1978,\n",
      "        2.9529, 2.7091, 2.4702, 2.2585, 2.0603, 1.8827, 1.7290, 1.5944, 1.4841,\n",
      "        1.3828, 1.3028, 1.2384, 1.1851, 1.1406, 1.1048, 1.0704, 1.0415, 1.0170,\n",
      "        0.9904, 0.9683, 0.9424, 0.9173, 0.8922, 0.8676, 0.8412, 0.8138, 0.7888,\n",
      "        0.7626, 0.7372, 0.7135, 0.6895, 0.6666, 0.6437, 0.6214, 0.6005, 0.5811,\n",
      "        0.5587], grad_fn=<AddBackward0>) tensor([7.3153, 7.3940, 7.2841, 7.2956, 7.3483, 7.3012, 7.2487, 7.2988, 7.2716,\n",
      "        7.2514, 7.0813, 7.0329, 6.8118, 6.6728, 6.2937, 6.0682, 5.6915, 5.3418,\n",
      "        4.9689, 4.6026, 4.2684, 3.9051, 3.5713, 3.3181, 3.0428, 2.8357, 2.6264,\n",
      "        2.4968, 2.3731, 2.2463, 2.1518, 2.0784, 1.9889, 1.9461, 1.9012, 1.8546,\n",
      "        1.8371, 1.7611, 1.7417, 1.6818, 1.6526, 1.6025, 1.5520, 1.5168, 1.4663,\n",
      "        1.4247, 1.3862, 1.3419, 1.2921, 1.2509, 1.2158, 1.1710, 1.1477, 1.1052,\n",
      "        1.1158], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.7851, 2.7854, 2.7928, 2.7794, 2.7722, 2.7690, 2.7566, 2.7393, 2.7312,\n",
      "        2.7268, 2.7111, 2.7056, 2.6685, 2.6431, 2.5985, 2.5707, 2.5207, 2.4562,\n",
      "        2.3903, 2.3280, 2.2368, 2.1562, 2.0430, 1.9464, 1.8325, 1.7280, 1.6160,\n",
      "        1.5075, 1.4104, 1.3097, 1.2166, 1.1304, 1.0557, 0.9877, 0.9278, 0.8693,\n",
      "        0.8271, 0.7847, 0.7492, 0.7145, 0.6869, 0.6610, 0.6431, 0.6227, 0.6052,\n",
      "        0.5882, 0.5758, 0.5602, 0.5472, 0.5341, 0.5220, 0.5085, 0.4950, 0.4809,\n",
      "        0.4652], grad_fn=<AddBackward0>) tensor([6.2315, 6.2121, 6.1061, 6.1750, 6.1453, 6.1226, 6.1615, 6.2013, 6.1627,\n",
      "        6.0274, 6.0261, 5.8637, 5.9297, 5.9471, 5.9527, 5.7754, 5.7190, 5.7022,\n",
      "        5.5617, 5.3753, 5.2480, 5.0270, 4.9956, 4.7326, 4.5926, 4.3572, 4.1275,\n",
      "        3.9528, 3.6843, 3.5200, 3.3775, 3.2128, 3.0580, 2.8712, 2.6914, 2.6530,\n",
      "        2.4860, 2.3551, 2.2328, 2.2262, 2.1386, 2.1300, 2.0123, 1.9749, 1.9433,\n",
      "        1.9458, 1.8181, 1.8488, 1.7913, 1.7862, 1.7505, 1.7039, 1.6957, 1.7509,\n",
      "        4.0843], grad_fn=<AddBackward0>)\n",
      "37873.096364974976\n",
      "r0 before lock-down  tensor([4.6358, 4.6110, 4.6377, 4.6344, 4.6159, 4.6157, 4.6182, 4.5876, 4.5723,\n",
      "        4.5252, 4.5034, 4.4185, 4.3088, 4.1096, 3.9314, 3.6920, 3.4575, 3.2048,\n",
      "        2.9495, 2.6968, 2.4530, 2.2365, 2.0346, 1.8553, 1.7005, 1.5656, 1.4559,\n",
      "        1.3551, 1.2758, 1.2124, 1.1601, 1.1167, 1.0817, 1.0483, 1.0204, 0.9967,\n",
      "        0.9710, 0.9497, 0.9248, 0.9004, 0.8762, 0.8525, 0.8269, 0.8002, 0.7760,\n",
      "        0.7505, 0.7258, 0.7027, 0.6793, 0.6569, 0.6347, 0.6128, 0.5924, 0.5734,\n",
      "        0.5515], grad_fn=<AddBackward0>) tensor([7.3834, 7.4678, 7.3499, 7.3524, 7.4301, 7.3801, 7.3167, 7.3774, 7.3436,\n",
      "        7.3255, 7.1491, 7.0902, 6.8677, 6.7277, 6.3294, 6.0944, 5.7032, 5.3280,\n",
      "        4.9530, 4.5839, 4.2317, 3.8614, 3.5262, 3.2666, 2.9905, 2.7844, 2.5725,\n",
      "        2.4461, 2.3260, 2.1996, 2.1065, 2.0347, 1.9481, 1.9072, 1.8612, 1.8174,\n",
      "        1.8006, 1.7282, 1.7089, 1.6512, 1.6225, 1.5745, 1.5272, 1.4933, 1.4434,\n",
      "        1.4026, 1.3653, 1.3218, 1.2743, 1.2342, 1.1991, 1.1554, 1.1323, 1.0922,\n",
      "        1.1066], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.8328, 2.8363, 2.8417, 2.8289, 2.8222, 2.8188, 2.8058, 2.7887, 2.7779,\n",
      "        2.7755, 2.7588, 2.7518, 2.7165, 2.6879, 2.6440, 2.6171, 2.5642, 2.4980,\n",
      "        2.4305, 2.3692, 2.2715, 2.1897, 2.0741, 1.9774, 1.8583, 1.7509, 1.6352,\n",
      "        1.5252, 1.4250, 1.3224, 1.2265, 1.1383, 1.0623, 0.9929, 0.9315, 0.8718,\n",
      "        0.8284, 0.7850, 0.7490, 0.7138, 0.6854, 0.6588, 0.6406, 0.6199, 0.6022,\n",
      "        0.5850, 0.5722, 0.5565, 0.5435, 0.5303, 0.5182, 0.5046, 0.4910, 0.4769,\n",
      "        0.4613], grad_fn=<AddBackward0>) tensor([6.3112, 6.2713, 6.1806, 6.2399, 6.2061, 6.1848, 6.2284, 6.2626, 6.2386,\n",
      "        6.0920, 6.0926, 5.9387, 5.9889, 6.0239, 6.0212, 5.8234, 5.7791, 5.7659,\n",
      "        5.6216, 5.4060, 5.3124, 5.0793, 5.0415, 4.7474, 4.6253, 4.3891, 4.1630,\n",
      "        3.9709, 3.7080, 3.5343, 3.3981, 3.2309, 3.0654, 2.8702, 2.6932, 2.6539,\n",
      "        2.4870, 2.3596, 2.2287, 2.2151, 2.1317, 2.1303, 2.0057, 1.9622, 1.9301,\n",
      "        1.9296, 1.8096, 1.8415, 1.7765, 1.7776, 1.7387, 1.6982, 1.6927, 1.7477,\n",
      "        4.2253], grad_fn=<AddBackward0>)\n",
      "20827.26254916191\n",
      "r0 before lock-down  tensor([4.6755, 4.6509, 4.6750, 4.6741, 4.6555, 4.6568, 4.6584, 4.6261, 4.6129,\n",
      "        4.5584, 4.5401, 4.4530, 4.3384, 4.1313, 3.9464, 3.6960, 3.4547, 3.1943,\n",
      "        2.9346, 2.6740, 2.4266, 2.2075, 2.0025, 1.8232, 1.6685, 1.5338, 1.4250,\n",
      "        1.3258, 1.2477, 1.1855, 1.1346, 1.0923, 1.0585, 1.0261, 0.9992, 0.9764,\n",
      "        0.9517, 0.9313, 0.9074, 0.8839, 0.8605, 0.8376, 0.8128, 0.7870, 0.7635,\n",
      "        0.7387, 0.7147, 0.6922, 0.6694, 0.6476, 0.6258, 0.6045, 0.5845, 0.5659,\n",
      "        0.5445], grad_fn=<AddBackward0>) tensor([7.4219, 7.5019, 7.3999, 7.3903, 7.4670, 7.4125, 7.3499, 7.4151, 7.3688,\n",
      "        7.3745, 7.1749, 7.1079, 6.8838, 6.7398, 6.3309, 6.0991, 5.6907, 5.3080,\n",
      "        4.9084, 4.5430, 4.1814, 3.8023, 3.4746, 3.2078, 2.9301, 2.7329, 2.5228,\n",
      "        2.3949, 2.2784, 2.1529, 2.0604, 1.9924, 1.9053, 1.8673, 1.8221, 1.7814,\n",
      "        1.7665, 1.6948, 1.6769, 1.6208, 1.5951, 1.5486, 1.5024, 1.4696, 1.4212,\n",
      "        1.3815, 1.3447, 1.3031, 1.2573, 1.2175, 1.1831, 1.1402, 1.1181, 1.0787,\n",
      "        1.0978], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.8554, 2.8590, 2.8619, 2.8454, 2.8413, 2.8411, 2.8268, 2.8098, 2.8002,\n",
      "        2.7940, 2.7758, 2.7698, 2.7363, 2.7066, 2.6599, 2.6357, 2.5830, 2.5135,\n",
      "        2.4473, 2.3795, 2.2871, 2.2025, 2.0840, 1.9860, 1.8680, 1.7562, 1.6394,\n",
      "        1.5294, 1.4263, 1.3232, 1.2264, 1.1377, 1.0604, 0.9902, 0.9285, 0.8682,\n",
      "        0.8246, 0.7807, 0.7443, 0.7091, 0.6802, 0.6536, 0.6352, 0.6144, 0.5968,\n",
      "        0.5794, 0.5667, 0.5510, 0.5382, 0.5249, 0.5130, 0.4994, 0.4859, 0.4717,\n",
      "        0.4563], grad_fn=<AddBackward0>) tensor([6.3033, 6.2615, 6.1879, 6.2708, 6.2160, 6.1709, 6.2231, 6.2595, 6.2236,\n",
      "        6.1021, 6.1149, 5.9524, 5.9844, 6.0297, 6.0426, 5.8206, 5.7706, 5.7749,\n",
      "        5.6137, 5.4434, 5.2946, 5.0713, 5.0451, 4.7478, 4.5975, 4.3952, 4.1610,\n",
      "        3.9526, 3.7099, 3.5295, 3.3907, 3.2173, 3.0611, 2.8705, 2.6820, 2.6452,\n",
      "        2.4730, 2.3438, 2.2120, 2.1951, 2.1165, 2.1119, 1.9855, 1.9456, 1.9103,\n",
      "        1.9179, 1.7974, 1.8281, 1.7595, 1.7643, 1.7208, 1.6876, 1.6808, 1.7434,\n",
      "        4.3582], grad_fn=<AddBackward0>)\n",
      "18288.141140937805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([4.7664, 4.7370, 4.7637, 4.7608, 4.7483, 4.7456, 4.7448, 4.7107, 4.6987,\n",
      "        4.6428, 4.6222, 4.5311, 4.4096, 4.1928, 3.9996, 3.7382, 3.4852, 3.2129,\n",
      "        2.9418, 2.6741, 2.4176, 2.1939, 1.9842, 1.8020, 1.6461, 1.5102, 1.4016,\n",
      "        1.3026, 1.2250, 1.1637, 1.1132, 1.0717, 1.0387, 1.0070, 0.9809, 0.9588,\n",
      "        0.9349, 0.9151, 0.8920, 0.8692, 0.8465, 0.8243, 0.8003, 0.7751, 0.7522,\n",
      "        0.7281, 0.7047, 0.6828, 0.6605, 0.6391, 0.6178, 0.5969, 0.5773, 0.5591,\n",
      "        0.5380], grad_fn=<AddBackward0>) tensor([7.5226, 7.6208, 7.5082, 7.5083, 7.5588, 7.5193, 7.4655, 7.5315, 7.4778,\n",
      "        7.4756, 7.2765, 7.2076, 6.9752, 6.8209, 6.3910, 6.1412, 5.7198, 5.3243,\n",
      "        4.9171, 4.5257, 4.1653, 3.7689, 3.4412, 3.1735, 2.8874, 2.6942, 2.4792,\n",
      "        2.3547, 2.2376, 2.1110, 2.0235, 1.9552, 1.8693, 1.8331, 1.7897, 1.7499,\n",
      "        1.7359, 1.6657, 1.6491, 1.5939, 1.5697, 1.5250, 1.4804, 1.4480, 1.4012,\n",
      "        1.3612, 1.3264, 1.2852, 1.2411, 1.2022, 1.1685, 1.1261, 1.1049, 1.0664,\n",
      "        1.0905], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.8432, 2.8476, 2.8523, 2.8332, 2.8307, 2.8294, 2.8149, 2.8010, 2.7873,\n",
      "        2.7836, 2.7641, 2.7572, 2.7268, 2.6977, 2.6508, 2.6243, 2.5741, 2.5042,\n",
      "        2.4371, 2.3686, 2.2780, 2.1914, 2.0756, 1.9751, 1.8585, 1.7453, 1.6293,\n",
      "        1.5188, 1.4155, 1.3118, 1.2158, 1.1270, 1.0500, 0.9806, 0.9190, 0.8584,\n",
      "        0.8149, 0.7714, 0.7349, 0.7000, 0.6713, 0.6449, 0.6265, 0.6061, 0.5885,\n",
      "        0.5714, 0.5588, 0.5433, 0.5307, 0.5176, 0.5058, 0.4925, 0.4792, 0.4652,\n",
      "        0.4500], grad_fn=<AddBackward0>) tensor([6.2666, 6.2143, 6.1330, 6.2325, 6.1652, 6.1272, 6.1831, 6.1979, 6.1907,\n",
      "        6.0526, 6.0760, 5.9191, 5.9330, 5.9731, 5.9864, 5.7819, 5.7152, 5.7247,\n",
      "        5.5705, 5.4088, 5.2441, 5.0360, 4.9874, 4.7092, 4.5441, 4.3597, 4.1181,\n",
      "        3.9145, 3.6761, 3.5085, 3.3583, 3.1920, 3.0331, 2.8317, 2.6468, 2.6215,\n",
      "        2.4505, 2.3163, 2.1899, 2.1686, 2.0925, 2.0836, 1.9643, 1.9168, 1.8871,\n",
      "        1.8903, 1.7750, 1.8049, 1.7361, 1.7436, 1.7017, 1.6703, 1.6619, 1.7285,\n",
      "        4.4878], grad_fn=<AddBackward0>)\n",
      "20312.822936058044\n",
      "r0 before lock-down  tensor([4.7130, 4.6839, 4.7079, 4.7046, 4.6928, 4.6929, 4.6916, 4.6565, 4.6428,\n",
      "        4.5870, 4.5652, 4.4729, 4.3498, 4.1316, 3.9381, 3.6787, 3.4204, 3.1489,\n",
      "        2.8794, 2.6128, 2.3577, 2.1368, 1.9299, 1.7516, 1.5994, 1.4668, 1.3614,\n",
      "        1.2654, 1.1906, 1.1318, 1.0832, 1.0435, 1.0122, 0.9821, 0.9572, 0.9364,\n",
      "        0.9137, 0.8950, 0.8730, 0.8513, 0.8296, 0.8083, 0.7852, 0.7609, 0.7389,\n",
      "        0.7156, 0.6928, 0.6716, 0.6500, 0.6292, 0.6084, 0.5880, 0.5689, 0.5511,\n",
      "        0.5306], grad_fn=<AddBackward0>) tensor([7.4165, 7.5131, 7.4110, 7.4146, 7.4623, 7.4087, 7.3566, 7.4299, 7.3802,\n",
      "        7.3787, 7.1823, 7.1175, 6.8827, 6.7280, 6.2902, 6.0212, 5.6172, 5.2176,\n",
      "        4.8033, 4.4162, 4.0616, 3.6686, 3.3494, 3.0855, 2.8047, 2.6187, 2.4105,\n",
      "        2.2914, 2.1771, 2.0516, 1.9715, 1.9060, 1.8215, 1.7878, 1.7475, 1.7098,\n",
      "        1.6971, 1.6302, 1.6151, 1.5626, 1.5388, 1.4963, 1.4526, 1.4223, 1.3760,\n",
      "        1.3367, 1.3047, 1.2639, 1.2220, 1.1838, 1.1520, 1.1097, 1.0895, 1.0521,\n",
      "        1.0820], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.8596, 2.8683, 2.8665, 2.8486, 2.8478, 2.8423, 2.8301, 2.8160, 2.8035,\n",
      "        2.8011, 2.7787, 2.7709, 2.7393, 2.7109, 2.6638, 2.6404, 2.5880, 2.5152,\n",
      "        2.4488, 2.3800, 2.2897, 2.2016, 2.0841, 1.9789, 1.8623, 1.7492, 1.6321,\n",
      "        1.5198, 1.4152, 1.3105, 1.2142, 1.1243, 1.0466, 0.9773, 0.9149, 0.8539,\n",
      "        0.8101, 0.7664, 0.7297, 0.6947, 0.6657, 0.6393, 0.6207, 0.6002, 0.5827,\n",
      "        0.5655, 0.5529, 0.5376, 0.5250, 0.5121, 0.5003, 0.4870, 0.4738, 0.4597,\n",
      "        0.4447], grad_fn=<AddBackward0>) tensor([6.2548, 6.1749, 6.1439, 6.2252, 6.1491, 6.1388, 6.1810, 6.1936, 6.1801,\n",
      "        6.0341, 6.0719, 5.9216, 5.9388, 5.9756, 5.9896, 5.7605, 5.7057, 5.7233,\n",
      "        5.5630, 5.3914, 5.2174, 5.0143, 4.9684, 4.7164, 4.5395, 4.3456, 4.0993,\n",
      "        3.9010, 3.6693, 3.5067, 3.3456, 3.1883, 3.0316, 2.8142, 2.6359, 2.6094,\n",
      "        2.4369, 2.2982, 2.1725, 2.1495, 2.0717, 2.0658, 1.9509, 1.9007, 1.8697,\n",
      "        1.8768, 1.7623, 1.7866, 1.7173, 1.7254, 1.6853, 1.6541, 1.6467, 1.7181,\n",
      "        4.6238], grad_fn=<AddBackward0>)\n",
      "19792.99001765251\n",
      "r0 before lock-down  tensor([4.8023, 4.7688, 4.7957, 4.7915, 4.7838, 4.7817, 4.7791, 4.7433, 4.7309,\n",
      "        4.6691, 4.6433, 4.5526, 4.4238, 4.1967, 3.9897, 3.7203, 3.4486, 3.1671,\n",
      "        2.8885, 2.6123, 2.3501, 2.1231, 1.9133, 1.7317, 1.5784, 1.4453, 1.3397,\n",
      "        1.2439, 1.1697, 1.1115, 1.0637, 1.0246, 0.9940, 0.9645, 0.9404, 0.9202,\n",
      "        0.8982, 0.8802, 0.8589, 0.8378, 0.8168, 0.7961, 0.7736, 0.7500, 0.7285,\n",
      "        0.7058, 0.6836, 0.6629, 0.6417, 0.6214, 0.6010, 0.5810, 0.5623, 0.5448,\n",
      "        0.5246], grad_fn=<AddBackward0>) tensor([7.5127, 7.6299, 7.5161, 7.5225, 7.5548, 7.5070, 7.4611, 7.5304, 7.4709,\n",
      "        7.4801, 7.2912, 7.1993, 6.9539, 6.7826, 6.3519, 6.0582, 5.6518, 5.2323,\n",
      "        4.8018, 4.4061, 4.0425, 3.6475, 3.3124, 3.0533, 2.7663, 2.5794, 2.3715,\n",
      "        2.2530, 2.1402, 2.0159, 1.9351, 1.8726, 1.7902, 1.7573, 1.7186, 1.6818,\n",
      "        1.6697, 1.6029, 1.5890, 1.5391, 1.5149, 1.4739, 1.4314, 1.4014, 1.3571,\n",
      "        1.3189, 1.2876, 1.2471, 1.2079, 1.1697, 1.1386, 1.0972, 1.0777, 1.0412,\n",
      "        1.0765], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.8809, 2.8876, 2.8839, 2.8685, 2.8655, 2.8607, 2.8512, 2.8374, 2.8230,\n",
      "        2.8190, 2.8004, 2.7918, 2.7610, 2.7305, 2.6811, 2.6587, 2.6080, 2.5329,\n",
      "        2.4659, 2.3957, 2.3043, 2.2146, 2.0964, 1.9904, 1.8707, 1.7576, 1.6385,\n",
      "        1.5247, 1.4191, 1.3129, 1.2160, 1.1255, 1.0462, 0.9758, 0.9132, 0.8519,\n",
      "        0.8073, 0.7631, 0.7260, 0.6910, 0.6615, 0.6350, 0.6160, 0.5955, 0.5777,\n",
      "        0.5605, 0.5479, 0.5326, 0.5200, 0.5070, 0.4954, 0.4820, 0.4688, 0.4548,\n",
      "        0.4398], grad_fn=<AddBackward0>) tensor([6.2602, 6.1953, 6.1756, 6.2381, 6.1773, 6.1667, 6.1855, 6.1964, 6.1913,\n",
      "        6.0609, 6.0735, 5.9244, 5.9354, 5.9878, 6.0132, 5.7744, 5.7040, 5.7316,\n",
      "        5.5673, 5.3993, 5.2274, 5.0280, 4.9743, 4.7176, 4.5532, 4.3438, 4.1055,\n",
      "        3.9070, 3.6677, 3.5097, 3.3412, 3.1735, 3.0354, 2.8203, 2.6327, 2.5962,\n",
      "        2.4282, 2.2910, 2.1655, 2.1304, 2.0582, 2.0459, 1.9380, 1.8812, 1.8576,\n",
      "        1.8629, 1.7488, 1.7711, 1.7036, 1.7108, 1.6680, 1.6406, 1.6376, 1.7089,\n",
      "        4.7546], grad_fn=<AddBackward0>)\n",
      "20385.834451675415\n",
      "r0 before lock-down  tensor([4.8796, 4.8423, 4.8742, 4.8663, 4.8614, 4.8561, 4.8522, 4.8163, 4.8043,\n",
      "        4.7391, 4.7083, 4.6148, 4.4839, 4.2491, 4.0342, 3.7533, 3.4697, 3.1770,\n",
      "        2.8890, 2.6067, 2.3381, 2.1065, 1.8939, 1.7100, 1.5557, 1.4226, 1.3174,\n",
      "        1.2220, 1.1486, 1.0911, 1.0440, 1.0059, 0.9758, 0.9472, 0.9238, 0.9042,\n",
      "        0.8830, 0.8655, 0.8449, 0.8245, 0.8042, 0.7841, 0.7623, 0.7393, 0.7183,\n",
      "        0.6962, 0.6745, 0.6543, 0.6336, 0.6137, 0.5937, 0.5741, 0.5558, 0.5386,\n",
      "        0.5188], grad_fn=<AddBackward0>) tensor([7.5854, 7.7197, 7.5831, 7.6034, 7.6274, 7.5883, 7.5453, 7.6138, 7.5470,\n",
      "        7.5597, 7.3835, 7.2849, 7.0157, 6.8264, 6.3778, 6.0736, 5.6666, 5.2402,\n",
      "        4.8028, 4.3831, 4.0156, 3.6119, 3.2722, 3.0163, 2.7297, 2.5392, 2.3297,\n",
      "        2.2162, 2.1021, 1.9792, 1.9001, 1.8365, 1.7586, 1.7274, 1.6878, 1.6536,\n",
      "        1.6415, 1.5756, 1.5644, 1.5149, 1.4918, 1.4528, 1.4112, 1.3816, 1.3375,\n",
      "        1.3011, 1.2710, 1.2312, 1.1930, 1.1558, 1.1250, 1.0855, 1.0657, 1.0304,\n",
      "        1.0711], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.8828, 2.8874, 2.8834, 2.8645, 2.8639, 2.8582, 2.8479, 2.8360, 2.8211,\n",
      "        2.8191, 2.8031, 2.7920, 2.7592, 2.7287, 2.6798, 2.6559, 2.6041, 2.5323,\n",
      "        2.4638, 2.3921, 2.3036, 2.2098, 2.0904, 1.9868, 1.8666, 1.7519, 1.6321,\n",
      "        1.5179, 1.4127, 1.3056, 1.2084, 1.1174, 1.0390, 0.9684, 0.9055, 0.8445,\n",
      "        0.7994, 0.7552, 0.7185, 0.6834, 0.6538, 0.6276, 0.6087, 0.5882, 0.5706,\n",
      "        0.5536, 0.5409, 0.5258, 0.5135, 0.5006, 0.4890, 0.4759, 0.4628, 0.4488,\n",
      "        0.4341], grad_fn=<AddBackward0>) tensor([6.2051, 6.1554, 6.1414, 6.2238, 6.1498, 6.1432, 6.1668, 6.1582, 6.1599,\n",
      "        6.0205, 6.0122, 5.8794, 5.9026, 5.9567, 5.9802, 5.7522, 5.6887, 5.6888,\n",
      "        5.5373, 5.3789, 5.1818, 5.0058, 4.9619, 4.6764, 4.5104, 4.3101, 4.0755,\n",
      "        3.8777, 3.6327, 3.4835, 3.3171, 3.1589, 3.0002, 2.7892, 2.6077, 2.5669,\n",
      "        2.4119, 2.2741, 2.1390, 2.1099, 2.0415, 2.0208, 1.9150, 1.8609, 1.8365,\n",
      "        1.8383, 1.7294, 1.7554, 1.6790, 1.6906, 1.6521, 1.6243, 1.6250, 1.6990,\n",
      "        4.8984], grad_fn=<AddBackward0>)\n",
      "27574.863924503326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([4.9183, 4.8767, 4.9127, 4.9048, 4.9010, 4.8957, 4.8925, 4.8559, 4.8393,\n",
      "        4.7739, 4.7434, 4.6470, 4.5096, 4.2677, 4.0466, 3.7595, 3.4678, 3.1673,\n",
      "        2.8737, 2.5856, 2.3143, 2.0796, 1.8663, 1.6820, 1.5279, 1.3956, 1.2918,\n",
      "        1.1976, 1.1253, 1.0689, 1.0229, 0.9858, 0.9566, 0.9288, 0.9063, 0.8876,\n",
      "        0.8671, 0.8504, 0.8304, 0.8109, 0.7912, 0.7718, 0.7507, 0.7283, 0.7080,\n",
      "        0.6864, 0.6653, 0.6455, 0.6253, 0.6059, 0.5863, 0.5671, 0.5491, 0.5323,\n",
      "        0.5128], grad_fn=<AddBackward0>) tensor([7.6201, 7.7713, 7.6158, 7.6340, 7.6591, 7.6139, 7.5676, 7.6357, 7.5871,\n",
      "        7.5920, 7.4068, 7.3061, 7.0395, 6.8466, 6.3839, 6.0619, 5.6506, 5.2170,\n",
      "        4.7680, 4.3480, 3.9687, 3.5654, 3.2222, 2.9665, 2.6863, 2.4965, 2.2839,\n",
      "        2.1705, 2.0618, 1.9402, 1.8624, 1.8001, 1.7257, 1.6947, 1.6563, 1.6222,\n",
      "        1.6130, 1.5491, 1.5401, 1.4906, 1.4688, 1.4303, 1.3897, 1.3613, 1.3180,\n",
      "        1.2841, 1.2541, 1.2160, 1.1784, 1.1410, 1.1111, 1.0721, 1.0527, 1.0193,\n",
      "        1.0655], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.8915, 2.8972, 2.8920, 2.8741, 2.8720, 2.8677, 2.8563, 2.8456, 2.8306,\n",
      "        2.8284, 2.8140, 2.8035, 2.7708, 2.7390, 2.6876, 2.6645, 2.6117, 2.5400,\n",
      "        2.4715, 2.3978, 2.3106, 2.2158, 2.0948, 1.9897, 1.8679, 1.7540, 1.6320,\n",
      "        1.5172, 1.4120, 1.3039, 1.2056, 1.1145, 1.0355, 0.9643, 0.9014, 0.8400,\n",
      "        0.7945, 0.7500, 0.7129, 0.6778, 0.6482, 0.6220, 0.6027, 0.5823, 0.5648,\n",
      "        0.5477, 0.5350, 0.5198, 0.5078, 0.4949, 0.4833, 0.4703, 0.4573, 0.4434,\n",
      "        0.4288], grad_fn=<AddBackward0>) tensor([6.1981, 6.1438, 6.1352, 6.2141, 6.1488, 6.1326, 6.1659, 6.1483, 6.1506,\n",
      "        6.0143, 5.9921, 5.8555, 5.8750, 5.9411, 5.9792, 5.7443, 5.6851, 5.6807,\n",
      "        5.5277, 5.3776, 5.1665, 4.9892, 4.9514, 4.6701, 4.5137, 4.2944, 4.0764,\n",
      "        3.8736, 3.6169, 3.4692, 3.3065, 3.1462, 2.9853, 2.7773, 2.5900, 2.5476,\n",
      "        2.3951, 2.2608, 2.1316, 2.0981, 2.0231, 2.0004, 1.9014, 1.8469, 1.8162,\n",
      "        1.8196, 1.7108, 1.7416, 1.6586, 1.6715, 1.6368, 1.6081, 1.6134, 1.6894,\n",
      "        5.0511], grad_fn=<AddBackward0>)\n",
      "11056.764044046402\n",
      "r0 before lock-down  tensor([4.9535, 4.9143, 4.9496, 4.9399, 4.9389, 4.9329, 4.9282, 4.8927, 4.8762,\n",
      "        4.8086, 4.7770, 4.6765, 4.5343, 4.2876, 4.0594, 3.7622, 3.4653, 3.1566,\n",
      "        2.8561, 2.5650, 2.2903, 2.0529, 1.8389, 1.6544, 1.5007, 1.3693, 1.2664,\n",
      "        1.1737, 1.1027, 1.0473, 1.0024, 0.9663, 0.9379, 0.9111, 0.8894, 0.8714,\n",
      "        0.8517, 0.8357, 0.8165, 0.7976, 0.7787, 0.7599, 0.7394, 0.7177, 0.6979,\n",
      "        0.6769, 0.6564, 0.6371, 0.6173, 0.5984, 0.5792, 0.5603, 0.5427, 0.5262,\n",
      "        0.5071], grad_fn=<AddBackward0>) tensor([7.6559, 7.7894, 7.6405, 7.6644, 7.6838, 7.6370, 7.5951, 7.6552, 7.6069,\n",
      "        7.6093, 7.4245, 7.3223, 7.0543, 6.8467, 6.3770, 6.0546, 5.6240, 5.1898,\n",
      "        4.7429, 4.3030, 3.9191, 3.5182, 3.1722, 2.9179, 2.6401, 2.4519, 2.2429,\n",
      "        2.1281, 2.0183, 1.9020, 1.8245, 1.7655, 1.6931, 1.6616, 1.6268, 1.5939,\n",
      "        1.5856, 1.5233, 1.5141, 1.4671, 1.4462, 1.4097, 1.3706, 1.3413, 1.2996,\n",
      "        1.2666, 1.2377, 1.2003, 1.1640, 1.1270, 1.0979, 1.0594, 1.0408, 1.0087,\n",
      "        1.0606], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.9062, 2.9118, 2.9056, 2.8880, 2.8859, 2.8821, 2.8700, 2.8574, 2.8467,\n",
      "        2.8416, 2.8294, 2.8181, 2.7857, 2.7550, 2.7006, 2.6776, 2.6266, 2.5515,\n",
      "        2.4855, 2.4074, 2.3207, 2.2254, 2.1024, 1.9979, 1.8734, 1.7583, 1.6355,\n",
      "        1.5188, 1.4139, 1.3048, 1.2055, 1.1133, 1.0341, 0.9621, 0.8992, 0.8372,\n",
      "        0.7911, 0.7463, 0.7090, 0.6738, 0.6440, 0.6174, 0.5982, 0.5777, 0.5600,\n",
      "        0.5430, 0.5303, 0.5152, 0.5031, 0.4903, 0.4788, 0.4658, 0.4528, 0.4388,\n",
      "        0.4244], grad_fn=<AddBackward0>) tensor([6.1933, 6.1425, 6.1382, 6.2133, 6.1471, 6.1238, 6.1655, 6.1585, 6.1348,\n",
      "        6.0184, 5.9801, 5.8480, 5.8618, 5.9224, 5.9786, 5.7423, 5.6650, 5.6826,\n",
      "        5.5027, 5.3815, 5.1653, 4.9834, 4.9486, 4.6504, 4.5109, 4.2911, 4.0700,\n",
      "        3.8799, 3.6033, 3.4574, 3.2974, 3.1457, 2.9749, 2.7721, 2.5713, 2.5342,\n",
      "        2.3802, 2.2512, 2.1171, 2.0823, 2.0065, 1.9942, 1.8861, 1.8312, 1.8062,\n",
      "        1.8088, 1.7019, 1.7291, 1.6492, 1.6632, 1.6303, 1.5981, 1.6042, 1.6893,\n",
      "        5.2039], grad_fn=<AddBackward0>)\n",
      "14081.583441019058\n",
      "r0 before lock-down  tensor([5.0239, 4.9801, 5.0140, 5.0060, 5.0044, 4.9995, 4.9938, 4.9610, 4.9426,\n",
      "        4.8734, 4.8414, 4.7376, 4.5882, 4.3337, 4.0952, 3.7879, 3.4826, 3.1647,\n",
      "        2.8561, 2.5575, 2.2773, 2.0356, 1.8196, 1.6338, 1.4793, 1.3483, 1.2457,\n",
      "        1.1535, 1.0833, 1.0285, 0.9846, 0.9493, 0.9215, 0.8954, 0.8743, 0.8570,\n",
      "        0.8380, 0.8225, 0.8040, 0.7856, 0.7673, 0.7491, 0.7292, 0.7081, 0.6889,\n",
      "        0.6683, 0.6482, 0.6295, 0.6101, 0.5915, 0.5727, 0.5542, 0.5368, 0.5206,\n",
      "        0.5019], grad_fn=<AddBackward0>) tensor([7.7145, 7.8632, 7.7210, 7.7390, 7.7631, 7.7110, 7.6674, 7.7155, 7.6720,\n",
      "        7.6705, 7.4786, 7.3680, 7.1033, 6.8841, 6.4103, 6.0748, 5.6244, 5.1846,\n",
      "        4.7250, 4.2815, 3.8914, 3.4913, 3.1385, 2.8825, 2.6028, 2.4122, 2.2045,\n",
      "        2.0944, 1.9823, 1.8701, 1.7901, 1.7325, 1.6633, 1.6326, 1.6007, 1.5671,\n",
      "        1.5598, 1.5010, 1.4904, 1.4467, 1.4254, 1.3905, 1.3505, 1.3232, 1.2824,\n",
      "        1.2512, 1.2229, 1.1866, 1.1512, 1.1149, 1.0862, 1.0480, 1.0305, 0.9988,\n",
      "        1.0574], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.9106, 2.9218, 2.9122, 2.8918, 2.8898, 2.8906, 2.8765, 2.8640, 2.8543,\n",
      "        2.8473, 2.8382, 2.8239, 2.7926, 2.7602, 2.7062, 2.6842, 2.6329, 2.5543,\n",
      "        2.4914, 2.4130, 2.3238, 2.2279, 2.1043, 2.0011, 1.8736, 1.7587, 1.6345,\n",
      "        1.5173, 1.4116, 1.3014, 1.2016, 1.1094, 1.0302, 0.9574, 0.8943, 0.8324,\n",
      "        0.7858, 0.7408, 0.7035, 0.6681, 0.6382, 0.6117, 0.5924, 0.5719, 0.5542,\n",
      "        0.5374, 0.5246, 0.5096, 0.4976, 0.4849, 0.4734, 0.4607, 0.4476, 0.4336,\n",
      "        0.4193], grad_fn=<AddBackward0>) tensor([6.1917, 6.1065, 6.1237, 6.2166, 6.1491, 6.0964, 6.1543, 6.1407, 6.1123,\n",
      "        6.0069, 5.9511, 5.8372, 5.8413, 5.9155, 5.9682, 5.7243, 5.6488, 5.6879,\n",
      "        5.4845, 5.3602, 5.1576, 4.9759, 4.9386, 4.6199, 4.4983, 4.2697, 4.0575,\n",
      "        3.8639, 3.5876, 3.4497, 3.2877, 3.1280, 2.9513, 2.7534, 2.5543, 2.5113,\n",
      "        2.3631, 2.2360, 2.1051, 2.0695, 1.9951, 1.9789, 1.8691, 1.8166, 1.7926,\n",
      "        1.7895, 1.6889, 1.7159, 1.6340, 1.6500, 1.6155, 1.5810, 1.5935, 1.6838,\n",
      "        5.3660], grad_fn=<AddBackward0>)\n",
      "9481.049050807953\n",
      "r0 before lock-down  tensor([5.0560, 5.0124, 5.0435, 5.0366, 5.0309, 5.0297, 5.0203, 4.9872, 4.9703,\n",
      "        4.8987, 4.8676, 4.7638, 4.6088, 4.3489, 4.1002, 3.7904, 3.4780, 3.1503,\n",
      "        2.8389, 2.5345, 2.2534, 2.0096, 1.7919, 1.6067, 1.4533, 1.3233, 1.2221,\n",
      "        1.1310, 1.0621, 1.0083, 0.9653, 0.9310, 0.9041, 0.8789, 0.8584, 0.8419,\n",
      "        0.8237, 0.8088, 0.7910, 0.7733, 0.7557, 0.7380, 0.7188, 0.6983, 0.6795,\n",
      "        0.6595, 0.6400, 0.6216, 0.6027, 0.5845, 0.5661, 0.5480, 0.5309, 0.5150,\n",
      "        0.4966], grad_fn=<AddBackward0>) tensor([7.7220, 7.8675, 7.7393, 7.7522, 7.7897, 7.7227, 7.6934, 7.7421, 7.6883,\n",
      "        7.6911, 7.4881, 7.3626, 7.1030, 6.8703, 6.4067, 6.0422, 5.5857, 5.1641,\n",
      "        4.6810, 4.2459, 3.8400, 3.4409, 3.0981, 2.8380, 2.5597, 2.3679, 2.1591,\n",
      "        2.0529, 1.9420, 1.8337, 1.7588, 1.7005, 1.6319, 1.6025, 1.5733, 1.5406,\n",
      "        1.5324, 1.4776, 1.4673, 1.4252, 1.4040, 1.3705, 1.3317, 1.3054, 1.2656,\n",
      "        1.2345, 1.2077, 1.1723, 1.1378, 1.1024, 1.0737, 1.0368, 1.0203, 0.9889,\n",
      "        1.0541], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.9426, 2.9573, 2.9438, 2.9256, 2.9264, 2.9222, 2.9088, 2.8960, 2.8863,\n",
      "        2.8775, 2.8699, 2.8571, 2.8225, 2.7886, 2.7357, 2.7118, 2.6627, 2.5801,\n",
      "        2.5189, 2.4379, 2.3499, 2.2517, 2.1255, 2.0192, 1.8906, 1.7735, 1.6483,\n",
      "        1.5283, 1.4192, 1.3089, 1.2073, 1.1144, 1.0336, 0.9596, 0.8956, 0.8331,\n",
      "        0.7856, 0.7404, 0.7023, 0.6663, 0.6360, 0.6092, 0.5898, 0.5690, 0.5510,\n",
      "        0.5340, 0.5211, 0.5060, 0.4941, 0.4813, 0.4698, 0.4570, 0.4439, 0.4298,\n",
      "        0.4156], grad_fn=<AddBackward0>) tensor([6.2257, 6.1231, 6.1643, 6.2356, 6.1530, 6.1315, 6.1864, 6.1735, 6.1412,\n",
      "        6.0489, 5.9858, 5.8577, 5.8833, 5.9626, 5.9992, 5.7678, 5.6706, 5.7325,\n",
      "        5.5060, 5.3920, 5.1709, 4.9839, 4.9498, 4.6444, 4.5108, 4.2838, 4.0551,\n",
      "        3.8688, 3.6136, 3.4547, 3.2950, 3.1257, 2.9519, 2.7569, 2.5582, 2.5076,\n",
      "        2.3647, 2.2252, 2.0960, 2.0637, 1.9893, 1.9730, 1.8543, 1.8004, 1.7886,\n",
      "        1.7790, 1.6822, 1.7098, 1.6235, 1.6398, 1.6060, 1.5733, 1.5878, 1.6878,\n",
      "        5.5510], grad_fn=<AddBackward0>)\n",
      "11979.47964143753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([5.0783, 5.0402, 5.0682, 5.0581, 5.0521, 5.0521, 5.0425, 5.0092, 4.9885,\n",
      "        4.9203, 4.8874, 4.7794, 4.6213, 4.3557, 4.0993, 3.7862, 3.4668, 3.1338,\n",
      "        2.8194, 2.5104, 2.2274, 1.9819, 1.7650, 1.5799, 1.4272, 1.2985, 1.1985,\n",
      "        1.1087, 1.0411, 0.9884, 0.9463, 0.9132, 0.8871, 0.8628, 0.8429, 0.8272,\n",
      "        0.8096, 0.7954, 0.7784, 0.7613, 0.7442, 0.7271, 0.7085, 0.6886, 0.6704,\n",
      "        0.6509, 0.6318, 0.6139, 0.5955, 0.5777, 0.5596, 0.5418, 0.5250, 0.5094,\n",
      "        0.4913], grad_fn=<AddBackward0>) tensor([7.7284, 7.8502, 7.7339, 7.7593, 7.7971, 7.7291, 7.6945, 7.7433, 7.7033,\n",
      "        7.6855, 7.4832, 7.3629, 7.0968, 6.8619, 6.3986, 6.0174, 5.5573, 5.1303,\n",
      "        4.6320, 4.2048, 3.7916, 3.3976, 3.0460, 2.7909, 2.5155, 2.3230, 2.1190,\n",
      "        2.0136, 1.9050, 1.7991, 1.7254, 1.6675, 1.6020, 1.5723, 1.5470, 1.5128,\n",
      "        1.5080, 1.4547, 1.4429, 1.4026, 1.3834, 1.3517, 1.3133, 1.2877, 1.2491,\n",
      "        1.2187, 1.1934, 1.1581, 1.1243, 1.0894, 1.0616, 1.0255, 1.0103, 0.9799,\n",
      "        1.0512], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.9655, 2.9752, 2.9609, 2.9439, 2.9476, 2.9417, 2.9310, 2.9132, 2.9047,\n",
      "        2.8953, 2.8875, 2.8768, 2.8404, 2.8077, 2.7561, 2.7299, 2.6811, 2.5949,\n",
      "        2.5364, 2.4531, 2.3647, 2.2646, 2.1384, 2.0298, 1.8988, 1.7816, 1.6545,\n",
      "        1.5327, 1.4234, 1.3117, 1.2092, 1.1151, 1.0333, 0.9596, 0.8948, 0.8314,\n",
      "        0.7836, 0.7379, 0.6996, 0.6633, 0.6327, 0.6056, 0.5861, 0.5649, 0.5470,\n",
      "        0.5299, 0.5169, 0.5018, 0.4899, 0.4772, 0.4657, 0.4528, 0.4398, 0.4256,\n",
      "        0.4116], grad_fn=<AddBackward0>) tensor([6.2078, 6.1415, 6.1876, 6.2515, 6.1504, 6.1363, 6.1752, 6.1930, 6.1547,\n",
      "        6.0647, 6.0007, 5.8588, 5.8963, 5.9659, 5.9902, 5.7696, 5.6691, 5.7514,\n",
      "        5.5013, 5.3920, 5.1690, 4.9879, 4.9415, 4.6449, 4.5199, 4.2825, 4.0574,\n",
      "        3.8759, 3.6139, 3.4573, 3.2910, 3.1317, 2.9605, 2.7470, 2.5478, 2.5070,\n",
      "        2.3573, 2.2192, 2.0869, 2.0497, 1.9755, 1.9605, 1.8396, 1.7930, 1.7755,\n",
      "        1.7686, 1.6755, 1.7020, 1.6160, 1.6275, 1.5927, 1.5663, 1.5769, 1.6865,\n",
      "        5.7583], grad_fn=<AddBackward0>)\n",
      "25921.07465147972\n",
      "r0 before lock-down  tensor([5.1632, 5.1237, 5.1503, 5.1385, 5.1328, 5.1329, 5.1231, 5.0934, 5.0693,\n",
      "        4.9989, 4.9651, 4.8523, 4.6878, 4.4130, 4.1464, 3.8234, 3.4930, 3.1511,\n",
      "        2.8286, 2.5107, 2.2226, 1.9722, 1.7519, 1.5645, 1.4111, 1.2820, 1.1818,\n",
      "        1.0924, 1.0252, 0.9730, 0.9314, 0.8988, 0.8733, 0.8495, 0.8302, 0.8149,\n",
      "        0.7978, 0.7841, 0.7676, 0.7509, 0.7344, 0.7178, 0.6997, 0.6802, 0.6625,\n",
      "        0.6434, 0.6247, 0.6073, 0.5891, 0.5717, 0.5539, 0.5364, 0.5199, 0.5045,\n",
      "        0.4867], grad_fn=<AddBackward0>) tensor([7.8169, 7.9370, 7.8287, 7.8620, 7.8974, 7.8290, 7.7925, 7.8229, 7.7932,\n",
      "        7.7744, 7.5621, 7.4459, 7.1737, 6.9279, 6.4550, 6.0601, 5.5883, 5.1426,\n",
      "        4.6279, 4.1989, 3.7705, 3.3723, 3.0211, 2.7637, 2.4846, 2.2907, 2.0894,\n",
      "        1.9836, 1.8762, 1.7701, 1.7004, 1.6423, 1.5762, 1.5478, 1.5229, 1.4914,\n",
      "        1.4875, 1.4345, 1.4236, 1.3844, 1.3655, 1.3348, 1.2968, 1.2722, 1.2351,\n",
      "        1.2050, 1.1810, 1.1455, 1.1130, 1.0783, 1.0511, 1.0158, 1.0011, 0.9712,\n",
      "        1.0507], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.9561, 2.9661, 2.9506, 2.9343, 2.9363, 2.9311, 2.9190, 2.9021, 2.8947,\n",
      "        2.8848, 2.8786, 2.8659, 2.8287, 2.7992, 2.7474, 2.7184, 2.6686, 2.5856,\n",
      "        2.5286, 2.4421, 2.3535, 2.2558, 2.1296, 2.0214, 1.8910, 1.7712, 1.6446,\n",
      "        1.5231, 1.4131, 1.3023, 1.2007, 1.1068, 1.0237, 0.9512, 0.8863, 0.8230,\n",
      "        0.7751, 0.7297, 0.6916, 0.6554, 0.6249, 0.5978, 0.5784, 0.5574, 0.5396,\n",
      "        0.5226, 0.5098, 0.4948, 0.4830, 0.4704, 0.4591, 0.4464, 0.4335, 0.4193,\n",
      "        0.4055], grad_fn=<AddBackward0>) tensor([6.1518, 6.0819, 6.1326, 6.1911, 6.1036, 6.0889, 6.1362, 6.1464, 6.1030,\n",
      "        6.0157, 5.9434, 5.8170, 5.8591, 5.9072, 5.9342, 5.7363, 5.6444, 5.7055,\n",
      "        5.4481, 5.3627, 5.1424, 4.9386, 4.8956, 4.5968, 4.4647, 4.2543, 4.0289,\n",
      "        3.8444, 3.5974, 3.4290, 3.2494, 3.0908, 2.9516, 2.7147, 2.5262, 2.4828,\n",
      "        2.3401, 2.1968, 2.0629, 2.0227, 1.9512, 1.9360, 1.8193, 1.7655, 1.7484,\n",
      "        1.7457, 1.6541, 1.6799, 1.5979, 1.6106, 1.5733, 1.5469, 1.5547, 1.6743,\n",
      "        5.8891], grad_fn=<AddBackward0>)\n",
      "9199.368178129196\n",
      "r0 before lock-down  tensor([5.1630, 5.1230, 5.1496, 5.1349, 5.1310, 5.1271, 5.1206, 5.0900, 5.0686,\n",
      "        4.9947, 4.9624, 4.8455, 4.6791, 4.4008, 4.1306, 3.8055, 3.4688, 3.1238,\n",
      "        2.7991, 2.4796, 2.1907, 1.9405, 1.7212, 1.5355, 1.3836, 1.2564, 1.1576,\n",
      "        1.0699, 1.0041, 0.9533, 0.9127, 0.8810, 0.8565, 0.8336, 0.8150, 0.8005,\n",
      "        0.7841, 0.7710, 0.7552, 0.7392, 0.7233, 0.7073, 0.6898, 0.6709, 0.6536,\n",
      "        0.6351, 0.6168, 0.5998, 0.5821, 0.5650, 0.5476, 0.5304, 0.5142, 0.4992,\n",
      "        0.4817], grad_fn=<AddBackward0>) tensor([7.7894, 7.9076, 7.8012, 7.8436, 7.8714, 7.8217, 7.7714, 7.8004, 7.7629,\n",
      "        7.7503, 7.5279, 7.4202, 7.1456, 6.8939, 6.4117, 6.0021, 5.5408, 5.0902,\n",
      "        4.5714, 4.1432, 3.7159, 3.3215, 2.9737, 2.7121, 2.4389, 2.2447, 2.0481,\n",
      "        1.9433, 1.8374, 1.7333, 1.6670, 1.6127, 1.5463, 1.5192, 1.4960, 1.4653,\n",
      "        1.4628, 1.4108, 1.4018, 1.3639, 1.3455, 1.3146, 1.2784, 1.2552, 1.2185,\n",
      "        1.1897, 1.1666, 1.1324, 1.0999, 1.0665, 1.0398, 1.0053, 0.9913, 0.9615,\n",
      "        1.0491], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.9920, 3.0035, 2.9907, 2.9712, 2.9750, 2.9689, 2.9582, 2.9399, 2.9331,\n",
      "        2.9233, 2.9149, 2.9015, 2.8660, 2.8348, 2.7862, 2.7530, 2.7024, 2.6194,\n",
      "        2.5619, 2.4728, 2.3827, 2.2851, 2.1531, 2.0447, 1.9134, 1.7903, 1.6615,\n",
      "        1.5385, 1.4268, 1.3145, 1.2104, 1.1148, 1.0305, 0.9562, 0.8908, 0.8266,\n",
      "        0.7777, 0.7314, 0.6926, 0.6559, 0.6249, 0.5972, 0.5774, 0.5562, 0.5379,\n",
      "        0.5207, 0.5076, 0.4925, 0.4805, 0.4679, 0.4564, 0.4436, 0.4306, 0.4163,\n",
      "        0.4025], grad_fn=<AddBackward0>) tensor([6.2152, 6.1337, 6.1651, 6.2434, 6.1460, 6.1359, 6.1744, 6.1909, 6.1441,\n",
      "        6.0539, 5.9944, 5.8711, 5.9011, 5.9603, 5.9567, 5.7857, 5.6966, 5.7481,\n",
      "        5.4880, 5.4097, 5.1882, 4.9679, 4.9548, 4.6374, 4.4892, 4.2921, 4.0637,\n",
      "        3.8657, 3.6125, 3.4368, 3.2659, 3.1088, 2.9641, 2.7368, 2.5312, 2.4869,\n",
      "        2.3463, 2.2032, 2.0687, 2.0241, 1.9492, 1.9351, 1.8188, 1.7573, 1.7456,\n",
      "        1.7402, 1.6478, 1.6752, 1.5921, 1.6016, 1.5682, 1.5433, 1.5530, 1.6773,\n",
      "        6.1252], grad_fn=<AddBackward0>)\n",
      "7022.886580705643\n",
      "r0 before lock-down  tensor([5.2310, 5.1943, 5.2156, 5.1993, 5.1979, 5.1942, 5.1876, 5.1565, 5.1328,\n",
      "        5.0623, 5.0241, 4.9062, 4.7302, 4.4467, 4.1675, 3.8351, 3.4875, 3.1355,\n",
      "        2.8015, 2.4749, 2.1823, 1.9282, 1.7064, 1.5198, 1.3669, 1.2397, 1.1412,\n",
      "        1.0540, 0.9887, 0.9384, 0.8985, 0.8673, 0.8434, 0.8210, 0.8029, 0.7888,\n",
      "        0.7730, 0.7604, 0.7450, 0.7295, 0.7141, 0.6986, 0.6815, 0.6630, 0.6462,\n",
      "        0.6281, 0.6103, 0.5936, 0.5762, 0.5595, 0.5423, 0.5254, 0.5094, 0.4946,\n",
      "        0.4774], grad_fn=<AddBackward0>) tensor([7.8644, 7.9687, 7.8845, 7.9275, 7.9470, 7.8954, 7.8467, 7.8722, 7.8425,\n",
      "        7.8074, 7.6006, 7.4780, 7.2151, 6.9432, 6.4510, 6.0224, 5.5590, 5.0840,\n",
      "        4.5677, 4.1398, 3.6952, 3.2983, 2.9506, 2.6818, 2.4126, 2.2167, 2.0185,\n",
      "        1.9138, 1.8110, 1.7071, 1.6388, 1.5882, 1.5229, 1.4974, 1.4742, 1.4455,\n",
      "        1.4435, 1.3918, 1.3836, 1.3463, 1.3299, 1.2987, 1.2632, 1.2409, 1.2056,\n",
      "        1.1774, 1.1547, 1.1215, 1.0892, 1.0565, 1.0302, 0.9965, 0.9826, 0.9535,\n",
      "        1.0502], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.9805, 2.9924, 2.9799, 2.9608, 2.9614, 2.9596, 2.9464, 2.9290, 2.9230,\n",
      "        2.9133, 2.9044, 2.8920, 2.8546, 2.8241, 2.7759, 2.7449, 2.6941, 2.6095,\n",
      "        2.5516, 2.4632, 2.3739, 2.2749, 2.1454, 2.0361, 1.9054, 1.7809, 1.6530,\n",
      "        1.5306, 1.4181, 1.3059, 1.2027, 1.1067, 1.0231, 0.9485, 0.8830, 0.8189,\n",
      "        0.7703, 0.7238, 0.6855, 0.6484, 0.6176, 0.5900, 0.5702, 0.5491, 0.5308,\n",
      "        0.5139, 0.5008, 0.4859, 0.4740, 0.4615, 0.4501, 0.4375, 0.4246, 0.4103,\n",
      "        0.3966], grad_fn=<AddBackward0>) tensor([6.1717, 6.0889, 6.1187, 6.1942, 6.1151, 6.0819, 6.1341, 6.1465, 6.0959,\n",
      "        6.0049, 5.9506, 5.8253, 5.8664, 5.9225, 5.9154, 5.7352, 5.6502, 5.7169,\n",
      "        5.4607, 5.3791, 5.1549, 4.9498, 4.9132, 4.6063, 4.4531, 4.2731, 4.0374,\n",
      "        3.8355, 3.5972, 3.4221, 3.2390, 3.0886, 2.9308, 2.7117, 2.5145, 2.4688,\n",
      "        2.3204, 2.1868, 2.0385, 2.0092, 1.9309, 1.9129, 1.7981, 1.7348, 1.7267,\n",
      "        1.7131, 1.6254, 1.6532, 1.5712, 1.5814, 1.5545, 1.5253, 1.5371, 1.6736,\n",
      "        6.2870], grad_fn=<AddBackward0>)\n",
      "13018.009011983871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([5.2808, 5.2448, 5.2661, 5.2542, 5.2517, 5.2433, 5.2357, 5.2061, 5.1844,\n",
      "        5.1109, 5.0703, 4.9493, 4.7652, 4.4792, 4.1916, 3.8527, 3.4954, 3.1366,\n",
      "        2.7964, 2.4638, 2.1680, 1.9128, 1.6884, 1.5016, 1.3484, 1.2217, 1.1237,\n",
      "        1.0372, 0.9726, 0.9231, 0.8839, 0.8533, 0.8300, 0.8082, 0.7906, 0.7770,\n",
      "        0.7618, 0.7496, 0.7348, 0.7198, 0.7049, 0.6898, 0.6733, 0.6552, 0.6388,\n",
      "        0.6211, 0.6037, 0.5873, 0.5703, 0.5539, 0.5370, 0.5203, 0.5046, 0.4900,\n",
      "        0.4730], grad_fn=<AddBackward0>) tensor([7.9154, 8.0169, 7.9349, 7.9566, 7.9849, 7.9458, 7.9024, 7.9170, 7.8771,\n",
      "        7.8468, 7.6432, 7.5173, 7.2637, 6.9668, 6.4661, 6.0251, 5.5632, 5.0765,\n",
      "        4.5542, 4.1263, 3.6720, 3.2621, 2.9203, 2.6486, 2.3814, 2.1833, 1.9870,\n",
      "        1.8846, 1.7832, 1.6777, 1.6114, 1.5627, 1.4978, 1.4731, 1.4526, 1.4247,\n",
      "        1.4224, 1.3726, 1.3649, 1.3294, 1.3132, 1.2831, 1.2486, 1.2273, 1.1921,\n",
      "        1.1651, 1.1429, 1.1105, 1.0786, 1.0459, 1.0208, 0.9874, 0.9737, 0.9455,\n",
      "        1.0513], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.9847, 2.9981, 2.9865, 2.9699, 2.9672, 2.9634, 2.9532, 2.9354, 2.9257,\n",
      "        2.9192, 2.9083, 2.8973, 2.8615, 2.8256, 2.7804, 2.7488, 2.6991, 2.6130,\n",
      "        2.5548, 2.4680, 2.3758, 2.2781, 2.1484, 2.0382, 1.9066, 1.7824, 1.6527,\n",
      "        1.5297, 1.4161, 1.3043, 1.2004, 1.1043, 1.0203, 0.9447, 0.8791, 0.8152,\n",
      "        0.7663, 0.7195, 0.6809, 0.6439, 0.6126, 0.5852, 0.5652, 0.5440, 0.5257,\n",
      "        0.5088, 0.4956, 0.4808, 0.4690, 0.4565, 0.4451, 0.4326, 0.4198, 0.4054,\n",
      "        0.3919], grad_fn=<AddBackward0>) tensor([6.1591, 6.0662, 6.0916, 6.1486, 6.0894, 6.0690, 6.1050, 6.1155, 6.0920,\n",
      "        5.9826, 5.9420, 5.8066, 5.8332, 5.9296, 5.9009, 5.7259, 5.6345, 5.7121,\n",
      "        5.4543, 5.3550, 5.1533, 4.9387, 4.8943, 4.5893, 4.4393, 4.2452, 4.0246,\n",
      "        3.8279, 3.5940, 3.4031, 3.2260, 3.0744, 2.9150, 2.7115, 2.5100, 2.4504,\n",
      "        2.3033, 2.1720, 2.0255, 1.9854, 1.9210, 1.8973, 1.7829, 1.7186, 1.7124,\n",
      "        1.6980, 1.6160, 1.6363, 1.5541, 1.5672, 1.5416, 1.5174, 1.5274, 1.6678,\n",
      "        6.4789], grad_fn=<AddBackward0>)\n",
      "11932.00752568245\n",
      "r0 before lock-down  tensor([5.2807, 5.2414, 5.2660, 5.2464, 5.2474, 5.2447, 5.2346, 5.2018, 5.1766,\n",
      "        5.1035, 5.0630, 4.9394, 4.7542, 4.4676, 4.1762, 3.8334, 3.4712, 3.1098,\n",
      "        2.7671, 2.4349, 2.1389, 1.8840, 1.6607, 1.4754, 1.3236, 1.1987, 1.1021,\n",
      "        1.0170, 0.9537, 0.9054, 0.8673, 0.8375, 0.8151, 0.7941, 0.7772, 0.7643,\n",
      "        0.7496, 0.7380, 0.7238, 0.7094, 0.6950, 0.6805, 0.6644, 0.6469, 0.6310,\n",
      "        0.6136, 0.5967, 0.5807, 0.5641, 0.5479, 0.5314, 0.5149, 0.4995, 0.4852,\n",
      "        0.4685], grad_fn=<AddBackward0>) tensor([7.8734, 7.9851, 7.8907, 7.9376, 7.9556, 7.8953, 7.8596, 7.8863, 7.8519,\n",
      "        7.8259, 7.6140, 7.4908, 7.2311, 6.9170, 6.4154, 5.9709, 5.5143, 5.0243,\n",
      "        4.5066, 4.0692, 3.6133, 3.2107, 2.8697, 2.5994, 2.3371, 2.1417, 1.9472,\n",
      "        1.8503, 1.7506, 1.6475, 1.5828, 1.5359, 1.4711, 1.4479, 1.4284, 1.4013,\n",
      "        1.3987, 1.3514, 1.3453, 1.3108, 1.2961, 1.2655, 1.2319, 1.2115, 1.1774,\n",
      "        1.1517, 1.1299, 1.0982, 1.0669, 1.0350, 1.0104, 0.9778, 0.9649, 0.9378,\n",
      "        1.0533], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.9852, 2.9971, 2.9876, 2.9692, 2.9676, 2.9599, 2.9516, 2.9333, 2.9248,\n",
      "        2.9194, 2.9075, 2.8977, 2.8624, 2.8254, 2.7798, 2.7470, 2.6982, 2.6149,\n",
      "        2.5552, 2.4668, 2.3735, 2.2773, 2.1450, 2.0369, 1.9050, 1.7796, 1.6496,\n",
      "        1.5267, 1.4124, 1.3005, 1.1967, 1.1001, 1.0160, 0.9402, 0.8742, 0.8105,\n",
      "        0.7611, 0.7144, 0.6756, 0.6387, 0.6072, 0.5798, 0.5598, 0.5384, 0.5203,\n",
      "        0.5034, 0.4902, 0.4754, 0.4637, 0.4513, 0.4400, 0.4273, 0.4146, 0.4002,\n",
      "        0.3869], grad_fn=<AddBackward0>) tensor([6.1199, 6.0408, 6.0535, 6.1194, 6.0539, 6.0583, 6.0799, 6.0967, 6.0660,\n",
      "        5.9472, 5.9121, 5.7733, 5.7969, 5.9035, 5.8746, 5.7140, 5.6156, 5.6732,\n",
      "        5.4268, 5.3368, 5.1472, 4.9170, 4.8976, 4.5710, 4.4193, 4.2375, 4.0132,\n",
      "        3.8125, 3.5855, 3.3906, 3.2079, 3.0583, 2.9001, 2.6952, 2.4984, 2.4273,\n",
      "        2.2906, 2.1521, 2.0111, 1.9689, 1.9084, 1.8851, 1.7655, 1.7093, 1.6943,\n",
      "        1.6777, 1.6029, 1.6245, 1.5371, 1.5484, 1.5227, 1.5081, 1.5154, 1.6641,\n",
      "        6.6272], grad_fn=<AddBackward0>)\n",
      "7870.052745103836\n",
      "r0 before lock-down  tensor([5.2822, 5.2414, 5.2672, 5.2450, 5.2436, 5.2424, 5.2355, 5.2045, 5.1758,\n",
      "        5.1018, 5.0602, 4.9381, 4.7483, 4.4595, 4.1628, 3.8173, 3.4491, 3.0863,\n",
      "        2.7426, 2.4085, 2.1121, 1.8569, 1.6352, 1.4511, 1.3004, 1.1771, 1.0817,\n",
      "        0.9979, 0.9358, 0.8886, 0.8515, 0.8226, 0.8008, 0.7805, 0.7643, 0.7520,\n",
      "        0.7380, 0.7269, 0.7133, 0.6994, 0.6855, 0.6715, 0.6559, 0.6389, 0.6234,\n",
      "        0.6065, 0.5899, 0.5744, 0.5581, 0.5422, 0.5259, 0.5098, 0.4946, 0.4805,\n",
      "        0.4641], grad_fn=<AddBackward0>) tensor([7.8472, 7.9621, 7.8632, 7.9224, 7.9494, 7.8794, 7.8363, 7.8518, 7.8290,\n",
      "        7.8021, 7.5970, 7.4553, 7.2027, 6.8788, 6.3786, 5.9275, 5.4813, 4.9790,\n",
      "        4.4536, 4.0189, 3.5631, 3.1672, 2.8194, 2.5534, 2.2974, 2.1000, 1.9113,\n",
      "        1.8180, 1.7185, 1.6170, 1.5540, 1.5079, 1.4472, 1.4243, 1.4040, 1.3796,\n",
      "        1.3766, 1.3319, 1.3259, 1.2928, 1.2786, 1.2493, 1.2169, 1.1969, 1.1641,\n",
      "        1.1387, 1.1176, 1.0862, 1.0556, 1.0240, 1.0008, 0.9690, 0.9560, 0.9298,\n",
      "        1.0553], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([2.9857, 2.9969, 2.9891, 2.9704, 2.9671, 2.9611, 2.9522, 2.9345, 2.9253,\n",
      "        2.9172, 2.9083, 2.8989, 2.8658, 2.8279, 2.7815, 2.7480, 2.7011, 2.6160,\n",
      "        2.5544, 2.4676, 2.3723, 2.2782, 2.1426, 2.0368, 1.9048, 1.7773, 1.6485,\n",
      "        1.5251, 1.4088, 1.2975, 1.1938, 1.0963, 1.0118, 0.9358, 0.8697, 0.8065,\n",
      "        0.7563, 0.7093, 0.6707, 0.6335, 0.6019, 0.5742, 0.5544, 0.5329, 0.5149,\n",
      "        0.4979, 0.4847, 0.4701, 0.4583, 0.4460, 0.4347, 0.4222, 0.4095, 0.3951,\n",
      "        0.3820], grad_fn=<AddBackward0>) tensor([6.0947, 6.0179, 6.0214, 6.0868, 6.0374, 6.0247, 6.0560, 6.0698, 6.0400,\n",
      "        5.9423, 5.8876, 5.7457, 5.7582, 5.8694, 5.8476, 5.6926, 5.5827, 5.6517,\n",
      "        5.4207, 5.3161, 5.1418, 4.8925, 4.9018, 4.5513, 4.3972, 4.2312, 3.9889,\n",
      "        3.7892, 3.5837, 3.3729, 3.1839, 3.0449, 2.8860, 2.6862, 2.4839, 2.3946,\n",
      "        2.2734, 2.1378, 1.9887, 1.9512, 1.8931, 1.8726, 1.7468, 1.6920, 1.6748,\n",
      "        1.6601, 1.5849, 1.6014, 1.5254, 1.5334, 1.5135, 1.5015, 1.5066, 1.6610,\n",
      "        6.7628], grad_fn=<AddBackward0>)\n",
      "4684.516261577606\n",
      "r0 before lock-down  tensor([5.3922, 5.3509, 5.3748, 5.3512, 5.3532, 5.3454, 5.3409, 5.3100, 5.2820,\n",
      "        5.2076, 5.1614, 5.0344, 4.8393, 4.5398, 4.2316, 3.8752, 3.4944, 3.1198,\n",
      "        2.7646, 2.4224, 2.1194, 1.8582, 1.6315, 1.4452, 1.2927, 1.1678, 1.0716,\n",
      "        0.9877, 0.9256, 0.8784, 0.8414, 0.8127, 0.7912, 0.7711, 0.7552, 0.7432,\n",
      "        0.7295, 0.7188, 0.7054, 0.6919, 0.6783, 0.6647, 0.6494, 0.6327, 0.6175,\n",
      "        0.6009, 0.5846, 0.5693, 0.5533, 0.5377, 0.5216, 0.5056, 0.4907, 0.4768,\n",
      "        0.4605], grad_fn=<AddBackward0>) tensor([7.9692, 8.0805, 7.9884, 8.0518, 8.0640, 8.0220, 7.9665, 7.9792, 7.9455,\n",
      "        7.9143, 7.7145, 7.5689, 7.3032, 6.9684, 6.4530, 5.9895, 5.5276, 5.0166,\n",
      "        4.4838, 4.0326, 3.5614, 3.1597, 2.8143, 2.5393, 2.2767, 2.0829, 1.8945,\n",
      "        1.7999, 1.6994, 1.5989, 1.5358, 1.4898, 1.4302, 1.4087, 1.3875, 1.3635,\n",
      "        1.3609, 1.3171, 1.3113, 1.2790, 1.2653, 1.2363, 1.2054, 1.1857, 1.1534,\n",
      "        1.1282, 1.1078, 1.0773, 1.0470, 1.0156, 0.9929, 0.9621, 0.9494, 0.9237,\n",
      "        1.0604], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.0220, 3.0328, 3.0248, 3.0093, 3.0071, 2.9976, 2.9874, 2.9716, 2.9591,\n",
      "        2.9534, 2.9469, 2.9359, 2.9008, 2.8652, 2.8168, 2.7834, 2.7324, 2.6494,\n",
      "        2.5871, 2.4999, 2.4005, 2.3068, 2.1659, 2.0603, 1.9250, 1.7960, 1.6655,\n",
      "        1.5398, 1.4216, 1.3086, 1.2032, 1.1037, 1.0184, 0.9407, 0.8735, 0.8096,\n",
      "        0.7587, 0.7111, 0.6715, 0.6341, 0.6018, 0.5736, 0.5535, 0.5315, 0.5133,\n",
      "        0.4961, 0.4827, 0.4681, 0.4560, 0.4436, 0.4323, 0.4197, 0.4069, 0.3925,\n",
      "        0.3793], grad_fn=<AddBackward0>) tensor([6.1389, 6.0659, 6.0694, 6.1155, 6.0559, 6.0610, 6.1038, 6.1048, 6.0947,\n",
      "        5.9833, 5.9149, 5.7799, 5.8013, 5.8926, 5.8861, 5.7233, 5.6371, 5.6839,\n",
      "        5.4477, 5.3337, 5.1781, 4.9109, 4.9419, 4.5730, 4.4258, 4.2471, 3.9975,\n",
      "        3.7973, 3.5914, 3.3754, 3.1918, 3.0546, 2.8855, 2.6956, 2.4926, 2.3960,\n",
      "        2.2754, 2.1334, 1.9943, 1.9407, 1.8863, 1.8711, 1.7405, 1.6925, 1.6754,\n",
      "        1.6587, 1.5808, 1.5870, 1.5177, 1.5292, 1.5053, 1.4941, 1.5072, 1.6726,\n",
      "        7.1295], grad_fn=<AddBackward0>)\n",
      "8977.437997281551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([5.3748, 5.3386, 5.3590, 5.3381, 5.3405, 5.3340, 5.3276, 5.2942, 5.2645,\n",
      "        5.1944, 5.1462, 5.0122, 4.8184, 4.5220, 4.2068, 3.8497, 3.4658, 3.0914,\n",
      "        2.7341, 2.3917, 2.0891, 1.8301, 1.6045, 1.4199, 1.2689, 1.1457, 1.0512,\n",
      "        0.9689, 0.9079, 0.8619, 0.8258, 0.7981, 0.7772, 0.7580, 0.7427, 0.7312,\n",
      "        0.7182, 0.7079, 0.6951, 0.6821, 0.6691, 0.6559, 0.6411, 0.6249, 0.6101,\n",
      "        0.5939, 0.5781, 0.5631, 0.5475, 0.5322, 0.5163, 0.5006, 0.4859, 0.4722,\n",
      "        0.4562], grad_fn=<AddBackward0>) tensor([7.9318, 8.0220, 7.9442, 7.9960, 8.0073, 7.9615, 7.9123, 7.9371, 7.9058,\n",
      "        7.8581, 7.6592, 7.5365, 7.2598, 6.9010, 6.4027, 5.9268, 5.4693, 4.9501,\n",
      "        4.4256, 3.9772, 3.5097, 3.1025, 2.7656, 2.4927, 2.2352, 2.0469, 1.8587,\n",
      "        1.7642, 1.6688, 1.5672, 1.5082, 1.4625, 1.4060, 1.3840, 1.3633, 1.3415,\n",
      "        1.3400, 1.2979, 1.2926, 1.2609, 1.2471, 1.2207, 1.1910, 1.1711, 1.1402,\n",
      "        1.1158, 1.0962, 1.0662, 1.0360, 1.0057, 0.9836, 0.9531, 0.9407, 0.9160,\n",
      "        1.0642], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.0537, 3.0629, 3.0575, 3.0388, 3.0386, 3.0276, 3.0176, 3.0039, 2.9937,\n",
      "        2.9867, 2.9778, 2.9658, 2.9315, 2.8950, 2.8450, 2.8123, 2.7615, 2.6773,\n",
      "        2.6154, 2.5274, 2.4226, 2.3311, 2.1871, 2.0804, 1.9441, 1.8126, 1.6806,\n",
      "        1.5529, 1.4326, 1.3185, 1.2100, 1.1102, 1.0241, 0.9452, 0.8772, 0.8126,\n",
      "        0.7603, 0.7123, 0.6722, 0.6343, 0.6015, 0.5729, 0.5523, 0.5300, 0.5114,\n",
      "        0.4940, 0.4805, 0.4657, 0.4534, 0.4409, 0.4295, 0.4168, 0.4039, 0.3894,\n",
      "        0.3761], grad_fn=<AddBackward0>) tensor([6.1695, 6.1078, 6.0948, 6.1565, 6.0868, 6.0987, 6.1402, 6.1300, 6.1057,\n",
      "        6.0031, 5.9484, 5.8176, 5.8321, 5.9292, 5.9284, 5.7586, 5.6670, 5.7146,\n",
      "        5.4684, 5.3525, 5.2266, 4.9319, 4.9706, 4.5947, 4.4354, 4.2624, 4.0046,\n",
      "        3.8070, 3.6055, 3.3828, 3.2281, 3.0744, 2.8931, 2.7058, 2.4933, 2.3953,\n",
      "        2.2908, 2.1366, 1.9933, 1.9382, 1.8871, 1.8669, 1.7374, 1.6881, 1.6714,\n",
      "        1.6579, 1.5696, 1.5780, 1.5105, 1.5218, 1.5009, 1.4906, 1.5063, 1.6724,\n",
      "        7.3681], grad_fn=<AddBackward0>)\n",
      "4767.549437820911\n",
      "r0 before lock-down  tensor([5.4292, 5.3959, 5.4168, 5.3913, 5.3930, 5.3859, 5.3787, 5.3487, 5.3134,\n",
      "        5.2457, 5.1976, 5.0574, 4.8621, 4.5594, 4.2359, 3.8709, 3.4789, 3.0987,\n",
      "        2.7350, 2.3878, 2.0811, 1.8196, 1.5922, 1.4072, 1.2557, 1.1322, 1.0380,\n",
      "        0.9560, 0.8956, 0.8499, 0.8143, 0.7870, 0.7665, 0.7477, 0.7329, 0.7217,\n",
      "        0.7091, 0.6992, 0.6869, 0.6742, 0.6615, 0.6487, 0.6343, 0.6184, 0.6040,\n",
      "        0.5881, 0.5726, 0.5579, 0.5425, 0.5275, 0.5119, 0.4964, 0.4818, 0.4683,\n",
      "        0.4525], grad_fn=<AddBackward0>) tensor([7.9849, 8.0594, 7.9826, 8.0473, 8.0625, 8.0151, 7.9711, 7.9829, 7.9670,\n",
      "        7.9023, 7.6994, 7.5831, 7.2894, 6.9270, 6.4229, 5.9416, 5.4783, 4.9466,\n",
      "        4.4216, 3.9655, 3.4947, 3.0830, 2.7476, 2.4644, 2.2065, 2.0246, 1.8356,\n",
      "        1.7413, 1.6441, 1.5454, 1.4865, 1.4413, 1.3887, 1.3657, 1.3444, 1.3248,\n",
      "        1.3218, 1.2826, 1.2762, 1.2457, 1.2341, 1.2079, 1.1784, 1.1592, 1.1300,\n",
      "        1.1048, 1.0858, 1.0569, 1.0265, 0.9972, 0.9755, 0.9456, 0.9332, 0.9095,\n",
      "        1.0704], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.0402, 3.0501, 3.0399, 3.0251, 3.0252, 3.0126, 3.0032, 2.9877, 2.9792,\n",
      "        2.9720, 2.9639, 2.9499, 2.9168, 2.8810, 2.8322, 2.7976, 2.7498, 2.6648,\n",
      "        2.6019, 2.5159, 2.4094, 2.3181, 2.1745, 2.0698, 1.9327, 1.8020, 1.6704,\n",
      "        1.5427, 1.4232, 1.3097, 1.2005, 1.1018, 1.0156, 0.9370, 0.8691, 0.8048,\n",
      "        0.7526, 0.7046, 0.6648, 0.6269, 0.5941, 0.5656, 0.5454, 0.5230, 0.5045,\n",
      "        0.4873, 0.4740, 0.4592, 0.4470, 0.4347, 0.4233, 0.4109, 0.3980, 0.3834,\n",
      "        0.3704], grad_fn=<AddBackward0>) tensor([6.1052, 6.0386, 6.0546, 6.0958, 6.0224, 6.0451, 6.0809, 6.0881, 6.0533,\n",
      "        5.9520, 5.8935, 5.7766, 5.7854, 5.8816, 5.8710, 5.7200, 5.6088, 5.6648,\n",
      "        5.4311, 5.3068, 5.1974, 4.9063, 4.9466, 4.5590, 4.4083, 4.2289, 3.9727,\n",
      "        3.7811, 3.5760, 3.3453, 3.2098, 3.0375, 2.8656, 2.6764, 2.4716, 2.3691,\n",
      "        2.2671, 2.1159, 1.9657, 1.9183, 1.8729, 1.8502, 1.7147, 1.6689, 1.6504,\n",
      "        1.6349, 1.5453, 1.5618, 1.4949, 1.5036, 1.4875, 1.4732, 1.4927, 1.6699,\n",
      "        7.4950], grad_fn=<AddBackward0>)\n",
      "11577.972533941269\n",
      "r0 before lock-down  tensor([5.4692, 5.4374, 5.4552, 5.4344, 5.4323, 5.4273, 5.4213, 5.3875, 5.3524,\n",
      "        5.2847, 5.2383, 5.0938, 4.8936, 4.5863, 4.2570, 3.8859, 3.4869, 3.0986,\n",
      "        2.7319, 2.3810, 2.0711, 1.8078, 1.5791, 1.3937, 1.2421, 1.1186, 1.0248,\n",
      "        0.9433, 0.8834, 0.8382, 0.8031, 0.7763, 0.7562, 0.7379, 0.7234, 0.7127,\n",
      "        0.7005, 0.6910, 0.6790, 0.6667, 0.6544, 0.6420, 0.6279, 0.6124, 0.5983,\n",
      "        0.5828, 0.5675, 0.5532, 0.5380, 0.5232, 0.5078, 0.4925, 0.4781, 0.4648,\n",
      "        0.4492], grad_fn=<AddBackward0>) tensor([8.0281, 8.0945, 8.0331, 8.0755, 8.1054, 8.0495, 8.0001, 8.0257, 8.0083,\n",
      "        7.9392, 7.7213, 7.6120, 7.3153, 6.9421, 6.4284, 5.9415, 5.4763, 4.9520,\n",
      "        4.4100, 3.9476, 3.4755, 3.0585, 2.7240, 2.4347, 2.1819, 2.0017, 1.8125,\n",
      "        1.7181, 1.6230, 1.5260, 1.4663, 1.4223, 1.3705, 1.3477, 1.3289, 1.3090,\n",
      "        1.3062, 1.2672, 1.2619, 1.2330, 1.2225, 1.1958, 1.1665, 1.1489, 1.1197,\n",
      "        1.0948, 1.0763, 1.0479, 1.0180, 0.9894, 0.9679, 0.9386, 0.9269, 0.9042,\n",
      "        1.0785], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.0764, 3.0865, 3.0742, 3.0599, 3.0597, 3.0457, 3.0355, 3.0196, 3.0137,\n",
      "        3.0049, 2.9955, 2.9831, 2.9506, 2.9161, 2.8662, 2.8315, 2.7812, 2.6969,\n",
      "        2.6313, 2.5442, 2.4378, 2.3436, 2.1965, 2.0910, 1.9535, 1.8206, 1.6863,\n",
      "        1.5576, 1.4356, 1.3202, 1.2083, 1.1096, 1.0221, 0.9422, 0.8736, 0.8084,\n",
      "        0.7550, 0.7064, 0.6661, 0.6275, 0.5942, 0.5652, 0.5446, 0.5218, 0.5032,\n",
      "        0.4855, 0.4720, 0.4570, 0.4448, 0.4324, 0.4208, 0.4082, 0.3953, 0.3806,\n",
      "        0.3675], grad_fn=<AddBackward0>) tensor([6.1303, 6.0644, 6.0877, 6.1299, 6.0528, 6.0827, 6.1233, 6.1321, 6.0837,\n",
      "        5.9891, 5.9428, 5.8145, 5.8164, 5.8960, 5.8949, 5.7421, 5.6449, 5.6894,\n",
      "        5.4619, 5.3384, 5.2152, 4.9354, 4.9877, 4.5910, 4.4230, 4.2396, 3.9931,\n",
      "        3.7913, 3.5918, 3.3652, 3.2486, 3.0507, 2.8781, 2.6867, 2.4734, 2.3712,\n",
      "        2.2800, 2.1183, 1.9669, 1.9174, 1.8717, 1.8505, 1.7100, 1.6687, 1.6439,\n",
      "        1.6328, 1.5388, 1.5588, 1.4849, 1.4951, 1.4823, 1.4677, 1.4914, 1.6840,\n",
      "        7.7830], grad_fn=<AddBackward0>)\n",
      "12793.480229377747\n",
      "r0 before lock-down  tensor([5.4833, 5.4488, 5.4658, 5.4489, 5.4493, 5.4392, 5.4346, 5.3998, 5.3626,\n",
      "        5.2906, 5.2474, 5.1007, 4.8991, 4.5879, 4.2531, 3.8783, 3.4778, 3.0833,\n",
      "        2.7156, 2.3636, 2.0520, 1.7890, 1.5610, 1.3756, 1.2245, 1.1022, 1.0093,\n",
      "        0.9288, 0.8694, 0.8250, 0.7907, 0.7645, 0.7449, 0.7271, 0.7132, 0.7028,\n",
      "        0.6911, 0.6820, 0.6706, 0.6587, 0.6468, 0.6347, 0.6211, 0.6059, 0.5922,\n",
      "        0.5770, 0.5621, 0.5480, 0.5331, 0.5185, 0.5033, 0.4882, 0.4740, 0.4609,\n",
      "        0.4455], grad_fn=<AddBackward0>) tensor([8.0100, 8.0832, 8.0240, 8.0538, 8.0771, 8.0359, 7.9802, 8.0094, 7.9992,\n",
      "        7.9420, 7.7084, 7.6037, 7.2949, 6.9213, 6.4122, 5.9220, 5.4396, 4.9323,\n",
      "        4.3782, 3.9096, 3.4460, 3.0232, 2.6852, 2.4037, 2.1544, 1.9710, 1.7839,\n",
      "        1.6897, 1.5996, 1.5024, 1.4436, 1.4025, 1.3508, 1.3290, 1.3105, 1.2917,\n",
      "        1.2894, 1.2513, 1.2467, 1.2191, 1.2078, 1.1832, 1.1544, 1.1370, 1.1087,\n",
      "        1.0846, 1.0656, 1.0385, 1.0089, 0.9808, 0.9598, 0.9305, 0.9197, 0.8981,\n",
      "        1.0866], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.0524, 3.0629, 3.0467, 3.0373, 3.0353, 3.0213, 3.0135, 2.9954, 2.9934,\n",
      "        2.9861, 2.9720, 2.9612, 2.9289, 2.8962, 2.8488, 2.8119, 2.7587, 2.6755,\n",
      "        2.6104, 2.5244, 2.4183, 2.3235, 2.1804, 2.0734, 1.9373, 1.8054, 1.6706,\n",
      "        1.5447, 1.4224, 1.3063, 1.1962, 1.0979, 1.0109, 0.9317, 0.8632, 0.7985,\n",
      "        0.7454, 0.6976, 0.6570, 0.6187, 0.5856, 0.5570, 0.5364, 0.5138, 0.4954,\n",
      "        0.4779, 0.4646, 0.4497, 0.4376, 0.4255, 0.4140, 0.4016, 0.3887, 0.3741,\n",
      "        0.3614], grad_fn=<AddBackward0>) tensor([6.0609, 5.9935, 6.0398, 6.0525, 5.9866, 6.0173, 6.0425, 6.0679, 5.9913,\n",
      "        5.8931, 5.8761, 5.7407, 5.7438, 5.8159, 5.8038, 5.6664, 5.5923, 5.6334,\n",
      "        5.4102, 5.2881, 5.1663, 4.8977, 4.9236, 4.5453, 4.3732, 4.1882, 3.9567,\n",
      "        3.7335, 3.5489, 3.3435, 3.2082, 3.0187, 2.8503, 2.6517, 2.4450, 2.3428,\n",
      "        2.2521, 2.0809, 1.9434, 1.8951, 1.8493, 1.8212, 1.6888, 1.6457, 1.6196,\n",
      "        1.6112, 1.5133, 1.5358, 1.4656, 1.4710, 1.4613, 1.4478, 1.4766, 1.6832,\n",
      "        7.9311], grad_fn=<AddBackward0>)\n",
      "4085.7895545959473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([5.5404, 5.5061, 5.5196, 5.5045, 5.5029, 5.4973, 5.4888, 5.4553, 5.4190,\n",
      "        5.3450, 5.3001, 5.1516, 4.9458, 4.6260, 4.2852, 3.9033, 3.4973, 3.0939,\n",
      "        2.7208, 2.3637, 2.0479, 1.7825, 1.5528, 1.3658, 1.2142, 1.0918, 0.9987,\n",
      "        0.9183, 0.8592, 0.8151, 0.7811, 0.7553, 0.7360, 0.7185, 0.7049, 0.6949,\n",
      "        0.6835, 0.6747, 0.6636, 0.6520, 0.6404, 0.6287, 0.6154, 0.6005, 0.5870,\n",
      "        0.5721, 0.5575, 0.5436, 0.5290, 0.5146, 0.4995, 0.4846, 0.4706, 0.4575,\n",
      "        0.4423], grad_fn=<AddBackward0>) tensor([8.0620, 8.1343, 8.0881, 8.1141, 8.1428, 8.0863, 8.0430, 8.0642, 8.0460,\n",
      "        7.9878, 7.7542, 7.6455, 7.3317, 6.9608, 6.4412, 5.9419, 5.4418, 4.9380,\n",
      "        4.3723, 3.9023, 3.4386, 3.0078, 2.6652, 2.3843, 2.1348, 1.9484, 1.7652,\n",
      "        1.6729, 1.5817, 1.4860, 1.4270, 1.3854, 1.3347, 1.3149, 1.2957, 1.2776,\n",
      "        1.2748, 1.2378, 1.2330, 1.2073, 1.1967, 1.1730, 1.1435, 1.1273, 1.0992,\n",
      "        1.0756, 1.0574, 1.0311, 1.0015, 0.9734, 0.9533, 0.9238, 0.9132, 0.8929,\n",
      "        1.0969], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.0809, 3.0910, 3.0729, 3.0663, 3.0624, 3.0517, 3.0435, 3.0193, 3.0222,\n",
      "        3.0140, 3.0001, 2.9876, 2.9571, 2.9255, 2.8767, 2.8368, 2.7844, 2.7005,\n",
      "        2.6366, 2.5481, 2.4406, 2.3458, 2.1992, 2.0912, 1.9531, 1.8203, 1.6831,\n",
      "        1.5569, 1.4321, 1.3148, 1.2032, 1.1042, 1.0158, 0.9352, 0.8666, 0.8006,\n",
      "        0.7471, 0.6985, 0.6573, 0.6186, 0.5849, 0.5560, 0.5348, 0.5121, 0.4933,\n",
      "        0.4756, 0.4621, 0.4470, 0.4348, 0.4225, 0.4111, 0.3984, 0.3856, 0.3708,\n",
      "        0.3582], grad_fn=<AddBackward0>) tensor([6.0827, 6.0194, 6.0712, 6.0692, 6.0174, 6.0232, 6.0531, 6.1172, 6.0101,\n",
      "        5.9158, 5.8978, 5.7735, 5.7651, 5.8256, 5.8234, 5.6988, 5.6167, 5.6566,\n",
      "        5.4225, 5.3127, 5.1862, 4.9085, 4.9451, 4.5632, 4.3981, 4.2014, 3.9789,\n",
      "        3.7410, 3.5673, 3.3575, 3.2196, 3.0248, 2.8608, 2.6708, 2.4446, 2.3543,\n",
      "        2.2558, 2.0844, 1.9434, 1.8932, 1.8463, 1.8132, 1.6902, 1.6363, 1.6092,\n",
      "        1.6027, 1.5020, 1.5271, 1.4567, 1.4608, 1.4482, 1.4489, 1.4754, 1.6964,\n",
      "        8.1941], grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.5712, 5.5290, 5.5433, 5.5328, 5.5295, 5.5209, 5.5148, 5.4801, 5.4422,\n",
      "        5.3675, 5.3269, 5.1739, 4.9610, 4.6401, 4.2964, 3.9085, 3.4959, 3.0899,\n",
      "        2.7141, 2.3518, 2.0354, 1.7690, 1.5389, 1.3517, 1.2002, 1.0785, 0.9859,\n",
      "        0.9061, 0.8476, 0.8040, 0.7704, 0.7451, 0.7263, 0.7091, 0.6960, 0.6864,\n",
      "        0.6754, 0.6669, 0.6562, 0.6450, 0.6337, 0.6224, 0.6094, 0.5948, 0.5817,\n",
      "        0.5670, 0.5527, 0.5390, 0.5246, 0.5104, 0.4956, 0.4808, 0.4670, 0.4541,\n",
      "        0.4390], grad_fn=<AddBackward0>) tensor([8.0534, 8.1477, 8.0979, 8.1106, 8.1446, 8.0979, 8.0430, 8.0700, 8.0542,\n",
      "        7.9920, 7.7403, 7.6436, 7.3417, 6.9546, 6.4197, 5.9224, 5.4287, 4.9138,\n",
      "        4.3394, 3.8884, 3.4181, 2.9827, 2.6409, 2.3597, 2.1134, 1.9226, 1.7410,\n",
      "        1.6496, 1.5600, 1.4656, 1.4082, 1.3670, 1.3176, 1.2995, 1.2806, 1.2623,\n",
      "        1.2608, 1.2243, 1.2193, 1.1950, 1.1848, 1.1616, 1.1322, 1.1173, 1.0889,\n",
      "        1.0657, 1.0483, 1.0230, 0.9936, 0.9659, 0.9465, 0.9177, 0.9068, 0.8884,\n",
      "        1.1090], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1080, 3.1177, 3.0985, 3.0931, 3.0891, 3.0737, 3.0668, 3.0434, 3.0480,\n",
      "        3.0409, 3.0256, 3.0129, 2.9835, 2.9515, 2.9011, 2.8615, 2.8091, 2.7250,\n",
      "        2.6609, 2.5720, 2.4621, 2.3657, 2.2168, 2.1089, 1.9683, 1.8333, 1.6937,\n",
      "        1.5677, 1.4411, 1.3216, 1.2096, 1.1099, 1.0194, 0.9384, 0.8690, 0.8021,\n",
      "        0.7480, 0.6987, 0.6571, 0.6180, 0.5839, 0.5545, 0.5331, 0.5102, 0.4911,\n",
      "        0.4732, 0.4594, 0.4443, 0.4320, 0.4195, 0.4081, 0.3953, 0.3824, 0.3674,\n",
      "        0.3549], grad_fn=<AddBackward0>) tensor([6.0961, 6.0393, 6.0936, 6.0848, 6.0335, 6.0691, 6.0907, 6.1476, 6.0312,\n",
      "        5.9301, 5.9198, 5.7972, 5.7795, 5.8449, 5.8482, 5.7186, 5.6361, 5.6687,\n",
      "        5.4321, 5.3180, 5.2003, 4.9215, 4.9613, 4.5691, 4.4076, 4.2198, 4.0015,\n",
      "        3.7428, 3.5699, 3.3711, 3.2133, 3.0132, 2.8672, 2.6670, 2.4354, 2.3532,\n",
      "        2.2529, 2.0852, 1.9446, 1.8878, 1.8459, 1.8128, 1.6847, 1.6243, 1.6032,\n",
      "        1.5940, 1.5000, 1.5185, 1.4469, 1.4553, 1.4399, 1.4439, 1.4692, 1.7064,\n",
      "        8.4543], grad_fn=<AddBackward0>)\n",
      "9528.356559038162\n",
      "r0 before lock-down  tensor([5.5854, 5.5418, 5.5577, 5.5492, 5.5442, 5.5357, 5.5323, 5.4930, 5.4571,\n",
      "        5.3791, 5.3389, 5.1839, 4.9690, 4.6472, 4.2989, 3.9056, 3.4896, 3.0816,\n",
      "        2.7024, 2.3387, 2.0210, 1.7547, 1.5237, 1.3370, 1.1857, 1.0644, 0.9724,\n",
      "        0.8934, 0.8355, 0.7925, 0.7596, 0.7347, 0.7163, 0.6997, 0.6870, 0.6778,\n",
      "        0.6671, 0.6590, 0.6487, 0.6378, 0.6270, 0.6160, 0.6033, 0.5891, 0.5762,\n",
      "        0.5619, 0.5478, 0.5345, 0.5203, 0.5063, 0.4916, 0.4771, 0.4634, 0.4506,\n",
      "        0.4357], grad_fn=<AddBackward0>) tensor([8.0622, 8.1592, 8.1044, 8.1081, 8.1479, 8.1033, 8.0374, 8.0781, 8.0522,\n",
      "        7.9996, 7.7444, 7.6487, 7.3422, 6.9377, 6.4026, 5.9103, 5.4127, 4.8880,\n",
      "        4.3178, 3.8616, 3.3908, 2.9456, 2.6134, 2.3288, 2.0856, 1.8994, 1.7190,\n",
      "        1.6278, 1.5382, 1.4453, 1.3884, 1.3485, 1.2998, 1.2810, 1.2649, 1.2478,\n",
      "        1.2464, 1.2092, 1.2057, 1.1823, 1.1722, 1.1500, 1.1214, 1.1074, 1.0789,\n",
      "        1.0564, 1.0397, 1.0141, 0.9853, 0.9585, 0.9393, 0.9110, 0.9008, 0.8831,\n",
      "        1.1216], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1066, 3.1165, 3.0972, 3.0933, 3.0898, 3.0718, 3.0650, 3.0403, 3.0441,\n",
      "        3.0366, 3.0235, 3.0126, 2.9795, 2.9485, 2.8990, 2.8595, 2.8084, 2.7226,\n",
      "        2.6601, 2.5708, 2.4625, 2.3625, 2.2182, 2.1075, 1.9655, 1.8297, 1.6918,\n",
      "        1.5652, 1.4380, 1.3183, 1.2065, 1.1070, 1.0156, 0.9349, 0.8651, 0.7982,\n",
      "        0.7441, 0.6947, 0.6529, 0.6138, 0.5795, 0.5502, 0.5284, 0.5057, 0.4865,\n",
      "        0.4686, 0.4547, 0.4395, 0.4274, 0.4149, 0.4035, 0.3906, 0.3778, 0.3626,\n",
      "        0.3503], grad_fn=<AddBackward0>) tensor([6.0617, 6.0040, 6.0572, 6.0373, 5.9847, 6.0382, 6.0547, 6.1222, 6.0131,\n",
      "        5.9138, 5.8939, 5.7606, 5.7636, 5.8272, 5.8239, 5.6970, 5.6087, 5.6529,\n",
      "        5.4051, 5.2957, 5.1653, 4.9118, 4.9129, 4.5429, 4.3942, 4.2172, 3.9760,\n",
      "        3.7223, 3.5569, 3.3591, 3.1962, 2.9884, 2.8597, 2.6509, 2.4275, 2.3425,\n",
      "        2.2404, 2.0729, 1.9345, 1.8753, 1.8321, 1.7946, 1.6780, 1.6065, 1.5899,\n",
      "        1.5830, 1.4852, 1.5103, 1.4333, 1.4398, 1.4245, 1.4361, 1.4629, 1.7061,\n",
      "        8.6232], grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.5907, 5.5483, 5.5586, 5.5560, 5.5515, 5.5375, 5.5339, 5.4965, 5.4593,\n",
      "        5.3832, 5.3421, 5.1869, 4.9662, 4.6466, 4.2930, 3.8956, 3.4783, 3.0692,\n",
      "        2.6878, 2.3220, 2.0042, 1.7373, 1.5065, 1.3203, 1.1701, 1.0495, 0.9583,\n",
      "        0.8802, 0.8230, 0.7806, 0.7485, 0.7241, 0.7062, 0.6901, 0.6777, 0.6689,\n",
      "        0.6587, 0.6511, 0.6411, 0.6307, 0.6201, 0.6095, 0.5972, 0.5834, 0.5708,\n",
      "        0.5568, 0.5430, 0.5300, 0.5161, 0.5023, 0.4878, 0.4734, 0.4598, 0.4472,\n",
      "        0.4325], grad_fn=<AddBackward0>) tensor([8.0449, 8.1377, 8.0988, 8.0832, 8.1192, 8.0952, 8.0264, 8.0659, 8.0405,\n",
      "        7.9771, 7.7241, 7.6184, 7.3307, 6.9031, 6.3716, 5.8806, 5.3760, 4.8437,\n",
      "        4.2721, 3.8222, 3.3494, 2.9071, 2.5830, 2.3014, 2.0561, 1.8727, 1.6948,\n",
      "        1.6030, 1.5167, 1.4283, 1.3656, 1.3291, 1.2813, 1.2621, 1.2474, 1.2332,\n",
      "        1.2306, 1.1947, 1.1919, 1.1681, 1.1598, 1.1374, 1.1106, 1.0966, 1.0693,\n",
      "        1.0475, 1.0317, 1.0063, 0.9773, 0.9512, 0.9323, 0.9048, 0.8948, 0.8783,\n",
      "        1.1349], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1218, 3.1356, 3.1140, 3.1096, 3.1051, 3.0871, 3.0815, 3.0583, 3.0635,\n",
      "        3.0543, 3.0417, 3.0304, 2.9960, 2.9658, 2.9156, 2.8747, 2.8249, 2.7383,\n",
      "        2.6738, 2.5868, 2.4773, 2.3742, 2.2307, 2.1182, 1.9762, 1.8396, 1.7004,\n",
      "        1.5726, 1.4441, 1.3236, 1.2108, 1.1096, 1.0182, 0.9374, 0.8665, 0.7989,\n",
      "        0.7442, 0.6944, 0.6522, 0.6127, 0.5780, 0.5483, 0.5263, 0.5033, 0.4840,\n",
      "        0.4658, 0.4518, 0.4365, 0.4242, 0.4117, 0.4001, 0.3872, 0.3742, 0.3589,\n",
      "        0.3467], grad_fn=<AddBackward0>) tensor([6.0746, 5.9974, 6.0599, 6.0417, 5.9946, 6.0470, 6.0608, 6.1144, 5.9986,\n",
      "        5.9135, 5.8871, 5.7580, 5.7661, 5.8318, 5.8291, 5.7130, 5.6127, 5.6629,\n",
      "        5.4243, 5.2952, 5.1708, 4.9328, 4.9198, 4.5571, 4.3983, 4.2189, 3.9734,\n",
      "        3.7251, 3.5620, 3.3638, 3.1985, 3.0037, 2.8616, 2.6390, 2.4243, 2.3422,\n",
      "        2.2386, 2.0673, 1.9271, 1.8670, 1.8265, 1.7914, 1.6716, 1.6008, 1.5763,\n",
      "        1.5751, 1.4776, 1.4981, 1.4214, 1.4304, 1.4189, 1.4336, 1.4648, 1.7087,\n",
      "        8.7811], grad_fn=<AddBackward0>)\n",
      "4269.2898535728455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([5.6608, 5.6205, 5.6287, 5.6282, 5.6213, 5.6110, 5.6015, 5.5663, 5.5277,\n",
      "        5.4498, 5.4065, 5.2476, 5.0226, 4.6954, 4.3356, 3.9295, 3.5055, 3.0901,\n",
      "        2.7016, 2.3306, 2.0076, 1.7373, 1.5036, 1.3158, 1.1643, 1.0427, 0.9510,\n",
      "        0.8728, 0.8155, 0.7730, 0.7412, 0.7169, 0.6992, 0.6833, 0.6712, 0.6626,\n",
      "        0.6526, 0.6452, 0.6354, 0.6253, 0.6150, 0.6047, 0.5926, 0.5790, 0.5667,\n",
      "        0.5529, 0.5393, 0.5264, 0.5127, 0.4990, 0.4847, 0.4704, 0.4569, 0.4445,\n",
      "        0.4299], grad_fn=<AddBackward0>) tensor([8.1201, 8.2035, 8.1705, 8.1507, 8.1914, 8.1562, 8.1052, 8.1335, 8.1132,\n",
      "        8.0487, 7.7957, 7.6894, 7.3985, 6.9664, 6.4225, 5.9273, 5.4074, 4.8640,\n",
      "        4.2852, 3.8235, 3.3519, 2.9009, 2.5785, 2.2889, 2.0417, 1.8594, 1.6823,\n",
      "        1.5880, 1.5034, 1.4179, 1.3510, 1.3163, 1.2685, 1.2501, 1.2347, 1.2222,\n",
      "        1.2195, 1.1850, 1.1819, 1.1585, 1.1497, 1.1285, 1.1025, 1.0885, 1.0614,\n",
      "        1.0404, 1.0250, 1.0002, 0.9716, 0.9461, 0.9266, 0.8996, 0.8900, 0.8744,\n",
      "        1.1535], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1282, 3.1420, 3.1220, 3.1199, 3.1123, 3.0929, 3.0873, 3.0643, 3.0710,\n",
      "        3.0596, 3.0473, 3.0370, 3.0018, 2.9749, 2.9221, 2.8823, 2.8322, 2.7448,\n",
      "        2.6808, 2.5933, 2.4838, 2.3793, 2.2369, 2.1229, 1.9794, 1.8434, 1.7032,\n",
      "        1.5742, 1.4454, 1.3244, 1.2110, 1.1096, 1.0171, 0.9358, 0.8648, 0.7969,\n",
      "        0.7419, 0.6918, 0.6490, 0.6096, 0.5746, 0.5445, 0.5225, 0.4993, 0.4799,\n",
      "        0.4616, 0.4475, 0.4323, 0.4199, 0.4073, 0.3958, 0.3828, 0.3698, 0.3544,\n",
      "        0.3424], grad_fn=<AddBackward0>) tensor([6.0681, 5.9862, 6.0430, 6.0085, 5.9782, 6.0414, 6.0613, 6.1072, 5.9848,\n",
      "        5.9132, 5.8851, 5.7523, 5.7636, 5.8105, 5.8258, 5.7043, 5.6075, 5.6595,\n",
      "        5.4191, 5.2908, 5.1633, 4.9349, 4.9072, 4.5502, 4.4004, 4.2072, 3.9681,\n",
      "        3.7201, 3.5560, 3.3557, 3.1903, 2.9922, 2.8642, 2.6387, 2.4171, 2.3308,\n",
      "        2.2265, 2.0588, 1.9252, 1.8563, 1.8169, 1.7872, 1.6603, 1.5937, 1.5619,\n",
      "        1.5616, 1.4621, 1.4790, 1.4074, 1.4209, 1.4088, 1.4260, 1.4651, 1.7205,\n",
      "        8.9796], grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.6644, 5.6279, 5.6357, 5.6360, 5.6257, 5.6216, 5.6067, 5.5739, 5.5363,\n",
      "        5.4572, 5.4112, 5.2522, 5.0266, 4.6975, 4.3320, 3.9224, 3.4982, 3.0791,\n",
      "        2.6899, 2.3166, 1.9935, 1.7229, 1.4891, 1.3024, 1.1509, 1.0302, 0.9390,\n",
      "        0.8615, 0.8047, 0.7628, 0.7315, 0.7076, 0.6904, 0.6750, 0.6632, 0.6550,\n",
      "        0.6453, 0.6382, 0.6289, 0.6191, 0.6092, 0.5991, 0.5873, 0.5740, 0.5620,\n",
      "        0.5485, 0.5352, 0.5225, 0.5090, 0.4955, 0.4813, 0.4671, 0.4538, 0.4414,\n",
      "        0.4270], grad_fn=<AddBackward0>) tensor([8.1207, 8.1883, 8.1590, 8.1389, 8.1874, 8.1335, 8.0987, 8.1194, 8.0937,\n",
      "        8.0312, 7.7845, 7.6732, 7.3764, 6.9398, 6.4037, 5.9086, 5.3748, 4.8422,\n",
      "        4.2542, 3.8028, 3.3247, 2.8751, 2.5571, 2.2584, 2.0216, 1.8372, 1.6608,\n",
      "        1.5667, 1.4852, 1.4005, 1.3340, 1.3025, 1.2537, 1.2345, 1.2196, 1.2082,\n",
      "        1.2071, 1.1730, 1.1714, 1.1476, 1.1383, 1.1180, 1.0936, 1.0800, 1.0530,\n",
      "        1.0322, 1.0174, 0.9935, 0.9650, 0.9393, 0.9207, 0.8937, 0.8849, 0.8704,\n",
      "        1.1717], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1067, 3.1201, 3.0982, 3.0956, 3.0907, 3.0716, 3.0662, 3.0446, 3.0499,\n",
      "        3.0393, 3.0249, 3.0158, 2.9821, 2.9520, 2.9025, 2.8638, 2.8149, 2.7272,\n",
      "        2.6627, 2.5757, 2.4654, 2.3627, 2.2218, 2.1084, 1.9658, 1.8302, 1.6914,\n",
      "        1.5622, 1.4343, 1.3145, 1.2011, 1.1002, 1.0081, 0.9275, 0.8566, 0.7887,\n",
      "        0.7344, 0.6844, 0.6417, 0.6027, 0.5677, 0.5377, 0.5158, 0.4928, 0.4734,\n",
      "        0.4551, 0.4412, 0.4260, 0.4137, 0.4013, 0.3898, 0.3770, 0.3639, 0.3486,\n",
      "        0.3369], grad_fn=<AddBackward0>) tensor([5.9989, 5.9232, 5.9886, 5.9601, 5.9134, 5.9748, 5.9951, 6.0316, 5.9200,\n",
      "        5.8488, 5.8336, 5.6942, 5.6938, 5.7672, 5.7651, 5.6407, 5.5398, 5.6010,\n",
      "        5.3731, 5.2466, 5.1302, 4.8961, 4.8636, 4.5055, 4.3596, 4.1696, 3.9237,\n",
      "        3.6901, 3.5212, 3.3109, 3.1577, 2.9622, 2.8407, 2.6113, 2.3939, 2.3194,\n",
      "        2.2055, 2.0392, 1.9123, 1.8333, 1.7974, 1.7712, 1.6369, 1.5723, 1.5406,\n",
      "        1.5396, 1.4402, 1.4606, 1.3883, 1.3999, 1.3914, 1.4089, 1.4563, 1.7198,\n",
      "        9.1317], grad_fn=<AddBackward0>)\n",
      "7996.736602067947\n",
      "r0 before lock-down  tensor([5.6965, 5.6611, 5.6643, 5.6710, 5.6586, 5.6561, 5.6442, 5.6064, 5.5681,\n",
      "        5.4929, 5.4409, 5.2796, 5.0495, 4.7206, 4.3465, 3.9348, 3.5075, 3.0824,\n",
      "        2.6899, 2.3134, 1.9877, 1.7151, 1.4807, 1.2933, 1.1416, 1.0209, 0.9300,\n",
      "        0.8526, 0.7960, 0.7545, 0.7235, 0.6998, 0.6829, 0.6677, 0.6563, 0.6484,\n",
      "        0.6390, 0.6321, 0.6231, 0.6136, 0.6040, 0.5942, 0.5827, 0.5696, 0.5578,\n",
      "        0.5445, 0.5314, 0.5189, 0.5056, 0.4923, 0.4782, 0.4641, 0.4509, 0.4387,\n",
      "        0.4244], grad_fn=<AddBackward0>) tensor([8.1464, 8.2117, 8.1976, 8.1533, 8.2094, 8.1503, 8.1055, 8.1409, 8.1141,\n",
      "        8.0360, 7.8079, 7.6950, 7.4022, 6.9410, 6.4153, 5.9060, 5.3599, 4.8358,\n",
      "        4.2413, 3.7900, 3.3103, 2.8650, 2.5401, 2.2450, 2.0067, 1.8191, 1.6417,\n",
      "        1.5497, 1.4683, 1.3833, 1.3175, 1.2883, 1.2387, 1.2212, 1.2062, 1.1960,\n",
      "        1.1954, 1.1623, 1.1607, 1.1383, 1.1291, 1.1090, 1.0854, 1.0719, 1.0456,\n",
      "        1.0247, 1.0099, 0.9871, 0.9588, 0.9332, 0.9150, 0.8887, 0.8808, 0.8672,\n",
      "        1.1933], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1534, 3.1635, 3.1436, 3.1413, 3.1366, 3.1168, 3.1102, 3.0891, 3.0952,\n",
      "        3.0820, 3.0700, 3.0592, 3.0284, 2.9932, 2.9430, 2.9053, 2.8560, 2.7663,\n",
      "        2.6995, 2.6139, 2.5023, 2.3967, 2.2546, 2.1377, 1.9925, 1.8545, 1.7146,\n",
      "        1.5832, 1.4518, 1.3307, 1.2155, 1.1118, 1.0187, 0.9362, 0.8643, 0.7954,\n",
      "        0.7401, 0.6890, 0.6454, 0.6059, 0.5698, 0.5393, 0.5170, 0.4934, 0.4736,\n",
      "        0.4549, 0.4407, 0.4254, 0.4128, 0.4002, 0.3886, 0.3756, 0.3625, 0.3471,\n",
      "        0.3350], grad_fn=<AddBackward0>) tensor([6.0378, 5.9814, 6.0314, 6.0058, 5.9545, 6.0184, 6.0445, 6.0778, 5.9583,\n",
      "        5.9059, 5.8727, 5.7447, 5.7235, 5.8250, 5.8278, 5.6929, 5.5920, 5.6578,\n",
      "        5.4382, 5.2891, 5.1698, 4.9397, 4.9014, 4.5466, 4.4047, 4.2119, 3.9518,\n",
      "        3.7116, 3.5580, 3.3333, 3.1740, 2.9930, 2.8606, 2.6365, 2.4127, 2.3343,\n",
      "        2.2136, 2.0493, 1.9203, 1.8291, 1.8043, 1.7746, 1.6356, 1.5707, 1.5363,\n",
      "        1.5430, 1.4419, 1.4548, 1.3887, 1.3973, 1.3907, 1.4157, 1.4633, 1.7412,\n",
      "        9.5259], grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.6909, 5.6561, 5.6597, 5.6699, 5.6489, 5.6490, 5.6374, 5.6017, 5.5613,\n",
      "        5.4846, 5.4369, 5.2704, 5.0412, 4.7095, 4.3355, 3.9229, 3.4927, 3.0648,\n",
      "        2.6738, 2.2975, 1.9716, 1.6994, 1.4653, 1.2788, 1.1281, 1.0080, 0.9179,\n",
      "        0.8412, 0.7854, 0.7444, 0.7139, 0.6907, 0.6743, 0.6595, 0.6485, 0.6409,\n",
      "        0.6318, 0.6254, 0.6167, 0.6075, 0.5983, 0.5888, 0.5776, 0.5648, 0.5533,\n",
      "        0.5402, 0.5274, 0.5152, 0.5020, 0.4889, 0.4749, 0.4610, 0.4479, 0.4358,\n",
      "        0.4216], grad_fn=<AddBackward0>) tensor([8.1103, 8.1744, 8.1548, 8.1039, 8.1858, 8.1161, 8.0731, 8.0969, 8.0792,\n",
      "        8.0038, 7.7611, 7.6634, 7.3645, 6.9038, 6.3668, 5.8601, 5.3176, 4.8093,\n",
      "        4.2040, 3.7523, 3.2753, 2.8355, 2.5147, 2.2188, 1.9827, 1.7974, 1.6216,\n",
      "        1.5288, 1.4462, 1.3634, 1.2996, 1.2706, 1.2221, 1.2063, 1.1929, 1.1817,\n",
      "        1.1828, 1.1504, 1.1488, 1.1267, 1.1192, 1.0998, 1.0756, 1.0628, 1.0378,\n",
      "        1.0175, 1.0023, 0.9796, 0.9524, 0.9273, 0.9093, 0.8831, 0.8759, 0.8637,\n",
      "        1.2153], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1299, 3.1389, 3.1215, 3.1212, 3.1120, 3.0953, 3.0865, 3.0687, 3.0714,\n",
      "        3.0612, 3.0455, 3.0365, 3.0071, 2.9721, 2.9225, 2.8837, 2.8358, 2.7450,\n",
      "        2.6819, 2.5939, 2.4843, 2.3793, 2.2369, 2.1219, 1.9773, 1.8400, 1.7001,\n",
      "        1.5684, 1.4392, 1.3181, 1.2038, 1.1009, 1.0079, 0.9254, 0.8545, 0.7855,\n",
      "        0.7306, 0.6799, 0.6364, 0.5971, 0.5614, 0.5310, 0.5088, 0.4852, 0.4658,\n",
      "        0.4472, 0.4332, 0.4179, 0.4056, 0.3931, 0.3817, 0.3688, 0.3558, 0.3404,\n",
      "        0.3287], grad_fn=<AddBackward0>) tensor([5.9761, 5.9257, 5.9583, 5.9250, 5.8974, 5.9436, 5.9833, 5.9989, 5.9016,\n",
      "        5.8322, 5.8226, 5.6857, 5.6554, 5.7628, 5.7605, 5.6374, 5.5320, 5.6107,\n",
      "        5.3727, 5.2481, 5.1167, 4.8849, 4.8571, 4.4881, 4.3513, 4.1624, 3.9109,\n",
      "        3.6807, 3.5076, 3.2930, 3.1257, 2.9455, 2.8231, 2.6122, 2.3725, 2.3120,\n",
      "        2.1839, 2.0225, 1.8942, 1.8003, 1.7737, 1.7495, 1.6072, 1.5520, 1.5047,\n",
      "        1.5176, 1.4124, 1.4338, 1.3653, 1.3785, 1.3751, 1.4089, 1.4571, 1.7306,\n",
      "        9.5822], grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([5.7595, 5.7287, 5.7284, 5.7426, 5.7168, 5.7208, 5.7064, 5.6726, 5.6342,\n",
      "        5.5563, 5.5016, 5.3333, 5.0990, 4.7625, 4.3792, 3.9584, 3.5250, 3.0878,\n",
      "        2.6914, 2.3090, 1.9781, 1.7030, 1.4659, 1.2773, 1.1251, 1.0038, 0.9130,\n",
      "        0.8361, 0.7800, 0.7390, 0.7083, 0.6853, 0.6689, 0.6543, 0.6434, 0.6360,\n",
      "        0.6271, 0.6208, 0.6124, 0.6034, 0.5943, 0.5850, 0.5740, 0.5615, 0.5501,\n",
      "        0.5372, 0.5246, 0.5125, 0.4995, 0.4864, 0.4725, 0.4586, 0.4456, 0.4335,\n",
      "        0.4194], grad_fn=<AddBackward0>) tensor([8.1912, 8.2415, 8.2328, 8.1700, 8.2660, 8.1853, 8.1491, 8.1647, 8.1344,\n",
      "        8.0592, 7.8355, 7.7274, 7.4297, 6.9567, 6.4168, 5.9103, 5.3397, 4.8384,\n",
      "        4.2155, 3.7651, 3.2830, 2.8359, 2.5121, 2.2130, 1.9749, 1.7898, 1.6142,\n",
      "        1.5174, 1.4359, 1.3523, 1.2912, 1.2609, 1.2133, 1.1966, 1.1837, 1.1730,\n",
      "        1.1746, 1.1410, 1.1407, 1.1190, 1.1131, 1.0934, 1.0702, 1.0565, 1.0324,\n",
      "        1.0119, 0.9970, 0.9749, 0.9478, 0.9231, 0.9049, 0.8792, 0.8725, 0.8616,\n",
      "        1.2417], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1778, 3.1871, 3.1694, 3.1711, 3.1633, 3.1419, 3.1341, 3.1170, 3.1217,\n",
      "        3.1104, 3.0939, 3.0836, 3.0531, 3.0207, 2.9695, 2.9309, 2.8806, 2.7922,\n",
      "        2.7252, 2.6354, 2.5249, 2.4182, 2.2725, 2.1555, 2.0078, 1.8688, 1.7258,\n",
      "        1.5921, 1.4605, 1.3362, 1.2207, 1.1155, 1.0203, 0.9365, 0.8641, 0.7939,\n",
      "        0.7378, 0.6861, 0.6416, 0.6014, 0.5649, 0.5337, 0.5109, 0.4868, 0.4669,\n",
      "        0.4479, 0.4335, 0.4179, 0.4053, 0.3927, 0.3810, 0.3678, 0.3547, 0.3391,\n",
      "        0.3271], grad_fn=<AddBackward0>) tensor([6.0439, 5.9927, 6.0241, 5.9825, 5.9451, 6.0159, 6.0518, 6.0591, 5.9531,\n",
      "        5.8866, 5.8800, 5.7539, 5.7258, 5.8158, 5.8224, 5.6943, 5.5960, 5.6509,\n",
      "        5.4343, 5.3117, 5.1715, 4.9331, 4.9129, 4.5387, 4.4069, 4.2040, 3.9563,\n",
      "        3.7156, 3.5410, 3.3387, 3.1549, 2.9775, 2.8586, 2.6368, 2.3942, 2.3306,\n",
      "        2.2034, 2.0342, 1.8993, 1.8091, 1.7803, 1.7557, 1.6122, 1.5520, 1.5085,\n",
      "        1.5205, 1.4144, 1.4350, 1.3696, 1.3793, 1.3739, 1.4165, 1.4666, 1.7544,\n",
      "        9.9308], grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.7540, 5.7254, 5.7262, 5.7394, 5.7152, 5.7177, 5.7011, 5.6670, 5.6268,\n",
      "        5.5552, 5.4955, 5.3284, 5.0928, 4.7548, 4.3705, 3.9465, 3.5140, 3.0742,\n",
      "        2.6769, 2.2943, 1.9640, 1.6889, 1.4525, 1.2641, 1.1128, 0.9922, 0.9018,\n",
      "        0.8255, 0.7701, 0.7294, 0.6993, 0.6766, 0.6607, 0.6464, 0.6359, 0.6288,\n",
      "        0.6203, 0.6144, 0.6062, 0.5976, 0.5888, 0.5798, 0.5691, 0.5568, 0.5457,\n",
      "        0.5331, 0.5207, 0.5088, 0.4959, 0.4830, 0.4693, 0.4555, 0.4426, 0.4306,\n",
      "        0.4167], grad_fn=<AddBackward0>) tensor([8.1730, 8.2095, 8.1986, 8.1413, 8.2310, 8.1551, 8.1266, 8.1403, 8.1161,\n",
      "        8.0170, 7.8101, 7.6972, 7.3989, 6.9209, 6.3778, 5.8781, 5.2957, 4.8085,\n",
      "        4.1841, 3.7345, 3.2512, 2.8060, 2.4809, 2.1891, 1.9486, 1.7655, 1.5936,\n",
      "        1.5006, 1.4165, 1.3357, 1.2743, 1.2454, 1.1976, 1.1827, 1.1702, 1.1599,\n",
      "        1.1618, 1.1286, 1.1302, 1.1085, 1.1032, 1.0830, 1.0605, 1.0476, 1.0239,\n",
      "        1.0040, 0.9900, 0.9678, 0.9415, 0.9166, 0.8990, 0.8735, 0.8678, 0.8580,\n",
      "        1.2679], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1786, 3.1839, 3.1661, 3.1675, 3.1629, 3.1402, 3.1329, 3.1167, 3.1207,\n",
      "        3.1074, 3.0945, 3.0834, 3.0510, 3.0199, 2.9664, 2.9298, 2.8775, 2.7925,\n",
      "        2.7237, 2.6352, 2.5235, 2.4191, 2.2717, 2.1544, 2.0067, 1.8655, 1.7241,\n",
      "        1.5907, 1.4584, 1.3340, 1.2189, 1.1140, 1.0186, 0.9337, 0.8615, 0.7910,\n",
      "        0.7350, 0.6831, 0.6387, 0.5981, 0.5617, 0.5302, 0.5074, 0.4832, 0.4632,\n",
      "        0.4440, 0.4297, 0.4141, 0.4015, 0.3887, 0.3772, 0.3639, 0.3507, 0.3352,\n",
      "        0.3232], grad_fn=<AddBackward0>) tensor([ 5.9940,  5.9649,  5.9990,  5.9567,  5.9065,  5.9832,  6.0160,  6.0145,\n",
      "         5.9120,  5.8599,  5.8347,  5.7145,  5.6996,  5.7821,  5.8074,  5.6675,\n",
      "         5.5859,  5.6192,  5.4195,  5.2872,  5.1524,  4.9015,  4.8924,  4.5204,\n",
      "         4.3916,  4.2115,  3.9454,  3.6992,  3.5341,  3.3290,  3.1423,  2.9561,\n",
      "         2.8348,  2.6349,  2.3908,  2.3326,  2.2004,  2.0293,  1.8911,  1.8023,\n",
      "         1.7676,  1.7473,  1.5999,  1.5429,  1.4973,  1.5143,  1.4018,  1.4212,\n",
      "         1.3561,  1.3762,  1.3686,  1.4079,  1.4690,  1.7616, 10.1345],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.7623, 5.7357, 5.7352, 5.7464, 5.7245, 5.7236, 5.7099, 5.6701, 5.6310,\n",
      "        5.5592, 5.4992, 5.3352, 5.0939, 4.7532, 4.3701, 3.9420, 3.5078, 3.0667,\n",
      "        2.6679, 2.2843, 1.9534, 1.6782, 1.4423, 1.2537, 1.1028, 0.9823, 0.8924,\n",
      "        0.8164, 0.7614, 0.7211, 0.6914, 0.6690, 0.6535, 0.6395, 0.6293, 0.6225,\n",
      "        0.6143, 0.6086, 0.6007, 0.5924, 0.5839, 0.5752, 0.5648, 0.5528, 0.5419,\n",
      "        0.5295, 0.5172, 0.5055, 0.4929, 0.4801, 0.4665, 0.4528, 0.4399, 0.4281,\n",
      "        0.4142], grad_fn=<AddBackward0>) tensor([8.1521, 8.1815, 8.1739, 8.1224, 8.2064, 8.1429, 8.1027, 8.1389, 8.1086,\n",
      "        8.0055, 7.8008, 7.6706, 7.3874, 6.9136, 6.3519, 5.8596, 5.2759, 4.7869,\n",
      "        4.1639, 3.7200, 3.2348, 2.7874, 2.4570, 2.1701, 1.9280, 1.7462, 1.5750,\n",
      "        1.4842, 1.4007, 1.3208, 1.2591, 1.2319, 1.1841, 1.1699, 1.1571, 1.1482,\n",
      "        1.1507, 1.1179, 1.1205, 1.0986, 1.0933, 1.0751, 1.0521, 1.0395, 1.0168,\n",
      "        0.9970, 0.9839, 0.9618, 0.9361, 0.9115, 0.8938, 0.8692, 0.8638, 0.8552,\n",
      "        1.2986], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1752, 3.1779, 3.1623, 3.1634, 3.1599, 3.1364, 3.1289, 3.1125, 3.1170,\n",
      "        3.1061, 3.0899, 3.0813, 3.0464, 3.0151, 2.9654, 2.9274, 2.8753, 2.7892,\n",
      "        2.7209, 2.6332, 2.5223, 2.4176, 2.2689, 2.1516, 2.0046, 1.8617, 1.7210,\n",
      "        1.5870, 1.4552, 1.3305, 1.2150, 1.1093, 1.0138, 0.9296, 0.8571, 0.7865,\n",
      "        0.7303, 0.6787, 0.6339, 0.5933, 0.5569, 0.5255, 0.5025, 0.4782, 0.4582,\n",
      "        0.4392, 0.4249, 0.4093, 0.3967, 0.3840, 0.3724, 0.3593, 0.3461, 0.3306,\n",
      "        0.3186], grad_fn=<AddBackward0>) tensor([ 5.9595,  5.9479,  5.9711,  5.9290,  5.8737,  5.9537,  5.9906,  5.9883,\n",
      "         5.8846,  5.8158,  5.8146,  5.6784,  5.6805,  5.7665,  5.7673,  5.6380,\n",
      "         5.5573,  5.6008,  5.3953,  5.2591,  5.1169,  4.8684,  4.8686,  4.4924,\n",
      "         4.3607,  4.1940,  3.9191,  3.6745,  3.5039,  3.3008,  3.1189,  2.9486,\n",
      "         2.8245,  2.6138,  2.3691,  2.3173,  2.1873,  2.0060,  1.8761,  1.7903,\n",
      "         1.7494,  1.7281,  1.5860,  1.5314,  1.4860,  1.4988,  1.3885,  1.4061,\n",
      "         1.3435,  1.3632,  1.3590,  1.3957,  1.4623,  1.7581, 10.3639],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.8292, 5.8035, 5.8038, 5.8108, 5.7931, 5.7923, 5.7724, 5.7339, 5.6921,\n",
      "        5.6248, 5.5586, 5.3930, 5.1492, 4.8020, 4.4097, 3.9774, 3.5394, 3.0914,\n",
      "        2.6858, 2.2968, 1.9615, 1.6827, 1.4441, 1.2533, 1.1008, 0.9793, 0.8886,\n",
      "        0.8121, 0.7569, 0.7164, 0.6867, 0.6642, 0.6488, 0.6350, 0.6249, 0.6182,\n",
      "        0.6101, 0.6046, 0.5970, 0.5888, 0.5805, 0.5719, 0.5617, 0.5499, 0.5391,\n",
      "        0.5269, 0.5148, 0.5032, 0.4907, 0.4780, 0.4644, 0.4507, 0.4379, 0.4261,\n",
      "        0.4123], grad_fn=<AddBackward0>) tensor([8.2164, 8.2414, 8.2309, 8.1953, 8.2636, 8.2013, 8.1782, 8.2101, 8.1851,\n",
      "        8.0613, 7.8720, 7.7342, 7.4446, 6.9654, 6.4080, 5.9006, 5.2956, 4.7990,\n",
      "        4.1780, 3.7300, 3.2393, 2.7903, 2.4532, 2.1670, 1.9236, 1.7415, 1.5670,\n",
      "        1.4774, 1.3928, 1.3117, 1.2509, 1.2241, 1.1753, 1.1602, 1.1494, 1.1405,\n",
      "        1.1429, 1.1110, 1.1133, 1.0920, 1.0860, 1.0699, 1.0472, 1.0337, 1.0117,\n",
      "        0.9927, 0.9797, 0.9576, 0.9327, 0.9077, 0.8904, 0.8662, 0.8609, 0.8536,\n",
      "        1.3357], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.1939, 3.1982, 3.1811, 3.1853, 3.1803, 3.1566, 3.1483, 3.1327, 3.1376,\n",
      "        3.1264, 3.1118, 3.1011, 3.0671, 3.0380, 2.9888, 2.9455, 2.8932, 2.8085,\n",
      "        2.7384, 2.6510, 2.5405, 2.4358, 2.2844, 2.1644, 2.0147, 1.8734, 1.7306,\n",
      "        1.5936, 1.4620, 1.3361, 1.2197, 1.1131, 1.0160, 0.9315, 0.8584, 0.7874,\n",
      "        0.7304, 0.6785, 0.6333, 0.5923, 0.5556, 0.5238, 0.5006, 0.4760, 0.4559,\n",
      "        0.4368, 0.4224, 0.4067, 0.3941, 0.3810, 0.3696, 0.3564, 0.3431, 0.3274,\n",
      "        0.3154], grad_fn=<AddBackward0>) tensor([ 5.9762,  5.9573,  5.9906,  5.9279,  5.8795,  5.9657,  6.0091,  5.9969,\n",
      "         5.8919,  5.8260,  5.8136,  5.6846,  5.6856,  5.7601,  5.7538,  5.6554,\n",
      "         5.5719,  5.6047,  5.4058,  5.2641,  5.1107,  4.8555,  4.8638,  4.4962,\n",
      "         4.3804,  4.1828,  3.9162,  3.6906,  3.5017,  3.2979,  3.1114,  2.9421,\n",
      "         2.8349,  2.6109,  2.3633,  2.3023,  2.1814,  1.9958,  1.8686,  1.7821,\n",
      "         1.7411,  1.7264,  1.5842,  1.5303,  1.4823,  1.5004,  1.3786,  1.3983,\n",
      "         1.3279,  1.3648,  1.3498,  1.3896,  1.4607,  1.7806, 10.6161],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([5.8085, 5.7853, 5.7828, 5.7919, 5.7721, 5.7717, 5.7488, 5.7145, 5.6702,\n",
      "        5.6033, 5.5363, 5.3712, 5.1263, 4.7784, 4.3877, 3.9548, 3.5177, 3.0732,\n",
      "        2.6674, 2.2800, 1.9449, 1.6678, 1.4306, 1.2409, 1.0893, 0.9685, 0.8786,\n",
      "        0.8026, 0.7480, 0.7081, 0.6788, 0.6568, 0.6417, 0.6283, 0.6185, 0.6122,\n",
      "        0.6045, 0.5992, 0.5919, 0.5840, 0.5760, 0.5677, 0.5577, 0.5462, 0.5356,\n",
      "        0.5236, 0.5117, 0.5003, 0.4879, 0.4753, 0.4618, 0.4482, 0.4355, 0.4238,\n",
      "        0.4100], grad_fn=<AddBackward0>) tensor([8.1593, 8.1762, 8.1739, 8.1350, 8.2037, 8.1429, 8.1312, 8.1492, 8.1294,\n",
      "        8.0080, 7.8201, 7.6841, 7.3975, 6.9204, 6.3599, 5.8621, 5.2613, 4.7546,\n",
      "        4.1467, 3.6965, 3.2179, 2.7660, 2.4281, 2.1439, 1.8999, 1.7213, 1.5470,\n",
      "        1.4612, 1.3753, 1.2940, 1.2369, 1.2101, 1.1635, 1.1488, 1.1377, 1.1290,\n",
      "        1.1317, 1.1017, 1.1024, 1.0827, 1.0776, 1.0622, 1.0398, 1.0263, 1.0058,\n",
      "        0.9866, 0.9737, 0.9517, 0.9275, 0.9033, 0.8860, 0.8617, 0.8570, 0.8514,\n",
      "        1.3726], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2020, 3.2042, 3.1844, 3.1881, 3.1865, 3.1617, 3.1534, 3.1414, 3.1434,\n",
      "        3.1308, 3.1182, 3.1068, 3.0713, 3.0448, 2.9978, 2.9521, 2.9019, 2.8146,\n",
      "        2.7450, 2.6568, 2.5466, 2.4406, 2.2885, 2.1703, 2.0178, 1.8768, 1.7314,\n",
      "        1.5953, 1.4634, 1.3359, 1.2203, 1.1131, 1.0153, 0.9300, 0.8572, 0.7858,\n",
      "        0.7281, 0.6763, 0.6311, 0.5898, 0.5529, 0.5210, 0.4975, 0.4729, 0.4527,\n",
      "        0.4334, 0.4188, 0.4032, 0.3906, 0.3775, 0.3660, 0.3527, 0.3394, 0.3235,\n",
      "        0.3116], grad_fn=<AddBackward0>) tensor([ 5.9508,  5.9424,  5.9913,  5.9331,  5.8652,  5.9568,  6.0053,  5.9664,\n",
      "         5.8801,  5.8258,  5.7970,  5.6735,  5.6833,  5.7407,  5.7227,  5.6414,\n",
      "         5.5436,  5.5943,  5.3863,  5.2544,  5.0961,  4.8456,  4.8556,  4.4671,\n",
      "         4.3714,  4.1622,  3.9200,  3.6738,  3.4797,  3.2915,  3.0910,  2.9236,\n",
      "         2.8227,  2.6103,  2.3515,  2.2955,  2.1853,  1.9929,  1.8566,  1.7758,\n",
      "         1.7338,  1.7192,  1.5780,  1.5196,  1.4733,  1.4889,  1.3738,  1.3915,\n",
      "         1.3185,  1.3536,  1.3415,  1.3816,  1.4607,  1.7939, 10.8178],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.8286, 5.8010, 5.8007, 5.8077, 5.7898, 5.7891, 5.7657, 5.7286, 5.6881,\n",
      "        5.6165, 5.5511, 5.3830, 5.1410, 4.7857, 4.3950, 3.9594, 3.5186, 3.0729,\n",
      "        2.6672, 2.2763, 1.9406, 1.6624, 1.4244, 1.2346, 1.0827, 0.9618, 0.8719,\n",
      "        0.7960, 0.7415, 0.7018, 0.6727, 0.6509, 0.6361, 0.6229, 0.6134, 0.6073,\n",
      "        0.5998, 0.5948, 0.5878, 0.5801, 0.5723, 0.5642, 0.5545, 0.5431, 0.5328,\n",
      "        0.5209, 0.5092, 0.4979, 0.4857, 0.4732, 0.4597, 0.4461, 0.4335, 0.4218,\n",
      "        0.4081], grad_fn=<AddBackward0>) tensor([8.1490, 8.1819, 8.1708, 8.1414, 8.2008, 8.1435, 8.1330, 8.1563, 8.1206,\n",
      "        8.0188, 7.8234, 7.6943, 7.3865, 6.9235, 6.3509, 5.8529, 5.2604, 4.7461,\n",
      "        4.1258, 3.6859, 3.2033, 2.7549, 2.4152, 2.1295, 1.8857, 1.7096, 1.5349,\n",
      "        1.4503, 1.3640, 1.2827, 1.2247, 1.1996, 1.1533, 1.1387, 1.1284, 1.1203,\n",
      "        1.1230, 1.0942, 1.0941, 1.0760, 1.0710, 1.0550, 1.0339, 1.0206, 1.0000,\n",
      "        0.9820, 0.9697, 0.9473, 0.9239, 0.8996, 0.8822, 0.8588, 0.8544, 0.8501,\n",
      "        1.4157], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2001, 3.2032, 3.1793, 3.1873, 3.1851, 3.1598, 3.1527, 3.1420, 3.1417,\n",
      "        3.1300, 3.1173, 3.1024, 3.0693, 3.0471, 2.9976, 2.9511, 2.8996, 2.8151,\n",
      "        2.7462, 2.6554, 2.5461, 2.4393, 2.2881, 2.1696, 2.0154, 1.8753, 1.7301,\n",
      "        1.5933, 1.4616, 1.3341, 1.2182, 1.1105, 1.0129, 0.9272, 0.8540, 0.7823,\n",
      "        0.7246, 0.6728, 0.6272, 0.5860, 0.5490, 0.5168, 0.4933, 0.4686, 0.4483,\n",
      "        0.4290, 0.4143, 0.3987, 0.3861, 0.3729, 0.3615, 0.3483, 0.3349, 0.3189,\n",
      "        0.3072], grad_fn=<AddBackward0>) tensor([ 5.9216,  5.9088,  5.9843,  5.8992,  5.8344,  5.9298,  5.9729,  5.9234,\n",
      "         5.8506,  5.7971,  5.7669,  5.6647,  5.6609,  5.6962,  5.6948,  5.6206,\n",
      "         5.5333,  5.5652,  5.3566,  5.2427,  5.0813,  4.8389,  4.8391,  4.4530,\n",
      "         4.3701,  4.1505,  3.9078,  3.6608,  3.4642,  3.2728,  3.0726,  2.9112,\n",
      "         2.8037,  2.5971,  2.3390,  2.2924,  2.1762,  1.9792,  1.8489,  1.7644,\n",
      "         1.7189,  1.7108,  1.5661,  1.5021,  1.4560,  1.4736,  1.3609,  1.3730,\n",
      "         1.3076,  1.3473,  1.3360,  1.3760,  1.4554,  1.8016, 10.9437],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.8717, 5.8452, 5.8394, 5.8515, 5.8330, 5.8317, 5.8094, 5.7722, 5.7327,\n",
      "        5.6575, 5.5927, 5.4185, 5.1774, 4.8150, 4.4178, 3.9816, 3.5365, 3.0880,\n",
      "        2.6769, 2.2826, 1.9451, 1.6646, 1.4242, 1.2337, 1.0803, 0.9588, 0.8682,\n",
      "        0.7922, 0.7374, 0.6978, 0.6686, 0.6468, 0.6321, 0.6190, 0.6096, 0.6037,\n",
      "        0.5964, 0.5914, 0.5846, 0.5771, 0.5695, 0.5616, 0.5520, 0.5408, 0.5306,\n",
      "        0.5188, 0.5072, 0.4961, 0.4839, 0.4715, 0.4580, 0.4444, 0.4318, 0.4201,\n",
      "        0.4064], grad_fn=<AddBackward0>) tensor([8.1753, 8.2064, 8.2149, 8.1650, 8.2280, 8.1707, 8.1546, 8.1785, 8.1366,\n",
      "        8.0419, 7.8423, 7.7259, 7.4048, 6.9481, 6.3819, 5.8668, 5.2675, 4.7464,\n",
      "        4.1315, 3.6924, 3.1982, 2.7511, 2.4176, 2.1232, 1.8825, 1.7020, 1.5320,\n",
      "        1.4447, 1.3580, 1.2747, 1.2178, 1.1930, 1.1435, 1.1318, 1.1220, 1.1121,\n",
      "        1.1161, 1.0879, 1.0874, 1.0706, 1.0647, 1.0496, 1.0296, 1.0165, 0.9955,\n",
      "        0.9781, 0.9661, 0.9433, 0.9212, 0.8962, 0.8795, 0.8568, 0.8525, 0.8496,\n",
      "        1.4636], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2278, 3.2340, 3.2055, 3.2175, 3.2136, 3.1871, 3.1842, 3.1708, 3.1725,\n",
      "        3.1596, 3.1455, 3.1277, 3.0972, 3.0753, 3.0271, 2.9774, 2.9275, 2.8405,\n",
      "        2.7730, 2.6836, 2.5699, 2.4610, 2.3093, 2.1894, 2.0334, 1.8926, 1.7450,\n",
      "        1.6063, 1.4739, 1.3451, 1.2270, 1.1182, 1.0202, 0.9327, 0.8586, 0.7866,\n",
      "        0.7278, 0.6755, 0.6291, 0.5876, 0.5500, 0.5174, 0.4936, 0.4685, 0.4479,\n",
      "        0.4283, 0.4134, 0.3976, 0.3848, 0.3715, 0.3599, 0.3466, 0.3330, 0.3167,\n",
      "        0.3051], grad_fn=<AddBackward0>) tensor([ 5.9477,  5.9188,  6.0198,  5.9106,  5.8572,  5.9574,  5.9801,  5.9459,\n",
      "         5.8607,  5.8105,  5.7905,  5.7050,  5.6849,  5.7241,  5.7130,  5.6524,\n",
      "         5.5514,  5.5985,  5.3741,  5.2503,  5.1063,  4.8684,  4.8649,  4.4718,\n",
      "         4.3930,  4.1596,  3.9241,  3.6806,  3.4714,  3.2740,  3.0853,  2.9242,\n",
      "         2.7971,  2.6058,  2.3494,  2.2905,  2.1842,  1.9859,  1.8531,  1.7667,\n",
      "         1.7261,  1.7183,  1.5668,  1.5044,  1.4543,  1.4736,  1.3615,  1.3763,\n",
      "         1.3093,  1.3450,  1.3353,  1.3757,  1.4620,  1.8260, 11.2354],\n",
      "       grad_fn=<AddBackward0>)\n",
      "9325.538086652756\n",
      "r0 before lock-down  tensor([5.8978, 5.8729, 5.8674, 5.8758, 5.8633, 5.8558, 5.8340, 5.7986, 5.7617,\n",
      "        5.6855, 5.6138, 5.4395, 5.1985, 4.8330, 4.4305, 3.9939, 3.5449, 3.0935,\n",
      "        2.6798, 2.2829, 1.9442, 1.6620, 1.4206, 1.2296, 1.0756, 0.9535, 0.8625,\n",
      "        0.7866, 0.7318, 0.6922, 0.6632, 0.6416, 0.6270, 0.6141, 0.6049, 0.5992,\n",
      "        0.5921, 0.5873, 0.5808, 0.5734, 0.5661, 0.5584, 0.5489, 0.5380, 0.5279,\n",
      "        0.5163, 0.5049, 0.4939, 0.4817, 0.4694, 0.4560, 0.4424, 0.4298, 0.4182,\n",
      "        0.4045], grad_fn=<AddBackward0>) tensor([8.1885, 8.2159, 8.2179, 8.1804, 8.2267, 8.1879, 8.1726, 8.1871, 8.1370,\n",
      "        8.0436, 7.8591, 7.7381, 7.4125, 6.9441, 6.3904, 5.8558, 5.2654, 4.7402,\n",
      "        4.1258, 3.6875, 3.1868, 2.7421, 2.4057, 2.1076, 1.8680, 1.6925, 1.5268,\n",
      "        1.4319, 1.3472, 1.2657, 1.2062, 1.1811, 1.1328, 1.1226, 1.1139, 1.1028,\n",
      "        1.1072, 1.0808, 1.0792, 1.0637, 1.0588, 1.0420, 1.0244, 1.0117, 0.9904,\n",
      "        0.9730, 0.9617, 0.9393, 0.9181, 0.8931, 0.8769, 0.8544, 0.8500, 0.8483,\n",
      "        1.5149], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2218, 3.2271, 3.2005, 3.2111, 3.2093, 3.1836, 3.1803, 3.1679, 3.1692,\n",
      "        3.1550, 3.1409, 3.1234, 3.0933, 3.0712, 3.0240, 2.9740, 2.9249, 2.8370,\n",
      "        2.7732, 2.6827, 2.5679, 2.4596, 2.3054, 2.1866, 2.0307, 1.8902, 1.7417,\n",
      "        1.6029, 1.4702, 1.3418, 1.2240, 1.1147, 1.0171, 0.9286, 0.8546, 0.7828,\n",
      "        0.7239, 0.6714, 0.6248, 0.5835, 0.5457, 0.5130, 0.4890, 0.4640, 0.4435,\n",
      "        0.4238, 0.4089, 0.3931, 0.3803, 0.3670, 0.3555, 0.3421, 0.3286, 0.3122,\n",
      "        0.3008], grad_fn=<AddBackward0>) tensor([ 5.9245,  5.9020,  5.9889,  5.8905,  5.8247,  5.9173,  5.9451,  5.9062,\n",
      "         5.8248,  5.7815,  5.7656,  5.6776,  5.6553,  5.6999,  5.6847,  5.6258,\n",
      "         5.5205,  5.5775,  5.3299,  5.2140,  5.0789,  4.8344,  4.8557,  4.4506,\n",
      "         4.3733,  4.1380,  3.9084,  3.6636,  3.4594,  3.2600,  3.0593,  2.9020,\n",
      "         2.7689,  2.5960,  2.3406,  2.2693,  2.1671,  1.9706,  1.8477,  1.7485,\n",
      "         1.7087,  1.7027,  1.5569,  1.4899,  1.4375,  1.4601,  1.3495,  1.3675,\n",
      "         1.2983,  1.3352,  1.3239,  1.3737,  1.4544,  1.8394, 11.4179],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([5.9068, 5.8749, 5.8736, 5.8773, 5.8725, 5.8632, 5.8456, 5.8067, 5.7664,\n",
      "        5.6893, 5.6210, 5.4433, 5.2015, 4.8386, 4.4307, 3.9917, 3.5434, 3.0901,\n",
      "        2.6741, 2.2784, 1.9384, 1.6561, 1.4142, 1.2229, 1.0690, 0.9470, 0.8559,\n",
      "        0.7802, 0.7255, 0.6863, 0.6573, 0.6361, 0.6217, 0.6090, 0.6000, 0.5946,\n",
      "        0.5877, 0.5832, 0.5769, 0.5698, 0.5627, 0.5552, 0.5460, 0.5352, 0.5253,\n",
      "        0.5139, 0.5026, 0.4918, 0.4797, 0.4675, 0.4541, 0.4405, 0.4280, 0.4164,\n",
      "        0.4027], grad_fn=<AddBackward0>) tensor([8.1678, 8.2216, 8.2062, 8.1856, 8.2071, 8.1712, 8.1460, 8.1670, 8.1277,\n",
      "        8.0370, 7.8395, 7.7268, 7.4020, 6.9124, 6.3746, 5.8434, 5.2465, 4.7244,\n",
      "        4.1194, 3.6666, 3.1716, 2.7277, 2.3934, 2.0967, 1.8563, 1.6774, 1.5160,\n",
      "        1.4200, 1.3355, 1.2516, 1.1962, 1.1700, 1.1246, 1.1139, 1.1057, 1.0939,\n",
      "        1.0982, 1.0736, 1.0728, 1.0565, 1.0534, 1.0357, 1.0193, 1.0069, 0.9861,\n",
      "        0.9683, 0.9574, 0.9356, 0.9145, 0.8899, 0.8743, 0.8518, 0.8482, 0.8475,\n",
      "        1.5729], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2554, 3.2608, 3.2317, 3.2437, 3.2438, 3.2182, 3.2118, 3.2022, 3.1998,\n",
      "        3.1867, 3.1715, 3.1539, 3.1265, 3.1038, 3.0579, 3.0057, 2.9572, 2.8660,\n",
      "        2.8048, 2.7094, 2.5975, 2.4835, 2.3301, 2.2081, 2.0504, 1.9096, 1.7596,\n",
      "        1.6172, 1.4837, 1.3536, 1.2338, 1.1242, 1.0242, 0.9348, 0.8597, 0.7873,\n",
      "        0.7272, 0.6742, 0.6266, 0.5849, 0.5466, 0.5134, 0.4888, 0.4636, 0.4427,\n",
      "        0.4228, 0.4077, 0.3916, 0.3786, 0.3652, 0.3535, 0.3400, 0.3264, 0.3096,\n",
      "        0.2985], grad_fn=<AddBackward0>) tensor([ 5.9466,  5.9244,  6.0256,  5.9180,  5.8454,  5.9331,  5.9800,  5.9229,\n",
      "         5.8641,  5.8143,  5.8066,  5.7173,  5.6801,  5.7297,  5.6989,  5.6529,\n",
      "         5.5434,  5.6168,  5.3478,  5.2592,  5.0906,  4.8794,  4.8797,  4.4854,\n",
      "         4.4094,  4.1542,  3.9172,  3.6908,  3.4734,  3.2738,  3.0780,  2.9008,\n",
      "         2.7860,  2.6050,  2.3490,  2.2719,  2.1774,  1.9672,  1.8547,  1.7441,\n",
      "         1.7047,  1.6993,  1.5576,  1.4884,  1.4361,  1.4569,  1.3431,  1.3658,\n",
      "         1.2944,  1.3341,  1.3256,  1.3761,  1.4601,  1.8695, 11.6201],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.9285, 5.8964, 5.8948, 5.8948, 5.8910, 5.8792, 5.8648, 5.8280, 5.7830,\n",
      "        5.7052, 5.6379, 5.4619, 5.2175, 4.8517, 4.4424, 4.0005, 3.5494, 3.0934,\n",
      "        2.6761, 2.2794, 1.9379, 1.6538, 1.4112, 1.2196, 1.0647, 0.9426, 0.8512,\n",
      "        0.7754, 0.7207, 0.6815, 0.6526, 0.6315, 0.6172, 0.6047, 0.5960, 0.5907,\n",
      "        0.5840, 0.5797, 0.5736, 0.5667, 0.5598, 0.5526, 0.5435, 0.5329, 0.5232,\n",
      "        0.5119, 0.5008, 0.4900, 0.4781, 0.4659, 0.4525, 0.4389, 0.4264, 0.4148,\n",
      "        0.4012], grad_fn=<AddBackward0>) tensor([8.1667, 8.2225, 8.2072, 8.1988, 8.2164, 8.1873, 8.1542, 8.1666, 8.1430,\n",
      "        8.0524, 7.8504, 7.7250, 7.4035, 6.9115, 6.3666, 5.8404, 5.2437, 4.7253,\n",
      "        4.1144, 3.6589, 3.1629, 2.7271, 2.3890, 2.0855, 1.8506, 1.6684, 1.5078,\n",
      "        1.4106, 1.3253, 1.2432, 1.1870, 1.1614, 1.1179, 1.1067, 1.0969, 1.0862,\n",
      "        1.0917, 1.0668, 1.0662, 1.0505, 1.0487, 1.0299, 1.0151, 1.0027, 0.9824,\n",
      "        0.9648, 0.9537, 0.9328, 0.9115, 0.8879, 0.8722, 0.8504, 0.8466, 0.8474,\n",
      "        1.6387], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2606, 3.2668, 3.2383, 3.2498, 3.2484, 3.2224, 3.2156, 3.2068, 3.2076,\n",
      "        3.1947, 3.1764, 3.1610, 3.1307, 3.1110, 3.0633, 3.0124, 2.9648, 2.8709,\n",
      "        2.8115, 2.7163, 2.6024, 2.4882, 2.3358, 2.2133, 2.0541, 1.9124, 1.7626,\n",
      "        1.6191, 1.4850, 1.3544, 1.2340, 1.1242, 1.0239, 0.9341, 0.8587, 0.7860,\n",
      "        0.7253, 0.6722, 0.6244, 0.5824, 0.5439, 0.5107, 0.4857, 0.4604, 0.4394,\n",
      "        0.4193, 0.4041, 0.3880, 0.3749, 0.3614, 0.3497, 0.3361, 0.3223, 0.3053,\n",
      "        0.2943], grad_fn=<AddBackward0>) tensor([ 5.9373,  5.9048,  6.0055,  5.8981,  5.8363,  5.9254,  5.9748,  5.9158,\n",
      "         5.8393,  5.7880,  5.7964,  5.6956,  5.6784,  5.7104,  5.6914,  5.6362,\n",
      "         5.5255,  5.6181,  5.3367,  5.2452,  5.0897,  4.8734,  4.8640,  4.4667,\n",
      "         4.3999,  4.1495,  3.9027,  3.6821,  3.4652,  3.2684,  3.0767,  2.8937,\n",
      "         2.7793,  2.5944,  2.3398,  2.2605,  2.1775,  1.9601,  1.8439,  1.7401,\n",
      "         1.7004,  1.6845,  1.5515,  1.4790,  1.4268,  1.4487,  1.3340,  1.3562,\n",
      "         1.2869,  1.3267,  1.3163,  1.3649,  1.4540,  1.8737, 11.7370],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.9653, 5.9361, 5.9331, 5.9317, 5.9262, 5.9182, 5.9038, 5.8633, 5.8222,\n",
      "        5.7381, 5.6725, 5.4926, 5.2488, 4.8755, 4.4646, 4.0194, 3.5652, 3.1055,\n",
      "        2.6855, 2.2858, 1.9421, 1.6568, 1.4122, 1.2194, 1.0632, 0.9402, 0.8485,\n",
      "        0.7720, 0.7171, 0.6779, 0.6492, 0.6280, 0.6138, 0.6014, 0.5928, 0.5875,\n",
      "        0.5811, 0.5769, 0.5710, 0.5643, 0.5576, 0.5505, 0.5415, 0.5311, 0.5215,\n",
      "        0.5103, 0.4993, 0.4887, 0.4768, 0.4646, 0.4512, 0.4376, 0.4250, 0.4135,\n",
      "        0.3998], grad_fn=<AddBackward0>) tensor([8.1883, 8.2393, 8.2242, 8.2236, 8.2449, 8.2054, 8.1699, 8.1942, 8.1529,\n",
      "        8.0810, 7.8667, 7.7475, 7.4156, 6.9389, 6.3819, 5.8523, 5.2508, 4.7314,\n",
      "        4.1187, 3.6599, 3.1627, 2.7175, 2.3785, 2.0722, 1.8433, 1.6622, 1.4983,\n",
      "        1.4100, 1.3208, 1.2371, 1.1785, 1.1531, 1.1109, 1.0993, 1.0895, 1.0818,\n",
      "        1.0858, 1.0618, 1.0589, 1.0444, 1.0436, 1.0257, 1.0107, 0.9982, 0.9785,\n",
      "        0.9626, 0.9519, 0.9307, 0.9090, 0.8860, 0.8706, 0.8490, 0.8455, 0.8473,\n",
      "        1.7123], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2849, 3.2934, 3.2627, 3.2734, 3.2746, 3.2472, 3.2396, 3.2324, 3.2337,\n",
      "        3.2186, 3.2017, 3.1861, 3.1570, 3.1360, 3.0862, 3.0368, 2.9901, 2.8956,\n",
      "        2.8366, 2.7393, 2.6222, 2.5093, 2.3560, 2.2311, 2.0701, 1.9272, 1.7775,\n",
      "        1.6305, 1.4958, 1.3636, 1.2426, 1.1312, 1.0294, 0.9392, 0.8624, 0.7892,\n",
      "        0.7279, 0.6743, 0.6256, 0.5833, 0.5442, 0.5107, 0.4852, 0.4597, 0.4383,\n",
      "        0.4180, 0.4027, 0.3863, 0.3732, 0.3594, 0.3476, 0.3339, 0.3200, 0.3029,\n",
      "        0.2917], grad_fn=<AddBackward0>) tensor([ 5.9625,  5.9163,  6.0307,  5.9284,  5.8509,  5.9463,  5.9994,  5.9370,\n",
      "         5.8573,  5.8178,  5.8181,  5.7167,  5.6962,  5.7353,  5.7305,  5.6616,\n",
      "         5.5465,  5.6394,  5.3526,  5.2702,  5.1285,  4.8959,  4.8797,  4.4912,\n",
      "         4.4229,  4.1704,  3.9026,  3.7022,  3.4751,  3.2758,  3.0737,  2.9010,\n",
      "         2.7923,  2.5948,  2.3536,  2.2616,  2.1769,  1.9570,  1.8480,  1.7441,\n",
      "         1.7039,  1.6828,  1.5579,  1.4772,  1.4296,  1.4412,  1.3291,  1.3518,\n",
      "         1.2804,  1.3260,  1.3183,  1.3660,  1.4618,  1.8877, 12.0200],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.9500, 5.9212, 5.9164, 5.9163, 5.9093, 5.9019, 5.8866, 5.8467, 5.8081,\n",
      "        5.7248, 5.6567, 5.4773, 5.2327, 4.8593, 4.4476, 4.0039, 3.5516, 3.0919,\n",
      "        2.6728, 2.2737, 1.9310, 1.6467, 1.4026, 1.2100, 1.0545, 0.9320, 0.8406,\n",
      "        0.7643, 0.7098, 0.6710, 0.6426, 0.6217, 0.6078, 0.5958, 0.5874, 0.5824,\n",
      "        0.5763, 0.5723, 0.5667, 0.5603, 0.5539, 0.5470, 0.5383, 0.5280, 0.5187,\n",
      "        0.5076, 0.4968, 0.4864, 0.4746, 0.4625, 0.4491, 0.4355, 0.4230, 0.4115,\n",
      "        0.3978], grad_fn=<AddBackward0>) tensor([8.1480, 8.1954, 8.1871, 8.1845, 8.2063, 8.1639, 8.1345, 8.1574, 8.1106,\n",
      "        8.0347, 7.8241, 7.7035, 7.3755, 6.9002, 6.3453, 5.8157, 5.2124, 4.6991,\n",
      "        4.0907, 3.6362, 3.1418, 2.6959, 2.3582, 2.0582, 1.8265, 1.6449, 1.4809,\n",
      "        1.3970, 1.3081, 1.2254, 1.1666, 1.1412, 1.1016, 1.0889, 1.0802, 1.0740,\n",
      "        1.0764, 1.0539, 1.0519, 1.0363, 1.0358, 1.0193, 1.0039, 0.9921, 0.9734,\n",
      "        0.9580, 0.9482, 0.9264, 0.9056, 0.8825, 0.8678, 0.8460, 0.8428, 0.8468,\n",
      "        1.7838], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2499, 3.2582, 3.2300, 3.2390, 3.2436, 3.2151, 3.2073, 3.1996, 3.2010,\n",
      "        3.1858, 3.1696, 3.1534, 3.1264, 3.1049, 3.0553, 3.0111, 2.9624, 2.8692,\n",
      "        2.8108, 2.7136, 2.5967, 2.4848, 2.3350, 2.2092, 2.0498, 1.9085, 1.7598,\n",
      "        1.6135, 1.4806, 1.3494, 1.2292, 1.1187, 1.0173, 0.9281, 0.8522, 0.7796,\n",
      "        0.7189, 0.6652, 0.6172, 0.5749, 0.5363, 0.5030, 0.4777, 0.4524, 0.4310,\n",
      "        0.4109, 0.3957, 0.3795, 0.3664, 0.3529, 0.3410, 0.3275, 0.3135, 0.2964,\n",
      "        0.2854], grad_fn=<AddBackward0>) tensor([ 5.8973,  5.8483,  5.9532,  5.8594,  5.7597,  5.8652,  5.9215,  5.8608,\n",
      "         5.7834,  5.7413,  5.7430,  5.6517,  5.6177,  5.6626,  5.6637,  5.5659,\n",
      "         5.4715,  5.5615,  5.2784,  5.2037,  5.0695,  4.8420,  4.8034,  4.4361,\n",
      "         4.3670,  4.1111,  3.8495,  3.6616,  3.4268,  3.2314,  3.0334,  2.8657,\n",
      "         2.7653,  2.5660,  2.3187,  2.2315,  2.1399,  1.9408,  1.8206,  1.7247,\n",
      "         1.6804,  1.6581,  1.5363,  1.4532,  1.4063,  1.4195,  1.3044,  1.3279,\n",
      "         1.2646,  1.3082,  1.3006,  1.3448,  1.4442,  1.8711, 11.9573],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([5.9991, 5.9714, 5.9612, 5.9661, 5.9594, 5.9486, 5.9331, 5.8908, 5.8540,\n",
      "        5.7706, 5.6993, 5.5166, 5.2718, 4.8908, 4.4778, 4.0297, 3.5744, 3.1101,\n",
      "        2.6864, 2.2857, 1.9389, 1.6521, 1.4065, 1.2118, 1.0551, 0.9318, 0.8394,\n",
      "        0.7626, 0.7077, 0.6686, 0.6402, 0.6192, 0.6053, 0.5933, 0.5851, 0.5802,\n",
      "        0.5742, 0.5703, 0.5648, 0.5586, 0.5523, 0.5456, 0.5370, 0.5269, 0.5176,\n",
      "        0.5067, 0.4959, 0.4855, 0.4738, 0.4617, 0.4483, 0.4346, 0.4220, 0.4105,\n",
      "        0.3968], grad_fn=<AddBackward0>) tensor([8.1779, 8.2199, 8.2244, 8.2099, 8.2299, 8.1970, 8.1690, 8.1974, 8.1445,\n",
      "        8.0651, 7.8588, 7.7416, 7.4085, 6.9368, 6.3656, 5.8382, 5.2265, 4.7111,\n",
      "        4.1070, 3.6344, 3.1522, 2.7032, 2.3554, 2.0611, 1.8232, 1.6391, 1.4758,\n",
      "        1.3917, 1.3036, 1.2216, 1.1621, 1.1378, 1.0974, 1.0843, 1.0757, 1.0691,\n",
      "        1.0725, 1.0497, 1.0483, 1.0329, 1.0335, 1.0167, 1.0015, 0.9898, 0.9711,\n",
      "        0.9560, 0.9474, 0.9246, 0.9047, 0.8818, 0.8672, 0.8450, 0.8431, 0.8489,\n",
      "        1.8716], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2620, 3.2678, 3.2425, 3.2491, 3.2536, 3.2289, 3.2189, 3.2135, 3.2133,\n",
      "        3.1978, 3.1835, 3.1664, 3.1380, 3.1183, 3.0685, 3.0227, 2.9719, 2.8820,\n",
      "        2.8256, 2.7266, 2.6073, 2.4948, 2.3466, 2.2186, 2.0575, 1.9168, 1.7669,\n",
      "        1.6193, 1.4868, 1.3535, 1.2333, 1.1218, 1.0202, 0.9302, 0.8539, 0.7804,\n",
      "        0.7193, 0.6653, 0.6167, 0.5741, 0.5352, 0.5015, 0.4762, 0.4505, 0.4289,\n",
      "        0.4087, 0.3934, 0.3771, 0.3638, 0.3502, 0.3384, 0.3248, 0.3108, 0.2937,\n",
      "        0.2827], grad_fn=<AddBackward0>) tensor([ 5.8893,  5.8558,  5.9458,  5.8647,  5.7682,  5.8504,  5.9189,  5.8499,\n",
      "         5.7775,  5.7411,  5.7279,  5.6435,  5.6196,  5.6580,  5.6605,  5.5726,\n",
      "         5.4928,  5.5569,  5.2665,  5.1969,  5.0777,  4.8515,  4.7976,  4.4432,\n",
      "         4.3807,  4.1104,  3.8583,  3.6722,  3.4234,  3.2461,  3.0356,  2.8723,\n",
      "         2.7615,  2.5645,  2.3114,  2.2347,  2.1365,  1.9350,  1.8211,  1.7200,\n",
      "         1.6751,  1.6522,  1.5198,  1.4451,  1.4033,  1.4121,  1.2975,  1.3184,\n",
      "         1.2589,  1.3066,  1.2958,  1.3469,  1.4551,  1.8993, 12.2609],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.0321, 6.0010, 5.9905, 5.9975, 5.9912, 5.9800, 5.9646, 5.9203, 5.8828,\n",
      "        5.7994, 5.7254, 5.5434, 5.2967, 4.9123, 4.4947, 4.0446, 3.5870, 3.1199,\n",
      "        2.6952, 2.2911, 1.9424, 1.6543, 1.4070, 1.2109, 1.0534, 0.9294, 0.8366,\n",
      "        0.7592, 0.7043, 0.6651, 0.6365, 0.6156, 0.6018, 0.5899, 0.5818, 0.5771,\n",
      "        0.5712, 0.5676, 0.5622, 0.5563, 0.5501, 0.5436, 0.5352, 0.5252, 0.5160,\n",
      "        0.5052, 0.4946, 0.4843, 0.4726, 0.4605, 0.4471, 0.4334, 0.4207, 0.4092,\n",
      "        0.3955], grad_fn=<AddBackward0>) tensor([8.1916, 8.2437, 8.2486, 8.2287, 8.2453, 8.2159, 8.1853, 8.2185, 8.1723,\n",
      "        8.0853, 7.8864, 7.7605, 7.4248, 6.9509, 6.3856, 5.8512, 5.2353, 4.7190,\n",
      "        4.1034, 3.6339, 3.1525, 2.6989, 2.3522, 2.0585, 1.8173, 1.6320, 1.4669,\n",
      "        1.3854, 1.2965, 1.2114, 1.1557, 1.1311, 1.0912, 1.0785, 1.0691, 1.0616,\n",
      "        1.0665, 1.0441, 1.0445, 1.0280, 1.0293, 1.0121, 0.9987, 0.9854, 0.9695,\n",
      "        0.9531, 0.9456, 0.9228, 0.9025, 0.8807, 0.8665, 0.8436, 0.8421, 0.8505,\n",
      "        1.9604], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2870, 3.2890, 3.2645, 3.2705, 3.2764, 3.2541, 3.2426, 3.2373, 3.2351,\n",
      "        3.2225, 3.2075, 3.1908, 3.1621, 3.1440, 3.0913, 3.0470, 2.9940, 2.9047,\n",
      "        2.8490, 2.7486, 2.6283, 2.5144, 2.3667, 2.2358, 2.0721, 1.9314, 1.7795,\n",
      "        1.6304, 1.4969, 1.3624, 1.2416, 1.1283, 1.0262, 0.9345, 0.8579, 0.7835,\n",
      "        0.7217, 0.6669, 0.6178, 0.5749, 0.5354, 0.5015, 0.4759, 0.4498, 0.4279,\n",
      "        0.4076, 0.3921, 0.3756, 0.3622, 0.3486, 0.3366, 0.3230, 0.3089, 0.2919,\n",
      "        0.2807], grad_fn=<AddBackward0>) tensor([ 5.8975,  5.8876,  5.9721,  5.8944,  5.7914,  5.8609,  5.9330,  5.8681,\n",
      "         5.8084,  5.7545,  5.7443,  5.6595,  5.6377,  5.6659,  5.6903,  5.5879,\n",
      "         5.5198,  5.5804,  5.2793,  5.2174,  5.0952,  4.8657,  4.8065,  4.4631,\n",
      "         4.4099,  4.1250,  3.8769,  3.6879,  3.4369,  3.2527,  3.0331,  2.8745,\n",
      "         2.7512,  2.5670,  2.3023,  2.2288,  2.1355,  1.9408,  1.8215,  1.7176,\n",
      "         1.6743,  1.6498,  1.5164,  1.4426,  1.4052,  1.4064,  1.2938,  1.3168,\n",
      "         1.2630,  1.2969,  1.2966,  1.3487,  1.4705,  1.9253, 12.6220],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.0189, 5.9902, 5.9797, 5.9884, 5.9799, 5.9659, 5.9521, 5.9083, 5.8756,\n",
      "        5.7888, 5.7137, 5.5294, 5.2860, 4.9000, 4.4849, 4.0340, 3.5752, 3.1100,\n",
      "        2.6867, 2.2837, 1.9343, 1.6467, 1.3998, 1.2039, 1.0467, 0.9228, 0.8302,\n",
      "        0.7531, 0.6983, 0.6594, 0.6311, 0.6105, 0.5970, 0.5854, 0.5775, 0.5730,\n",
      "        0.5675, 0.5641, 0.5590, 0.5533, 0.5474, 0.5411, 0.5328, 0.5231, 0.5141,\n",
      "        0.5035, 0.4930, 0.4828, 0.4712, 0.4592, 0.4457, 0.4320, 0.4193, 0.4077,\n",
      "        0.3940], grad_fn=<AddBackward0>) tensor([8.1650, 8.2110, 8.2129, 8.1882, 8.2130, 8.1921, 8.1553, 8.1869, 8.1272,\n",
      "        8.0501, 7.8550, 7.7342, 7.3883, 6.9164, 6.3426, 5.8161, 5.2125, 4.6916,\n",
      "        4.0723, 3.6015, 3.1270, 2.6790, 2.3330, 2.0410, 1.8010, 1.6229, 1.4567,\n",
      "        1.3741, 1.2875, 1.2011, 1.1474, 1.1212, 1.0827, 1.0707, 1.0609, 1.0552,\n",
      "        1.0592, 1.0365, 1.0373, 1.0222, 1.0246, 1.0065, 0.9959, 0.9814, 0.9656,\n",
      "        0.9501, 0.9424, 0.9205, 0.9002, 0.8783, 0.8642, 0.8419, 0.8419, 0.8520,\n",
      "        2.0472], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.2955, 3.2963, 3.2730, 3.2797, 3.2854, 3.2632, 3.2509, 3.2480, 3.2425,\n",
      "        3.2309, 3.2149, 3.2008, 3.1695, 3.1551, 3.0989, 3.0558, 3.0019, 2.9138,\n",
      "        2.8578, 2.7586, 2.6375, 2.5238, 2.3741, 2.2442, 2.0788, 1.9383, 1.7851,\n",
      "        1.6351, 1.5016, 1.3662, 1.2451, 1.1307, 1.0277, 0.9357, 0.8591, 0.7841,\n",
      "        0.7218, 0.6662, 0.6172, 0.5739, 0.5342, 0.4999, 0.4740, 0.4477, 0.4257,\n",
      "        0.4052, 0.3896, 0.3730, 0.3595, 0.3458, 0.3338, 0.3201, 0.3059, 0.2888,\n",
      "        0.2776], grad_fn=<AddBackward0>) tensor([ 5.8923,  5.8884,  5.9669,  5.8848,  5.7819,  5.8531,  5.9281,  5.8514,\n",
      "         5.8127,  5.7512,  5.7473,  5.6515,  5.6475,  5.6538,  5.7020,  5.5966,\n",
      "         5.5313,  5.5848,  5.2877,  5.2161,  5.0949,  4.8637,  4.8136,  4.4604,\n",
      "         4.4153,  4.1221,  3.8793,  3.6945,  3.4335,  3.2506,  3.0286,  2.8738,\n",
      "         2.7568,  2.5677,  2.2946,  2.2245,  2.1308,  1.9465,  1.8159,  1.7090,\n",
      "         1.6689,  1.6455,  1.5147,  1.4383,  1.3958,  1.3988,  1.2876,  1.3072,\n",
      "         1.2554,  1.2926,  1.2935,  1.3476,  1.4744,  1.9423, 12.8714],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([5.9970, 5.9658, 5.9588, 5.9670, 5.9599, 5.9447, 5.9294, 5.8829, 5.8492,\n",
      "        5.7656, 5.6953, 5.5076, 5.2652, 4.8784, 4.4673, 4.0139, 3.5570, 3.0932,\n",
      "        2.6719, 2.2714, 1.9233, 1.6361, 1.3910, 1.1953, 1.0383, 0.9151, 0.8228,\n",
      "        0.7462, 0.6918, 0.6532, 0.6251, 0.6049, 0.5916, 0.5803, 0.5728, 0.5685,\n",
      "        0.5633, 0.5602, 0.5555, 0.5501, 0.5444, 0.5384, 0.5303, 0.5209, 0.5120,\n",
      "        0.5016, 0.4913, 0.4813, 0.4697, 0.4577, 0.4442, 0.4305, 0.4178, 0.4062,\n",
      "        0.3925], grad_fn=<AddBackward0>) tensor([8.1147, 8.1669, 8.1588, 8.1343, 8.1546, 8.1402, 8.1084, 8.1463, 8.0921,\n",
      "        8.0026, 7.7944, 7.6873, 7.3395, 6.8738, 6.2899, 5.7826, 5.1796, 4.6668,\n",
      "        4.0476, 3.5733, 3.1037, 2.6598, 2.3078, 2.0247, 1.7909, 1.6082, 1.4438,\n",
      "        1.3605, 1.2725, 1.1878, 1.1372, 1.1104, 1.0712, 1.0622, 1.0514, 1.0472,\n",
      "        1.0525, 1.0286, 1.0314, 1.0165, 1.0190, 1.0012, 0.9916, 0.9772, 0.9620,\n",
      "        0.9474, 0.9404, 0.9180, 0.8975, 0.8767, 0.8621, 0.8407, 0.8414, 0.8532,\n",
      "        2.1500], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3001, 3.3011, 3.2770, 3.2841, 3.2899, 3.2680, 3.2545, 3.2538, 3.2457,\n",
      "        3.2351, 3.2199, 3.2046, 3.1760, 3.1601, 3.1055, 3.0628, 3.0081, 2.9180,\n",
      "        2.8635, 2.7662, 2.6456, 2.5294, 2.3789, 2.2505, 2.0843, 1.9427, 1.7889,\n",
      "        1.6379, 1.5035, 1.3678, 1.2458, 1.1321, 1.0274, 0.9355, 0.8584, 0.7833,\n",
      "        0.7208, 0.6647, 0.6153, 0.5720, 0.5319, 0.4974, 0.4714, 0.4449, 0.4227,\n",
      "        0.4020, 0.3864, 0.3697, 0.3562, 0.3424, 0.3303, 0.3165, 0.3023, 0.2851,\n",
      "        0.2738], grad_fn=<AddBackward0>) tensor([ 5.8805,  5.8797,  5.9612,  5.8772,  5.7726,  5.8420,  5.9232,  5.8382,\n",
      "         5.8154,  5.7474,  5.7399,  5.6509,  5.6344,  5.6510,  5.6892,  5.5879,\n",
      "         5.5259,  5.5930,  5.2850,  5.2015,  5.0745,  4.8596,  4.8115,  4.4434,\n",
      "         4.3945,  4.1090,  3.8687,  3.6890,  3.4287,  3.2476,  3.0293,  2.8564,\n",
      "         2.7629,  2.5626,  2.2948,  2.2153,  2.1203,  1.9392,  1.8145,  1.6989,\n",
      "         1.6622,  1.6383,  1.5032,  1.4286,  1.3858,  1.3958,  1.2785,  1.2986,\n",
      "         1.2436,  1.2821,  1.2878,  1.3488,  1.4683,  1.9448, 13.0618],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.0454, 6.0093, 6.0079, 6.0112, 6.0031, 5.9890, 5.9730, 5.9240, 5.8951,\n",
      "        5.8119, 5.7385, 5.5452, 5.3041, 4.9140, 4.4972, 4.0416, 3.5802, 3.1118,\n",
      "        2.6889, 2.2846, 1.9331, 1.6441, 1.3966, 1.1993, 1.0408, 0.9163, 0.8230,\n",
      "        0.7458, 0.6910, 0.6520, 0.6238, 0.6035, 0.5902, 0.5789, 0.5714, 0.5672,\n",
      "        0.5620, 0.5592, 0.5545, 0.5493, 0.5437, 0.5378, 0.5299, 0.5204, 0.5117,\n",
      "        0.5013, 0.4910, 0.4810, 0.4695, 0.4575, 0.4439, 0.4300, 0.4172, 0.4056,\n",
      "        0.3917], grad_fn=<AddBackward0>) tensor([8.1386, 8.2016, 8.1781, 8.1716, 8.1968, 8.1776, 8.1457, 8.1901, 8.1195,\n",
      "        8.0244, 7.8235, 7.7256, 7.3649, 6.8926, 6.3153, 5.7928, 5.1947, 4.6923,\n",
      "        4.0517, 3.5831, 3.1103, 2.6644, 2.3105, 2.0232, 1.7901, 1.6086, 1.4458,\n",
      "        1.3596, 1.2690, 1.1851, 1.1342, 1.1070, 1.0668, 1.0582, 1.0492, 1.0450,\n",
      "        1.0526, 1.0261, 1.0301, 1.0147, 1.0172, 1.0003, 0.9916, 0.9770, 0.9614,\n",
      "        0.9464, 0.9409, 0.9177, 0.8969, 0.8768, 0.8630, 0.8408, 0.8430, 0.8566,\n",
      "        2.2755], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3123, 3.3156, 3.2874, 3.2970, 3.3011, 3.2791, 3.2663, 3.2684, 3.2558,\n",
      "        3.2479, 3.2312, 3.2167, 3.1888, 3.1741, 3.1201, 3.0793, 3.0226, 2.9324,\n",
      "        2.8755, 2.7796, 2.6585, 2.5406, 2.3914, 2.2622, 2.0939, 1.9507, 1.7980,\n",
      "        1.6459, 1.5095, 1.3738, 1.2512, 1.1360, 1.0305, 0.9380, 0.8607, 0.7850,\n",
      "        0.7221, 0.6657, 0.6157, 0.5718, 0.5313, 0.4967, 0.4703, 0.4437, 0.4212,\n",
      "        0.4004, 0.3846, 0.3676, 0.3541, 0.3403, 0.3281, 0.3142, 0.3000, 0.2828,\n",
      "        0.2714], grad_fn=<AddBackward0>) tensor([ 5.8847,  5.8668,  5.9751,  5.8756,  5.7798,  5.8515,  5.9292,  5.8294,\n",
      "         5.8304,  5.7506,  5.7517,  5.6593,  5.6379,  5.6535,  5.6864,  5.5730,\n",
      "         5.5234,  5.5922,  5.3007,  5.2053,  5.0771,  4.8751,  4.8064,  4.4431,\n",
      "         4.4033,  4.1266,  3.8630,  3.6828,  3.4404,  3.2463,  3.0268,  2.8661,\n",
      "         2.7764,  2.5763,  2.2971,  2.2168,  2.1173,  1.9336,  1.8153,  1.7027,\n",
      "         1.6674,  1.6308,  1.5015,  1.4198,  1.3835,  1.3904,  1.2754,  1.3001,\n",
      "         1.2453,  1.2746,  1.2851,  1.3525,  1.4755,  1.9702, 13.4050],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.0705, 6.0294, 6.0330, 6.0361, 6.0272, 6.0117, 5.9965, 5.9492, 5.9183,\n",
      "        5.8334, 5.7617, 5.5647, 5.3238, 4.9299, 4.5138, 4.0536, 3.5902, 3.1218,\n",
      "        2.6963, 2.2903, 1.9377, 1.6467, 1.3987, 1.2002, 1.0407, 0.9153, 0.8215,\n",
      "        0.7439, 0.6888, 0.6497, 0.6214, 0.6012, 0.5880, 0.5767, 0.5694, 0.5653,\n",
      "        0.5603, 0.5576, 0.5531, 0.5481, 0.5427, 0.5369, 0.5292, 0.5198, 0.5112,\n",
      "        0.5009, 0.4907, 0.4807, 0.4692, 0.4571, 0.4434, 0.4294, 0.4165, 0.4048,\n",
      "        0.3908], grad_fn=<AddBackward0>) tensor([8.1444, 8.2225, 8.1852, 8.1796, 8.2021, 8.1877, 8.1540, 8.1942, 8.1293,\n",
      "        8.0357, 7.8279, 7.7375, 7.3683, 6.9038, 6.3121, 5.8009, 5.2029, 4.6879,\n",
      "        4.0529, 3.5871, 3.1076, 2.6686, 2.3056, 2.0180, 1.7848, 1.6065, 1.4425,\n",
      "        1.3534, 1.2657, 1.1803, 1.1289, 1.1016, 1.0618, 1.0544, 1.0458, 1.0433,\n",
      "        1.0494, 1.0220, 1.0261, 1.0131, 1.0154, 0.9998, 0.9903, 0.9764, 0.9597,\n",
      "        0.9462, 0.9410, 0.9176, 0.8965, 0.8770, 0.8623, 0.8410, 0.8443, 0.8593,\n",
      "        2.3973], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3079, 3.3099, 3.2836, 3.2922, 3.2972, 3.2750, 3.2612, 3.2640, 3.2527,\n",
      "        3.2428, 3.2285, 3.2128, 3.1854, 3.1712, 3.1187, 3.0781, 3.0208, 2.9336,\n",
      "        2.8753, 2.7772, 2.6588, 2.5392, 2.3903, 2.2616, 2.0939, 1.9492, 1.7962,\n",
      "        1.6445, 1.5077, 1.3722, 1.2495, 1.1339, 1.0286, 0.9354, 0.8587, 0.7824,\n",
      "        0.7195, 0.6627, 0.6124, 0.5687, 0.5281, 0.4932, 0.4668, 0.4399, 0.4175,\n",
      "        0.3965, 0.3807, 0.3637, 0.3501, 0.3363, 0.3241, 0.3102, 0.2960, 0.2790,\n",
      "        0.2674], grad_fn=<AddBackward0>) tensor([ 5.8627,  5.8490,  5.9494,  5.8557,  5.7544,  5.8303,  5.9108,  5.8102,\n",
      "         5.8050,  5.7381,  5.7256,  5.6424,  5.6192,  5.6349,  5.6598,  5.5482,\n",
      "         5.5036,  5.5580,  5.2746,  5.1962,  5.0540,  4.8656,  4.7926,  4.4301,\n",
      "         4.3811,  4.1200,  3.8581,  3.6743,  3.4338,  3.2367,  3.0121,  2.8582,\n",
      "         2.7627,  2.5757,  2.2772,  2.2115,  2.1030,  1.9304,  1.8194,  1.6946,\n",
      "         1.6562,  1.6238,  1.4898,  1.4123,  1.3718,  1.3743,  1.2622,  1.2866,\n",
      "         1.2371,  1.2668,  1.2770,  1.3473,  1.4774,  1.9792, 13.6692],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.0729, 6.0328, 6.0384, 6.0410, 6.0297, 6.0134, 5.9987, 5.9535, 5.9210,\n",
      "        5.8403, 5.7679, 5.5700, 5.3294, 4.9288, 4.5149, 4.0510, 3.5898, 3.1208,\n",
      "        2.6946, 2.2894, 1.9355, 1.6441, 1.3962, 1.1969, 1.0371, 0.9117, 0.8177,\n",
      "        0.7399, 0.6850, 0.6457, 0.6176, 0.5975, 0.5845, 0.5734, 0.5663, 0.5624,\n",
      "        0.5576, 0.5551, 0.5509, 0.5461, 0.5409, 0.5354, 0.5277, 0.5186, 0.5101,\n",
      "        0.4999, 0.4898, 0.4800, 0.4685, 0.4563, 0.4426, 0.4284, 0.4155, 0.4037,\n",
      "        0.3897], grad_fn=<AddBackward0>) tensor([8.1320, 8.2102, 8.1665, 8.1575, 8.1905, 8.1786, 8.1400, 8.1734, 8.1144,\n",
      "        8.0046, 7.8004, 7.7096, 7.3380, 6.8944, 6.2888, 5.7942, 5.1845, 4.6717,\n",
      "        4.0401, 3.5680, 3.0951, 2.6584, 2.2883, 2.0087, 1.7782, 1.5949, 1.4321,\n",
      "        1.3443, 1.2559, 1.1768, 1.1203, 1.0939, 1.0536, 1.0467, 1.0405, 1.0387,\n",
      "        1.0453, 1.0170, 1.0219, 1.0093, 1.0129, 0.9964, 0.9879, 0.9730, 0.9571,\n",
      "        0.9445, 0.9397, 0.9163, 0.8948, 0.8765, 0.8619, 0.8409, 0.8455, 0.8623,\n",
      "        2.5304], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3056, 3.3050, 3.2789, 3.2917, 3.2943, 3.2718, 3.2568, 3.2599, 3.2469,\n",
      "        3.2413, 3.2270, 3.2102, 3.1837, 3.1667, 3.1173, 3.0769, 3.0191, 2.9322,\n",
      "        2.8761, 2.7768, 2.6586, 2.5381, 2.3899, 2.2618, 2.0928, 1.9492, 1.7959,\n",
      "        1.6437, 1.5069, 1.3708, 1.2482, 1.1320, 1.0266, 0.9338, 0.8566, 0.7800,\n",
      "        0.7169, 0.6598, 0.6096, 0.5658, 0.5249, 0.4899, 0.4634, 0.4364, 0.4138,\n",
      "        0.3928, 0.3768, 0.3599, 0.3462, 0.3323, 0.3200, 0.3061, 0.2918, 0.2744,\n",
      "        0.2630], grad_fn=<AddBackward0>) tensor([ 5.8306,  5.8303,  5.9313,  5.8134,  5.7270,  5.8046,  5.8937,  5.7905,\n",
      "         5.7975,  5.7073,  5.6953,  5.6197,  5.5929,  5.6285,  5.6396,  5.5249,\n",
      "         5.4879,  5.5428,  5.2510,  5.1798,  5.0381,  4.8569,  4.7792,  4.4093,\n",
      "         4.3725,  4.0996,  3.8420,  3.6612,  3.4189,  3.2289,  3.0004,  2.8538,\n",
      "         2.7574,  2.5629,  2.2648,  2.2040,  2.0960,  1.9268,  1.8092,  1.6789,\n",
      "         1.6463,  1.6176,  1.4777,  1.4003,  1.3587,  1.3630,  1.2535,  1.2757,\n",
      "         1.2250,  1.2569,  1.2685,  1.3399,  1.4701,  1.9833, 13.6883],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.0925, 6.0518, 6.0538, 6.0595, 6.0472, 6.0321, 6.0174, 5.9737, 5.9425,\n",
      "        5.8581, 5.7859, 5.5860, 5.3433, 4.9407, 4.5253, 4.0617, 3.5981, 3.1278,\n",
      "        2.7000, 2.2950, 1.9390, 1.6465, 1.3973, 1.1971, 1.0367, 0.9106, 0.8160,\n",
      "        0.7380, 0.6828, 0.6434, 0.6153, 0.5952, 0.5822, 0.5712, 0.5643, 0.5605,\n",
      "        0.5559, 0.5536, 0.5495, 0.5449, 0.5399, 0.5345, 0.5270, 0.5181, 0.5096,\n",
      "        0.4995, 0.4895, 0.4797, 0.4682, 0.4560, 0.4421, 0.4279, 0.4148, 0.4029,\n",
      "        0.3887], grad_fn=<AddBackward0>) tensor([8.1346, 8.2141, 8.1840, 8.1653, 8.1995, 8.1828, 8.1447, 8.1712, 8.1084,\n",
      "        8.0096, 7.8037, 7.7142, 7.3449, 6.8977, 6.2948, 5.7887, 5.1869, 4.6747,\n",
      "        4.0459, 3.5581, 3.0933, 2.6564, 2.2892, 2.0087, 1.7770, 1.5912, 1.4296,\n",
      "        1.3376, 1.2514, 1.1709, 1.1145, 1.0886, 1.0490, 1.0439, 1.0366, 1.0331,\n",
      "        1.0418, 1.0144, 1.0184, 1.0065, 1.0109, 0.9948, 0.9865, 0.9716, 0.9557,\n",
      "        0.9446, 0.9394, 0.9156, 0.8948, 0.8764, 0.8619, 0.8407, 0.8468, 0.8657,\n",
      "        2.6628], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3252, 3.3211, 3.2980, 3.3099, 3.3117, 3.2876, 3.2749, 3.2778, 3.2656,\n",
      "        3.2581, 3.2437, 3.2269, 3.2015, 3.1851, 3.1345, 3.0934, 3.0377, 2.9492,\n",
      "        2.8938, 2.7939, 2.6743, 2.5533, 2.4047, 2.2742, 2.1022, 1.9602, 1.8060,\n",
      "        1.6531, 1.5135, 1.3778, 1.2532, 1.1367, 1.0300, 0.9365, 0.8587, 0.7815,\n",
      "        0.7180, 0.6605, 0.6096, 0.5653, 0.5241, 0.4888, 0.4620, 0.4347, 0.4119,\n",
      "        0.3907, 0.3745, 0.3575, 0.3437, 0.3298, 0.3173, 0.3034, 0.2889, 0.2717,\n",
      "        0.2601], grad_fn=<AddBackward0>) tensor([ 5.8231,  5.8456,  5.9208,  5.8142,  5.7294,  5.8182,  5.8941,  5.7959,\n",
      "         5.8000,  5.7187,  5.7081,  5.6332,  5.5977,  5.6342,  5.6517,  5.5437,\n",
      "         5.4871,  5.5567,  5.2591,  5.1872,  5.0467,  4.8669,  4.7821,  4.4240,\n",
      "         4.4054,  4.1007,  3.8423,  3.6543,  3.4340,  3.2257,  3.0103,  2.8565,\n",
      "         2.7681,  2.5694,  2.2670,  2.2063,  2.0903,  1.9195,  1.8044,  1.6790,\n",
      "         1.6404,  1.6118,  1.4717,  1.3965,  1.3548,  1.3587,  1.2495,  1.2660,\n",
      "         1.2177,  1.2467,  1.2646,  1.3351,  1.4800,  1.9955, 14.0136],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.1136, 6.0729, 6.0768, 6.0827, 6.0677, 6.0539, 6.0385, 5.9948, 5.9624,\n",
      "        5.8762, 5.8037, 5.6041, 5.3597, 4.9556, 4.5376, 4.0739, 3.6090, 3.1376,\n",
      "        2.7078, 2.3021, 1.9444, 1.6503, 1.3999, 1.1989, 1.0375, 0.9108, 0.8156,\n",
      "        0.7372, 0.6816, 0.6419, 0.6138, 0.5937, 0.5807, 0.5698, 0.5630, 0.5594,\n",
      "        0.5549, 0.5527, 0.5490, 0.5445, 0.5397, 0.5344, 0.5270, 0.5182, 0.5098,\n",
      "        0.4997, 0.4898, 0.4800, 0.4685, 0.4562, 0.4422, 0.4277, 0.4145, 0.4025,\n",
      "        0.3882], grad_fn=<AddBackward0>) tensor([8.1424, 8.2191, 8.1838, 8.1656, 8.2073, 8.1892, 8.1500, 8.1777, 8.1169,\n",
      "        8.0234, 7.8166, 7.7235, 7.3547, 6.9068, 6.3060, 5.7913, 5.1901, 4.6756,\n",
      "        4.0483, 3.5549, 3.0936, 2.6622, 2.2947, 2.0113, 1.7779, 1.5899, 1.4268,\n",
      "        1.3340, 1.2472, 1.1669, 1.1109, 1.0862, 1.0469, 1.0419, 1.0339, 1.0324,\n",
      "        1.0406, 1.0151, 1.0166, 1.0051, 1.0090, 0.9940, 0.9865, 0.9715, 0.9561,\n",
      "        0.9458, 0.9393, 0.9164, 0.8958, 0.8779, 0.8624, 0.8430, 0.8500, 0.8709,\n",
      "        2.8261], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3076, 3.3005, 3.2816, 3.2941, 3.2936, 3.2695, 3.2571, 3.2627, 3.2484,\n",
      "        3.2415, 3.2276, 3.2109, 3.1862, 3.1685, 3.1217, 3.0782, 3.0255, 2.9391,\n",
      "        2.8812, 2.7828, 2.6631, 2.5435, 2.3957, 2.2664, 2.0940, 1.9521, 1.7990,\n",
      "        1.6468, 1.5078, 1.3723, 1.2478, 1.1316, 1.0254, 0.9316, 0.8541, 0.7768,\n",
      "        0.7135, 0.6563, 0.6056, 0.5610, 0.5198, 0.4845, 0.4577, 0.4303, 0.4075,\n",
      "        0.3863, 0.3702, 0.3532, 0.3394, 0.3255, 0.3131, 0.2992, 0.2847, 0.2677,\n",
      "        0.2559], grad_fn=<AddBackward0>) tensor([ 5.7789,  5.8206,  5.8669,  5.7585,  5.6890,  5.7801,  5.8538,  5.7415,\n",
      "         5.7582,  5.6764,  5.6616,  5.5916,  5.5531,  5.6019,  5.5991,  5.5112,\n",
      "         5.4379,  5.5014,  5.2266,  5.1499,  5.0146,  4.8317,  4.7500,  4.3877,\n",
      "         4.3743,  4.0782,  3.8158,  3.6273,  3.4058,  3.2001,  2.9934,  2.8396,\n",
      "         2.7502,  2.5591,  2.2532,  2.2016,  2.0810,  1.9033,  1.7774,  1.6650,\n",
      "         1.6293,  1.5967,  1.4539,  1.3852,  1.3452,  1.3456,  1.2359,  1.2546,\n",
      "         1.2019,  1.2340,  1.2552,  1.3247,  1.4808,  1.9922, 14.2695],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.1044, 6.0646, 6.0677, 6.0785, 6.0589, 6.0418, 6.0338, 5.9881, 5.9544,\n",
      "        5.8695, 5.7966, 5.5950, 5.3524, 4.9471, 4.5272, 4.0648, 3.6025, 3.1329,\n",
      "        2.7030, 2.2969, 1.9396, 1.6465, 1.3956, 1.1947, 1.0332, 0.9067, 0.8113,\n",
      "        0.7330, 0.6773, 0.6377, 0.6098, 0.5898, 0.5771, 0.5664, 0.5599, 0.5563,\n",
      "        0.5522, 0.5502, 0.5467, 0.5424, 0.5379, 0.5329, 0.5257, 0.5170, 0.5087,\n",
      "        0.4988, 0.4890, 0.4793, 0.4678, 0.4555, 0.4413, 0.4267, 0.4134, 0.4013,\n",
      "        0.3869], grad_fn=<AddBackward0>) tensor([8.1137, 8.1881, 8.1569, 8.1227, 8.1800, 8.1694, 8.1075, 8.1372, 8.0842,\n",
      "        7.9864, 7.7794, 7.6930, 7.3221, 6.8768, 6.2863, 5.7693, 5.1611, 4.6426,\n",
      "        4.0230, 3.5419, 3.0831, 2.6426, 2.2833, 2.0039, 1.7694, 1.5761, 1.4180,\n",
      "        1.3244, 1.2403, 1.1593, 1.1015, 1.0802, 1.0392, 1.0362, 1.0261, 1.0290,\n",
      "        1.0338, 1.0089, 1.0109, 1.0014, 1.0055, 0.9903, 0.9828, 0.9692, 0.9540,\n",
      "        0.9449, 0.9367, 0.9147, 0.8955, 0.8775, 0.8618, 0.8431, 0.8517, 0.8749,\n",
      "        2.9570], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3399, 3.3321, 3.3148, 3.3260, 3.3251, 3.3005, 3.2876, 3.2936, 3.2814,\n",
      "        3.2748, 3.2557, 3.2406, 3.2163, 3.2021, 3.1525, 3.1094, 3.0571, 2.9695,\n",
      "        2.9109, 2.8131, 2.6917, 2.5704, 2.4210, 2.2893, 2.1166, 1.9723, 1.8157,\n",
      "        1.6634, 1.5223, 1.3851, 1.2595, 1.1417, 1.0338, 0.9388, 0.8604, 0.7822,\n",
      "        0.7178, 0.6602, 0.6082, 0.5631, 0.5216, 0.4855, 0.4583, 0.4306, 0.4075,\n",
      "        0.3859, 0.3695, 0.3522, 0.3383, 0.3242, 0.3116, 0.2975, 0.2829, 0.2658,\n",
      "        0.2539], grad_fn=<AddBackward0>) tensor([ 5.8051,  5.8483,  5.8873,  5.7906,  5.7201,  5.8111,  5.8911,  5.7770,\n",
      "         5.7802,  5.6972,  5.7148,  5.6329,  5.5944,  5.6258,  5.6364,  5.5463,\n",
      "         5.4662,  5.5366,  5.2643,  5.1759,  5.0420,  4.8592,  4.7789,  4.4203,\n",
      "         4.3941,  4.1043,  3.8550,  3.6467,  3.4270,  3.2194,  3.0043,  2.8521,\n",
      "         2.7651,  2.5736,  2.2633,  2.2078,  2.0876,  1.9022,  1.7919,  1.6757,\n",
      "         1.6259,  1.6005,  1.4584,  1.3870,  1.3404,  1.3456,  1.2338,  1.2530,\n",
      "         1.1987,  1.2309,  1.2491,  1.3278,  1.4902,  2.0266, 14.6446],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.1632, 6.1204, 6.1264, 6.1339, 6.1199, 6.0970, 6.0907, 6.0463, 6.0119,\n",
      "        5.9256, 5.8501, 5.6453, 5.4020, 4.9930, 4.5663, 4.1013, 3.6330, 3.1597,\n",
      "        2.7253, 2.3165, 1.9550, 1.6600, 1.4057, 1.2023, 1.0392, 0.9111, 0.8144,\n",
      "        0.7350, 0.6789, 0.6387, 0.6104, 0.5903, 0.5775, 0.5667, 0.5603, 0.5568,\n",
      "        0.5527, 0.5508, 0.5474, 0.5433, 0.5389, 0.5340, 0.5269, 0.5182, 0.5100,\n",
      "        0.5000, 0.4903, 0.4805, 0.4690, 0.4565, 0.4421, 0.4272, 0.4137, 0.4014,\n",
      "        0.3868], grad_fn=<AddBackward0>) tensor([8.1613, 8.2448, 8.2059, 8.1814, 8.2191, 8.2270, 8.1594, 8.1836, 8.1341,\n",
      "        8.0328, 7.8321, 7.7453, 7.3668, 6.9093, 6.3252, 5.7974, 5.1954, 4.6714,\n",
      "        4.0512, 3.5638, 3.1061, 2.6517, 2.2989, 2.0163, 1.7759, 1.5840, 1.4234,\n",
      "        1.3294, 1.2395, 1.1620, 1.1020, 1.0807, 1.0399, 1.0369, 1.0260, 1.0284,\n",
      "        1.0359, 1.0093, 1.0127, 1.0034, 1.0069, 0.9922, 0.9846, 0.9725, 0.9570,\n",
      "        0.9477, 0.9394, 0.9186, 0.8984, 0.8801, 0.8641, 0.8454, 0.8556, 0.8826,\n",
      "        3.1396], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3281, 3.3204, 3.3038, 3.3131, 3.3148, 3.2855, 3.2765, 3.2806, 3.2701,\n",
      "        3.2627, 3.2449, 3.2269, 3.2057, 3.1898, 3.1415, 3.0982, 3.0499, 2.9608,\n",
      "        2.9013, 2.8055, 2.6827, 2.5633, 2.4135, 2.2827, 2.1094, 1.9669, 1.8092,\n",
      "        1.6561, 1.5162, 1.3797, 1.2542, 1.1356, 1.0288, 0.9339, 0.8551, 0.7774,\n",
      "        0.7132, 0.6557, 0.6037, 0.5586, 0.5171, 0.4809, 0.4537, 0.4260, 0.4031,\n",
      "        0.3815, 0.3650, 0.3478, 0.3340, 0.3199, 0.3074, 0.2933, 0.2788, 0.2615,\n",
      "        0.2498], grad_fn=<AddBackward0>) tensor([ 5.7554,  5.7979,  5.8336,  5.7497,  5.6655,  5.7832,  5.8399,  5.7381,\n",
      "         5.7368,  5.6585,  5.6653,  5.6041,  5.5506,  5.5917,  5.6009,  5.5129,\n",
      "         5.4127,  5.4921,  5.2306,  5.1348,  5.0127,  4.8157,  4.7420,  4.3801,\n",
      "         4.3595,  4.0589,  3.8247,  3.6304,  3.4022,  3.1881,  2.9803,  2.8455,\n",
      "         2.7408,  2.5555,  2.2586,  2.1909,  2.0692,  1.8807,  1.7723,  1.6559,\n",
      "         1.6100,  1.5905,  1.4464,  1.3775,  1.3206,  1.3267,  1.2232,  1.2505,\n",
      "         1.1914,  1.2279,  1.2450,  1.3252,  1.4705,  2.0333, 14.7832],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.1356, 6.0937, 6.0963, 6.1092, 6.0941, 6.0693, 6.0626, 6.0183, 5.9842,\n",
      "        5.9015, 5.8237, 5.6192, 5.3772, 4.9710, 4.5447, 4.0812, 3.6170, 3.1442,\n",
      "        2.7124, 2.3054, 1.9453, 1.6519, 1.3981, 1.1957, 1.0330, 0.9051, 0.8087,\n",
      "        0.7296, 0.6737, 0.6337, 0.6057, 0.5857, 0.5734, 0.5627, 0.5566, 0.5535,\n",
      "        0.5496, 0.5481, 0.5450, 0.5411, 0.5371, 0.5324, 0.5255, 0.5170, 0.5090,\n",
      "        0.4992, 0.4896, 0.4799, 0.4684, 0.4559, 0.4414, 0.4264, 0.4127, 0.4004,\n",
      "        0.3857], grad_fn=<AddBackward0>) tensor([8.1105, 8.1886, 8.1625, 8.1207, 8.1622, 8.1747, 8.1123, 8.1347, 8.0838,\n",
      "        7.9722, 7.7824, 7.6970, 7.3160, 6.8564, 6.2769, 5.7579, 5.1542, 4.6424,\n",
      "        4.0231, 3.5378, 3.0894, 2.6324, 2.2872, 2.0037, 1.7663, 1.5747, 1.4142,\n",
      "        1.3215, 1.2307, 1.1527, 1.0924, 1.0730, 1.0312, 1.0306, 1.0185, 1.0207,\n",
      "        1.0299, 1.0034, 1.0084, 1.0010, 1.0033, 0.9922, 0.9815, 0.9709, 0.9550,\n",
      "        0.9456, 0.9385, 0.9178, 0.8997, 0.8801, 0.8641, 0.8463, 0.8584, 0.8875,\n",
      "        3.3080], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3633, 3.3574, 3.3393, 3.3475, 3.3518, 3.3204, 3.3136, 3.3187, 3.3066,\n",
      "        3.2973, 3.2797, 3.2622, 3.2419, 3.2250, 3.1807, 3.1336, 3.0858, 2.9972,\n",
      "        2.9381, 2.8366, 2.7146, 2.5945, 2.4432, 2.3091, 2.1340, 1.9911, 1.8299,\n",
      "        1.6750, 1.5316, 1.3943, 1.2667, 1.1467, 1.0384, 0.9430, 0.8620, 0.7836,\n",
      "        0.7185, 0.6601, 0.6073, 0.5615, 0.5194, 0.4827, 0.4550, 0.4270, 0.4037,\n",
      "        0.3818, 0.3650, 0.3476, 0.3335, 0.3192, 0.3066, 0.2922, 0.2777, 0.2603,\n",
      "        0.2483], grad_fn=<AddBackward0>) tensor([ 5.8015,  5.8292,  5.8758,  5.8000,  5.6962,  5.8227,  5.8703,  5.7628,\n",
      "         5.7722,  5.7053,  5.7080,  5.6449,  5.5865,  5.6338,  5.6173,  5.5544,\n",
      "         5.4461,  5.5189,  5.2511,  5.1886,  5.0452,  4.8386,  4.7673,  4.4093,\n",
      "         4.3820,  4.0671,  3.8423,  3.6458,  3.4325,  3.2067,  2.9978,  2.8631,\n",
      "         2.7557,  2.5500,  2.2742,  2.1973,  2.0771,  1.8874,  1.7794,  1.6657,\n",
      "         1.6182,  1.5972,  1.4526,  1.3848,  1.3220,  1.3304,  1.2261,  1.2524,\n",
      "         1.1977,  1.2335,  1.2461,  1.3394,  1.4820,  2.0569, 15.1640],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.1530, 6.1170, 6.1185, 6.1311, 6.1162, 6.0879, 6.0830, 6.0422, 6.0057,\n",
      "        5.9255, 5.8425, 5.6376, 5.3971, 4.9840, 4.5590, 4.0915, 3.6275, 3.1538,\n",
      "        2.7215, 2.3136, 1.9502, 1.6564, 1.4011, 1.1976, 1.0340, 0.9053, 0.8082,\n",
      "        0.7288, 0.6726, 0.6323, 0.6041, 0.5842, 0.5718, 0.5614, 0.5552, 0.5523,\n",
      "        0.5486, 0.5472, 0.5444, 0.5406, 0.5368, 0.5323, 0.5256, 0.5172, 0.5093,\n",
      "        0.4996, 0.4900, 0.4804, 0.4688, 0.4562, 0.4415, 0.4262, 0.4124, 0.4000,\n",
      "        0.3850], grad_fn=<AddBackward0>) tensor([8.1329, 8.1914, 8.1688, 8.1260, 8.1664, 8.1850, 8.1200, 8.1340, 8.0924,\n",
      "        7.9704, 7.7953, 7.7027, 7.3151, 6.8707, 6.2775, 5.7672, 5.1605, 4.6459,\n",
      "        4.0229, 3.5294, 3.0954, 2.6345, 2.2910, 2.0039, 1.7700, 1.5746, 1.4141,\n",
      "        1.3191, 1.2242, 1.1498, 1.0911, 1.0673, 1.0283, 1.0261, 1.0163, 1.0173,\n",
      "        1.0280, 1.0023, 1.0068, 1.0017, 1.0027, 0.9917, 0.9812, 0.9720, 0.9555,\n",
      "        0.9480, 0.9391, 0.9177, 0.9010, 0.8807, 0.8659, 0.8483, 0.8614, 0.8936,\n",
      "        3.5040], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3765, 3.3700, 3.3519, 3.3616, 3.3648, 3.3334, 3.3276, 3.3307, 3.3194,\n",
      "        3.3093, 3.2941, 3.2763, 3.2542, 3.2379, 3.1949, 3.1484, 3.1009, 3.0107,\n",
      "        2.9514, 2.8524, 2.7271, 2.6062, 2.4565, 2.3194, 2.1431, 2.0008, 1.8381,\n",
      "        1.6812, 1.5382, 1.3998, 1.2715, 1.1512, 1.0417, 0.9456, 0.8643, 0.7853,\n",
      "        0.7194, 0.6605, 0.6075, 0.5614, 0.5189, 0.4819, 0.4539, 0.4256, 0.4022,\n",
      "        0.3800, 0.3632, 0.3456, 0.3313, 0.3171, 0.3043, 0.2899, 0.2751, 0.2577,\n",
      "        0.2458], grad_fn=<AddBackward0>) tensor([ 5.7960,  5.8260,  5.8733,  5.7898,  5.6938,  5.8154,  5.8633,  5.7650,\n",
      "         5.7711,  5.7099,  5.7011,  5.6398,  5.5933,  5.6373,  5.6132,  5.5500,\n",
      "         5.4394,  5.5219,  5.2556,  5.1759,  5.0490,  4.8457,  4.7570,  4.4201,\n",
      "         4.3933,  4.0696,  3.8466,  3.6606,  3.4333,  3.2116,  3.0015,  2.8551,\n",
      "         2.7565,  2.5508,  2.2677,  2.1990,  2.0846,  1.8937,  1.7778,  1.6626,\n",
      "         1.6113,  1.5950,  1.4515,  1.3818,  1.3171,  1.3308,  1.2233,  1.2498,\n",
      "         1.1983,  1.2257,  1.2493,  1.3361,  1.4972,  2.0779, 15.4240],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.1896, 6.1557, 6.1576, 6.1734, 6.1560, 6.1270, 6.1247, 6.0838, 6.0428,\n",
      "        5.9630, 5.8806, 5.6709, 5.4318, 5.0126, 4.5843, 4.1160, 3.6504, 3.1706,\n",
      "        2.7371, 2.3268, 1.9611, 1.6648, 1.4075, 1.2026, 1.0373, 0.9075, 0.8095,\n",
      "        0.7290, 0.6725, 0.6318, 0.6034, 0.5835, 0.5710, 0.5606, 0.5545, 0.5517,\n",
      "        0.5482, 0.5469, 0.5443, 0.5407, 0.5370, 0.5327, 0.5262, 0.5178, 0.5100,\n",
      "        0.5003, 0.4908, 0.4812, 0.4696, 0.4568, 0.4418, 0.4263, 0.4122, 0.3996,\n",
      "        0.3844], grad_fn=<AddBackward0>) tensor([8.1733, 8.2260, 8.2030, 8.1501, 8.1993, 8.2179, 8.1421, 8.1611, 8.1305,\n",
      "        8.0019, 7.8221, 7.7384, 7.3404, 6.9014, 6.3051, 5.7831, 5.1697, 4.6690,\n",
      "        4.0384, 3.5431, 3.1020, 2.6437, 2.2978, 2.0081, 1.7754, 1.5756, 1.4147,\n",
      "        1.3198, 1.2228, 1.1497, 1.0898, 1.0673, 1.0266, 1.0239, 1.0149, 1.0168,\n",
      "        1.0258, 1.0019, 1.0055, 1.0007, 1.0048, 0.9924, 0.9825, 0.9744, 0.9568,\n",
      "        0.9498, 0.9415, 0.9199, 0.9037, 0.8829, 0.8677, 0.8500, 0.8646, 0.9003,\n",
      "        3.7125], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3453, 3.3374, 3.3155, 3.3254, 3.3302, 3.2972, 3.2964, 3.3000, 3.2858,\n",
      "        3.2781, 3.2629, 3.2458, 3.2258, 3.2078, 3.1664, 3.1199, 3.0716, 2.9825,\n",
      "        2.9245, 2.8260, 2.7047, 2.5836, 2.4341, 2.2994, 2.1234, 1.9834, 1.8205,\n",
      "        1.6662, 1.5241, 1.3859, 1.2596, 1.1408, 1.0312, 0.9361, 0.8553, 0.7774,\n",
      "        0.7116, 0.6534, 0.6002, 0.5548, 0.5124, 0.4755, 0.4478, 0.4196, 0.3964,\n",
      "        0.3743, 0.3576, 0.3401, 0.3258, 0.3118, 0.2990, 0.2847, 0.2699, 0.2526,\n",
      "        0.2407], grad_fn=<AddBackward0>) tensor([ 5.7058,  5.7452,  5.8159,  5.7315,  5.6272,  5.7598,  5.7774,  5.6802,\n",
      "         5.7056,  5.6296,  5.6216,  5.5611,  5.5056,  5.5603,  5.5297,  5.4768,\n",
      "         5.3739,  5.4577,  5.1913,  5.1160,  4.9758,  4.7806,  4.7045,  4.3615,\n",
      "         4.3453,  4.0156,  3.8135,  3.6139,  3.3944,  3.1896,  2.9674,  2.8123,\n",
      "         2.7371,  2.5227,  2.2502,  2.1645,  2.0610,  1.8632,  1.7678,  1.6360,\n",
      "         1.5937,  1.5823,  1.4368,  1.3693,  1.2957,  1.3075,  1.2059,  1.2325,\n",
      "         1.1899,  1.2109,  1.2362,  1.3242,  1.4912,  2.0653, 15.4543],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.1612, 6.1244, 6.1312, 6.1442, 6.1284, 6.1012, 6.0981, 6.0539, 6.0139,\n",
      "        5.9363, 5.8519, 5.6450, 5.4066, 4.9903, 4.5617, 4.0950, 3.6333, 3.1564,\n",
      "        2.7237, 2.3151, 1.9516, 1.6570, 1.4005, 1.1962, 1.0311, 0.9017, 0.8037,\n",
      "        0.7237, 0.6675, 0.6269, 0.5987, 0.5790, 0.5668, 0.5567, 0.5508, 0.5483,\n",
      "        0.5451, 0.5441, 0.5418, 0.5386, 0.5352, 0.5311, 0.5248, 0.5167, 0.5090,\n",
      "        0.4995, 0.4901, 0.4806, 0.4690, 0.4561, 0.4410, 0.4253, 0.4110, 0.3983,\n",
      "        0.3829], grad_fn=<AddBackward0>) tensor([8.1223, 8.1842, 8.1476, 8.1010, 8.1464, 8.1578, 8.0857, 8.1171, 8.0824,\n",
      "        7.9521, 7.7781, 7.6858, 7.2912, 6.8462, 6.2641, 5.7483, 5.1281, 4.6317,\n",
      "        4.0169, 3.5226, 3.0813, 2.6223, 2.2786, 1.9953, 1.7640, 1.5672, 1.4075,\n",
      "        1.3077, 1.2111, 1.1393, 1.0824, 1.0589, 1.0188, 1.0160, 1.0101, 1.0110,\n",
      "        1.0186, 0.9970, 1.0017, 0.9965, 1.0016, 0.9900, 0.9805, 0.9704, 0.9545,\n",
      "        0.9493, 0.9407, 0.9195, 0.9032, 0.8822, 0.8668, 0.8504, 0.8665, 0.9069,\n",
      "        3.8967], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3813, 3.3721, 3.3508, 3.3594, 3.3662, 3.3324, 3.3306, 3.3349, 3.3217,\n",
      "        3.3104, 3.2962, 3.2794, 3.2633, 3.2407, 3.2030, 3.1568, 3.1058, 3.0166,\n",
      "        2.9584, 2.8594, 2.7360, 2.6136, 2.4639, 2.3257, 2.1489, 2.0068, 1.8420,\n",
      "        1.6862, 1.5414, 1.4010, 1.2737, 1.1533, 1.0414, 0.9459, 0.8632, 0.7844,\n",
      "        0.7176, 0.6584, 0.6042, 0.5584, 0.5152, 0.4778, 0.4494, 0.4208, 0.3972,\n",
      "        0.3748, 0.3577, 0.3400, 0.3255, 0.3113, 0.2984, 0.2840, 0.2691, 0.2518,\n",
      "        0.2393], grad_fn=<AddBackward0>) tensor([ 5.7388,  5.7803,  5.8503,  5.7737,  5.6602,  5.7930,  5.8205,  5.7202,\n",
      "         5.7410,  5.6857,  5.6684,  5.6073,  5.5299,  5.6152,  5.5627,  5.5066,\n",
      "         5.4214,  5.5021,  5.2291,  5.1496,  5.0180,  4.8205,  4.7340,  4.4023,\n",
      "         4.3766,  4.0446,  3.8425,  3.6296,  3.4172,  3.2193,  2.9858,  2.8308,\n",
      "         2.7638,  2.5287,  2.2712,  2.1783,  2.0760,  1.8756,  1.7830,  1.6379,\n",
      "         1.5982,  1.5818,  1.4416,  1.3684,  1.2994,  1.3075,  1.2083,  1.2338,\n",
      "         1.1981,  1.2175,  1.2375,  1.3334,  1.5101,  2.0893, 15.9793],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.1271, 6.0933, 6.0958, 6.1131, 6.0991, 6.0686, 6.0653, 6.0207, 5.9838,\n",
      "        5.9013, 5.8214, 5.6157, 5.3754, 4.9616, 4.5348, 4.0714, 3.6114, 3.1395,\n",
      "        2.7096, 2.3025, 1.9408, 1.6476, 1.3921, 1.1888, 1.0243, 0.8951, 0.7975,\n",
      "        0.7179, 0.6618, 0.6216, 0.5936, 0.5742, 0.5622, 0.5524, 0.5468, 0.5447,\n",
      "        0.5418, 0.5410, 0.5391, 0.5362, 0.5331, 0.5293, 0.5233, 0.5154, 0.5080,\n",
      "        0.4985, 0.4894, 0.4800, 0.4683, 0.4554, 0.4401, 0.4242, 0.4098, 0.3969,\n",
      "        0.3813], grad_fn=<AddBackward0>) tensor([8.0682, 8.1180, 8.0979, 8.0352, 8.0755, 8.0970, 8.0281, 8.0607, 8.0165,\n",
      "        7.9047, 7.7176, 7.6250, 7.2432, 6.7975, 6.2194, 5.7076, 5.0962, 4.5906,\n",
      "        3.9800, 3.4964, 3.0571, 2.6039, 2.2640, 1.9817, 1.7535, 1.5599, 1.3981,\n",
      "        1.2970, 1.2022, 1.1269, 1.0744, 1.0493, 1.0130, 1.0088, 1.0023, 1.0027,\n",
      "        1.0111, 0.9902, 0.9964, 0.9930, 0.9975, 0.9873, 0.9777, 0.9681, 0.9514,\n",
      "        0.9480, 0.9387, 0.9181, 0.9017, 0.8827, 0.8675, 0.8502, 0.8674, 0.9106,\n",
      "        4.0658], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3851, 3.3706, 3.3503, 3.3585, 3.3670, 3.3331, 3.3297, 3.3345, 3.3218,\n",
      "        3.3107, 3.2991, 3.2818, 3.2654, 3.2414, 3.2052, 3.1579, 3.1089, 3.0209,\n",
      "        2.9607, 2.8624, 2.7383, 2.6173, 2.4671, 2.3271, 2.1512, 2.0081, 1.8446,\n",
      "        1.6878, 1.5424, 1.4017, 1.2749, 1.1534, 1.0417, 0.9458, 0.8624, 0.7835,\n",
      "        0.7166, 0.6572, 0.6026, 0.5567, 0.5132, 0.4759, 0.4472, 0.4184, 0.3947,\n",
      "        0.3723, 0.3550, 0.3373, 0.3228, 0.3085, 0.2956, 0.2811, 0.2661, 0.2488,\n",
      "        0.2362], grad_fn=<AddBackward0>) tensor([ 5.6995,  5.7673,  5.8356,  5.7593,  5.6348,  5.7701,  5.8067,  5.7061,\n",
      "         5.7257,  5.6683,  5.6386,  5.5834,  5.5067,  5.5995,  5.5443,  5.4970,\n",
      "         5.4044,  5.4788,  5.2214,  5.1348,  5.0081,  4.8038,  4.7222,  4.4025,\n",
      "         4.3667,  4.0424,  3.8268,  3.6224,  3.4159,  3.2150,  2.9733,  2.8290,\n",
      "         2.7526,  2.5198,  2.2702,  2.1760,  2.0708,  1.8665,  1.7813,  1.6309,\n",
      "         1.5964,  1.5674,  1.4339,  1.3668,  1.2929,  1.3018,  1.2081,  1.2349,\n",
      "         1.1924,  1.2145,  1.2341,  1.3283,  1.5090,  2.0977, 16.2116],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.2004, 6.1633, 6.1655, 6.1851, 6.1699, 6.1403, 6.1391, 6.0888, 6.0562,\n",
      "        5.9719, 5.8880, 5.6834, 5.4372, 5.0201, 4.5853, 4.1180, 3.6502, 3.1746,\n",
      "        2.7402, 2.3281, 1.9626, 1.6657, 1.4068, 1.2006, 1.0336, 0.9024, 0.8031,\n",
      "        0.7221, 0.6652, 0.6244, 0.5958, 0.5762, 0.5641, 0.5542, 0.5486, 0.5465,\n",
      "        0.5437, 0.5431, 0.5413, 0.5385, 0.5356, 0.5319, 0.5260, 0.5181, 0.5106,\n",
      "        0.5012, 0.4920, 0.4825, 0.4707, 0.4575, 0.4418, 0.4255, 0.4108, 0.3976,\n",
      "        0.3816], grad_fn=<AddBackward0>) tensor([8.1346, 8.1973, 8.1768, 8.1099, 8.1473, 8.1698, 8.0926, 8.1426, 8.0813,\n",
      "        7.9676, 7.7914, 7.6881, 7.3089, 6.8517, 6.2756, 5.7539, 5.1513, 4.6329,\n",
      "        4.0157, 3.5285, 3.0784, 2.6239, 2.2807, 1.9950, 1.7617, 1.5671, 1.4052,\n",
      "        1.3035, 1.2058, 1.1284, 1.0783, 1.0552, 1.0143, 1.0112, 1.0060, 1.0061,\n",
      "        1.0155, 0.9938, 0.9996, 0.9971, 1.0031, 0.9918, 0.9824, 0.9719, 0.9569,\n",
      "        0.9528, 0.9440, 0.9234, 0.9081, 0.8884, 0.8733, 0.8555, 0.8742, 0.9223,\n",
      "        4.3341], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3832, 3.3695, 3.3491, 3.3565, 3.3667, 3.3305, 3.3274, 3.3344, 3.3200,\n",
      "        3.3071, 3.2992, 3.2811, 3.2635, 3.2411, 3.2037, 3.1586, 3.1089, 3.0231,\n",
      "        2.9605, 2.8633, 2.7392, 2.6189, 2.4686, 2.3281, 2.1536, 2.0085, 1.8448,\n",
      "        1.6881, 1.5419, 1.4010, 1.2744, 1.1523, 1.0410, 0.9448, 0.8609, 0.7818,\n",
      "        0.7149, 0.6551, 0.6006, 0.5545, 0.5107, 0.4736, 0.4447, 0.4157, 0.3919,\n",
      "        0.3694, 0.3521, 0.3343, 0.3198, 0.3055, 0.2925, 0.2780, 0.2630, 0.2457,\n",
      "        0.2331], grad_fn=<AddBackward0>) tensor([ 5.6787,  5.7403,  5.8126,  5.7389,  5.6048,  5.7549,  5.7891,  5.6793,\n",
      "         5.7095,  5.6623,  5.6120,  5.5651,  5.4963,  5.5785,  5.5379,  5.4811,\n",
      "         5.3961,  5.4563,  5.2159,  5.1241,  4.9998,  4.7872,  4.7065,  4.3873,\n",
      "         4.3396,  4.0316,  3.8158,  3.6088,  3.4080,  3.2087,  2.9627,  2.8217,\n",
      "         2.7310,  2.5032,  2.2635,  2.1753,  2.0631,  1.8688,  1.7726,  1.6283,\n",
      "         1.6042,  1.5597,  1.4224,  1.3574,  1.2864,  1.2951,  1.2015,  1.2306,\n",
      "         1.1864,  1.2079,  1.2374,  1.3305,  1.5150,  2.1174, 16.4398],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2130, 6.1771, 6.1786, 6.1994, 6.1825, 6.1536, 6.1514, 6.1059, 6.0713,\n",
      "        5.9825, 5.9004, 5.6962, 5.4490, 5.0292, 4.5929, 4.1264, 3.6569, 3.1805,\n",
      "        2.7456, 2.3333, 1.9664, 1.6693, 1.4089, 1.2024, 1.0345, 0.9026, 0.8027,\n",
      "        0.7211, 0.6640, 0.6230, 0.5943, 0.5747, 0.5627, 0.5528, 0.5474, 0.5456,\n",
      "        0.5429, 0.5425, 0.5409, 0.5384, 0.5357, 0.5322, 0.5264, 0.5186, 0.5113,\n",
      "        0.5019, 0.4927, 0.4832, 0.4713, 0.4580, 0.4420, 0.4253, 0.4104, 0.3969,\n",
      "        0.3807], grad_fn=<AddBackward0>) tensor([8.1322, 8.1887, 8.1713, 8.1044, 8.1466, 8.1640, 8.0927, 8.1278, 8.0703,\n",
      "        7.9687, 7.7854, 7.6782, 7.3011, 6.8491, 6.2748, 5.7455, 5.1501, 4.6371,\n",
      "        4.0188, 3.5291, 3.0835, 2.6222, 2.2885, 1.9935, 1.7625, 1.5668, 1.4039,\n",
      "        1.3014, 1.2035, 1.1263, 1.0767, 1.0513, 1.0114, 1.0107, 1.0041, 1.0031,\n",
      "        1.0135, 0.9907, 0.9994, 0.9971, 1.0050, 0.9919, 0.9824, 0.9737, 0.9571,\n",
      "        0.9537, 0.9469, 0.9250, 0.9096, 0.8907, 0.8746, 0.8591, 0.8761, 0.9313,\n",
      "        4.5041], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3854, 3.3725, 3.3507, 3.3590, 3.3682, 3.3331, 3.3285, 3.3353, 3.3216,\n",
      "        3.3090, 3.3008, 3.2839, 3.2655, 3.2436, 3.2085, 3.1628, 3.1145, 3.0303,\n",
      "        2.9643, 2.8680, 2.7448, 2.6238, 2.4721, 2.3318, 2.1572, 2.0109, 1.8473,\n",
      "        1.6894, 1.5452, 1.4020, 1.2757, 1.1530, 1.0415, 0.9447, 0.8605, 0.7811,\n",
      "        0.7141, 0.6540, 0.5992, 0.5529, 0.5088, 0.4715, 0.4426, 0.4134, 0.3896,\n",
      "        0.3670, 0.3495, 0.3315, 0.3170, 0.3027, 0.2896, 0.2752, 0.2601, 0.2428,\n",
      "        0.2300], grad_fn=<AddBackward0>) tensor([ 5.6614,  5.7193,  5.7991,  5.7184,  5.5926,  5.7371,  5.7791,  5.6725,\n",
      "         5.6979,  5.6509,  5.6013,  5.5521,  5.4907,  5.5690,  5.5192,  5.4668,\n",
      "         5.3758,  5.4268,  5.2084,  5.1105,  4.9813,  4.7744,  4.7025,  4.3803,\n",
      "         4.3255,  4.0267,  3.8064,  3.6102,  3.3810,  3.2055,  2.9511,  2.8124,\n",
      "         2.7206,  2.4965,  2.2599,  2.1729,  2.0546,  1.8631,  1.7684,  1.6258,\n",
      "         1.6030,  1.5560,  1.4104,  1.3495,  1.2773,  1.2827,  1.1929,  1.2268,\n",
      "         1.1805,  1.2018,  1.2342,  1.3250,  1.5279,  2.1327, 16.6851],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.1680, 6.1341, 6.1344, 6.1560, 6.1377, 6.1106, 6.1077, 6.0627, 6.0290,\n",
      "        5.9389, 5.8591, 5.6588, 5.4103, 4.9924, 4.5588, 4.0969, 3.6296, 3.1584,\n",
      "        2.7271, 2.3176, 1.9538, 1.6580, 1.3994, 1.1938, 1.0270, 0.8957, 0.7962,\n",
      "        0.7150, 0.6583, 0.6175, 0.5891, 0.5697, 0.5580, 0.5485, 0.5434, 0.5418,\n",
      "        0.5395, 0.5394, 0.5382, 0.5360, 0.5336, 0.5304, 0.5250, 0.5174, 0.5102,\n",
      "        0.5010, 0.4920, 0.4826, 0.4706, 0.4572, 0.4411, 0.4241, 0.4089, 0.3952,\n",
      "        0.3788], grad_fn=<AddBackward0>) tensor([8.0671, 8.1157, 8.1040, 8.0354, 8.0804, 8.0916, 8.0254, 8.0563, 7.9996,\n",
      "        7.9046, 7.7154, 7.6002, 7.2365, 6.7886, 6.2206, 5.6911, 5.1148, 4.5972,\n",
      "        3.9836, 3.5018, 3.0553, 2.6031, 2.2730, 1.9823, 1.7509, 1.5528, 1.3919,\n",
      "        1.2887, 1.1899, 1.1139, 1.0657, 1.0431, 1.0037, 1.0031, 0.9963, 0.9961,\n",
      "        1.0070, 0.9864, 0.9964, 0.9927, 1.0041, 0.9878, 0.9779, 0.9713, 0.9564,\n",
      "        0.9515, 0.9459, 0.9240, 0.9102, 0.8905, 0.8744, 0.8598, 0.8778, 0.9369,\n",
      "        4.6575], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3997, 3.3876, 3.3645, 3.3726, 3.3824, 3.3487, 3.3400, 3.3508, 3.3353,\n",
      "        3.3224, 3.3168, 3.2976, 3.2783, 3.2569, 3.2248, 3.1787, 3.1301, 3.0430,\n",
      "        2.9782, 2.8828, 2.7579, 2.6389, 2.4839, 2.3432, 2.1689, 2.0201, 1.8565,\n",
      "        1.6968, 1.5521, 1.4085, 1.2804, 1.1574, 1.0452, 0.9478, 0.8629, 0.7828,\n",
      "        0.7153, 0.6549, 0.5997, 0.5530, 0.5085, 0.4709, 0.4417, 0.4122, 0.3882,\n",
      "        0.3654, 0.3477, 0.3297, 0.3150, 0.3005, 0.2873, 0.2727, 0.2574, 0.2399,\n",
      "        0.2271], grad_fn=<AddBackward0>) tensor([ 5.6589,  5.7138,  5.8026,  5.7236,  5.5954,  5.7287,  5.7952,  5.6658,\n",
      "         5.7015,  5.6593,  5.5968,  5.5595,  5.5039,  5.5825,  5.5155,  5.4726,\n",
      "         5.3804,  5.4493,  5.2245,  5.1155,  4.9949,  4.7718,  4.7166,  4.3866,\n",
      "         4.3214,  4.0356,  3.8077,  3.6173,  3.3820,  3.1960,  2.9579,  2.8134,\n",
      "         2.7208,  2.4969,  2.2611,  2.1819,  2.0574,  1.8649,  1.7680,  1.6266,\n",
      "         1.6063,  1.5550,  1.4082,  1.3485,  1.2741,  1.2791,  1.1899,  1.2177,\n",
      "         1.1750,  1.1983,  1.2289,  1.3222,  1.5371,  2.1492, 16.8071],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.1979, 6.1652, 6.1676, 6.1851, 6.1726, 6.1461, 6.1419, 6.0943, 6.0621,\n",
      "        5.9702, 5.8895, 5.6893, 5.4365, 5.0198, 4.5810, 4.1160, 3.6472, 3.1754,\n",
      "        2.7407, 2.3292, 1.9644, 1.6667, 1.4059, 1.1993, 1.0310, 0.8987, 0.7980,\n",
      "        0.7163, 0.6591, 0.6179, 0.5893, 0.5700, 0.5581, 0.5486, 0.5438, 0.5423,\n",
      "        0.5402, 0.5402, 0.5393, 0.5373, 0.5351, 0.5322, 0.5269, 0.5193, 0.5121,\n",
      "        0.5030, 0.4940, 0.4845, 0.4725, 0.4588, 0.4422, 0.4248, 0.4093, 0.3953,\n",
      "        0.3785], grad_fn=<AddBackward0>) tensor([8.0901, 8.1302, 8.1160, 8.0611, 8.0915, 8.0952, 8.0351, 8.0736, 8.0097,\n",
      "        7.9181, 7.7291, 7.6053, 7.2482, 6.7914, 6.2323, 5.7025, 5.1241, 4.5973,\n",
      "        3.9953, 3.5154, 3.0571, 2.6093, 2.2826, 1.9845, 1.7558, 1.5541, 1.3960,\n",
      "        1.2881, 1.1889, 1.1135, 1.0669, 1.0436, 1.0062, 1.0033, 0.9970, 0.9987,\n",
      "        1.0074, 0.9899, 0.9984, 0.9957, 1.0100, 0.9896, 0.9822, 0.9755, 0.9618,\n",
      "        0.9547, 0.9485, 0.9298, 0.9130, 0.8943, 0.8792, 0.8653, 0.8832, 0.9510,\n",
      "        4.9157], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4164, 3.4058, 3.3836, 3.3903, 3.4007, 3.3685, 3.3564, 3.3683, 3.3533,\n",
      "        3.3381, 3.3332, 3.3126, 3.2961, 3.2728, 3.2443, 3.1968, 3.1475, 3.0624,\n",
      "        2.9986, 2.8992, 2.7748, 2.6563, 2.5005, 2.3576, 2.1838, 2.0339, 1.8684,\n",
      "        1.7075, 1.5617, 1.4171, 1.2877, 1.1638, 1.0508, 0.9529, 0.8670, 0.7861,\n",
      "        0.7183, 0.6570, 0.6015, 0.5541, 0.5093, 0.4713, 0.4416, 0.4118, 0.3877,\n",
      "        0.3644, 0.3466, 0.3285, 0.3136, 0.2990, 0.2856, 0.2709, 0.2555, 0.2379,\n",
      "        0.2249], grad_fn=<AddBackward0>) tensor([ 5.6680,  5.7163,  5.7998,  5.7287,  5.5995,  5.7214,  5.8052,  5.6735,\n",
      "         5.7102,  5.6791,  5.6100,  5.5822,  5.5125,  5.6073,  5.5211,  5.4883,\n",
      "         5.3998,  5.4561,  5.2242,  5.1381,  5.0155,  4.7796,  4.7252,  4.4009,\n",
      "         4.3248,  4.0365,  3.8172,  3.6288,  3.3918,  3.2056,  2.9734,  2.8281,\n",
      "         2.7314,  2.5018,  2.2730,  2.1907,  2.0580,  1.8763,  1.7691,  1.6315,\n",
      "         1.6030,  1.5519,  1.4096,  1.3485,  1.2659,  1.2826,  1.1917,  1.2167,\n",
      "         1.1743,  1.2000,  1.2338,  1.3286,  1.5501,  2.1625, 17.1240],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.2061, 6.1727, 6.1762, 6.1925, 6.1772, 6.1566, 6.1500, 6.1023, 6.0693,\n",
      "        5.9789, 5.8965, 5.6946, 5.4411, 5.0247, 4.5816, 4.1208, 3.6503, 3.1792,\n",
      "        2.7439, 2.3327, 1.9679, 1.6689, 1.4076, 1.2002, 1.0315, 0.8985, 0.7972,\n",
      "        0.7149, 0.6576, 0.6162, 0.5876, 0.5683, 0.5565, 0.5473, 0.5424, 0.5411,\n",
      "        0.5393, 0.5396, 0.5389, 0.5372, 0.5353, 0.5326, 0.5274, 0.5200, 0.5129,\n",
      "        0.5039, 0.4950, 0.4855, 0.4733, 0.4594, 0.4425, 0.4247, 0.4088, 0.3945,\n",
      "        0.3774], grad_fn=<AddBackward0>) tensor([8.0805, 8.1232, 8.1041, 8.0528, 8.0967, 8.0799, 8.0260, 8.0641, 8.0016,\n",
      "        7.9054, 7.7212, 7.6040, 7.2456, 6.7850, 6.2394, 5.6925, 5.1215, 4.5942,\n",
      "        3.9974, 3.5109, 3.0485, 2.6077, 2.2823, 1.9862, 1.7514, 1.5500, 1.3912,\n",
      "        1.2869, 1.1852, 1.1096, 1.0625, 1.0397, 1.0037, 0.9978, 0.9961, 0.9974,\n",
      "        1.0057, 0.9890, 0.9977, 0.9958, 1.0092, 0.9889, 0.9857, 0.9766, 0.9639,\n",
      "        0.9565, 0.9495, 0.9323, 0.9170, 0.8980, 0.8813, 0.8683, 0.8866, 0.9595,\n",
      "        5.0944], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3844, 3.3748, 3.3539, 3.3614, 3.3720, 3.3403, 3.3273, 3.3409, 3.3259,\n",
      "        3.3101, 3.3042, 3.2827, 3.2706, 3.2457, 3.2163, 3.1732, 3.1257, 3.0350,\n",
      "        2.9743, 2.8763, 2.7527, 2.6340, 2.4826, 2.3405, 2.1670, 2.0173, 1.8536,\n",
      "        1.6938, 1.5483, 1.4058, 1.2765, 1.1528, 1.0410, 0.9440, 0.8584, 0.7782,\n",
      "        0.7105, 0.6498, 0.5947, 0.5474, 0.5029, 0.4651, 0.4355, 0.4058, 0.3819,\n",
      "        0.3589, 0.3411, 0.3230, 0.3083, 0.2937, 0.2804, 0.2658, 0.2504, 0.2328,\n",
      "        0.2200], grad_fn=<AddBackward0>) tensor([ 5.6141,  5.6627,  5.7402,  5.6617,  5.5345,  5.6536,  5.7427,  5.6015,\n",
      "         5.6401,  5.6115,  5.5537,  5.5372,  5.4428,  5.5489,  5.4692,  5.4192,\n",
      "         5.3221,  5.4198,  5.1766,  5.0902,  4.9651,  4.7397,  4.6633,  4.3423,\n",
      "         4.2738,  3.9959,  3.7715,  3.5847,  3.3575,  3.1589,  2.9396,  2.8084,\n",
      "         2.7083,  2.4717,  2.2520,  2.1667,  2.0393,  1.8507,  1.7419,  1.6107,\n",
      "         1.5811,  1.5362,  1.3996,  1.3390,  1.2480,  1.2605,  1.1719,  1.1992,\n",
      "         1.1579,  1.1887,  1.2211,  1.3151,  1.5372,  2.1500, 17.1141],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2172, 6.1874, 6.1856, 6.2050, 6.1866, 6.1678, 6.1621, 6.1135, 6.0787,\n",
      "        5.9908, 5.9093, 5.7065, 5.4497, 5.0334, 4.5886, 4.1261, 3.6570, 3.1852,\n",
      "        2.7490, 2.3371, 1.9717, 1.6721, 1.4099, 1.2016, 1.0321, 0.8987, 0.7967,\n",
      "        0.7138, 0.6562, 0.6147, 0.5859, 0.5668, 0.5549, 0.5458, 0.5412, 0.5401,\n",
      "        0.5385, 0.5390, 0.5385, 0.5371, 0.5355, 0.5331, 0.5280, 0.5208, 0.5138,\n",
      "        0.5049, 0.4960, 0.4865, 0.4742, 0.4601, 0.4428, 0.4246, 0.4084, 0.3937,\n",
      "        0.3763], grad_fn=<AddBackward0>) tensor([8.0815, 8.1120, 8.1127, 8.0502, 8.1010, 8.0820, 8.0230, 8.0655, 8.0090,\n",
      "        7.9025, 7.7139, 7.5954, 7.2483, 6.7806, 6.2370, 5.6969, 5.1159, 4.5917,\n",
      "        3.9982, 3.5144, 3.0484, 2.6055, 2.2822, 1.9872, 1.7528, 1.5448, 1.3881,\n",
      "        1.2857, 1.1819, 1.1068, 1.0572, 1.0346, 1.0014, 0.9964, 0.9931, 0.9943,\n",
      "        1.0047, 0.9882, 0.9971, 0.9960, 1.0080, 0.9903, 0.9892, 0.9777, 0.9656,\n",
      "        0.9593, 0.9519, 0.9353, 0.9214, 0.9007, 0.8849, 0.8711, 0.8920, 0.9717,\n",
      "        5.3160], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4186, 3.4085, 3.3865, 3.3967, 3.4060, 3.3734, 3.3612, 3.3762, 3.3577,\n",
      "        3.3438, 3.3373, 3.3164, 3.3028, 3.2788, 3.2502, 3.2083, 3.1622, 3.0674,\n",
      "        3.0081, 2.9092, 2.7822, 2.6636, 2.5122, 2.3655, 2.1920, 2.0402, 1.8734,\n",
      "        1.7127, 1.5644, 1.4218, 1.2897, 1.1647, 1.0516, 0.9530, 0.8664, 0.7853,\n",
      "        0.7164, 0.6548, 0.5990, 0.5512, 0.5058, 0.4675, 0.4373, 0.4073, 0.3829,\n",
      "        0.3595, 0.3414, 0.3231, 0.3081, 0.2933, 0.2797, 0.2648, 0.2493, 0.2314,\n",
      "        0.2184], grad_fn=<AddBackward0>) tensor([ 5.6462,  5.6950,  5.7793,  5.6866,  5.5687,  5.6901,  5.7727,  5.6270,\n",
      "         5.6830,  5.6413,  5.5923,  5.5694,  5.4871,  5.5906,  5.5067,  5.4505,\n",
      "         5.3441,  5.4605,  5.2091,  5.1197,  5.0099,  4.7732,  4.6814,  4.3834,\n",
      "         4.2983,  4.0183,  3.8092,  3.6067,  3.3863,  3.1670,  2.9617,  2.8268,\n",
      "         2.7247,  2.4919,  2.2681,  2.1769,  2.0572,  1.8712,  1.7597,  1.6185,\n",
      "         1.5961,  1.5422,  1.4093,  1.3402,  1.2519,  1.2645,  1.1739,  1.2036,\n",
      "         1.1627,  1.1930,  1.2311,  1.3256,  1.5448,  2.1740, 17.3740],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2104, 6.1839, 6.1804, 6.2010, 6.1864, 6.1662, 6.1576, 6.1099, 6.0723,\n",
      "        5.9865, 5.9039, 5.7005, 5.4462, 5.0296, 4.5850, 4.1222, 3.6538, 3.1817,\n",
      "        2.7467, 2.3359, 1.9708, 1.6708, 1.4082, 1.2002, 1.0303, 0.8965, 0.7942,\n",
      "        0.7111, 0.6534, 0.6118, 0.5830, 0.5640, 0.5523, 0.5433, 0.5389, 0.5381,\n",
      "        0.5367, 0.5376, 0.5374, 0.5362, 0.5350, 0.5328, 0.5281, 0.5210, 0.5141,\n",
      "        0.5054, 0.4965, 0.4871, 0.4747, 0.4604, 0.4427, 0.4241, 0.4075, 0.3925,\n",
      "        0.3747], grad_fn=<AddBackward0>) tensor([8.0667, 8.0889, 8.0947, 8.0271, 8.0651, 8.0526, 8.0014, 8.0422, 7.9932,\n",
      "        7.8802, 7.6934, 7.5773, 7.2237, 6.7583, 6.2114, 5.6781, 5.1016, 4.5853,\n",
      "        3.9918, 3.5041, 3.0379, 2.6000, 2.2840, 1.9817, 1.7469, 1.5381, 1.3836,\n",
      "        1.2788, 1.1764, 1.1006, 1.0530, 1.0287, 0.9968, 0.9918, 0.9899, 0.9893,\n",
      "        0.9990, 0.9862, 0.9941, 0.9958, 1.0065, 0.9908, 0.9892, 0.9796, 0.9667,\n",
      "        0.9598, 0.9552, 0.9388, 0.9233, 0.9012, 0.8869, 0.8736, 0.8933, 0.9823,\n",
      "        5.4973], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.3963, 3.3804, 3.3619, 3.3754, 3.3826, 3.3509, 3.3387, 3.3519, 3.3363,\n",
      "        3.3222, 3.3158, 3.2943, 3.2790, 3.2600, 3.2295, 3.1885, 3.1438, 3.0485,\n",
      "        2.9902, 2.8911, 2.7673, 2.6480, 2.4972, 2.3514, 2.1799, 2.0288, 1.8628,\n",
      "        1.7019, 1.5553, 1.4134, 1.2817, 1.1576, 1.0445, 0.9465, 0.8602, 0.7797,\n",
      "        0.7105, 0.6496, 0.5936, 0.5461, 0.5009, 0.4627, 0.4324, 0.4024, 0.3782,\n",
      "        0.3549, 0.3369, 0.3185, 0.3036, 0.2888, 0.2753, 0.2605, 0.2449, 0.2271,\n",
      "        0.2141], grad_fn=<AddBackward0>) tensor([ 5.5852,  5.6653,  5.7287,  5.6192,  5.5160,  5.6326,  5.7161,  5.5818,\n",
      "         5.6233,  5.5805,  5.5351,  5.5180,  5.4458,  5.5279,  5.4589,  5.3990,\n",
      "         5.2937,  5.4143,  5.1688,  5.0836,  4.9632,  4.7398,  4.6479,  4.3556,\n",
      "         4.2609,  3.9841,  3.7770,  3.5859,  3.3576,  3.1386,  2.9377,  2.7967,\n",
      "         2.7076,  2.4719,  2.2513,  2.1567,  2.0480,  1.8498,  1.7478,  1.6031,\n",
      "         1.5786,  1.5276,  1.4026,  1.3328,  1.2405,  1.2490,  1.1610,  1.1913,\n",
      "         1.1493,  1.1766,  1.2180,  1.3153,  1.5441,  2.1693, 17.4531],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2236, 6.1973, 6.1947, 6.2158, 6.2008, 6.1771, 6.1720, 6.1235, 6.0858,\n",
      "        5.9995, 5.9169, 5.7112, 5.4560, 5.0415, 4.5940, 4.1287, 3.6607, 3.1893,\n",
      "        2.7530, 2.3424, 1.9762, 1.6754, 1.4119, 1.2024, 1.0321, 0.8975, 0.7944,\n",
      "        0.7109, 0.6528, 0.6110, 0.5821, 0.5630, 0.5515, 0.5426, 0.5384, 0.5377,\n",
      "        0.5365, 0.5377, 0.5379, 0.5370, 0.5360, 0.5341, 0.5295, 0.5226, 0.5158,\n",
      "        0.5072, 0.4983, 0.4889, 0.4763, 0.4617, 0.4436, 0.4245, 0.4075, 0.3921,\n",
      "        0.3738], grad_fn=<AddBackward0>) tensor([8.0654, 8.0867, 8.0903, 8.0237, 8.0627, 8.0597, 8.0019, 8.0412, 7.9889,\n",
      "        7.8788, 7.6893, 7.5810, 7.2299, 6.7490, 6.2073, 5.6827, 5.1083, 4.5848,\n",
      "        3.9991, 3.5047, 3.0385, 2.5994, 2.2824, 1.9887, 1.7481, 1.5382, 1.3840,\n",
      "        1.2759, 1.1763, 1.0956, 1.0495, 1.0272, 0.9917, 0.9902, 0.9859, 0.9899,\n",
      "        0.9982, 0.9844, 0.9929, 0.9939, 1.0054, 0.9923, 0.9923, 0.9827, 0.9711,\n",
      "        0.9620, 0.9597, 0.9427, 0.9298, 0.9060, 0.8890, 0.8780, 0.8988, 0.9924,\n",
      "        5.7194], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4189, 3.4025, 3.3846, 3.3991, 3.4041, 3.3728, 3.3609, 3.3743, 3.3594,\n",
      "        3.3434, 3.3382, 3.3168, 3.3025, 3.2831, 3.2520, 3.2096, 3.1666, 3.0726,\n",
      "        3.0137, 2.9127, 2.7902, 2.6691, 2.5155, 2.3687, 2.1972, 2.0461, 1.8774,\n",
      "        1.7152, 1.5672, 1.4247, 1.2909, 1.1659, 1.0519, 0.9531, 0.8659, 0.7845,\n",
      "        0.7145, 0.6529, 0.5962, 0.5481, 0.5025, 0.4638, 0.4332, 0.4029, 0.3781,\n",
      "        0.3546, 0.3365, 0.3177, 0.3028, 0.2878, 0.2740, 0.2592, 0.2434, 0.2255,\n",
      "        0.2124], grad_fn=<AddBackward0>) tensor([ 5.5955,  5.6726,  5.7369,  5.6220,  5.5300,  5.6457,  5.7240,  5.5930,\n",
      "         5.6333,  5.5931,  5.5477,  5.5285,  5.4550,  5.5417,  5.4791,  5.4249,\n",
      "         5.3109,  5.4221,  5.1814,  5.1056,  4.9694,  4.7522,  4.6751,  4.3832,\n",
      "         4.2778,  3.9898,  3.7910,  3.6009,  3.3722,  3.1450,  2.9561,  2.8133,\n",
      "         2.7190,  2.4800,  2.2564,  2.1621,  2.0545,  1.8601,  1.7590,  1.6079,\n",
      "         1.5825,  1.5301,  1.3981,  1.3282,  1.2436,  1.2519,  1.1538,  1.1947,\n",
      "         1.1470,  1.1809,  1.2291,  1.3208,  1.5543,  2.2033, 17.7884],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.2228, 6.1938, 6.1935, 6.2107, 6.1989, 6.1745, 6.1693, 6.1207, 6.0827,\n",
      "        5.9950, 5.9120, 5.7045, 5.4511, 5.0375, 4.5912, 4.1272, 3.6590, 3.1879,\n",
      "        2.7532, 2.3425, 1.9763, 1.6757, 1.4120, 1.2022, 1.0313, 0.8963, 0.7927,\n",
      "        0.7089, 0.6506, 0.6089, 0.5799, 0.5609, 0.5495, 0.5406, 0.5369, 0.5362,\n",
      "        0.5353, 0.5368, 0.5372, 0.5367, 0.5360, 0.5344, 0.5299, 0.5233, 0.5166,\n",
      "        0.5081, 0.4992, 0.4898, 0.4771, 0.4623, 0.4438, 0.4241, 0.4068, 0.3911,\n",
      "        0.3724], grad_fn=<AddBackward0>) tensor([8.0382, 8.0676, 8.0646, 8.0088, 8.0404, 8.0398, 7.9804, 8.0209, 7.9684,\n",
      "        7.8630, 7.6771, 7.5703, 7.2150, 6.7323, 6.1879, 5.6616, 5.0928, 4.5717,\n",
      "        3.9834, 3.4969, 3.0329, 2.5956, 2.2747, 1.9832, 1.7459, 1.5352, 1.3819,\n",
      "        1.2748, 1.1729, 1.0911, 1.0449, 1.0221, 0.9870, 0.9880, 0.9805, 0.9872,\n",
      "        0.9974, 0.9827, 0.9913, 0.9926, 1.0051, 0.9913, 0.9957, 0.9842, 0.9712,\n",
      "        0.9640, 0.9614, 0.9464, 0.9324, 0.9090, 0.8925, 0.8825, 0.9032, 1.0056,\n",
      "        5.9708], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4377, 3.4204, 3.4016, 3.4166, 3.4228, 3.3883, 3.3822, 3.3912, 3.3785,\n",
      "        3.3624, 3.3541, 3.3365, 3.3222, 3.3033, 3.2709, 3.2290, 3.1862, 3.0918,\n",
      "        3.0342, 2.9316, 2.8079, 2.6862, 2.5313, 2.3841, 2.2132, 2.0610, 1.8904,\n",
      "        1.7275, 1.5781, 1.4347, 1.2986, 1.1738, 1.0585, 0.9584, 0.8711, 0.7891,\n",
      "        0.7182, 0.6561, 0.5989, 0.5503, 0.5040, 0.4650, 0.4340, 0.4033, 0.3782,\n",
      "        0.3544, 0.3361, 0.3171, 0.3020, 0.2868, 0.2729, 0.2578, 0.2418, 0.2237,\n",
      "        0.2107], grad_fn=<AddBackward0>) tensor([ 5.5963,  5.6799,  5.7464,  5.6299,  5.5310,  5.6668,  5.7091,  5.6080,\n",
      "         5.6364,  5.5973,  5.5693,  5.5284,  5.4569,  5.5440,  5.4891,  5.4331,\n",
      "         5.3203,  5.4337,  5.1859,  5.1165,  4.9868,  4.7678,  4.6958,  4.4005,\n",
      "         4.2793,  3.9909,  3.7929,  3.6024,  3.3739,  3.1471,  2.9776,  2.8191,\n",
      "         2.7333,  2.5015,  2.2670,  2.1691,  2.0683,  1.8673,  1.7652,  1.6140,\n",
      "         1.5942,  1.5343,  1.4009,  1.3271,  1.2480,  1.2541,  1.1532,  1.1966,\n",
      "         1.1482,  1.1817,  1.2332,  1.3325,  1.5800,  2.2299, 18.0036],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2849, 6.2587, 6.2559, 6.2756, 6.2647, 6.2376, 6.2327, 6.1815, 6.1496,\n",
      "        6.0609, 5.9741, 5.7649, 5.5040, 5.0890, 4.6384, 4.1700, 3.6961, 3.2198,\n",
      "        2.7813, 2.3678, 1.9962, 1.6936, 1.4259, 1.2133, 1.0403, 0.9033, 0.7983,\n",
      "        0.7132, 0.6539, 0.6116, 0.5822, 0.5629, 0.5514, 0.5425, 0.5387, 0.5382,\n",
      "        0.5374, 0.5391, 0.5397, 0.5394, 0.5388, 0.5373, 0.5330, 0.5264, 0.5197,\n",
      "        0.5111, 0.5023, 0.4927, 0.4797, 0.4644, 0.4453, 0.4250, 0.4073, 0.3912,\n",
      "        0.3717], grad_fn=<AddBackward0>) tensor([8.1045, 8.1275, 8.1308, 8.0683, 8.0960, 8.1026, 8.0420, 8.0889, 8.0188,\n",
      "        7.9110, 7.7297, 7.6200, 7.2766, 6.7781, 6.2264, 5.6928, 5.1284, 4.6066,\n",
      "        4.0155, 3.5186, 3.0581, 2.6073, 2.2925, 1.9987, 1.7568, 1.5482, 1.3863,\n",
      "        1.2760, 1.1788, 1.0942, 1.0457, 1.0234, 0.9888, 0.9932, 0.9868, 0.9894,\n",
      "        1.0005, 0.9858, 0.9952, 0.9971, 1.0117, 0.9994, 1.0004, 0.9916, 0.9768,\n",
      "        0.9694, 0.9675, 0.9512, 0.9374, 0.9159, 0.8993, 0.8889, 0.9124, 1.0185,\n",
      "        6.2927], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4540, 3.4362, 3.4172, 3.4341, 3.4410, 3.4051, 3.3991, 3.4079, 3.3964,\n",
      "        3.3792, 3.3688, 3.3530, 3.3403, 3.3223, 3.2858, 3.2492, 3.2038, 3.1108,\n",
      "        3.0512, 2.9484, 2.8244, 2.7042, 2.5470, 2.3979, 2.2265, 2.0721, 1.8999,\n",
      "        1.7374, 1.5867, 1.4419, 1.3043, 1.1789, 1.0631, 0.9625, 0.8737, 0.7914,\n",
      "        0.7199, 0.6575, 0.5996, 0.5506, 0.5039, 0.4644, 0.4332, 0.4023, 0.3769,\n",
      "        0.3529, 0.3345, 0.3153, 0.3000, 0.2847, 0.2707, 0.2553, 0.2392, 0.2209,\n",
      "        0.2080], grad_fn=<AddBackward0>) tensor([ 5.6041,  5.6908,  5.7574,  5.6331,  5.5299,  5.6742,  5.7153,  5.6178,\n",
      "         5.6386,  5.6043,  5.5907,  5.5382,  5.4599,  5.5458,  5.5169,  5.4310,\n",
      "         5.3326,  5.4396,  5.1998,  5.1277,  5.0011,  4.7618,  4.6999,  4.4139,\n",
      "         4.2833,  4.0024,  3.8117,  3.6056,  3.3756,  3.1554,  2.9951,  2.8271,\n",
      "         2.7347,  2.4943,  2.2771,  2.1732,  2.0712,  1.8615,  1.7658,  1.6115,\n",
      "         1.5957,  1.5376,  1.4029,  1.3232,  1.2449,  1.2487,  1.1507,  1.1920,\n",
      "         1.1471,  1.1817,  1.2304,  1.3376,  1.5853,  2.2396, 18.0667],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2570, 6.2306, 6.2276, 6.2486, 6.2363, 6.2094, 6.2046, 6.1532, 6.1207,\n",
      "        6.0367, 5.9496, 5.7383, 5.4812, 5.0643, 4.6151, 4.1521, 3.6799, 3.2055,\n",
      "        2.7703, 2.3595, 1.9893, 1.6881, 1.4212, 1.2089, 1.0364, 0.8994, 0.7945,\n",
      "        0.7096, 0.6501, 0.6080, 0.5788, 0.5596, 0.5483, 0.5397, 0.5361, 0.5360,\n",
      "        0.5355, 0.5376, 0.5384, 0.5385, 0.5383, 0.5371, 0.5331, 0.5267, 0.5201,\n",
      "        0.5117, 0.5029, 0.4933, 0.4802, 0.4647, 0.4451, 0.4243, 0.4061, 0.3897,\n",
      "        0.3697], grad_fn=<AddBackward0>) tensor([8.0550, 8.0783, 8.0841, 8.0175, 8.0495, 8.0546, 7.9959, 8.0398, 7.9762,\n",
      "        7.8535, 7.6753, 7.5765, 7.2228, 6.7423, 6.1936, 5.6540, 5.0986, 4.5881,\n",
      "        3.9955, 3.4987, 3.0440, 2.5921, 2.2821, 1.9897, 1.7441, 1.5389, 1.3783,\n",
      "        1.2655, 1.1734, 1.0892, 1.0402, 1.0193, 0.9857, 0.9862, 0.9819, 0.9841,\n",
      "        0.9961, 0.9798, 0.9923, 0.9942, 1.0114, 0.9990, 0.9981, 0.9919, 0.9772,\n",
      "        0.9686, 0.9693, 0.9527, 0.9395, 0.9169, 0.8987, 0.8916, 0.9161, 1.0269,\n",
      "        6.4981], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4537, 3.4376, 3.4180, 3.4359, 3.4446, 3.4048, 3.4020, 3.4100, 3.3994,\n",
      "        3.3817, 3.3700, 3.3533, 3.3433, 3.3257, 3.2909, 3.2517, 3.2064, 3.1149,\n",
      "        3.0549, 2.9542, 2.8269, 2.7081, 2.5509, 2.4023, 2.2298, 2.0743, 1.9025,\n",
      "        1.7396, 1.5888, 1.4438, 1.3062, 1.1797, 1.0633, 0.9627, 0.8737, 0.7908,\n",
      "        0.7192, 0.6565, 0.5981, 0.5491, 0.5019, 0.4624, 0.4308, 0.4000, 0.3742,\n",
      "        0.3502, 0.3316, 0.3124, 0.2970, 0.2817, 0.2675, 0.2522, 0.2360, 0.2177,\n",
      "        0.2049], grad_fn=<AddBackward0>) tensor([ 5.5980,  5.6721,  5.7430,  5.6126,  5.5020,  5.6655,  5.6875,  5.5973,\n",
      "         5.6146,  5.5818,  5.5756,  5.5325,  5.4376,  5.5299,  5.4905,  5.4250,\n",
      "         5.3273,  5.4323,  5.1917,  5.1067,  5.0034,  4.7589,  4.6938,  4.4046,\n",
      "         4.2776,  4.0056,  3.8078,  3.6023,  3.3690,  3.1478,  2.9812,  2.8245,\n",
      "         2.7421,  2.4936,  2.2746,  2.1770,  2.0610,  1.8552,  1.7659,  1.6021,\n",
      "         1.5949,  1.5294,  1.3959,  1.3034,  1.2397,  1.2352,  1.1413,  1.1867,\n",
      "         1.1394,  1.1685,  1.2280,  1.3300,  1.5920,  2.2418, 18.2058],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2527, 6.2290, 6.2238, 6.2458, 6.2345, 6.2064, 6.2028, 6.1477, 6.1153,\n",
      "        6.0303, 5.9465, 5.7343, 5.4779, 5.0569, 4.6123, 4.1488, 3.6779, 3.2051,\n",
      "        2.7696, 2.3586, 1.9888, 1.6884, 1.4209, 1.2083, 1.0356, 0.8983, 0.7928,\n",
      "        0.7076, 0.6481, 0.6059, 0.5768, 0.5575, 0.5463, 0.5379, 0.5347, 0.5347,\n",
      "        0.5346, 0.5369, 0.5381, 0.5386, 0.5387, 0.5378, 0.5340, 0.5278, 0.5213,\n",
      "        0.5130, 0.5043, 0.4946, 0.4814, 0.4654, 0.4453, 0.4239, 0.4052, 0.3883,\n",
      "        0.3678], grad_fn=<AddBackward0>) tensor([8.0376, 8.0494, 8.0647, 7.9922, 8.0207, 8.0294, 7.9696, 8.0259, 7.9602,\n",
      "        7.8421, 7.6533, 7.5591, 7.1983, 6.7333, 6.1707, 5.6368, 5.0808, 4.5705,\n",
      "        3.9854, 3.4939, 3.0387, 2.5840, 2.2802, 1.9907, 1.7392, 1.5319, 1.3751,\n",
      "        1.2600, 1.1662, 1.0842, 1.0323, 1.0151, 0.9840, 0.9834, 0.9792, 0.9803,\n",
      "        0.9926, 0.9791, 0.9932, 0.9929, 1.0094, 1.0002, 1.0035, 0.9937, 0.9799,\n",
      "        0.9716, 0.9726, 0.9565, 0.9417, 0.9201, 0.9010, 0.8953, 0.9220, 1.0397,\n",
      "        6.6624], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4363, 3.4230, 3.4043, 3.4202, 3.4295, 3.3901, 3.3871, 3.3931, 3.3821,\n",
      "        3.3663, 3.3549, 3.3384, 3.3300, 3.3101, 3.2785, 3.2403, 3.1941, 3.1044,\n",
      "        3.0456, 2.9431, 2.8159, 2.6993, 2.5429, 2.3951, 2.2223, 2.0665, 1.8966,\n",
      "        1.7330, 1.5828, 1.4381, 1.3015, 1.1749, 1.0592, 0.9585, 0.8695, 0.7866,\n",
      "        0.7154, 0.6527, 0.5942, 0.5453, 0.4981, 0.4588, 0.4273, 0.3962, 0.3705,\n",
      "        0.3466, 0.3279, 0.3087, 0.2934, 0.2781, 0.2639, 0.2486, 0.2325, 0.2142,\n",
      "        0.2014], grad_fn=<AddBackward0>) tensor([ 5.5694,  5.6256,  5.6937,  5.5729,  5.4615,  5.6232,  5.6462,  5.5697,\n",
      "         5.5922,  5.5486,  5.5397,  5.4976,  5.3974,  5.5063,  5.4517,  5.3860,\n",
      "         5.2947,  5.3922,  5.1506,  5.0788,  4.9821,  4.7292,  4.6628,  4.3715,\n",
      "         4.2533,  3.9827,  3.7807,  3.5851,  3.3504,  3.1328,  2.9589,  2.8052,\n",
      "         2.7159,  2.4784,  2.2651,  2.1739,  2.0529,  1.8461,  1.7619,  1.5957,\n",
      "         1.5877,  1.5189,  1.3808,  1.2998,  1.2286,  1.2232,  1.1326,  1.1790,\n",
      "         1.1284,  1.1555,  1.2204,  1.3265,  1.5847,  2.2492, 18.3401],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.2816, 6.2555, 6.2508, 6.2732, 6.2584, 6.2348, 6.2296, 6.1759, 6.1409,\n",
      "        6.0539, 5.9715, 5.7580, 5.5013, 5.0778, 4.6298, 4.1659, 3.6937, 3.2197,\n",
      "        2.7831, 2.3699, 1.9990, 1.6969, 1.4277, 1.2137, 1.0398, 0.9013, 0.7946,\n",
      "        0.7089, 0.6489, 0.6062, 0.5768, 0.5576, 0.5463, 0.5379, 0.5349, 0.5351,\n",
      "        0.5352, 0.5377, 0.5392, 0.5400, 0.5403, 0.5396, 0.5360, 0.5299, 0.5235,\n",
      "        0.5152, 0.5065, 0.4966, 0.4831, 0.4668, 0.4459, 0.4239, 0.4046, 0.3872,\n",
      "        0.3660], grad_fn=<AddBackward0>) tensor([8.0527, 8.0666, 8.0829, 8.0096, 8.0480, 8.0432, 7.9857, 8.0384, 7.9797,\n",
      "        7.8674, 7.6720, 7.5770, 7.2121, 6.7471, 6.1888, 5.6479, 5.0923, 4.5795,\n",
      "        3.9939, 3.5050, 3.0448, 2.5920, 2.2879, 1.9971, 1.7420, 1.5326, 1.3769,\n",
      "        1.2610, 1.1659, 1.0852, 1.0338, 1.0137, 0.9834, 0.9831, 0.9788, 0.9816,\n",
      "        0.9919, 0.9783, 0.9941, 0.9932, 1.0137, 1.0013, 1.0075, 0.9965, 0.9852,\n",
      "        0.9769, 0.9766, 0.9616, 0.9467, 0.9248, 0.9069, 0.8990, 0.9308, 1.0523,\n",
      "        6.8628], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4647, 3.4538, 3.4329, 3.4504, 3.4569, 3.4183, 3.4155, 3.4234, 3.4127,\n",
      "        3.3979, 3.3847, 3.3687, 3.3597, 3.3393, 3.3067, 3.2694, 3.2245, 3.1353,\n",
      "        3.0766, 2.9734, 2.8438, 2.7257, 2.5684, 2.4200, 2.2440, 2.0870, 1.9151,\n",
      "        1.7492, 1.5977, 1.4518, 1.3126, 1.1853, 1.0684, 0.9660, 0.8754, 0.7920,\n",
      "        0.7198, 0.6566, 0.5972, 0.5477, 0.4998, 0.4599, 0.4281, 0.3967, 0.3707,\n",
      "        0.3464, 0.3275, 0.3081, 0.2926, 0.2772, 0.2628, 0.2473, 0.2311, 0.2127,\n",
      "        0.1997], grad_fn=<AddBackward0>) tensor([ 5.6034,  5.6472,  5.7256,  5.5978,  5.4970,  5.6562,  5.6767,  5.5943,\n",
      "         5.6164,  5.5644,  5.5666,  5.5237,  5.4283,  5.5417,  5.4957,  5.4231,\n",
      "         5.3259,  5.4158,  5.1735,  5.1027,  5.0094,  4.7627,  4.6910,  4.3893,\n",
      "         4.2821,  3.9992,  3.7996,  3.6060,  3.3686,  3.1388,  2.9800,  2.8133,\n",
      "         2.7145,  2.4896,  2.2846,  2.1829,  2.0648,  1.8444,  1.7668,  1.5981,\n",
      "         1.5926,  1.5253,  1.3812,  1.3029,  1.2314,  1.2270,  1.1355,  1.1812,\n",
      "         1.1314,  1.1585,  1.2220,  1.3411,  1.5991,  2.2777, 18.6697],\n",
      "       grad_fn=<AddBackward0>)\n",
      "4011.658249616623\n",
      "r0 before lock-down  tensor([6.2786, 6.2485, 6.2476, 6.2647, 6.2522, 6.2290, 6.2201, 6.1696, 6.1354,\n",
      "        6.0509, 5.9664, 5.7546, 5.4959, 5.0740, 4.6241, 4.1605, 3.6913, 3.2175,\n",
      "        2.7805, 2.3694, 1.9984, 1.6958, 1.4266, 1.2123, 1.0381, 0.8996, 0.7925,\n",
      "        0.7065, 0.6462, 0.6037, 0.5743, 0.5549, 0.5439, 0.5356, 0.5327, 0.5333,\n",
      "        0.5336, 0.5365, 0.5382, 0.5394, 0.5401, 0.5397, 0.5363, 0.5304, 0.5241,\n",
      "        0.5160, 0.5073, 0.4975, 0.4837, 0.4671, 0.4457, 0.4230, 0.4032, 0.3853,\n",
      "        0.3636], grad_fn=<AddBackward0>) tensor([8.0215, 8.0483, 8.0491, 7.9963, 8.0269, 8.0207, 7.9737, 8.0161, 7.9571,\n",
      "        7.8329, 7.6448, 7.5479, 7.1872, 6.7197, 6.1680, 5.6304, 5.0686, 4.5610,\n",
      "        3.9843, 3.4879, 3.0327, 2.5905, 2.2841, 1.9950, 1.7385, 1.5279, 1.3734,\n",
      "        1.2536, 1.1634, 1.0777, 1.0274, 1.0103, 0.9759, 0.9774, 0.9751, 0.9774,\n",
      "        0.9890, 0.9749, 0.9938, 0.9908, 1.0122, 1.0018, 1.0094, 0.9981, 0.9876,\n",
      "        0.9786, 0.9792, 0.9643, 0.9505, 0.9292, 0.9092, 0.9010, 0.9327, 1.0629,\n",
      "        7.0279], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4557, 3.4437, 3.4221, 3.4403, 3.4471, 3.4077, 3.4081, 3.4144, 3.4040,\n",
      "        3.3884, 3.3763, 3.3584, 3.3508, 3.3315, 3.3009, 3.2633, 3.2149, 3.1301,\n",
      "        3.0719, 2.9691, 2.8385, 2.7214, 2.5643, 2.4166, 2.2407, 2.0838, 1.9119,\n",
      "        1.7467, 1.5963, 1.4481, 1.3096, 1.1827, 1.0661, 0.9635, 0.8729, 0.7897,\n",
      "        0.7173, 0.6540, 0.5947, 0.5451, 0.4972, 0.4573, 0.4252, 0.3939, 0.3679,\n",
      "        0.3436, 0.3246, 0.3052, 0.2897, 0.2743, 0.2600, 0.2444, 0.2282, 0.2100,\n",
      "        0.1968], grad_fn=<AddBackward0>) tensor([ 5.5663,  5.6176,  5.6979,  5.5657,  5.4670,  5.6309,  5.6331,  5.5611,\n",
      "         5.5811,  5.5364,  5.5318,  5.5031,  5.4039,  5.5099,  5.4592,  5.3870,\n",
      "         5.3144,  5.3823,  5.1399,  5.0711,  4.9858,  4.7355,  4.6689,  4.3605,\n",
      "         4.2559,  3.9764,  3.7740,  3.5783,  3.3312,  3.1328,  2.9691,  2.7993,\n",
      "         2.6987,  2.4840,  2.2768,  2.1721,  2.0623,  1.8375,  1.7578,  1.5883,\n",
      "         1.5847,  1.5174,  1.3800,  1.3010,  1.2240,  1.2196,  1.1294,  1.1710,\n",
      "         1.1302,  1.1532,  1.2115,  1.3473,  1.6013,  2.2755, 18.8971],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2816, 6.2502, 6.2500, 6.2675, 6.2560, 6.2307, 6.2180, 6.1690, 6.1377,\n",
      "        6.0528, 5.9663, 5.7580, 5.4959, 5.0742, 4.6218, 4.1603, 3.6927, 3.2185,\n",
      "        2.7823, 2.3717, 2.0006, 1.6967, 1.4274, 1.2129, 1.0383, 0.8990, 0.7916,\n",
      "        0.7052, 0.6445, 0.6018, 0.5722, 0.5531, 0.5422, 0.5339, 0.5313, 0.5321,\n",
      "        0.5326, 0.5356, 0.5379, 0.5394, 0.5404, 0.5402, 0.5372, 0.5314, 0.5250,\n",
      "        0.5171, 0.5086, 0.4986, 0.4847, 0.4676, 0.4456, 0.4223, 0.4019, 0.3834,\n",
      "        0.3613], grad_fn=<AddBackward0>) tensor([8.0027, 8.0313, 8.0322, 7.9785, 8.0087, 8.0076, 7.9695, 8.0072, 7.9409,\n",
      "        7.8167, 7.6363, 7.5244, 7.1764, 6.7076, 6.1648, 5.6223, 5.0555, 4.5551,\n",
      "        3.9799, 3.4811, 3.0267, 2.5953, 2.2860, 1.9967, 1.7379, 1.5266, 1.3694,\n",
      "        1.2484, 1.1592, 1.0742, 1.0277, 1.0058, 0.9729, 0.9769, 0.9687, 0.9732,\n",
      "        0.9886, 0.9778, 0.9902, 0.9896, 1.0118, 1.0041, 1.0084, 0.9991, 0.9933,\n",
      "        0.9811, 0.9807, 0.9693, 0.9538, 0.9319, 0.9138, 0.9040, 0.9364, 1.0750,\n",
      "        7.1872], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4909, 3.4797, 3.4599, 3.4764, 3.4856, 3.4435, 3.4460, 3.4507, 3.4418,\n",
      "        3.4261, 3.4126, 3.3954, 3.3883, 3.3690, 3.3375, 3.3023, 3.2526, 3.1682,\n",
      "        3.1085, 3.0061, 2.8740, 2.7545, 2.5957, 2.4464, 2.2689, 2.1085, 1.9346,\n",
      "        1.7679, 1.6158, 1.4650, 1.3243, 1.1962, 1.0782, 0.9739, 0.8821, 0.7975,\n",
      "        0.7241, 0.6599, 0.5995, 0.5492, 0.5004, 0.4600, 0.4272, 0.3954, 0.3690,\n",
      "        0.3442, 0.3249, 0.3052, 0.2895, 0.2739, 0.2594, 0.2436, 0.2274, 0.2090,\n",
      "        0.1956], grad_fn=<AddBackward0>) tensor([ 5.6155,  5.6653,  5.7308,  5.6121,  5.4991,  5.6758,  5.6670,  5.6016,\n",
      "         5.6179,  5.5719,  5.5754,  5.5422,  5.4449,  5.5515,  5.5051,  5.4221,\n",
      "         5.3535,  5.4186,  5.1766,  5.1007,  5.0150,  4.7716,  4.7059,  4.3936,\n",
      "         4.2833,  4.0140,  3.8053,  3.6054,  3.3549,  3.1614,  3.0038,  2.8219,\n",
      "         2.7174,  2.5027,  2.2929,  2.1925,  2.0769,  1.8467,  1.7736,  1.6000,\n",
      "         1.5947,  1.5189,  1.3838,  1.3025,  1.2219,  1.2191,  1.1326,  1.1740,\n",
      "         1.1295,  1.1549,  1.2235,  1.3585,  1.6268,  2.3141, 19.3523],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2514, 6.2235, 6.2209, 6.2408, 6.2272, 6.2039, 6.1885, 6.1422, 6.1090,\n",
      "        6.0265, 5.9395, 5.7322, 5.4701, 5.0483, 4.5984, 4.1410, 3.6764, 3.2031,\n",
      "        2.7701, 2.3619, 1.9927, 1.6903, 1.4216, 1.2072, 1.0335, 0.8943, 0.7869,\n",
      "        0.7006, 0.6401, 0.5975, 0.5680, 0.5490, 0.5383, 0.5302, 0.5278, 0.5290,\n",
      "        0.5296, 0.5330, 0.5357, 0.5376, 0.5389, 0.5392, 0.5364, 0.5308, 0.5245,\n",
      "        0.5169, 0.5084, 0.4984, 0.4843, 0.4669, 0.4443, 0.4204, 0.3995, 0.3805,\n",
      "        0.3578], grad_fn=<AddBackward0>) tensor([7.9614, 7.9767, 7.9830, 7.9240, 7.9589, 7.9537, 7.9230, 7.9540, 7.8911,\n",
      "        7.7622, 7.5859, 7.4733, 7.1297, 6.6706, 6.1271, 5.5827, 5.0211, 4.5339,\n",
      "        3.9582, 3.4597, 3.0089, 2.5767, 2.2712, 1.9921, 1.7283, 1.5180, 1.3610,\n",
      "        1.2417, 1.1527, 1.0660, 1.0205, 0.9968, 0.9647, 0.9729, 0.9636, 0.9659,\n",
      "        0.9840, 0.9731, 0.9853, 0.9833, 1.0092, 1.0007, 1.0073, 0.9971, 0.9949,\n",
      "        0.9822, 0.9783, 0.9709, 0.9549, 0.9325, 0.9153, 0.9033, 0.9359, 1.0772,\n",
      "        7.2821], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4680, 3.4544, 3.4354, 3.4550, 3.4614, 3.4201, 3.4230, 3.4276, 3.4212,\n",
      "        3.4059, 3.3919, 3.3748, 3.3652, 3.3492, 3.3167, 3.2826, 3.2322, 3.1518,\n",
      "        3.0904, 2.9900, 2.8589, 2.7373, 2.5795, 2.4331, 2.2564, 2.0975, 1.9250,\n",
      "        1.7578, 1.6069, 1.4564, 1.3165, 1.1890, 1.0713, 0.9677, 0.8762, 0.7919,\n",
      "        0.7186, 0.6549, 0.5944, 0.5441, 0.4955, 0.4550, 0.4225, 0.3906, 0.3643,\n",
      "        0.3397, 0.3204, 0.3008, 0.2851, 0.2695, 0.2549, 0.2392, 0.2229, 0.2043,\n",
      "        0.1915], grad_fn=<AddBackward0>) tensor([ 5.5587,  5.6199,  5.6824,  5.5492,  5.4487,  5.6196,  5.6117,  5.5482,\n",
      "         5.5551,  5.5085,  5.5156,  5.4844,  5.4045,  5.4924,  5.4576,  5.3735,\n",
      "         5.3118,  5.3609,  5.1367,  5.0547,  4.9710,  4.7447,  4.6888,  4.3625,\n",
      "         4.2552,  3.9805,  3.7705,  3.5854,  3.3301,  3.1460,  2.9894,  2.8075,\n",
      "         2.7043,  2.4839,  2.2791,  2.1756,  2.0599,  1.8222,  1.7536,  1.5833,\n",
      "         1.5777,  1.5119,  1.3670,  1.2951,  1.2129,  1.2050,  1.1191,  1.1585,\n",
      "         1.1198,  1.1416,  1.2143,  1.3456,  1.6120,  2.3256, 19.1370],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.2856, 6.2598, 6.2561, 6.2763, 6.2606, 6.2408, 6.2216, 6.1739, 6.1439,\n",
      "        6.0591, 5.9742, 5.7664, 5.4997, 5.0741, 4.6242, 4.1630, 3.6974, 3.2222,\n",
      "        2.7866, 2.3767, 2.0046, 1.7009, 1.4297, 1.2140, 1.0386, 0.8981, 0.7896,\n",
      "        0.7024, 0.6411, 0.5981, 0.5685, 0.5493, 0.5386, 0.5306, 0.5283, 0.5295,\n",
      "        0.5305, 0.5342, 0.5370, 0.5394, 0.5409, 0.5414, 0.5389, 0.5334, 0.5272,\n",
      "        0.5195, 0.5111, 0.5009, 0.4865, 0.4686, 0.4452, 0.4205, 0.3989, 0.3792,\n",
      "        0.3559], grad_fn=<AddBackward0>) tensor([7.9931, 8.0019, 8.0082, 7.9512, 7.9930, 7.9755, 7.9571, 7.9926, 7.9159,\n",
      "        7.7917, 7.6066, 7.4911, 7.1518, 6.6996, 6.1424, 5.5999, 5.0349, 4.5437,\n",
      "        3.9728, 3.4713, 3.0221, 2.5872, 2.2811, 1.9988, 1.7348, 1.5229, 1.3629,\n",
      "        1.2429, 1.1570, 1.0685, 1.0189, 0.9951, 0.9668, 0.9725, 0.9637, 0.9672,\n",
      "        0.9819, 0.9731, 0.9876, 0.9843, 1.0122, 1.0054, 1.0116, 1.0025, 0.9996,\n",
      "        0.9880, 0.9832, 0.9754, 0.9611, 0.9377, 0.9230, 0.9088, 0.9417, 1.0927,\n",
      "        7.4778], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4746, 3.4605, 3.4408, 3.4613, 3.4683, 3.4278, 3.4298, 3.4358, 3.4272,\n",
      "        3.4129, 3.3964, 3.3846, 3.3731, 3.3574, 3.3269, 3.2926, 3.2415, 3.1607,\n",
      "        3.0982, 2.9977, 2.8684, 2.7471, 2.5879, 2.4404, 2.2643, 2.1044, 1.9317,\n",
      "        1.7629, 1.6113, 1.4600, 1.3207, 1.1919, 1.0736, 0.9697, 0.8776, 0.7927,\n",
      "        0.7193, 0.6550, 0.5941, 0.5437, 0.4946, 0.4541, 0.4214, 0.3891, 0.3627,\n",
      "        0.3380, 0.3187, 0.2989, 0.2831, 0.2675, 0.2528, 0.2372, 0.2207, 0.2022,\n",
      "        0.1893], grad_fn=<AddBackward0>) tensor([ 5.5501,  5.6151,  5.6794,  5.5421,  5.4394,  5.6071,  5.6063,  5.5330,\n",
      "         5.5525,  5.5018,  5.5228,  5.4662,  5.3989,  5.4878,  5.4415,  5.3624,\n",
      "         5.3074,  5.3605,  5.1437,  5.0649,  4.9645,  4.7341,  4.6898,  4.3655,\n",
      "         4.2489,  3.9754,  3.7610,  3.5858,  3.3359,  3.1488,  2.9731,  2.8031,\n",
      "         2.7022,  2.4764,  2.2741,  2.1759,  2.0564,  1.8170,  1.7557,  1.5844,\n",
      "         1.5802,  1.5065,  1.3632,  1.2959,  1.2134,  1.2003,  1.1144,  1.1526,\n",
      "         1.1193,  1.1407,  1.2138,  1.3470,  1.6239,  2.3603, 19.4503],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2942, 6.2693, 6.2676, 6.2858, 6.2672, 6.2509, 6.2316, 6.1856, 6.1540,\n",
      "        6.0677, 5.9857, 5.7773, 5.5077, 5.0805, 4.6312, 4.1689, 3.7020, 3.2288,\n",
      "        2.7927, 2.3819, 2.0095, 1.7050, 1.4329, 1.2166, 1.0400, 0.8988, 0.7895,\n",
      "        0.7019, 0.6403, 0.5969, 0.5674, 0.5481, 0.5374, 0.5296, 0.5275, 0.5289,\n",
      "        0.5301, 0.5340, 0.5373, 0.5400, 0.5418, 0.5427, 0.5403, 0.5351, 0.5289,\n",
      "        0.5213, 0.5129, 0.5026, 0.4878, 0.4694, 0.4453, 0.4198, 0.3976, 0.3773,\n",
      "        0.3533], grad_fn=<AddBackward0>) tensor([7.9967, 8.0027, 8.0024, 7.9517, 8.0023, 7.9727, 7.9558, 7.9854, 7.9137,\n",
      "        7.7903, 7.5979, 7.4843, 7.1488, 6.7007, 6.1357, 5.5979, 5.0386, 4.5380,\n",
      "        3.9678, 3.4737, 3.0185, 2.5869, 2.2820, 1.9979, 1.7352, 1.5238, 1.3653,\n",
      "        1.2422, 1.1540, 1.0665, 1.0130, 0.9922, 0.9637, 0.9682, 0.9601, 0.9645,\n",
      "        0.9800, 0.9756, 0.9882, 0.9848, 1.0145, 1.0050, 1.0149, 1.0041, 1.0019,\n",
      "        0.9913, 0.9847, 0.9774, 0.9636, 0.9439, 0.9255, 0.9114, 0.9462, 1.1068,\n",
      "        7.6255], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4693, 3.4564, 3.4369, 3.4571, 3.4640, 3.4235, 3.4249, 3.4326, 3.4244,\n",
      "        3.4098, 3.3920, 3.3828, 3.3711, 3.3533, 3.3261, 3.2903, 3.2411, 3.1583,\n",
      "        3.0974, 2.9974, 2.8689, 2.7467, 2.5864, 2.4398, 2.2640, 2.1043, 1.9312,\n",
      "        1.7629, 1.6102, 1.4587, 1.3191, 1.1901, 1.0719, 0.9678, 0.8754, 0.7904,\n",
      "        0.7167, 0.6524, 0.5917, 0.5409, 0.4917, 0.4511, 0.4183, 0.3861, 0.3594,\n",
      "        0.3348, 0.3154, 0.2957, 0.2798, 0.2641, 0.2495, 0.2338, 0.2173, 0.1988,\n",
      "        0.1860], grad_fn=<AddBackward0>) tensor([ 5.5343,  5.5932,  5.6574,  5.5207,  5.4182,  5.5847,  5.5899,  5.5076,\n",
      "         5.5284,  5.4814,  5.5090,  5.4428,  5.3774,  5.4778,  5.4142,  5.3494,\n",
      "         5.2874,  5.3530,  5.1270,  5.0448,  4.9445,  4.7200,  4.6834,  4.3512,\n",
      "         4.2343,  3.9542,  3.7441,  3.5602,  3.3223,  3.1314,  2.9590,  2.7963,\n",
      "         2.6855,  2.4663,  2.2670,  2.1688,  2.0524,  1.8073,  1.7379,  1.5660,\n",
      "         1.5741,  1.5005,  1.3532,  1.2807,  1.2108,  1.1920,  1.1023,  1.1455,\n",
      "         1.1098,  1.1372,  1.2040,  1.3432,  1.6273,  2.3494, 19.4961],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.2930, 6.2675, 6.2640, 6.2843, 6.2654, 6.2484, 6.2287, 6.1861, 6.1512,\n",
      "        6.0661, 5.9826, 5.7750, 5.5051, 5.0783, 4.6298, 4.1671, 3.7000, 3.2283,\n",
      "        2.7933, 2.3820, 2.0099, 1.7052, 1.4329, 1.2165, 1.0393, 0.8976, 0.7878,\n",
      "        0.6999, 0.6382, 0.5946, 0.5651, 0.5459, 0.5353, 0.5275, 0.5256, 0.5272,\n",
      "        0.5288, 0.5331, 0.5366, 0.5396, 0.5418, 0.5429, 0.5408, 0.5358, 0.5297,\n",
      "        0.5221, 0.5138, 0.5034, 0.4884, 0.4695, 0.4447, 0.4184, 0.3956, 0.3746,\n",
      "        0.3501], grad_fn=<AddBackward0>) tensor([7.9782, 7.9849, 7.9892, 7.9343, 7.9852, 7.9572, 7.9430, 7.9595, 7.8979,\n",
      "        7.7726, 7.5861, 7.4689, 7.1307, 6.6820, 6.1141, 5.5843, 5.0293, 4.5273,\n",
      "        3.9540, 3.4673, 3.0161, 2.5835, 2.2800, 1.9955, 1.7324, 1.5208, 1.3630,\n",
      "        1.2379, 1.1468, 1.0616, 1.0083, 0.9885, 0.9583, 0.9646, 0.9573, 0.9629,\n",
      "        0.9768, 0.9703, 0.9862, 0.9853, 1.0148, 1.0057, 1.0148, 1.0047, 1.0063,\n",
      "        0.9939, 0.9887, 0.9792, 0.9666, 0.9470, 0.9291, 0.9141, 0.9511, 1.1224,\n",
      "        7.7539], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4880, 3.4751, 3.4565, 3.4750, 3.4843, 3.4440, 3.4436, 3.4498, 3.4450,\n",
      "        3.4278, 3.4095, 3.4019, 3.3923, 3.3736, 3.3451, 3.3101, 3.2612, 3.1781,\n",
      "        3.1172, 3.0173, 2.8865, 2.7657, 2.6037, 2.4566, 2.2805, 2.1184, 1.9448,\n",
      "        1.7748, 1.6212, 1.4680, 1.3274, 1.1972, 1.0780, 0.9735, 0.8798, 0.7942,\n",
      "        0.7197, 0.6548, 0.5935, 0.5422, 0.4924, 0.4515, 0.4183, 0.3858, 0.3588,\n",
      "        0.3340, 0.3144, 0.2944, 0.2784, 0.2627, 0.2479, 0.2321, 0.2155, 0.1969,\n",
      "        0.1841], grad_fn=<AddBackward0>) tensor([ 5.5441,  5.6003,  5.6671,  5.5401,  5.4237,  5.5848,  5.6001,  5.5295,\n",
      "         5.5324,  5.5000,  5.5327,  5.4554,  5.3800,  5.4886,  5.4375,  5.3711,\n",
      "         5.3071,  5.3772,  5.1487,  5.0651,  4.9733,  4.7385,  4.7039,  4.3671,\n",
      "         4.2402,  3.9723,  3.7523,  3.5708,  3.3305,  3.1462,  2.9719,  2.8117,\n",
      "         2.6970,  2.4690,  2.2734,  2.1758,  2.0612,  1.8141,  1.7427,  1.5682,\n",
      "         1.5799,  1.4989,  1.3513,  1.2798,  1.2129,  1.1895,  1.0994,  1.1442,\n",
      "         1.1104,  1.1341,  1.2046,  1.3452,  1.6382,  2.3739, 19.7844],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.3114, 6.2867, 6.2813, 6.3037, 6.2845, 6.2655, 6.2473, 6.2042, 6.1691,\n",
      "        6.0836, 6.0003, 5.7933, 5.5205, 5.0914, 4.6419, 4.1794, 3.7119, 3.2389,\n",
      "        2.8026, 2.3899, 2.0169, 1.7115, 1.4382, 1.2204, 1.0423, 0.8993, 0.7888,\n",
      "        0.7004, 0.6381, 0.5943, 0.5645, 0.5452, 0.5348, 0.5271, 0.5253, 0.5271,\n",
      "        0.5291, 0.5336, 0.5373, 0.5406, 0.5433, 0.5447, 0.5429, 0.5379, 0.5319,\n",
      "        0.5243, 0.5159, 0.5054, 0.4900, 0.4704, 0.4448, 0.4177, 0.3942, 0.3725,\n",
      "        0.3473], grad_fn=<AddBackward0>) tensor([7.9890, 7.9925, 7.9991, 7.9409, 7.9910, 7.9696, 7.9475, 7.9681, 7.9054,\n",
      "        7.7820, 7.5938, 7.4675, 7.1388, 6.6914, 6.1223, 5.5858, 5.0279, 4.5289,\n",
      "        3.9606, 3.4760, 3.0227, 2.5908, 2.2829, 1.9985, 1.7335, 1.5258, 1.3637,\n",
      "        1.2355, 1.1440, 1.0598, 1.0063, 0.9877, 0.9566, 0.9637, 0.9556, 0.9637,\n",
      "        0.9767, 0.9688, 0.9897, 0.9893, 1.0172, 1.0075, 1.0170, 1.0089, 1.0102,\n",
      "        0.9992, 0.9916, 0.9815, 0.9700, 0.9504, 0.9317, 0.9202, 0.9548, 1.1363,\n",
      "        7.9309], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4905, 3.4833, 3.4636, 3.4790, 3.4904, 3.4482, 3.4507, 3.4547, 3.4502,\n",
      "        3.4324, 3.4159, 3.4066, 3.3994, 3.3795, 3.3521, 3.3178, 3.2678, 3.1838,\n",
      "        3.1246, 3.0254, 2.8946, 2.7732, 2.6118, 2.4634, 2.2850, 2.1247, 1.9496,\n",
      "        1.7792, 1.6244, 1.4719, 1.3300, 1.1990, 1.0795, 0.9746, 0.8802, 0.7946,\n",
      "        0.7198, 0.6545, 0.5930, 0.5412, 0.4914, 0.4501, 0.4168, 0.3841, 0.3570,\n",
      "        0.3320, 0.3126, 0.2925, 0.2764, 0.2606, 0.2458, 0.2300, 0.2134, 0.1951,\n",
      "        0.1819], grad_fn=<AddBackward0>) tensor([ 5.5460,  5.5719,  5.6444,  5.5339,  5.4070,  5.5819,  5.5780,  5.5232,\n",
      "         5.5237,  5.4885,  5.5201,  5.4499,  5.3649,  5.4797,  5.4287,  5.3628,\n",
      "         5.3049,  5.3817,  5.1411,  5.0609,  4.9618,  4.7314,  4.6858,  4.3600,\n",
      "         4.2463,  3.9573,  3.7440,  3.5629,  3.3265,  3.1326,  2.9650,  2.8125,\n",
      "         2.6907,  2.4619,  2.2760,  2.1682,  2.0552,  1.8109,  1.7340,  1.5649,\n",
      "         1.5719,  1.4969,  1.3457,  1.2758,  1.2094,  1.1925,  1.0880,  1.1361,\n",
      "         1.1043,  1.1291,  1.2078,  1.3494,  1.6567,  2.4003, 20.1598],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.2917, 6.2661, 6.2611, 6.2844, 6.2661, 6.2462, 6.2279, 6.1845, 6.1494,\n",
      "        6.0661, 5.9806, 5.7748, 5.5023, 5.0725, 4.6282, 4.1661, 3.6993, 3.2296,\n",
      "        2.7957, 2.3844, 2.0125, 1.7081, 1.4349, 1.2173, 1.0395, 0.8963, 0.7857,\n",
      "        0.6975, 0.6349, 0.5913, 0.5615, 0.5424, 0.5321, 0.5245, 0.5231, 0.5251,\n",
      "        0.5275, 0.5322, 0.5365, 0.5402, 0.5433, 0.5450, 0.5434, 0.5388, 0.5329,\n",
      "        0.5255, 0.5171, 0.5066, 0.4909, 0.4708, 0.4444, 0.4165, 0.3923, 0.3701,\n",
      "        0.3442], grad_fn=<AddBackward0>) tensor([7.9457, 7.9541, 7.9613, 7.9007, 7.9466, 7.9306, 7.9053, 7.9292, 7.8671,\n",
      "        7.7373, 7.5576, 7.4283, 7.1053, 6.6643, 6.0809, 5.5561, 5.0084, 4.5072,\n",
      "        3.9386, 3.4579, 3.0087, 2.5788, 2.2774, 1.9959, 1.7293, 1.5232, 1.3600,\n",
      "        1.2285, 1.1409, 1.0502, 1.0014, 0.9824, 0.9499, 0.9585, 0.9515, 0.9615,\n",
      "        0.9732, 0.9671, 0.9882, 0.9902, 1.0160, 1.0097, 1.0212, 1.0103, 1.0114,\n",
      "        1.0017, 0.9939, 0.9868, 0.9723, 0.9560, 0.9371, 0.9258, 0.9599, 1.1532,\n",
      "        8.1018], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5174, 3.5118, 3.4925, 3.5061, 3.5193, 3.4778, 3.4813, 3.4832, 3.4796,\n",
      "        3.4617, 3.4440, 3.4374, 3.4287, 3.4110, 3.3840, 3.3482, 3.2983, 3.2131,\n",
      "        3.1551, 3.0536, 2.9220, 2.7989, 2.6381, 2.4868, 2.3074, 2.1453, 1.9684,\n",
      "        1.7960, 1.6380, 1.4850, 1.3416, 1.2090, 1.0885, 0.9821, 0.8867, 0.8000,\n",
      "        0.7242, 0.6579, 0.5959, 0.5435, 0.4931, 0.4512, 0.4174, 0.3843, 0.3569,\n",
      "        0.3315, 0.3119, 0.2916, 0.2753, 0.2593, 0.2444, 0.2283, 0.2116, 0.1929,\n",
      "        0.1798], grad_fn=<AddBackward0>) tensor([ 5.5846,  5.5993,  5.6715,  5.5735,  5.4358,  5.6036,  5.5951,  5.5520,\n",
      "         5.5522,  5.5172,  5.5560,  5.4701,  5.3955,  5.5029,  5.4478,  5.3939,\n",
      "         5.3338,  5.4148,  5.1646,  5.0955,  4.9916,  4.7645,  4.7051,  4.3876,\n",
      "         4.2649,  3.9752,  3.7603,  3.5788,  3.3561,  3.1530,  2.9778,  2.8256,\n",
      "         2.6996,  2.4707,  2.2831,  2.1750,  2.0619,  1.8235,  1.7369,  1.5700,\n",
      "         1.5692,  1.4985,  1.3497,  1.2764,  1.2099,  1.1981,  1.0922,  1.1328,\n",
      "         1.1027,  1.1297,  1.2069,  1.3551,  1.6610,  2.4296, 20.2364],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.3500, 6.3243, 6.3205, 6.3406, 6.3228, 6.3011, 6.2837, 6.2420, 6.2044,\n",
      "        6.1217, 6.0361, 5.8265, 5.5498, 5.1168, 4.6681, 4.2037, 3.7323, 3.2593,\n",
      "        2.8213, 2.4085, 2.0323, 1.7247, 1.4488, 1.2287, 1.0489, 0.9037, 0.7915,\n",
      "        0.7021, 0.6388, 0.5945, 0.5644, 0.5451, 0.5347, 0.5273, 0.5259, 0.5283,\n",
      "        0.5308, 0.5359, 0.5406, 0.5446, 0.5482, 0.5502, 0.5489, 0.5443, 0.5385,\n",
      "        0.5309, 0.5224, 0.5116, 0.4953, 0.4744, 0.4469, 0.4177, 0.3926, 0.3695,\n",
      "        0.3426], grad_fn=<AddBackward0>) tensor([7.9914, 8.0007, 8.0031, 7.9526, 7.9981, 7.9842, 7.9563, 7.9751, 7.9220,\n",
      "        7.7814, 7.6001, 7.4728, 7.1537, 6.7048, 6.1180, 5.5871, 5.0426, 4.5381,\n",
      "        3.9689, 3.4747, 3.0300, 2.5927, 2.2927, 2.0089, 1.7404, 1.5326, 1.3683,\n",
      "        1.2342, 1.1430, 1.0569, 1.0062, 0.9861, 0.9537, 0.9620, 0.9571, 0.9650,\n",
      "        0.9793, 0.9751, 0.9954, 0.9999, 1.0265, 1.0228, 1.0293, 1.0211, 1.0197,\n",
      "        1.0123, 1.0076, 0.9971, 0.9830, 0.9683, 0.9450, 0.9372, 0.9727, 1.1700,\n",
      "        8.3186], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.4754, 3.4731, 3.4533, 3.4659, 3.4807, 3.4377, 3.4419, 3.4418, 3.4376,\n",
      "        3.4215, 3.4060, 3.4001, 3.3908, 3.3740, 3.3480, 3.3117, 3.2628, 3.1788,\n",
      "        3.1217, 3.0223, 2.8923, 2.7710, 2.6106, 2.4621, 2.2848, 2.1240, 1.9466,\n",
      "        1.7787, 1.6200, 1.4695, 1.3268, 1.1966, 1.0767, 0.9708, 0.8765, 0.7903,\n",
      "        0.7151, 0.6493, 0.5880, 0.5359, 0.4861, 0.4444, 0.4110, 0.3781, 0.3508,\n",
      "        0.3259, 0.3063, 0.2863, 0.2701, 0.2543, 0.2395, 0.2235, 0.2071, 0.1885,\n",
      "        0.1757], grad_fn=<AddBackward0>) tensor([ 5.5215,  5.5172,  5.5926,  5.4995,  5.3564,  5.5317,  5.5211,  5.4899,\n",
      "         5.4946,  5.4504,  5.4799,  5.3913,  5.3255,  5.4322,  5.3781,  5.3295,\n",
      "         5.2690,  5.3496,  5.1064,  5.0335,  4.9317,  4.7022,  4.6528,  4.3301,\n",
      "         4.2060,  3.9211,  3.7316,  3.5239,  3.3273,  3.1132,  2.9496,  2.7764,\n",
      "         2.6614,  2.4435,  2.2510,  2.1483,  2.0369,  1.8046,  1.7139,  1.5500,\n",
      "         1.5445,  1.4802,  1.3280,  1.2599,  1.1985,  1.1781,  1.0781,  1.1179,\n",
      "         1.0957,  1.1177,  1.1941,  1.3514,  1.6430,  2.4327, 20.2243],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.3848, 6.3608, 6.3569, 6.3778, 6.3600, 6.3376, 6.3210, 6.2781, 6.2396,\n",
      "        6.1557, 6.0702, 5.8607, 5.5815, 5.1460, 4.6936, 4.2278, 3.7548, 3.2794,\n",
      "        2.8400, 2.4248, 2.0460, 1.7369, 1.4585, 1.2369, 1.0557, 0.9091, 0.7956,\n",
      "        0.7054, 0.6412, 0.5964, 0.5661, 0.5468, 0.5365, 0.5292, 0.5280, 0.5307,\n",
      "        0.5335, 0.5389, 0.5440, 0.5484, 0.5523, 0.5546, 0.5537, 0.5492, 0.5434,\n",
      "        0.5357, 0.5271, 0.5161, 0.4992, 0.4774, 0.4488, 0.4184, 0.3923, 0.3684,\n",
      "        0.3405], grad_fn=<AddBackward0>) tensor([8.0271, 8.0310, 8.0333, 7.9806, 8.0293, 8.0133, 7.9828, 8.0028, 7.9551,\n",
      "        7.8154, 7.6308, 7.4992, 7.1765, 6.7278, 6.1429, 5.6050, 5.0578, 4.5575,\n",
      "        3.9804, 3.4891, 3.0474, 2.6053, 2.3095, 2.0241, 1.7510, 1.5376, 1.3726,\n",
      "        1.2373, 1.1452, 1.0607, 1.0074, 0.9886, 0.9585, 0.9648, 0.9607, 0.9672,\n",
      "        0.9821, 0.9787, 1.0003, 1.0060, 1.0342, 1.0336, 1.0349, 1.0291, 1.0255,\n",
      "        1.0234, 1.0170, 1.0067, 0.9909, 0.9776, 0.9554, 0.9479, 0.9847, 1.1916,\n",
      "        8.5169], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5049, 3.5004, 3.4834, 3.4926, 3.5100, 3.4690, 3.4706, 3.4692, 3.4698,\n",
      "        3.4523, 3.4349, 3.4284, 3.4193, 3.4047, 3.3782, 3.3417, 3.2930, 3.2096,\n",
      "        3.1522, 3.0526, 2.9214, 2.7957, 2.6364, 2.4845, 2.3066, 2.1439, 1.9646,\n",
      "        1.7960, 1.6351, 1.4834, 1.3387, 1.2070, 1.0856, 0.9790, 0.8837, 0.7962,\n",
      "        0.7200, 0.6536, 0.5916, 0.5387, 0.4881, 0.4461, 0.4122, 0.3788, 0.3513,\n",
      "        0.3260, 0.3062, 0.2859, 0.2695, 0.2536, 0.2385, 0.2225, 0.2059, 0.1872,\n",
      "        0.1742], grad_fn=<AddBackward0>) tensor([ 5.5425,  5.5491,  5.6113,  5.5364,  5.3795,  5.5399,  5.5467,  5.5235,\n",
      "         5.4998,  5.4676,  5.5063,  5.4208,  5.3563,  5.4526,  5.4051,  5.3599,\n",
      "         5.2942,  5.3716,  5.1238,  5.0504,  4.9521,  4.7406,  4.6753,  4.3629,\n",
      "         4.2303,  3.9471,  3.7620,  3.5386,  3.3435,  3.1246,  2.9685,  2.7968,\n",
      "         2.6822,  2.4498,  2.2590,  2.1679,  2.0523,  1.8145,  1.7208,  1.5573,\n",
      "         1.5579,  1.4848,  1.3277,  1.2598,  1.1982,  1.1776,  1.0796,  1.1163,\n",
      "         1.0979,  1.1224,  1.2082,  1.3638,  1.6580,  2.4629, 20.5322],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.3465, 6.3197, 6.3179, 6.3369, 6.3201, 6.2985, 6.2818, 6.2369, 6.2000,\n",
      "        6.1173, 6.0291, 5.8235, 5.5467, 5.1119, 4.6646, 4.2001, 3.7299, 3.2589,\n",
      "        2.8229, 2.4114, 2.0345, 1.7278, 1.4503, 1.2296, 1.0490, 0.9031, 0.7900,\n",
      "        0.7000, 0.6360, 0.5913, 0.5612, 0.5420, 0.5318, 0.5248, 0.5239, 0.5268,\n",
      "        0.5299, 0.5356, 0.5411, 0.5458, 0.5501, 0.5528, 0.5522, 0.5479, 0.5420,\n",
      "        0.5345, 0.5259, 0.5148, 0.4977, 0.4753, 0.4459, 0.4148, 0.3880, 0.3634,\n",
      "        0.3351], grad_fn=<AddBackward0>) tensor([7.9607, 7.9713, 7.9686, 7.9227, 7.9644, 7.9470, 7.9187, 7.9470, 7.8946,\n",
      "        7.7541, 7.5792, 7.4398, 7.1164, 6.6742, 6.0868, 5.5609, 5.0214, 4.5222,\n",
      "        3.9501, 3.4603, 3.0255, 2.5834, 2.2925, 2.0155, 1.7390, 1.5257, 1.3632,\n",
      "        1.2244, 1.1326, 1.0486, 0.9976, 0.9793, 0.9529, 0.9578, 0.9547, 0.9600,\n",
      "        0.9754, 0.9740, 0.9927, 1.0029, 1.0347, 1.0296, 1.0303, 1.0265, 1.0272,\n",
      "        1.0242, 1.0188, 1.0063, 0.9857, 0.9745, 0.9549, 0.9451, 0.9855, 1.2008,\n",
      "        8.5232], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5060, 3.4981, 3.4834, 3.4918, 3.5092, 3.4700, 3.4730, 3.4684, 3.4719,\n",
      "        3.4538, 3.4371, 3.4300, 3.4225, 3.4070, 3.3785, 3.3452, 3.2959, 3.2127,\n",
      "        3.1548, 3.0576, 2.9237, 2.8002, 2.6397, 2.4874, 2.3099, 2.1456, 1.9664,\n",
      "        1.7963, 1.6355, 1.4841, 1.3397, 1.2067, 1.0852, 0.9782, 0.8827, 0.7951,\n",
      "        0.7186, 0.6519, 0.5901, 0.5368, 0.4864, 0.4439, 0.4101, 0.3766, 0.3489,\n",
      "        0.3237, 0.3037, 0.2835, 0.2671, 0.2511, 0.2360, 0.2201, 0.2034, 0.1847,\n",
      "        0.1715], grad_fn=<AddBackward0>) tensor([ 5.5223,  5.5470,  5.5974,  5.5255,  5.3705,  5.5196,  5.5244,  5.5139,\n",
      "         5.4777,  5.4476,  5.4875,  5.4076,  5.3338,  5.4363,  5.4026,  5.3434,\n",
      "         5.2824,  5.3555,  5.1144,  5.0254,  4.9442,  4.7170,  4.6600,  4.3465,\n",
      "         4.2087,  3.9353,  3.7479,  3.5340,  3.3355,  3.1059,  2.9415,  2.7805,\n",
      "         2.6669,  2.4427,  2.2462,  2.1573,  2.0495,  1.8163,  1.7113,  1.5541,\n",
      "         1.5459,  1.4873,  1.3203,  1.2531,  1.1923,  1.1671,  1.0750,  1.1115,\n",
      "         1.0949,  1.1247,  1.2172,  1.3575,  1.6662,  2.4806, 20.6775],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.3862, 6.3584, 6.3561, 6.3759, 6.3588, 6.3392, 6.3206, 6.2761, 6.2360,\n",
      "        6.1549, 6.0672, 5.8615, 5.5816, 5.1425, 4.6935, 4.2260, 3.7522, 3.2808,\n",
      "        2.8423, 2.4288, 2.0493, 1.7401, 1.4605, 1.2379, 1.0552, 0.9080, 0.7936,\n",
      "        0.7025, 0.6378, 0.5926, 0.5622, 0.5429, 0.5324, 0.5256, 0.5247, 0.5279,\n",
      "        0.5312, 0.5371, 0.5429, 0.5479, 0.5525, 0.5555, 0.5551, 0.5509, 0.5450,\n",
      "        0.5373, 0.5286, 0.5172, 0.4995, 0.4763, 0.4457, 0.4134, 0.3857, 0.3602,\n",
      "        0.3311], grad_fn=<AddBackward0>) tensor([7.9914, 8.0087, 8.0043, 7.9557, 8.0016, 7.9764, 7.9543, 7.9805, 7.9341,\n",
      "        7.7874, 7.6071, 7.4646, 7.1401, 6.6998, 6.1079, 5.5836, 5.0458, 4.5378,\n",
      "        3.9666, 3.4736, 3.0377, 2.5978, 2.3022, 2.0244, 1.7531, 1.5310, 1.3656,\n",
      "        1.2262, 1.1337, 1.0479, 0.9951, 0.9789, 0.9551, 0.9563, 0.9572, 0.9593,\n",
      "        0.9755, 0.9761, 0.9952, 1.0075, 1.0397, 1.0351, 1.0353, 1.0309, 1.0339,\n",
      "        1.0320, 1.0240, 1.0092, 0.9886, 0.9775, 0.9592, 0.9474, 0.9937, 1.2072,\n",
      "        8.5825], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5055, 3.4985, 3.4831, 3.4900, 3.5074, 3.4692, 3.4719, 3.4672, 3.4729,\n",
      "        3.4545, 3.4372, 3.4291, 3.4233, 3.4093, 3.3803, 3.3475, 3.2985, 3.2137,\n",
      "        3.1573, 3.0597, 2.9241, 2.8030, 2.6428, 2.4902, 2.3121, 2.1470, 1.9690,\n",
      "        1.7979, 1.6365, 1.4852, 1.3403, 1.2070, 1.0851, 0.9779, 0.8815, 0.7944,\n",
      "        0.7172, 0.6506, 0.5887, 0.5351, 0.4842, 0.4418, 0.4078, 0.3742, 0.3464,\n",
      "        0.3212, 0.3012, 0.2810, 0.2644, 0.2485, 0.2335, 0.2176, 0.2010, 0.1826,\n",
      "        0.1691], grad_fn=<AddBackward0>) tensor([ 5.5017,  5.5213,  5.5778,  5.5133,  5.3595,  5.5060,  5.5111,  5.5038,\n",
      "         5.4542,  5.4248,  5.4713,  5.3979,  5.3168,  5.4164,  5.3882,  5.3274,\n",
      "         5.2694,  5.3531,  5.1083,  5.0197,  4.9504,  4.7093,  4.6524,  4.3379,\n",
      "         4.2025,  3.9346,  3.7323,  3.5237,  3.3287,  3.0954,  2.9311,  2.7740,\n",
      "         2.6630,  2.4367,  2.2565,  2.1453,  2.0491,  1.8073,  1.6957,  1.5424,\n",
      "         1.5470,  1.4793,  1.3080,  1.2442,  1.1853,  1.1581,  1.0663,  1.1043,\n",
      "         1.0964,  1.1263,  1.2208,  1.3570,  1.6830,  2.4979, 20.9834],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.3742, 6.3475, 6.3451, 6.3663, 6.3461, 6.3280, 6.3118, 6.2666, 6.2273,\n",
      "        6.1424, 6.0561, 5.8519, 5.5721, 5.1299, 4.6836, 4.2180, 3.7466, 3.2757,\n",
      "        2.8390, 2.4264, 2.0477, 1.7389, 1.4593, 1.2362, 1.0537, 0.9059, 0.7913,\n",
      "        0.7001, 0.6351, 0.5899, 0.5594, 0.5404, 0.5300, 0.5233, 0.5225, 0.5261,\n",
      "        0.5298, 0.5360, 0.5421, 0.5475, 0.5526, 0.5559, 0.5559, 0.5517, 0.5458,\n",
      "        0.5384, 0.5296, 0.5179, 0.5000, 0.4760, 0.4444, 0.4112, 0.3826, 0.3563,\n",
      "        0.3267], grad_fn=<AddBackward0>) tensor([7.9634, 7.9792, 7.9729, 7.9249, 7.9784, 7.9509, 7.9167, 7.9457, 7.8965,\n",
      "        7.7630, 7.5803, 7.4371, 7.1103, 6.6835, 6.0894, 5.5635, 5.0214, 4.5224,\n",
      "        3.9514, 3.4616, 3.0262, 2.5864, 2.2888, 2.0199, 1.7421, 1.5273, 1.3601,\n",
      "        1.2195, 1.1299, 1.0420, 0.9900, 0.9725, 0.9490, 0.9532, 0.9561, 0.9554,\n",
      "        0.9709, 0.9732, 0.9948, 1.0062, 1.0366, 1.0375, 1.0363, 1.0328, 1.0367,\n",
      "        1.0327, 1.0269, 1.0143, 0.9903, 0.9773, 0.9582, 0.9463, 0.9977, 1.2133,\n",
      "        8.6220], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5213, 3.5156, 3.4986, 3.5071, 3.5234, 3.4853, 3.4891, 3.4844, 3.4904,\n",
      "        3.4719, 3.4538, 3.4431, 3.4408, 3.4268, 3.3990, 3.3648, 3.3164, 3.2322,\n",
      "        3.1755, 3.0789, 2.9414, 2.8199, 2.6591, 2.5038, 2.3276, 2.1599, 1.9798,\n",
      "        1.8085, 1.6464, 1.4934, 1.3475, 1.2130, 1.0901, 0.9823, 0.8852, 0.7972,\n",
      "        0.7193, 0.6525, 0.5898, 0.5359, 0.4844, 0.4418, 0.4075, 0.3736, 0.3456,\n",
      "        0.3202, 0.3000, 0.2797, 0.2629, 0.2470, 0.2318, 0.2159, 0.1991, 0.1806,\n",
      "        0.1671], grad_fn=<AddBackward0>) tensor([ 5.5112,  5.5243,  5.5927,  5.5218,  5.3704,  5.5164,  5.5160,  5.5112,\n",
      "         5.4626,  5.4298,  5.4839,  5.4274,  5.3261,  5.4295,  5.3990,  5.3479,\n",
      "         5.2860,  5.3631,  5.1248,  5.0256,  4.9619,  4.7222,  4.6647,  4.3604,\n",
      "         4.1992,  3.9404,  3.7464,  3.5279,  3.3286,  3.0985,  2.9314,  2.7782,\n",
      "         2.6663,  2.4380,  2.2551,  2.1486,  2.0584,  1.8042,  1.7027,  1.5432,\n",
      "         1.5514,  1.4770,  1.3083,  1.2439,  1.1819,  1.1559,  1.0641,  1.1014,\n",
      "         1.0991,  1.1300,  1.2188,  1.3593,  1.6913,  2.5071, 21.1950],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.3971, 6.3693, 6.3669, 6.3890, 6.3686, 6.3515, 6.3351, 6.2893, 6.2483,\n",
      "        6.1643, 6.0777, 5.8740, 5.5942, 5.1466, 4.6992, 4.2333, 3.7597, 3.2873,\n",
      "        2.8504, 2.4366, 2.0572, 1.7468, 1.4653, 1.2409, 1.0574, 0.9085, 0.7930,\n",
      "        0.7009, 0.6353, 0.5899, 0.5592, 0.5402, 0.5299, 0.5232, 0.5227, 0.5266,\n",
      "        0.5304, 0.5370, 0.5436, 0.5494, 0.5549, 0.5586, 0.5589, 0.5549, 0.5490,\n",
      "        0.5416, 0.5328, 0.5208, 0.5023, 0.4776, 0.4449, 0.4104, 0.3809, 0.3538,\n",
      "        0.3233], grad_fn=<AddBackward0>) tensor([7.9769, 7.9942, 7.9879, 7.9418, 7.9931, 7.9626, 7.9289, 7.9597, 7.9130,\n",
      "        7.7756, 7.5902, 7.4470, 7.1099, 6.6962, 6.1003, 5.5681, 5.0328, 4.5348,\n",
      "        3.9617, 3.4700, 3.0268, 2.5898, 2.2947, 2.0290, 1.7456, 1.5259, 1.3550,\n",
      "        1.2212, 1.1311, 1.0402, 0.9885, 0.9715, 0.9443, 0.9529, 0.9559, 0.9549,\n",
      "        0.9713, 0.9739, 0.9959, 1.0083, 1.0399, 1.0427, 1.0399, 1.0397, 1.0451,\n",
      "        1.0406, 1.0306, 1.0215, 1.0001, 0.9849, 0.9601, 0.9513, 1.0032, 1.2290,\n",
      "        8.7544], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5149, 3.5097, 3.4900, 3.5030, 3.5149, 3.4776, 3.4840, 3.4772, 3.4845,\n",
      "        3.4679, 3.4475, 3.4368, 3.4345, 3.4229, 3.3945, 3.3615, 3.3132, 3.2311,\n",
      "        3.1728, 3.0769, 2.9393, 2.8189, 2.6588, 2.5021, 2.3264, 2.1589, 1.9796,\n",
      "        1.8072, 1.6452, 1.4915, 1.3464, 1.2120, 1.0884, 0.9809, 0.8834, 0.7957,\n",
      "        0.7173, 0.6504, 0.5875, 0.5336, 0.4821, 0.4393, 0.4049, 0.3710, 0.3429,\n",
      "        0.3175, 0.2973, 0.2769, 0.2602, 0.2443, 0.2292, 0.2131, 0.1964, 0.1782,\n",
      "        0.1644], grad_fn=<AddBackward0>) tensor([ 5.4846,  5.4964,  5.5796,  5.4838,  5.3565,  5.4997,  5.4868,  5.4909,\n",
      "         5.4370,  5.3959,  5.4637,  5.4132,  5.3124,  5.4018,  5.3827,  5.3284,\n",
      "         5.2671,  5.3345,  5.1108,  5.0099,  4.9514,  4.7020,  4.6425,  4.3494,\n",
      "         4.1869,  3.9284,  3.7251,  3.5154,  3.3203,  3.1005,  2.9205,  2.7636,\n",
      "         2.6592,  2.4257,  2.2453,  2.1317,  2.0511,  1.8001,  1.6994,  1.5340,\n",
      "         1.5430,  1.4657,  1.3001,  1.2358,  1.1784,  1.1499,  1.0561,  1.0985,\n",
      "         1.0946,  1.1230,  1.2082,  1.3619,  1.6974,  2.4964, 21.4307],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.3837, 6.3565, 6.3526, 6.3746, 6.3537, 6.3390, 6.3204, 6.2761, 6.2338,\n",
      "        6.1488, 6.0625, 5.8641, 5.5807, 5.1335, 4.6900, 4.2243, 3.7500, 3.2797,\n",
      "        2.8452, 2.4321, 2.0542, 1.7443, 1.4623, 1.2381, 1.0548, 0.9057, 0.7899,\n",
      "        0.6974, 0.6319, 0.5865, 0.5557, 0.5368, 0.5266, 0.5200, 0.5197, 0.5238,\n",
      "        0.5279, 0.5348, 0.5416, 0.5477, 0.5536, 0.5576, 0.5582, 0.5543, 0.5484,\n",
      "        0.5411, 0.5323, 0.5201, 0.5011, 0.4758, 0.4421, 0.4068, 0.3767, 0.3490,\n",
      "        0.3180], grad_fn=<AddBackward0>) tensor([7.9449, 7.9606, 7.9595, 7.9130, 7.9664, 7.9316, 7.9031, 7.9312, 7.8895,\n",
      "        7.7526, 7.5682, 7.4099, 7.0856, 6.6699, 6.0684, 5.5401, 5.0180, 4.5198,\n",
      "        3.9461, 3.4586, 3.0103, 2.5757, 2.2898, 2.0242, 1.7385, 1.5163, 1.3472,\n",
      "        1.2145, 1.1245, 1.0336, 0.9810, 0.9670, 0.9368, 0.9455, 0.9484, 0.9478,\n",
      "        0.9641, 0.9680, 0.9943, 1.0054, 1.0396, 1.0368, 1.0386, 1.0370, 1.0445,\n",
      "        1.0399, 1.0269, 1.0199, 0.9992, 0.9803, 0.9593, 0.9512, 0.9984, 1.2235,\n",
      "        8.7838], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5156, 3.5089, 3.4934, 3.5040, 3.5172, 3.4805, 3.4855, 3.4793, 3.4867,\n",
      "        3.4690, 3.4495, 3.4387, 3.4361, 3.4260, 3.3997, 3.3686, 3.3174, 3.2352,\n",
      "        3.1777, 3.0808, 2.9438, 2.8236, 2.6624, 2.5058, 2.3300, 2.1626, 1.9832,\n",
      "        1.8091, 1.6471, 1.4931, 1.3474, 1.2132, 1.0891, 0.9815, 0.8832, 0.7952,\n",
      "        0.7165, 0.6494, 0.5864, 0.5321, 0.4803, 0.4373, 0.4030, 0.3688, 0.3408,\n",
      "        0.3152, 0.2948, 0.2745, 0.2577, 0.2417, 0.2266, 0.2106, 0.1939, 0.1757,\n",
      "        0.1618], grad_fn=<AddBackward0>) tensor([ 5.4713,  5.4957,  5.5551,  5.4744,  5.3363,  5.4792,  5.4732,  5.4746,\n",
      "         5.4224,  5.3899,  5.4524,  5.4008,  5.3051,  5.3888,  5.3600,  5.2994,\n",
      "         5.2547,  5.3263,  5.0999,  5.0080,  4.9446,  4.6952,  4.6387,  4.3469,\n",
      "         4.1849,  3.9211,  3.7141,  3.5175,  3.3200,  3.1029,  2.9227,  2.7555,\n",
      "         2.6515,  2.4152,  2.2444,  2.1277,  2.0461,  1.7960,  1.6851,  1.5286,\n",
      "         1.5407,  1.4662,  1.2889,  1.2355,  1.1636,  1.1474,  1.0540,  1.0900,\n",
      "         1.0904,  1.1187,  1.2041,  1.3609,  1.7084,  2.4969, 21.5909],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.3919, 6.3667, 6.3617, 6.3889, 6.3648, 6.3494, 6.3302, 6.2846, 6.2470,\n",
      "        6.1571, 6.0729, 5.8748, 5.5905, 5.1418, 4.6979, 4.2333, 3.7570, 3.2871,\n",
      "        2.8528, 2.4382, 2.0604, 1.7494, 1.4666, 1.2416, 1.0575, 0.9076, 0.7909,\n",
      "        0.6980, 0.6319, 0.5862, 0.5554, 0.5365, 0.5263, 0.5199, 0.5198, 0.5242,\n",
      "        0.5285, 0.5359, 0.5429, 0.5496, 0.5558, 0.5603, 0.5612, 0.5574, 0.5515,\n",
      "        0.5443, 0.5353, 0.5229, 0.5032, 0.4771, 0.4422, 0.4057, 0.3745, 0.3460,\n",
      "        0.3143], grad_fn=<AddBackward0>) tensor([7.9503, 7.9586, 7.9608, 7.8979, 7.9637, 7.9324, 7.9014, 7.9337, 7.8738,\n",
      "        7.7553, 7.5663, 7.4009, 7.0784, 6.6622, 6.0592, 5.5285, 5.0147, 4.5185,\n",
      "        3.9431, 3.4628, 3.0093, 2.5823, 2.2973, 2.0303, 1.7424, 1.5153, 1.3436,\n",
      "        1.2124, 1.1224, 1.0335, 0.9798, 0.9657, 0.9358, 0.9449, 0.9480, 0.9454,\n",
      "        0.9650, 0.9679, 0.9993, 1.0106, 1.0441, 1.0394, 1.0416, 1.0433, 1.0541,\n",
      "        1.0446, 1.0353, 1.0268, 1.0062, 0.9868, 0.9658, 0.9572, 1.0067, 1.2313,\n",
      "        8.8411], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5402, 3.5319, 3.5181, 3.5294, 3.5430, 3.5055, 3.5099, 3.5032, 3.5139,\n",
      "        3.4962, 3.4763, 3.4634, 3.4607, 3.4523, 3.4276, 3.3948, 3.3439, 3.2631,\n",
      "        3.2041, 3.1078, 2.9667, 2.8472, 2.6857, 2.5261, 2.3501, 2.1810, 1.9986,\n",
      "        1.8249, 1.6618, 1.5062, 1.3578, 1.2230, 1.0977, 0.9888, 0.8893, 0.8006,\n",
      "        0.7213, 0.6535, 0.5897, 0.5345, 0.4824, 0.4390, 0.4043, 0.3696, 0.3413,\n",
      "        0.3154, 0.2949, 0.2744, 0.2575, 0.2413, 0.2261, 0.2099, 0.1932, 0.1750,\n",
      "        0.1608], grad_fn=<AddBackward0>) tensor([ 5.4886,  5.5223,  5.5728,  5.4911,  5.3501,  5.4953,  5.4961,  5.4953,\n",
      "         5.4302,  5.4010,  5.4627,  5.4251,  5.3318,  5.4076,  5.3704,  5.3251,\n",
      "         5.2757,  5.3406,  5.1189,  5.0239,  4.9784,  4.7143,  4.6565,  4.3730,\n",
      "         4.2037,  3.9365,  3.7436,  3.5228,  3.3188,  3.1038,  2.9400,  2.7620,\n",
      "         2.6587,  2.4268,  2.2600,  2.1440,  2.0528,  1.8028,  1.6895,  1.5391,\n",
      "         1.5455,  1.4656,  1.2955,  1.2408,  1.1673,  1.1532,  1.0632,  1.0971,\n",
      "         1.0947,  1.1274,  1.2092,  1.3802,  1.7225,  2.5427, 22.0789],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.3949, 6.3696, 6.3658, 6.3914, 6.3682, 6.3533, 6.3339, 6.2856, 6.2525,\n",
      "        6.1614, 6.0745, 5.8771, 5.5931, 5.1435, 4.7005, 4.2358, 3.7600, 3.2913,\n",
      "        2.8572, 2.4426, 2.0646, 1.7533, 1.4696, 1.2444, 1.0594, 0.9085, 0.7914,\n",
      "        0.6980, 0.6316, 0.5856, 0.5547, 0.5359, 0.5257, 0.5195, 0.5196, 0.5243,\n",
      "        0.5288, 0.5366, 0.5440, 0.5510, 0.5577, 0.5624, 0.5637, 0.5599, 0.5540,\n",
      "        0.5467, 0.5376, 0.5248, 0.5046, 0.4775, 0.4414, 0.4037, 0.3716, 0.3423,\n",
      "        0.3099], grad_fn=<AddBackward0>) tensor([7.9428, 7.9532, 7.9527, 7.8943, 7.9568, 7.9246, 7.8949, 7.9333, 7.8599,\n",
      "        7.7455, 7.5617, 7.3965, 7.0705, 6.6556, 6.0524, 5.5245, 5.0118, 4.5132,\n",
      "        3.9415, 3.4613, 3.0084, 2.5849, 2.3024, 2.0293, 1.7417, 1.5178, 1.3404,\n",
      "        1.2105, 1.1224, 1.0304, 0.9776, 0.9631, 0.9362, 0.9451, 0.9461, 0.9457,\n",
      "        0.9675, 0.9694, 1.0002, 1.0124, 1.0489, 1.0417, 1.0440, 1.0481, 1.0573,\n",
      "        1.0496, 1.0411, 1.0297, 1.0098, 0.9901, 0.9681, 0.9582, 1.0121, 1.2415,\n",
      "        8.8885], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5238, 3.5179, 3.5019, 3.5124, 3.5264, 3.4913, 3.4943, 3.4880, 3.4973,\n",
      "        3.4796, 3.4623, 3.4497, 3.4467, 3.4387, 3.4143, 3.3822, 3.3338, 3.2522,\n",
      "        3.1922, 3.0970, 2.9570, 2.8388, 2.6785, 2.5192, 2.3429, 2.1740, 1.9923,\n",
      "        1.8196, 1.6560, 1.5017, 1.3538, 1.2193, 1.0943, 0.9853, 0.8857, 0.7974,\n",
      "        0.7185, 0.6505, 0.5866, 0.5316, 0.4793, 0.4360, 0.4012, 0.3666, 0.3384,\n",
      "        0.3125, 0.2919, 0.2715, 0.2545, 0.2384, 0.2233, 0.2071, 0.1903, 0.1720,\n",
      "        0.1581], grad_fn=<AddBackward0>) tensor([ 5.4516,  5.4688,  5.5354,  5.4559,  5.3129,  5.4453,  5.4543,  5.4545,\n",
      "         5.3950,  5.3698,  5.4174,  5.3817,  5.2906,  5.3658,  5.3324,  5.2870,\n",
      "         5.2274,  5.3022,  5.0901,  5.0002,  4.9470,  4.6817,  4.6178,  4.3413,\n",
      "         4.1799,  3.9189,  3.7273,  3.5008,  3.3118,  3.0836,  2.9235,  2.7465,\n",
      "         2.6396,  2.4148,  2.2529,  2.1302,  2.0316,  1.7888,  1.6817,  1.5292,\n",
      "         1.5389,  1.4578,  1.2872,  1.2289,  1.1594,  1.1441,  1.0562,  1.0909,\n",
      "         1.0905,  1.1236,  1.2053,  1.3732,  1.7343,  2.5730, 22.0759],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4116, 6.3881, 6.3815, 6.4094, 6.3862, 6.3683, 6.3518, 6.3016, 6.2702,\n",
      "        6.1802, 6.0915, 5.8916, 5.6101, 5.1558, 4.7121, 4.2475, 3.7721, 3.3030,\n",
      "        2.8684, 2.4527, 2.0733, 1.7613, 1.4763, 1.2502, 1.0639, 0.9118, 0.7939,\n",
      "        0.6997, 0.6329, 0.5866, 0.5555, 0.5368, 0.5267, 0.5207, 0.5210, 0.5260,\n",
      "        0.5310, 0.5390, 0.5471, 0.5545, 0.5618, 0.5670, 0.5686, 0.5649, 0.5590,\n",
      "        0.5518, 0.5426, 0.5295, 0.5085, 0.4804, 0.4428, 0.4038, 0.3705, 0.3401,\n",
      "        0.3071], grad_fn=<AddBackward0>) tensor([7.9537, 7.9564, 7.9654, 7.9005, 7.9601, 7.9386, 7.9013, 7.9474, 7.8644,\n",
      "        7.7458, 7.5691, 7.4078, 7.0712, 6.6644, 6.0583, 5.5281, 5.0145, 4.5131,\n",
      "        3.9429, 3.4641, 3.0155, 2.5921, 2.3104, 2.0295, 1.7425, 1.5216, 1.3439,\n",
      "        1.2132, 1.1200, 1.0338, 0.9804, 0.9642, 0.9383, 0.9469, 0.9489, 0.9487,\n",
      "        0.9672, 0.9747, 1.0064, 1.0191, 1.0553, 1.0468, 1.0534, 1.0578, 1.0676,\n",
      "        1.0592, 1.0496, 1.0378, 1.0201, 1.0016, 0.9817, 0.9677, 1.0287, 1.2613,\n",
      "        8.9433], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5354, 3.5293, 3.5136, 3.5220, 3.5381, 3.5027, 3.5067, 3.4981, 3.5096,\n",
      "        3.4908, 3.4751, 3.4632, 3.4586, 3.4519, 3.4272, 3.3950, 3.3478, 3.2660,\n",
      "        3.2083, 3.1105, 2.9716, 2.8513, 2.6919, 2.5325, 2.3548, 2.1861, 2.0025,\n",
      "        1.8285, 1.6645, 1.5089, 1.3608, 1.2247, 1.0997, 0.9893, 0.8895, 0.8004,\n",
      "        0.7211, 0.6524, 0.5881, 0.5325, 0.4798, 0.4363, 0.4012, 0.3663, 0.3377,\n",
      "        0.3117, 0.2910, 0.2704, 0.2533, 0.2371, 0.2218, 0.2056, 0.1886, 0.1703,\n",
      "        0.1565], grad_fn=<AddBackward0>) tensor([ 5.4485,  5.4692,  5.5377,  5.4690,  5.3147,  5.4465,  5.4540,  5.4650,\n",
      "         5.3970,  5.3770,  5.4152,  5.3818,  5.2981,  5.3685,  5.3401,  5.2978,\n",
      "         5.2362,  5.3110,  5.0860,  5.0119,  4.9475,  4.6976,  4.6249,  4.3386,\n",
      "         4.1838,  3.9149,  3.7281,  3.5066,  3.3166,  3.0943,  2.9215,  2.7565,\n",
      "         2.6379,  2.4260,  2.2552,  2.1338,  2.0348,  1.7935,  1.6826,  1.5342,\n",
      "         1.5436,  1.4558,  1.2839,  1.2312,  1.1613,  1.1434,  1.0553,  1.0944,\n",
      "         1.0904,  1.1237,  1.2113,  1.3778,  1.7460,  2.6009, 22.2870],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.3987, 6.3764, 6.3696, 6.3982, 6.3763, 6.3570, 6.3416, 6.2942, 6.2604,\n",
      "        6.1710, 6.0812, 5.8824, 5.6000, 5.1457, 4.7036, 4.2399, 3.7665, 3.2991,\n",
      "        2.8653, 2.4505, 2.0718, 1.7598, 1.4750, 1.2489, 1.0622, 0.9099, 0.7916,\n",
      "        0.6972, 0.6303, 0.5838, 0.5528, 0.5341, 0.5241, 0.5183, 0.5188, 0.5240,\n",
      "        0.5294, 0.5377, 0.5463, 0.5541, 0.5617, 0.5674, 0.5691, 0.5656, 0.5599,\n",
      "        0.5526, 0.5433, 0.5301, 0.5085, 0.4797, 0.4409, 0.4008, 0.3668, 0.3359,\n",
      "        0.3021], grad_fn=<AddBackward0>) tensor([7.9408, 7.9399, 7.9476, 7.8791, 7.9352, 7.9213, 7.8780, 7.9153, 7.8413,\n",
      "        7.7198, 7.5468, 7.3850, 7.0502, 6.6436, 6.0387, 5.5102, 4.9986, 4.5001,\n",
      "        3.9318, 3.4547, 3.0073, 2.5868, 2.3087, 2.0240, 1.7397, 1.5146, 1.3391,\n",
      "        1.2085, 1.1140, 1.0284, 0.9732, 0.9587, 0.9338, 0.9430, 0.9451, 0.9461,\n",
      "        0.9644, 0.9741, 1.0034, 1.0200, 1.0543, 1.0451, 1.0538, 1.0579, 1.0685,\n",
      "        1.0614, 1.0546, 1.0381, 1.0218, 1.0042, 0.9845, 0.9721, 1.0298, 1.2652,\n",
      "        9.0149], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5513, 3.5421, 3.5295, 3.5373, 3.5530, 3.5199, 3.5226, 3.5146, 3.5265,\n",
      "        3.5062, 3.4920, 3.4807, 3.4772, 3.4700, 3.4446, 3.4109, 3.3660, 3.2847,\n",
      "        3.2252, 3.1275, 2.9870, 2.8691, 2.7069, 2.5481, 2.3683, 2.1999, 2.0142,\n",
      "        1.8394, 1.6746, 1.5173, 1.3692, 1.2311, 1.1055, 0.9945, 0.8935, 0.8036,\n",
      "        0.7239, 0.6545, 0.5897, 0.5336, 0.4804, 0.4367, 0.4010, 0.3658, 0.3371,\n",
      "        0.3109, 0.2899, 0.2691, 0.2520, 0.2357, 0.2202, 0.2038, 0.1868, 0.1683,\n",
      "        0.1545], grad_fn=<AddBackward0>) tensor([ 5.4501,  5.4889,  5.5404,  5.4770,  5.3230,  5.4438,  5.4599,  5.4681,\n",
      "         5.4030,  5.3889,  5.4210,  5.3810,  5.2963,  5.3730,  5.3524,  5.3195,\n",
      "         5.2460,  5.3204,  5.1072,  5.0315,  4.9733,  4.7050,  4.6488,  4.3468,\n",
      "         4.2019,  3.9214,  3.7446,  3.5194,  3.3209,  3.1063,  2.9210,  2.7696,\n",
      "         2.6420,  2.4300,  2.2646,  2.1460,  2.0417,  1.8038,  1.6860,  1.5371,\n",
      "         1.5444,  1.4520,  1.2851,  1.2331,  1.1571,  1.1400,  1.0536,  1.0977,\n",
      "         1.0873,  1.1243,  1.2160,  1.3868,  1.7558,  2.6116, 22.4235],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.4183, 6.3917, 6.3866, 6.4169, 6.3952, 6.3735, 6.3586, 6.3127, 6.2794,\n",
      "        6.1885, 6.0984, 5.9021, 5.6146, 5.1583, 4.7148, 4.2507, 3.7781, 3.3094,\n",
      "        2.8748, 2.4582, 2.0783, 1.7651, 1.4798, 1.2524, 1.0646, 0.9111, 0.7920,\n",
      "        0.6969, 0.6295, 0.5825, 0.5515, 0.5327, 0.5226, 0.5168, 0.5175, 0.5229,\n",
      "        0.5284, 0.5369, 0.5458, 0.5539, 0.5618, 0.5678, 0.5697, 0.5661, 0.5605,\n",
      "        0.5531, 0.5435, 0.5300, 0.5077, 0.4781, 0.4381, 0.3969, 0.3620, 0.3303,\n",
      "        0.2963], grad_fn=<AddBackward0>) tensor([7.9431, 7.9572, 7.9590, 7.8877, 7.9415, 7.9341, 7.8903, 7.9197, 7.8441,\n",
      "        7.7264, 7.5533, 7.3835, 7.0612, 6.6486, 6.0445, 5.5132, 4.9976, 4.4994,\n",
      "        3.9336, 3.4606, 3.0152, 2.5949, 2.3112, 2.0253, 1.7391, 1.5123, 1.3379,\n",
      "        1.2056, 1.1090, 1.0254, 0.9648, 0.9537, 0.9325, 0.9386, 0.9413, 0.9448,\n",
      "        0.9611, 0.9741, 1.0026, 1.0207, 1.0567, 1.0442, 1.0556, 1.0594, 1.0706,\n",
      "        1.0621, 1.0584, 1.0386, 1.0236, 1.0009, 0.9822, 0.9703, 1.0266, 1.2575,\n",
      "        8.9135], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5499, 3.5427, 3.5305, 3.5374, 3.5549, 3.5215, 3.5250, 3.5139, 3.5269,\n",
      "        3.5088, 3.4934, 3.4818, 3.4773, 3.4730, 3.4488, 3.4142, 3.3674, 3.2890,\n",
      "        3.2286, 3.1325, 2.9920, 2.8737, 2.7122, 2.5521, 2.3747, 2.2035, 2.0179,\n",
      "        1.8429, 1.6764, 1.5188, 1.3708, 1.2324, 1.1068, 0.9954, 0.8936, 0.8037,\n",
      "        0.7237, 0.6541, 0.5890, 0.5327, 0.4793, 0.4351, 0.3993, 0.3640, 0.3353,\n",
      "        0.3090, 0.2879, 0.2671, 0.2500, 0.2335, 0.2182, 0.2017, 0.1847, 0.1662,\n",
      "        0.1524], grad_fn=<AddBackward0>) tensor([ 5.4441,  5.4720,  5.5231,  5.4668,  5.3046,  5.4236,  5.4393,  5.4616,\n",
      "         5.3896,  5.3683,  5.4084,  5.3741,  5.2935,  5.3596,  5.3348,  5.3093,\n",
      "         5.2485,  5.3062,  5.1029,  5.0206,  4.9582,  4.6962,  4.6334,  4.3410,\n",
      "         4.1749,  3.9128,  3.7345,  3.5040,  3.3262,  3.1111,  2.9221,  2.7677,\n",
      "         2.6367,  2.4219,  2.2732,  2.1455,  2.0399,  1.8005,  1.6840,  1.5256,\n",
      "         1.5357,  1.4555,  1.2816,  1.2315,  1.1501,  1.1333,  1.0467,  1.0931,\n",
      "         1.0865,  1.1316,  1.2179,  1.3942,  1.7645,  2.6511, 22.6169],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4333, 6.4091, 6.4032, 6.4310, 6.4111, 6.3875, 6.3739, 6.3265, 6.2939,\n",
      "        6.2027, 6.1128, 5.9133, 5.6274, 5.1716, 4.7239, 4.2600, 3.7894, 3.3199,\n",
      "        2.8853, 2.4672, 2.0861, 1.7720, 1.4854, 1.2573, 1.0681, 0.9135, 0.7935,\n",
      "        0.6978, 0.6300, 0.5826, 0.5515, 0.5326, 0.5224, 0.5169, 0.5178, 0.5234,\n",
      "        0.5292, 0.5379, 0.5473, 0.5558, 0.5639, 0.5703, 0.5726, 0.5691, 0.5633,\n",
      "        0.5558, 0.5461, 0.5322, 0.5092, 0.4785, 0.4373, 0.3949, 0.3590, 0.3265,\n",
      "        0.2919], grad_fn=<AddBackward0>) tensor([7.9523, 7.9569, 7.9641, 7.8981, 7.9461, 7.9435, 7.8954, 7.9304, 7.8526,\n",
      "        7.7335, 7.5590, 7.3950, 7.0656, 6.6430, 6.0529, 5.5182, 4.9941, 4.4994,\n",
      "        3.9329, 3.4667, 3.0213, 2.6018, 2.3187, 2.0276, 1.7443, 1.5131, 1.3412,\n",
      "        1.2042, 1.1048, 1.0260, 0.9633, 0.9528, 0.9326, 0.9387, 0.9414, 0.9433,\n",
      "        0.9611, 0.9786, 1.0039, 1.0241, 1.0618, 1.0518, 1.0584, 1.0606, 1.0743,\n",
      "        1.0666, 1.0645, 1.0452, 1.0306, 1.0079, 0.9875, 0.9742, 1.0321, 1.2691,\n",
      "        8.9423], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5451, 3.5384, 3.5263, 3.5332, 3.5510, 3.5150, 3.5209, 3.5107, 3.5237,\n",
      "        3.5053, 3.4902, 3.4791, 3.4748, 3.4690, 3.4458, 3.4132, 3.3667, 3.2860,\n",
      "        3.2270, 3.1328, 2.9911, 2.8741, 2.7123, 2.5516, 2.3741, 2.2026, 2.0178,\n",
      "        1.8424, 1.6755, 1.5182, 1.3698, 1.2316, 1.1053, 0.9941, 0.8916, 0.8020,\n",
      "        0.7219, 0.6519, 0.5868, 0.5304, 0.4767, 0.4326, 0.3965, 0.3613, 0.3325,\n",
      "        0.3061, 0.2850, 0.2642, 0.2470, 0.2306, 0.2152, 0.1987, 0.1817, 0.1631,\n",
      "        0.1496], grad_fn=<AddBackward0>) tensor([ 5.4232,  5.4462,  5.4960,  5.4417,  5.2735,  5.4115,  5.4115,  5.4313,\n",
      "         5.3619,  5.3446,  5.3823,  5.3458,  5.2684,  5.3470,  5.3186,  5.2853,\n",
      "         5.2223,  5.2975,  5.0877,  4.9978,  4.9450,  4.6761,  4.6151,  4.3324,\n",
      "         4.1647,  3.9069,  3.7164,  3.4927,  3.3164,  3.1013,  2.9151,  2.7548,\n",
      "         2.6342,  2.4159,  2.2763,  2.1368,  2.0320,  1.7945,  1.6706,  1.5106,\n",
      "         1.5283,  1.4404,  1.2727,  1.2189,  1.1375,  1.1248,  1.0428,  1.0863,\n",
      "         1.0805,  1.1246,  1.2138,  1.3879,  1.7668,  2.6260, 22.5114],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4194, 6.3933, 6.3878, 6.4167, 6.3946, 6.3742, 6.3586, 6.3106, 6.2788,\n",
      "        6.1848, 6.0988, 5.8961, 5.6153, 5.1568, 4.7128, 4.2499, 3.7811, 3.3135,\n",
      "        2.8795, 2.4632, 2.0836, 1.7691, 1.4836, 1.2557, 1.0662, 0.9110, 0.7909,\n",
      "        0.6948, 0.6272, 0.5797, 0.5485, 0.5297, 0.5196, 0.5143, 0.5153, 0.5211,\n",
      "        0.5272, 0.5362, 0.5458, 0.5547, 0.5631, 0.5697, 0.5722, 0.5689, 0.5629,\n",
      "        0.5554, 0.5455, 0.5313, 0.5078, 0.4762, 0.4340, 0.3907, 0.3541, 0.3210,\n",
      "        0.2860], grad_fn=<AddBackward0>) tensor([7.9160, 7.9269, 7.9317, 7.8609, 7.9217, 7.9034, 7.8635, 7.9012, 7.8220,\n",
      "        7.7134, 7.5251, 7.3702, 7.0286, 6.6171, 6.0200, 5.4939, 4.9714, 4.4813,\n",
      "        3.9228, 3.4572, 3.0088, 2.6011, 2.3097, 2.0173, 1.7353, 1.5114, 1.3362,\n",
      "        1.2030, 1.0965, 1.0201, 0.9586, 0.9478, 0.9272, 0.9333, 0.9361, 0.9364,\n",
      "        0.9546, 0.9727, 1.0010, 1.0209, 1.0598, 1.0522, 1.0589, 1.0575, 1.0741,\n",
      "        1.0662, 1.0654, 1.0485, 1.0327, 1.0108, 0.9866, 0.9686, 1.0313, 1.2727,\n",
      "        8.9202], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5540, 3.5467, 3.5346, 3.5403, 3.5594, 3.5234, 3.5311, 3.5210, 3.5328,\n",
      "        3.5158, 3.4975, 3.4895, 3.4843, 3.4804, 3.4567, 3.4257, 3.3760, 3.2977,\n",
      "        3.2407, 3.1453, 3.0043, 2.8854, 2.7241, 2.5626, 2.3845, 2.2104, 2.0273,\n",
      "        1.8503, 1.6827, 1.5246, 1.3754, 1.2367, 1.1095, 0.9973, 0.8946, 0.8042,\n",
      "        0.7238, 0.6532, 0.5877, 0.5307, 0.4767, 0.4322, 0.3959, 0.3604, 0.3314,\n",
      "        0.3048, 0.2836, 0.2627, 0.2454, 0.2289, 0.2134, 0.1969, 0.1798, 0.1612,\n",
      "        0.1476], grad_fn=<AddBackward0>) tensor([ 5.4168,  5.4467,  5.4935,  5.4485,  5.2762,  5.4128,  5.4032,  5.4236,\n",
      "         5.3631,  5.3399,  5.3948,  5.3446,  5.2717,  5.3450,  5.3223,  5.2813,\n",
      "         5.2407,  5.3020,  5.0830,  4.9991,  4.9399,  4.6844,  4.6166,  4.3373,\n",
      "         4.1669,  3.9290,  3.7180,  3.4975,  3.3202,  3.1060,  2.9236,  2.7558,\n",
      "         2.6421,  2.4273,  2.2771,  2.1423,  2.0253,  1.7930,  1.6654,  1.5097,\n",
      "         1.5285,  1.4340,  1.2691,  1.2150,  1.1339,  1.1253,  1.0377,  1.0822,\n",
      "         1.0782,  1.1218,  1.2186,  1.3948,  1.7663,  2.6422, 22.7139],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4305, 6.4057, 6.4007, 6.4285, 6.4087, 6.3857, 6.3706, 6.3241, 6.2910,\n",
      "        6.1991, 6.1109, 5.9085, 5.6255, 5.1654, 4.7211, 4.2579, 3.7889, 3.3222,\n",
      "        2.8867, 2.4708, 2.0910, 1.7748, 1.4881, 1.2595, 1.0687, 0.9127, 0.7918,\n",
      "        0.6952, 0.6269, 0.5791, 0.5479, 0.5289, 0.5190, 0.5138, 0.5149, 0.5209,\n",
      "        0.5273, 0.5366, 0.5465, 0.5558, 0.5645, 0.5716, 0.5742, 0.5712, 0.5651,\n",
      "        0.5575, 0.5475, 0.5329, 0.5086, 0.4760, 0.4326, 0.3882, 0.3506, 0.3170,\n",
      "        0.2814], grad_fn=<AddBackward0>) tensor([7.9232, 7.9327, 7.9346, 7.8680, 7.9237, 7.9130, 7.8661, 7.8996, 7.8262,\n",
      "        7.7083, 7.5290, 7.3677, 7.0298, 6.6194, 6.0221, 5.4948, 4.9730, 4.4790,\n",
      "        3.9278, 3.4610, 3.0061, 2.6047, 2.3128, 2.0208, 1.7369, 1.5132, 1.3336,\n",
      "        1.2013, 1.0976, 1.0191, 0.9554, 0.9476, 0.9245, 0.9288, 0.9356, 0.9345,\n",
      "        0.9524, 0.9705, 1.0010, 1.0225, 1.0654, 1.0576, 1.0640, 1.0616, 1.0794,\n",
      "        1.0713, 1.0690, 1.0506, 1.0365, 1.0152, 0.9917, 0.9733, 1.0385, 1.2785,\n",
      "        8.9604], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5636, 3.5580, 3.5447, 3.5495, 3.5691, 3.5341, 3.5403, 3.5336, 3.5444,\n",
      "        3.5278, 3.5086, 3.5020, 3.4966, 3.4923, 3.4710, 3.4371, 3.3879, 3.3149,\n",
      "        3.2551, 3.1587, 3.0186, 2.8983, 2.7380, 2.5742, 2.3942, 2.2212, 2.0373,\n",
      "        1.8588, 1.6899, 1.5316, 1.3811, 1.2420, 1.1144, 1.0011, 0.8979, 0.8071,\n",
      "        0.7260, 0.6545, 0.5888, 0.5314, 0.4769, 0.4321, 0.3954, 0.3597, 0.3305,\n",
      "        0.3037, 0.2823, 0.2613, 0.2440, 0.2274, 0.2117, 0.1953, 0.1781, 0.1595,\n",
      "        0.1459], grad_fn=<AddBackward0>) tensor([ 5.4215,  5.4413,  5.4968,  5.4566,  5.2826,  5.4122,  5.4132,  5.4158,\n",
      "         5.3636,  5.3383,  5.4001,  5.3411,  5.2721,  5.3495,  5.3173,  5.2932,\n",
      "         5.2536,  5.2893,  5.0821,  5.0060,  4.9391,  4.6921,  4.6108,  4.3457,\n",
      "         4.1838,  3.9327,  3.7175,  3.5036,  3.3353,  3.1135,  2.9370,  2.7633,\n",
      "         2.6435,  2.4381,  2.2826,  2.1381,  2.0271,  1.8060,  1.6675,  1.5075,\n",
      "         1.5290,  1.4314,  1.2657,  1.2104,  1.1257,  1.1184,  1.0443,  1.0811,\n",
      "         1.0768,  1.1245,  1.2235,  1.3966,  1.7915,  2.6699, 22.9700],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.4551, 6.4316, 6.4255, 6.4543, 6.4335, 6.4118, 6.3942, 6.3501, 6.3129,\n",
      "        6.2226, 6.1344, 5.9317, 5.6455, 5.1859, 4.7390, 4.2741, 3.8025, 3.3367,\n",
      "        2.9000, 2.4833, 2.1018, 1.7838, 1.4955, 1.2651, 1.0729, 0.9159, 0.7940,\n",
      "        0.6962, 0.6274, 0.5793, 0.5479, 0.5287, 0.5189, 0.5137, 0.5151, 0.5212,\n",
      "        0.5279, 0.5375, 0.5478, 0.5574, 0.5664, 0.5739, 0.5767, 0.5737, 0.5675,\n",
      "        0.5597, 0.5495, 0.5345, 0.5094, 0.4757, 0.4309, 0.3853, 0.3469, 0.3126,\n",
      "        0.2765], grad_fn=<AddBackward0>) tensor([7.9428, 7.9487, 7.9556, 7.8876, 7.9423, 7.9280, 7.8920, 7.9151, 7.8522,\n",
      "        7.7300, 7.5482, 7.3852, 7.0535, 6.6285, 6.0320, 5.5062, 4.9909, 4.4869,\n",
      "        3.9385, 3.4669, 3.0112, 2.6096, 2.3186, 2.0290, 1.7450, 1.5143, 1.3333,\n",
      "        1.2047, 1.0989, 1.0178, 0.9536, 0.9469, 0.9224, 0.9290, 0.9354, 0.9336,\n",
      "        0.9514, 0.9703, 1.0022, 1.0243, 1.0675, 1.0582, 1.0683, 1.0667, 1.0833,\n",
      "        1.0739, 1.0702, 1.0512, 1.0394, 1.0174, 0.9954, 0.9707, 1.0389, 1.2837,\n",
      "        8.9740], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5644, 3.5608, 3.5471, 3.5501, 3.5715, 3.5358, 3.5410, 3.5380, 3.5473,\n",
      "        3.5302, 3.5101, 3.5057, 3.4997, 3.4955, 3.4748, 3.4406, 3.3926, 3.3219,\n",
      "        3.2611, 3.1654, 3.0250, 2.9031, 2.7421, 2.5782, 2.3991, 2.2249, 2.0399,\n",
      "        1.8623, 1.6921, 1.5336, 1.3820, 1.2431, 1.1145, 1.0009, 0.8974, 0.8065,\n",
      "        0.7251, 0.6534, 0.5872, 0.5297, 0.4751, 0.4301, 0.3933, 0.3575, 0.3283,\n",
      "        0.3014, 0.2799, 0.2589, 0.2416, 0.2250, 0.2092, 0.1927, 0.1756, 0.1571,\n",
      "        0.1435], grad_fn=<AddBackward0>) tensor([ 5.4153,  5.4266,  5.4830,  5.4557,  5.2746,  5.4044,  5.4103,  5.3946,\n",
      "         5.3515,  5.3315,  5.3962,  5.3339,  5.2649,  5.3467,  5.3140,  5.2927,\n",
      "         5.2496,  5.2749,  5.0712,  4.9916,  4.9276,  4.6910,  4.6103,  4.3425,\n",
      "         4.1720,  3.9265,  3.7130,  3.4889,  3.3262,  3.1012,  2.9314,  2.7476,\n",
      "         2.6384,  2.4321,  2.2789,  2.1289,  2.0152,  1.7962,  1.6663,  1.4996,\n",
      "         1.5201,  1.4261,  1.2620,  1.2078,  1.1223,  1.1172,  1.0401,  1.0755,\n",
      "         1.0647,  1.1148,  1.2203,  1.4019,  1.7890,  2.6781, 23.1263],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4434, 6.4195, 6.4138, 6.4399, 6.4205, 6.3992, 6.3818, 6.3378, 6.3011,\n",
      "        6.2093, 6.1228, 5.9203, 5.6333, 5.1759, 4.7295, 4.2649, 3.7953, 3.3320,\n",
      "        2.8964, 2.4804, 2.1006, 1.7825, 1.4939, 1.2636, 1.0712, 0.9138, 0.7915,\n",
      "        0.6935, 0.6245, 0.5766, 0.5451, 0.5259, 0.5162, 0.5112, 0.5126, 0.5189,\n",
      "        0.5258, 0.5358, 0.5464, 0.5562, 0.5657, 0.5735, 0.5764, 0.5734, 0.5672,\n",
      "        0.5594, 0.5490, 0.5337, 0.5078, 0.4733, 0.4274, 0.3809, 0.3419, 0.3071,\n",
      "        0.2706], grad_fn=<AddBackward0>) tensor([7.9113, 7.9215, 7.9233, 7.8658, 7.9175, 7.8992, 7.8617, 7.8835, 7.8226,\n",
      "        7.7025, 7.5195, 7.3583, 7.0271, 6.5965, 6.0060, 5.4861, 4.9710, 4.4675,\n",
      "        3.9215, 3.4567, 2.9970, 2.5980, 2.3137, 2.0243, 1.7414, 1.5107, 1.3299,\n",
      "        1.1995, 1.0955, 1.0128, 0.9481, 0.9420, 0.9164, 0.9217, 0.9301, 0.9318,\n",
      "        0.9515, 0.9673, 0.9986, 1.0244, 1.0663, 1.0554, 1.0665, 1.0679, 1.0818,\n",
      "        1.0735, 1.0685, 1.0487, 1.0397, 1.0152, 0.9934, 0.9666, 1.0360, 1.2771,\n",
      "        8.9485], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5694, 3.5651, 3.5529, 3.5560, 3.5762, 3.5424, 3.5465, 3.5447, 3.5535,\n",
      "        3.5364, 3.5162, 3.5118, 3.5087, 3.5035, 3.4818, 3.4473, 3.4013, 3.3306,\n",
      "        3.2710, 3.1745, 3.0334, 2.9132, 2.7497, 2.5838, 2.4067, 2.2319, 2.0460,\n",
      "        1.8674, 1.6964, 1.5382, 1.3848, 1.2458, 1.1171, 1.0029, 0.8989, 0.8073,\n",
      "        0.7257, 0.6532, 0.5870, 0.5292, 0.4741, 0.4290, 0.3919, 0.3560, 0.3266,\n",
      "        0.2996, 0.2780, 0.2570, 0.2397, 0.2229, 0.2072, 0.1906, 0.1736, 0.1552,\n",
      "        0.1414], grad_fn=<AddBackward0>) tensor([ 5.4123,  5.4268,  5.4724,  5.4450,  5.2700,  5.3929,  5.4033,  5.3825,\n",
      "         5.3422,  5.3220,  5.3915,  5.3327,  5.2492,  5.3371,  5.3136,  5.3000,\n",
      "         5.2488,  5.2708,  5.0629,  4.9885,  4.9286,  4.6821,  4.6144,  4.3599,\n",
      "         4.1709,  3.9212,  3.7133,  3.4928,  3.3326,  3.0963,  2.9439,  2.7505,\n",
      "         2.6349,  2.4301,  2.2780,  2.1333,  2.0125,  1.8032,  1.6584,  1.4959,\n",
      "         1.5225,  1.4189,  1.2573,  1.2057,  1.1200,  1.1130,  1.0350,  1.0738,\n",
      "         1.0585,  1.1148,  1.2154,  1.4051,  1.7929,  2.6831, 23.4028],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4589, 6.4345, 6.4282, 6.4564, 6.4339, 6.4152, 6.3951, 6.3529, 6.3152,\n",
      "        6.2247, 6.1368, 5.9330, 5.6459, 5.1887, 4.7412, 4.2759, 3.8047, 3.3426,\n",
      "        2.9054, 2.4890, 2.1092, 1.7896, 1.4997, 1.2684, 1.0747, 0.9164, 0.7933,\n",
      "        0.6943, 0.6248, 0.5766, 0.5450, 0.5257, 0.5161, 0.5112, 0.5129, 0.5192,\n",
      "        0.5265, 0.5368, 0.5478, 0.5581, 0.5679, 0.5760, 0.5792, 0.5763, 0.5700,\n",
      "        0.5619, 0.5514, 0.5357, 0.5091, 0.4733, 0.4261, 0.3784, 0.3384, 0.3031,\n",
      "        0.2661], grad_fn=<AddBackward0>) tensor([7.9124, 7.9243, 7.9299, 7.8671, 7.9285, 7.9024, 7.8706, 7.8871, 7.8286,\n",
      "        7.7028, 7.5220, 7.3633, 7.0317, 6.5933, 6.0044, 5.4840, 4.9735, 4.4670,\n",
      "        3.9274, 3.4622, 2.9984, 2.6043, 2.3208, 2.0288, 1.7446, 1.5059, 1.3278,\n",
      "        1.1995, 1.0976, 1.0127, 0.9464, 0.9406, 0.9154, 0.9197, 0.9284, 0.9324,\n",
      "        0.9533, 0.9677, 0.9990, 1.0273, 1.0704, 1.0598, 1.0722, 1.0721, 1.0871,\n",
      "        1.0803, 1.0747, 1.0518, 1.0463, 1.0220, 0.9956, 0.9673, 1.0390, 1.2717,\n",
      "        8.9944], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5782, 3.5714, 3.5618, 3.5646, 3.5827, 3.5503, 3.5545, 3.5546, 3.5625,\n",
      "        3.5445, 3.5259, 3.5218, 3.5187, 3.5132, 3.4913, 3.4590, 3.4125, 3.3408,\n",
      "        3.2818, 3.1855, 3.0437, 2.9241, 2.7609, 2.5934, 2.4163, 2.2392, 2.0526,\n",
      "        1.8740, 1.7034, 1.5427, 1.3891, 1.2491, 1.1201, 1.0055, 0.9006, 0.8087,\n",
      "        0.7264, 0.6536, 0.5873, 0.5290, 0.4736, 0.4282, 0.3909, 0.3548, 0.3253,\n",
      "        0.2982, 0.2765, 0.2554, 0.2380, 0.2212, 0.2053, 0.1888, 0.1717, 0.1533,\n",
      "        0.1394], grad_fn=<AddBackward0>) tensor([ 5.4030,  5.4332,  5.4606,  5.4355,  5.2753,  5.3900,  5.4020,  5.3737,\n",
      "         5.3343,  5.3255,  5.3838,  5.3284,  5.2450,  5.3397,  5.3193,  5.2957,\n",
      "         5.2481,  5.2770,  5.0703,  4.9915,  4.9302,  4.6811,  4.6067,  4.3625,\n",
      "         4.1663,  3.9311,  3.7236,  3.4930,  3.3150,  3.1014,  2.9408,  2.7527,\n",
      "         2.6327,  2.4280,  2.2795,  2.1348,  2.0185,  1.8056,  1.6522,  1.4955,\n",
      "         1.5210,  1.4196,  1.2568,  1.1987,  1.1192,  1.1121,  1.0345,  1.0722,\n",
      "         1.0603,  1.1194,  1.2263,  1.4117,  1.7982,  2.6869, 23.5684],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4595, 6.4329, 6.4271, 6.4563, 6.4357, 6.4157, 6.3943, 6.3543, 6.3114,\n",
      "        6.2238, 6.1342, 5.9313, 5.6455, 5.1879, 4.7416, 4.2764, 3.8041, 3.3443,\n",
      "        2.9076, 2.4920, 2.1122, 1.7930, 1.5023, 1.2706, 1.0759, 0.9170, 0.7931,\n",
      "        0.6938, 0.6240, 0.5755, 0.5438, 0.5246, 0.5150, 0.5104, 0.5122, 0.5189,\n",
      "        0.5263, 0.5370, 0.5485, 0.5592, 0.5694, 0.5780, 0.5813, 0.5786, 0.5723,\n",
      "        0.5640, 0.5534, 0.5374, 0.5100, 0.4732, 0.4247, 0.3758, 0.3350, 0.2991,\n",
      "        0.2616], grad_fn=<AddBackward0>) tensor([7.8958, 7.9172, 7.9160, 7.8532, 7.9104, 7.8884, 7.8587, 7.8692, 7.8268,\n",
      "        7.6916, 7.5145, 7.3551, 7.0193, 6.5778, 5.9900, 5.4717, 4.9739, 4.4626,\n",
      "        3.9248, 3.4599, 2.9976, 2.5994, 2.3165, 2.0239, 1.7451, 1.5022, 1.3267,\n",
      "        1.1982, 1.0941, 1.0109, 0.9434, 0.9376, 0.9115, 0.9152, 0.9260, 0.9278,\n",
      "        0.9532, 0.9681, 0.9981, 1.0296, 1.0721, 1.0607, 1.0746, 1.0753, 1.0914,\n",
      "        1.0875, 1.0811, 1.0586, 1.0535, 1.0286, 0.9994, 0.9690, 1.0406, 1.2785,\n",
      "        9.0297], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5826, 3.5767, 3.5664, 3.5685, 3.5882, 3.5549, 3.5615, 3.5604, 3.5679,\n",
      "        3.5505, 3.5322, 3.5283, 3.5233, 3.5203, 3.4973, 3.4667, 3.4211, 3.3491,\n",
      "        3.2896, 3.1958, 3.0512, 2.9335, 2.7696, 2.6014, 2.4220, 2.2455, 2.0592,\n",
      "        1.8794, 1.7087, 1.5468, 1.3924, 1.2523, 1.1226, 1.0072, 0.9024, 0.8097,\n",
      "        0.7269, 0.6538, 0.5872, 0.5284, 0.4728, 0.4273, 0.3897, 0.3534, 0.3237,\n",
      "        0.2965, 0.2747, 0.2534, 0.2359, 0.2191, 0.2031, 0.1865, 0.1693, 0.1508,\n",
      "        0.1372], grad_fn=<AddBackward0>) tensor([ 5.4011,  5.4252,  5.4544,  5.4355,  5.2687,  5.3876,  5.3876,  5.3660,\n",
      "         5.3302,  5.3220,  5.3782,  5.3223,  5.2527,  5.3372,  5.3228,  5.2959,\n",
      "         5.2459,  5.2799,  5.0780,  4.9849,  4.9394,  4.6783,  4.6032,  4.3622,\n",
      "         4.1793,  3.9325,  3.7210,  3.4926,  3.3102,  3.1033,  2.9434,  2.7471,\n",
      "         2.6310,  2.4327,  2.2717,  2.1363,  2.0211,  1.8043,  1.6503,  1.4971,\n",
      "         1.5238,  1.4151,  1.2548,  1.1956,  1.1162,  1.1075,  1.0273,  1.0674,\n",
      "         1.0593,  1.1169,  1.2252,  1.4062,  1.7964,  2.6960, 23.5204],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.4617, 6.4356, 6.4284, 6.4597, 6.4372, 6.4179, 6.3957, 6.3581, 6.3152,\n",
      "        6.2273, 6.1352, 5.9328, 5.6480, 5.1893, 4.7403, 4.2781, 3.8059, 3.3479,\n",
      "        2.9106, 2.4954, 2.1159, 1.7968, 1.5048, 1.2727, 1.0770, 0.9177, 0.7928,\n",
      "        0.6932, 0.6229, 0.5744, 0.5426, 0.5232, 0.5137, 0.5094, 0.5113, 0.5181,\n",
      "        0.5257, 0.5369, 0.5487, 0.5597, 0.5703, 0.5793, 0.5827, 0.5801, 0.5736,\n",
      "        0.5652, 0.5543, 0.5378, 0.5097, 0.4717, 0.4220, 0.3721, 0.3305, 0.2940,\n",
      "        0.2563], grad_fn=<AddBackward0>) tensor([7.8846, 7.9050, 7.9056, 7.8389, 7.8993, 7.8776, 7.8474, 7.8509, 7.8113,\n",
      "        7.6767, 7.5081, 7.3421, 7.0032, 6.5614, 5.9886, 5.4611, 4.9699, 4.4528,\n",
      "        3.9217, 3.4600, 2.9960, 2.5931, 2.3174, 2.0225, 1.7467, 1.4957, 1.3275,\n",
      "        1.1917, 1.0911, 1.0022, 0.9392, 0.9348, 0.9091, 0.9112, 0.9231, 0.9270,\n",
      "        0.9555, 0.9675, 0.9985, 1.0315, 1.0756, 1.0577, 1.0758, 1.0777, 1.0961,\n",
      "        1.0894, 1.0884, 1.0622, 1.0550, 1.0331, 1.0007, 0.9663, 1.0418, 1.2826,\n",
      "        8.9753], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5731, 3.5664, 3.5586, 3.5617, 3.5780, 3.5455, 3.5522, 3.5508, 3.5604,\n",
      "        3.5427, 3.5265, 3.5210, 3.5155, 3.5141, 3.4904, 3.4627, 3.4147, 3.3457,\n",
      "        3.2847, 3.1923, 3.0483, 2.9295, 2.7675, 2.5984, 2.4196, 2.2429, 2.0557,\n",
      "        1.8764, 1.7066, 1.5444, 1.3897, 1.2496, 1.1200, 1.0044, 0.8997, 0.8069,\n",
      "        0.7240, 0.6509, 0.5843, 0.5254, 0.4698, 0.4243, 0.3866, 0.3504, 0.3206,\n",
      "        0.2935, 0.2717, 0.2505, 0.2330, 0.2162, 0.2002, 0.1836, 0.1665, 0.1480,\n",
      "        0.1346], grad_fn=<AddBackward0>) tensor([ 5.3813,  5.4078,  5.4259,  5.4008,  5.2552,  5.3723,  5.3710,  5.3499,\n",
      "         5.3078,  5.3020,  5.3435,  5.3023,  5.2372,  5.3154,  5.3065,  5.2679,\n",
      "         5.2332,  5.2553,  5.0667,  4.9642,  4.9212,  4.6655,  4.5825,  4.3444,\n",
      "         4.1577,  3.9137,  3.7092,  3.4782,  3.2864,  3.0830,  2.9299,  2.7322,\n",
      "         2.6178,  2.4222,  2.2597,  2.1260,  2.0128,  1.7974,  1.6410,  1.4921,\n",
      "         1.5154,  1.4050,  1.2536,  1.1869,  1.1132,  1.0952,  1.0177,  1.0534,\n",
      "         1.0487,  1.1039,  1.2227,  1.4073,  1.7877,  2.7059, 23.5001],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4951, 6.4703, 6.4630, 6.4947, 6.4708, 6.4539, 6.4302, 6.3935, 6.3489,\n",
      "        6.2603, 6.1667, 5.9656, 5.6790, 5.2162, 4.7671, 4.3022, 3.8276, 3.3684,\n",
      "        2.9295, 2.5130, 2.1315, 1.8100, 1.5165, 1.2823, 1.0846, 0.9237, 0.7973,\n",
      "        0.6967, 0.6258, 0.5769, 0.5444, 0.5253, 0.5157, 0.5115, 0.5138, 0.5209,\n",
      "        0.5289, 0.5403, 0.5529, 0.5643, 0.5755, 0.5849, 0.5886, 0.5860, 0.5795,\n",
      "        0.5709, 0.5597, 0.5427, 0.5135, 0.4741, 0.4227, 0.3711, 0.3283, 0.2910,\n",
      "        0.2526], grad_fn=<AddBackward0>) tensor([7.9197, 7.9368, 7.9353, 7.8704, 7.9324, 7.9057, 7.8781, 7.8768, 7.8440,\n",
      "        7.7078, 7.5410, 7.3634, 7.0279, 6.5859, 6.0011, 5.4805, 4.9906, 4.4746,\n",
      "        3.9423, 3.4778, 3.0125, 2.6107, 2.3314, 2.0338, 1.7572, 1.5018, 1.3328,\n",
      "        1.1947, 1.0931, 1.0037, 0.9463, 0.9343, 0.9127, 0.9141, 0.9241, 0.9302,\n",
      "        0.9591, 0.9759, 1.0029, 1.0377, 1.0791, 1.0648, 1.0828, 1.0874, 1.1062,\n",
      "        1.1022, 1.1040, 1.0757, 1.0673, 1.0445, 1.0074, 0.9685, 1.0551, 1.2856,\n",
      "        8.9986], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5628, 3.5582, 3.5454, 3.5509, 3.5677, 3.5346, 3.5413, 3.5408, 3.5497,\n",
      "        3.5319, 3.5180, 3.5104, 3.5070, 3.5058, 3.4831, 3.4574, 3.4064, 3.3388,\n",
      "        3.2790, 3.1865, 3.0447, 2.9236, 2.7637, 2.5944, 2.4154, 2.2399, 2.0518,\n",
      "        1.8729, 1.7035, 1.5422, 1.3871, 1.2468, 1.1168, 1.0021, 0.8967, 0.8045,\n",
      "        0.7214, 0.6485, 0.5818, 0.5226, 0.4673, 0.4219, 0.3840, 0.3478, 0.3180,\n",
      "        0.2909, 0.2690, 0.2479, 0.2304, 0.2136, 0.1976, 0.1810, 0.1640, 0.1456,\n",
      "        0.1322], grad_fn=<AddBackward0>) tensor([ 5.3512,  5.3643,  5.4112,  5.3758,  5.2231,  5.3454,  5.3454,  5.3144,\n",
      "         5.2818,  5.2781,  5.3074,  5.2797,  5.2056,  5.2872,  5.2762,  5.2304,\n",
      "         5.2144,  5.2296,  5.0407,  4.9390,  4.8875,  4.6485,  4.5529,  4.3192,\n",
      "         4.1374,  3.8848,  3.6886,  3.4579,  3.2664,  3.0533,  2.9066,  2.7160,\n",
      "         2.6125,  2.4024,  2.2565,  2.1139,  2.0079,  1.7893,  1.6381,  1.4959,\n",
      "         1.5096,  1.3911,  1.2463,  1.1780,  1.1096,  1.0897,  1.0126,  1.0471,\n",
      "         1.0368,  1.0967,  1.2129,  1.4144,  1.7927,  2.7090, 23.5293],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4717, 6.4493, 6.4420, 6.4705, 6.4465, 6.4308, 6.4079, 6.3683, 6.3264,\n",
      "        6.2382, 6.1424, 5.9446, 5.6593, 5.1969, 4.7524, 4.2868, 3.8151, 3.3594,\n",
      "        2.9222, 2.5073, 2.1280, 1.8076, 1.5144, 1.2804, 1.0828, 0.9219, 0.7951,\n",
      "        0.6944, 0.6234, 0.5745, 0.5420, 0.5229, 0.5137, 0.5094, 0.5120, 0.5195,\n",
      "        0.5277, 0.5395, 0.5525, 0.5643, 0.5758, 0.5856, 0.5893, 0.5871, 0.5805,\n",
      "        0.5717, 0.5603, 0.5428, 0.5129, 0.4725, 0.4199, 0.3674, 0.3239, 0.2862,\n",
      "        0.2475], grad_fn=<AddBackward0>) tensor([7.8821, 7.8926, 7.8919, 7.8357, 7.8971, 7.8663, 7.8361, 7.8465, 7.8046,\n",
      "        7.6685, 7.5098, 7.3280, 6.9899, 6.5540, 5.9616, 5.4556, 4.9697, 4.4531,\n",
      "        3.9259, 3.4693, 3.0027, 2.6026, 2.3275, 2.0299, 1.7496, 1.4934, 1.3298,\n",
      "        1.1914, 1.0866, 0.9962, 0.9429, 0.9294, 0.9057, 0.9151, 0.9226, 0.9231,\n",
      "        0.9551, 0.9719, 1.0021, 1.0356, 1.0837, 1.0652, 1.0868, 1.0881, 1.1092,\n",
      "        1.1082, 1.1057, 1.0777, 1.0709, 1.0419, 1.0073, 0.9648, 1.0496, 1.2860,\n",
      "        9.0453], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5974, 3.5939, 3.5813, 3.5889, 3.6037, 3.5697, 3.5784, 3.5771, 3.5883,\n",
      "        3.5695, 3.5548, 3.5493, 3.5448, 3.5452, 3.5230, 3.4960, 3.4451, 3.3782,\n",
      "        3.3164, 3.2235, 3.0805, 2.9596, 2.7970, 2.6256, 2.4438, 2.2685, 2.0762,\n",
      "        1.8948, 1.7235, 1.5610, 1.4034, 1.2614, 1.1297, 1.0131, 0.9058, 0.8128,\n",
      "        0.7280, 0.6545, 0.5868, 0.5266, 0.4704, 0.4245, 0.3860, 0.3492, 0.3190,\n",
      "        0.2915, 0.2695, 0.2480, 0.2304, 0.2133, 0.1972, 0.1804, 0.1633, 0.1447,\n",
      "        0.1312], grad_fn=<AddBackward0>) tensor([ 5.3991,  5.4077,  5.4525,  5.4066,  5.2644,  5.3928,  5.3803,  5.3555,\n",
      "         5.3143,  5.3171,  5.3512,  5.3125,  5.2456,  5.3252,  5.3123,  5.2741,\n",
      "         5.2592,  5.2683,  5.0883,  4.9866,  4.9333,  4.6834,  4.5919,  4.3572,\n",
      "         4.1799,  3.9060,  3.7242,  3.4941,  3.3015,  3.0739,  2.9297,  2.7326,\n",
      "         2.6278,  2.4222,  2.2838,  2.1241,  2.0299,  1.7961,  1.6457,  1.5053,\n",
      "         1.5225,  1.3936,  1.2495,  1.1880,  1.1145,  1.0959,  1.0146,  1.0536,\n",
      "         1.0405,  1.1125,  1.2220,  1.4286,  1.8134,  2.7578, 23.8363],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4583, 6.4382, 6.4286, 6.4586, 6.4332, 6.4180, 6.3932, 6.3552, 6.3119,\n",
      "        6.2267, 6.1285, 5.9317, 5.6476, 5.1859, 4.7427, 4.2780, 3.8073, 3.3544,\n",
      "        2.9184, 2.5053, 2.1271, 1.8067, 1.5133, 1.2796, 1.0817, 0.9206, 0.7934,\n",
      "        0.6923, 0.6211, 0.5720, 0.5396, 0.5205, 0.5114, 0.5073, 0.5100, 0.5176,\n",
      "        0.5260, 0.5380, 0.5514, 0.5635, 0.5752, 0.5853, 0.5891, 0.5870, 0.5803,\n",
      "        0.5713, 0.5596, 0.5418, 0.5110, 0.4698, 0.4161, 0.3627, 0.3189, 0.2808,\n",
      "        0.2421], grad_fn=<AddBackward0>) tensor([7.8532, 7.8594, 7.8640, 7.8064, 7.8720, 7.8379, 7.8159, 7.8178, 7.7853,\n",
      "        7.6355, 7.4861, 7.3034, 6.9620, 6.5266, 5.9351, 5.4368, 4.9560, 4.4393,\n",
      "        3.9155, 3.4589, 2.9970, 2.5997, 2.3305, 2.0289, 1.7469, 1.4880, 1.3249,\n",
      "        1.1857, 1.0798, 0.9928, 0.9379, 0.9247, 0.8996, 0.9086, 0.9168, 0.9179,\n",
      "        0.9516, 0.9698, 0.9996, 1.0355, 1.0834, 1.0629, 1.0906, 1.0860, 1.1066,\n",
      "        1.1084, 1.1052, 1.0745, 1.0721, 1.0409, 1.0034, 0.9663, 1.0389, 1.2811,\n",
      "        8.9949], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5810, 3.5774, 3.5652, 3.5709, 3.5853, 3.5516, 3.5613, 3.5601, 3.5703,\n",
      "        3.5534, 3.5398, 3.5323, 3.5298, 3.5301, 3.5081, 3.4810, 3.4327, 3.3653,\n",
      "        3.3048, 3.2122, 3.0701, 2.9502, 2.7872, 2.6159, 2.4345, 2.2607, 2.0707,\n",
      "        1.8872, 1.7180, 1.5554, 1.3980, 1.2568, 1.1253, 1.0088, 0.9015, 0.8089,\n",
      "        0.7241, 0.6510, 0.5833, 0.5231, 0.4667, 0.4210, 0.3827, 0.3460, 0.3157,\n",
      "        0.2885, 0.2664, 0.2451, 0.2275, 0.2105, 0.1945, 0.1776, 0.1606, 0.1420,\n",
      "        0.1288], grad_fn=<AddBackward0>) tensor([ 5.3510,  5.3599,  5.4029,  5.3658,  5.2297,  5.3598,  5.3378,  5.3158,\n",
      "         5.2767,  5.2778,  5.3077,  5.2809,  5.2009,  5.2860,  5.2758,  5.2416,\n",
      "         5.2179,  5.2332,  5.0549,  4.9526,  4.8998,  4.6506,  4.5660,  4.3368,\n",
      "         4.1641,  3.8853,  3.6917,  3.4863,  3.2788,  3.0565,  2.9207,  2.7120,\n",
      "         2.6129,  2.4034,  2.2711,  2.1100,  2.0169,  1.7724,  1.6259,  1.4912,\n",
      "         1.5174,  1.3829,  1.2388,  1.1783,  1.1134,  1.0867,  1.0114,  1.0486,\n",
      "         1.0349,  1.1075,  1.2131,  1.4297,  1.8104,  2.7584, 23.7305],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.4777, 6.4566, 6.4485, 6.4766, 6.4508, 6.4372, 6.4115, 6.3740, 6.3323,\n",
      "        6.2439, 6.1448, 5.9492, 5.6637, 5.2008, 4.7553, 4.2893, 3.8181, 3.3642,\n",
      "        2.9275, 2.5145, 2.1347, 1.8135, 1.5186, 1.2836, 1.0846, 0.9223, 0.7941,\n",
      "        0.6924, 0.6206, 0.5711, 0.5386, 0.5194, 0.5104, 0.5064, 0.5092, 0.5169,\n",
      "        0.5254, 0.5378, 0.5515, 0.5638, 0.5759, 0.5862, 0.5901, 0.5879, 0.5810,\n",
      "        0.5718, 0.5598, 0.5414, 0.5099, 0.4677, 0.4128, 0.3585, 0.3142, 0.2758,\n",
      "        0.2371], grad_fn=<AddBackward0>) tensor([7.8614, 7.8681, 7.8692, 7.8194, 7.8824, 7.8458, 7.8267, 7.8250, 7.7890,\n",
      "        7.6475, 7.4980, 7.3107, 6.9678, 6.5266, 5.9367, 5.4419, 4.9599, 4.4442,\n",
      "        3.9216, 3.4596, 3.0036, 2.5991, 2.3318, 2.0329, 1.7477, 1.4884, 1.3269,\n",
      "        1.1811, 1.0764, 0.9929, 0.9347, 0.9220, 0.8970, 0.9044, 0.9133, 0.9176,\n",
      "        0.9512, 0.9687, 0.9972, 1.0352, 1.0835, 1.0652, 1.0924, 1.0892, 1.1075,\n",
      "        1.1064, 1.1043, 1.0759, 1.0684, 1.0381, 1.0017, 0.9594, 1.0418, 1.2857,\n",
      "        9.0033], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6035, 3.5999, 3.5897, 3.5932, 3.6112, 3.5748, 3.5859, 3.5857, 3.5959,\n",
      "        3.5772, 3.5650, 3.5588, 3.5556, 3.5565, 3.5348, 3.5076, 3.4596, 3.3929,\n",
      "        3.3306, 3.2364, 3.0956, 2.9738, 2.8104, 2.6377, 2.4549, 2.2791, 2.0872,\n",
      "        1.9034, 1.7320, 1.5675, 1.4094, 1.2664, 1.1333, 1.0163, 0.9072, 0.8139,\n",
      "        0.7285, 0.6545, 0.5859, 0.5251, 0.4681, 0.4221, 0.3833, 0.3463, 0.3156,\n",
      "        0.2882, 0.2659, 0.2444, 0.2266, 0.2096, 0.1934, 0.1764, 0.1592, 0.1405,\n",
      "        0.1273], grad_fn=<AddBackward0>) tensor([ 5.3753,  5.3830,  5.4137,  5.3925,  5.2346,  5.3779,  5.3502,  5.3247,\n",
      "         5.2871,  5.3009,  5.3238,  5.2918,  5.2170,  5.3002,  5.2937,  5.2568,\n",
      "         5.2380,  5.2447,  5.0811,  4.9854,  4.9192,  4.6731,  4.5847,  4.3493,\n",
      "         4.1839,  3.9029,  3.7112,  3.4933,  3.2893,  3.0728,  2.9238,  2.7222,\n",
      "         2.6250,  2.4035,  2.2831,  2.1186,  2.0130,  1.7739,  1.6290,  1.4920,\n",
      "         1.5187,  1.3802,  1.2409,  1.1764,  1.1192,  1.0814,  1.0120,  1.0483,\n",
      "         1.0416,  1.0995,  1.2196,  1.4361,  1.8196,  2.7904, 23.8624],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4978, 6.4788, 6.4689, 6.5006, 6.4733, 6.4586, 6.4327, 6.3974, 6.3544,\n",
      "        6.2630, 6.1668, 5.9658, 5.6827, 5.2193, 4.7703, 4.3029, 3.8310, 3.3770,\n",
      "        2.9393, 2.5250, 2.1434, 1.8220, 1.5250, 1.2890, 1.0883, 0.9251, 0.7956,\n",
      "        0.6930, 0.6206, 0.5709, 0.5381, 0.5189, 0.5098, 0.5060, 0.5089, 0.5169,\n",
      "        0.5254, 0.5381, 0.5522, 0.5647, 0.5770, 0.5877, 0.5916, 0.5894, 0.5823,\n",
      "        0.5727, 0.5604, 0.5414, 0.5091, 0.4659, 0.4096, 0.3544, 0.3094, 0.2707,\n",
      "        0.2319], grad_fn=<AddBackward0>) tensor([7.8794, 7.8819, 7.8894, 7.8289, 7.8962, 7.8612, 7.8426, 7.8342, 7.8004,\n",
      "        7.6644, 7.5065, 7.3306, 6.9784, 6.5276, 5.9442, 5.4494, 4.9687, 4.4496,\n",
      "        3.9282, 3.4674, 3.0150, 2.6021, 2.3405, 2.0355, 1.7527, 1.4878, 1.3280,\n",
      "        1.1829, 1.0782, 0.9900, 0.9340, 0.9207, 0.8956, 0.9043, 0.9119, 0.9153,\n",
      "        0.9519, 0.9682, 0.9960, 1.0347, 1.0860, 1.0631, 1.0964, 1.0918, 1.1081,\n",
      "        1.1118, 1.1057, 1.0785, 1.0716, 1.0355, 0.9985, 0.9546, 1.0454, 1.2860,\n",
      "        8.9535], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6002, 3.5956, 3.5866, 3.5911, 3.6076, 3.5733, 3.5810, 3.5842, 3.5915,\n",
      "        3.5745, 3.5643, 3.5570, 3.5543, 3.5555, 3.5349, 3.5071, 3.4588, 3.3950,\n",
      "        3.3315, 3.2366, 3.0973, 2.9752, 2.8128, 2.6407, 2.4570, 2.2813, 2.0879,\n",
      "        1.9040, 1.7336, 1.5677, 1.4098, 1.2660, 1.1337, 1.0162, 0.9069, 0.8130,\n",
      "        0.7274, 0.6533, 0.5847, 0.5236, 0.4665, 0.4203, 0.3812, 0.3443, 0.3135,\n",
      "        0.2861, 0.2637, 0.2422, 0.2245, 0.2074, 0.1911, 0.1743, 0.1571, 0.1384,\n",
      "        0.1252], grad_fn=<AddBackward0>) tensor([ 5.3578,  5.3710,  5.4001,  5.3734,  5.2190,  5.3519,  5.3483,  5.3034,\n",
      "         5.2803,  5.2864,  5.3047,  5.2791,  5.2000,  5.2866,  5.2781,  5.2476,\n",
      "         5.2339,  5.2286,  5.0704,  4.9806,  4.9092,  4.6647,  4.5717,  4.3300,\n",
      "         4.1698,  3.8870,  3.7107,  3.4894,  3.2753,  3.0704,  2.9186,  2.7255,\n",
      "         2.6129,  2.3970,  2.2736,  2.1215,  2.0186,  1.7715,  1.6224,  1.4899,\n",
      "         1.5120,  1.3706,  1.2402,  1.1686,  1.1093,  1.0770,  1.0057,  1.0433,\n",
      "         1.0386,  1.0971,  1.2196,  1.4262,  1.8173,  2.8022, 23.9592],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4765, 6.4601, 6.4467, 6.4786, 6.4533, 6.4376, 6.4139, 6.3770, 6.3347,\n",
      "        6.2427, 6.1452, 5.9450, 5.6650, 5.2043, 4.7542, 4.2896, 3.8187, 3.3682,\n",
      "        2.9330, 2.5214, 2.1403, 1.8201, 1.5238, 1.2876, 1.0867, 0.9235, 0.7937,\n",
      "        0.6908, 0.6185, 0.5688, 0.5360, 0.5169, 0.5080, 0.5043, 0.5074, 0.5158,\n",
      "        0.5247, 0.5377, 0.5522, 0.5653, 0.5780, 0.5890, 0.5932, 0.5911, 0.5839,\n",
      "        0.5743, 0.5617, 0.5423, 0.5091, 0.4649, 0.4073, 0.3510, 0.3054, 0.2663,\n",
      "        0.2274], grad_fn=<AddBackward0>) tensor([7.8471, 7.8439, 7.8618, 7.7991, 7.8605, 7.8317, 7.8047, 7.8025, 7.7662,\n",
      "        7.6340, 7.4822, 7.3038, 6.9440, 6.4919, 5.9200, 5.4273, 4.9554, 4.4361,\n",
      "        3.9146, 3.4521, 3.0065, 2.5933, 2.3306, 2.0306, 1.7506, 1.4825, 1.3244,\n",
      "        1.1811, 1.0757, 0.9844, 0.9327, 0.9194, 0.8924, 0.9014, 0.9103, 0.9132,\n",
      "        0.9511, 0.9668, 0.9976, 1.0355, 1.0874, 1.0643, 1.0991, 1.0934, 1.1140,\n",
      "        1.1154, 1.1099, 1.0800, 1.0774, 1.0362, 0.9972, 0.9565, 1.0453, 1.2927,\n",
      "        8.9499], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6151, 3.6103, 3.6017, 3.6066, 3.6236, 3.5870, 3.5988, 3.6010, 3.6080,\n",
      "        3.5893, 3.5800, 3.5739, 3.5723, 3.5730, 3.5529, 3.5241, 3.4753, 3.4133,\n",
      "        3.3499, 3.2543, 3.1155, 2.9924, 2.8306, 2.6569, 2.4712, 2.2948, 2.0992,\n",
      "        1.9148, 1.7438, 1.5765, 1.4168, 1.2727, 1.1393, 1.0210, 0.9112, 0.8162,\n",
      "        0.7298, 0.6554, 0.5860, 0.5245, 0.4669, 0.4205, 0.3810, 0.3438, 0.3128,\n",
      "        0.2852, 0.2628, 0.2411, 0.2232, 0.2061, 0.1897, 0.1728, 0.1556, 0.1369,\n",
      "        0.1237], grad_fn=<AddBackward0>) tensor([ 5.3678,  5.3827,  5.4081,  5.3818,  5.2241,  5.3680,  5.3437,  5.3070,\n",
      "         5.2847,  5.3010,  5.3168,  5.2861,  5.1998,  5.2942,  5.2850,  5.2640,\n",
      "         5.2558,  5.2385,  5.0829,  4.9971,  4.9196,  4.6767,  4.5764,  4.3353,\n",
      "         4.1829,  3.8976,  3.7303,  3.5008,  3.2827,  3.0787,  2.9366,  2.7308,\n",
      "         2.6176,  2.3980,  2.2675,  2.1260,  2.0212,  1.7686,  1.6241,  1.4886,\n",
      "         1.5157,  1.3713,  1.2447,  1.1700,  1.1155,  1.0780,  1.0029,  1.0397,\n",
      "         1.0399,  1.1016,  1.2294,  1.4422,  1.8225,  2.8262, 24.1742],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.4998, 6.4859, 6.4733, 6.5038, 6.4769, 6.4602, 6.4377, 6.4011, 6.3569,\n",
      "        6.2644, 6.1671, 5.9676, 5.6852, 5.2242, 4.7715, 4.3055, 3.8335, 3.3822,\n",
      "        2.9461, 2.5334, 2.1504, 1.8296, 1.5312, 1.2939, 1.0914, 0.9269, 0.7958,\n",
      "        0.6923, 0.6192, 0.5692, 0.5363, 0.5170, 0.5082, 0.5046, 0.5080, 0.5165,\n",
      "        0.5256, 0.5391, 0.5539, 0.5674, 0.5805, 0.5918, 0.5962, 0.5941, 0.5865,\n",
      "        0.5767, 0.5637, 0.5438, 0.5096, 0.4641, 0.4050, 0.3477, 0.3015, 0.2619,\n",
      "        0.2228], grad_fn=<AddBackward0>) tensor([7.8667, 7.8571, 7.8706, 7.8133, 7.8779, 7.8559, 7.8230, 7.8197, 7.7849,\n",
      "        7.6570, 7.4995, 7.3157, 6.9584, 6.4967, 5.9268, 5.4340, 4.9612, 4.4433,\n",
      "        3.9206, 3.4571, 3.0181, 2.6002, 2.3403, 2.0380, 1.7581, 1.4832, 1.3275,\n",
      "        1.1795, 1.0768, 0.9861, 0.9298, 0.9217, 0.8909, 0.9036, 0.9074, 0.9137,\n",
      "        0.9532, 0.9670, 1.0023, 1.0423, 1.0939, 1.0710, 1.1053, 1.0971, 1.1229,\n",
      "        1.1191, 1.1160, 1.0841, 1.0807, 1.0405, 1.0023, 0.9579, 1.0431, 1.2971,\n",
      "        8.9652], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6052, 3.6008, 3.5903, 3.5970, 3.6125, 3.5766, 3.5881, 3.5909, 3.5968,\n",
      "        3.5802, 3.5715, 3.5638, 3.5647, 3.5639, 3.5425, 3.5155, 3.4676, 3.4075,\n",
      "        3.3429, 3.2496, 3.1116, 2.9893, 2.8268, 2.6535, 2.4672, 2.2913, 2.0961,\n",
      "        1.9122, 1.7419, 1.5743, 1.4150, 1.2712, 1.1375, 1.0186, 0.9091, 0.8141,\n",
      "        0.7279, 0.6533, 0.5839, 0.5223, 0.4647, 0.4181, 0.3785, 0.3414, 0.3104,\n",
      "        0.2828, 0.2603, 0.2388, 0.2209, 0.2038, 0.1874, 0.1706, 0.1534, 0.1349,\n",
      "        0.1216], grad_fn=<AddBackward0>) tensor([ 5.3376,  5.3496,  5.3833,  5.3495,  5.2004,  5.3395,  5.3183,  5.2798,\n",
      "         5.2639,  5.2725,  5.2857,  5.2635,  5.1698,  5.2732,  5.2742,  5.2471,\n",
      "         5.2394,  5.2157,  5.0684,  4.9762,  4.8951,  4.6527,  4.5603,  4.3153,\n",
      "         4.1748,  3.8871,  3.7194,  3.4882,  3.2647,  3.0677,  2.9227,  2.7135,\n",
      "         2.6064,  2.4005,  2.2643,  2.1210,  2.0093,  1.7621,  1.6152,  1.4800,\n",
      "         1.5060,  1.3647,  1.2391,  1.1604,  1.1102,  1.0748,  0.9997,  1.0323,\n",
      "         1.0362,  1.0938,  1.2318,  1.4288,  1.8345,  2.8185, 24.3113],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.4809, 6.4676, 6.4559, 6.4844, 6.4581, 6.4429, 6.4229, 6.3831, 6.3421,\n",
      "        6.2483, 6.1490, 5.9522, 5.6694, 5.2088, 4.7594, 4.2931, 3.8228, 3.3743,\n",
      "        2.9405, 2.5284, 2.1469, 1.8277, 1.5293, 1.2924, 1.0892, 0.9247, 0.7933,\n",
      "        0.6897, 0.6165, 0.5663, 0.5335, 0.5143, 0.5057, 0.5023, 0.5059, 0.5145,\n",
      "        0.5238, 0.5376, 0.5528, 0.5665, 0.5800, 0.5915, 0.5960, 0.5940, 0.5862,\n",
      "        0.5763, 0.5628, 0.5425, 0.5075, 0.4610, 0.4009, 0.3429, 0.2962, 0.2565,\n",
      "        0.2174], grad_fn=<AddBackward0>) tensor([7.8397, 7.8293, 7.8362, 7.7887, 7.8493, 7.8256, 7.7822, 7.7869, 7.7444,\n",
      "        7.6245, 7.4739, 7.2789, 6.9255, 6.4688, 5.8930, 5.4087, 4.9434, 4.4254,\n",
      "        3.9055, 3.4506, 3.0116, 2.5892, 2.3303, 2.0270, 1.7544, 1.4771, 1.3194,\n",
      "        1.1742, 1.0725, 0.9816, 0.9229, 0.9189, 0.8874, 0.9003, 0.9013, 0.9102,\n",
      "        0.9511, 0.9647, 0.9974, 1.0445, 1.0905, 1.0705, 1.1076, 1.0955, 1.1206,\n",
      "        1.1172, 1.1202, 1.0807, 1.0803, 1.0395, 1.0020, 0.9549, 1.0386, 1.2925,\n",
      "        8.9056], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.5913, 3.5861, 3.5788, 3.5828, 3.5981, 3.5635, 3.5745, 3.5777, 3.5824,\n",
      "        3.5682, 3.5578, 3.5517, 3.5530, 3.5526, 3.5312, 3.5059, 3.4586, 3.4009,\n",
      "        3.3349, 3.2415, 3.1042, 2.9810, 2.8206, 2.6456, 2.4611, 2.2860, 2.0901,\n",
      "        1.9066, 1.7386, 1.5702, 1.4112, 1.2676, 1.1337, 1.0151, 0.9061, 0.8111,\n",
      "        0.7248, 0.6502, 0.5812, 0.5196, 0.4619, 0.4152, 0.3757, 0.3388, 0.3077,\n",
      "        0.2801, 0.2578, 0.2362, 0.2184, 0.2013, 0.1849, 0.1682, 0.1511, 0.1327,\n",
      "        0.1195], grad_fn=<AddBackward0>) tensor([ 5.3063,  5.3246,  5.3392,  5.3204,  5.1719,  5.3043,  5.2888,  5.2459,\n",
      "         5.2402,  5.2353,  5.2604,  5.2337,  5.1346,  5.2420,  5.2476,  5.2111,\n",
      "         5.2053,  5.1706,  5.0362,  4.9468,  4.8713,  4.6326,  4.5310,  4.3038,\n",
      "         4.1521,  3.8624,  3.7078,  3.4746,  3.2337,  3.0456,  2.9046,  2.6966,\n",
      "         2.5962,  2.3931,  2.2493,  2.1114,  2.0061,  1.7617,  1.6030,  1.4657,\n",
      "         1.5012,  1.3636,  1.2360,  1.1519,  1.1007,  1.0732,  0.9931,  1.0253,\n",
      "         1.0272,  1.0846,  1.2282,  1.4274,  1.8522,  2.8459, 24.3844],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5114, 6.5030, 6.4897, 6.5157, 6.4895, 6.4707, 6.4546, 6.4172, 6.3756,\n",
      "        6.2810, 6.1799, 5.9820, 5.6968, 5.2334, 4.7809, 4.3145, 3.8419, 3.3919,\n",
      "        2.9570, 2.5431, 2.1592, 1.8390, 1.5390, 1.2998, 1.0949, 0.9289, 0.7963,\n",
      "        0.6917, 0.6178, 0.5673, 0.5342, 0.5149, 0.5063, 0.5030, 0.5068, 0.5156,\n",
      "        0.5251, 0.5392, 0.5550, 0.5690, 0.5830, 0.5948, 0.5993, 0.5973, 0.5893,\n",
      "        0.5790, 0.5650, 0.5440, 0.5082, 0.4603, 0.3988, 0.3396, 0.2923, 0.2520,\n",
      "        0.2129], grad_fn=<AddBackward0>) tensor([7.8653, 7.8416, 7.8480, 7.8129, 7.8729, 7.8615, 7.8025, 7.7990, 7.7581,\n",
      "        7.6405, 7.4919, 7.2948, 6.9412, 6.4859, 5.9085, 5.4192, 4.9538, 4.4367,\n",
      "        3.9150, 3.4618, 3.0242, 2.5991, 2.3323, 2.0308, 1.7603, 1.4839, 1.3216,\n",
      "        1.1756, 1.0747, 0.9812, 0.9255, 0.9164, 0.8894, 0.9009, 0.9002, 0.9109,\n",
      "        0.9567, 0.9715, 0.9969, 1.0481, 1.0936, 1.0728, 1.1146, 1.0999, 1.1282,\n",
      "        1.1251, 1.1253, 1.0888, 1.0804, 1.0421, 1.0044, 0.9507, 1.0307, 1.2891,\n",
      "        8.8589], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6013, 3.5966, 3.5908, 3.5939, 3.6086, 3.5756, 3.5842, 3.5909, 3.5942,\n",
      "        3.5794, 3.5679, 3.5657, 3.5654, 3.5653, 3.5446, 3.5193, 3.4740, 3.4158,\n",
      "        3.3471, 3.2558, 3.1186, 2.9932, 2.8337, 2.6575, 2.4718, 2.2960, 2.0988,\n",
      "        1.9146, 1.7453, 1.5768, 1.4165, 1.2719, 1.1370, 1.0181, 0.9081, 0.8131,\n",
      "        0.7256, 0.6507, 0.5815, 0.5192, 0.4613, 0.4142, 0.3745, 0.3374, 0.3062,\n",
      "        0.2783, 0.2560, 0.2343, 0.2165, 0.1994, 0.1829, 0.1661, 0.1490, 0.1306,\n",
      "        0.1175], grad_fn=<AddBackward0>) tensor([ 5.3144,  5.3293,  5.3370,  5.3216,  5.1769,  5.3029,  5.2976,  5.2395,\n",
      "         5.2429,  5.2422,  5.2742,  5.2266,  5.1366,  5.2496,  5.2509,  5.2207,\n",
      "         5.2042,  5.1760,  5.0562,  4.9533,  4.8751,  4.6438,  4.5370,  4.3105,\n",
      "         4.1613,  3.8690,  3.7128,  3.4781,  3.2429,  3.0422,  2.9100,  2.7039,\n",
      "         2.6093,  2.3935,  2.2567,  2.1019,  2.0182,  1.7621,  1.5961,  1.4643,\n",
      "         1.4968,  1.3645,  1.2351,  1.1472,  1.0924,  1.0753,  0.9872,  1.0239,\n",
      "         1.0223,  1.0810,  1.2278,  1.4307,  1.8541,  2.8380, 24.4008],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5145, 6.5079, 6.4930, 6.5199, 6.4937, 6.4732, 6.4580, 6.4179, 6.3797,\n",
      "        6.2854, 6.1835, 5.9843, 5.6986, 5.2355, 4.7813, 4.3174, 3.8447, 3.3961,\n",
      "        2.9609, 2.5475, 2.1636, 1.8430, 1.5424, 1.3024, 1.0969, 0.9301, 0.7968,\n",
      "        0.6916, 0.6172, 0.5666, 0.5334, 0.5140, 0.5055, 0.5023, 0.5063, 0.5154,\n",
      "        0.5252, 0.5396, 0.5559, 0.5703, 0.5846, 0.5967, 0.6013, 0.5995, 0.5911,\n",
      "        0.5807, 0.5664, 0.5446, 0.5080, 0.4589, 0.3962, 0.3360, 0.2881, 0.2476,\n",
      "        0.2084], grad_fn=<AddBackward0>) tensor([7.8603, 7.8302, 7.8406, 7.8042, 7.8653, 7.8577, 7.7974, 7.7996, 7.7493,\n",
      "        7.6277, 7.4844, 7.2896, 6.9374, 6.4800, 5.9069, 5.4090, 4.9490, 4.4329,\n",
      "        3.9158, 3.4654, 3.0266, 2.6026, 2.3357, 2.0365, 1.7613, 1.4813, 1.3177,\n",
      "        1.1733, 1.0718, 0.9745, 0.9209, 0.9137, 0.8881, 0.9018, 0.9000, 0.9098,\n",
      "        0.9576, 0.9726, 0.9960, 1.0520, 1.0997, 1.0779, 1.1180, 1.1033, 1.1357,\n",
      "        1.1292, 1.1301, 1.0981, 1.0880, 1.0438, 1.0013, 0.9474, 1.0298, 1.2845,\n",
      "        8.8356], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6146, 3.6103, 3.6055, 3.6082, 3.6222, 3.5914, 3.5992, 3.6078, 3.6083,\n",
      "        3.5953, 3.5827, 3.5822, 3.5805, 3.5827, 3.5615, 3.5355, 3.4917, 3.4326,\n",
      "        3.3649, 3.2752, 3.1346, 3.0086, 2.8496, 2.6712, 2.4859, 2.3080, 2.1095,\n",
      "        1.9244, 1.7546, 1.5848, 1.4228, 1.2779, 1.1414, 1.0224, 0.9115, 0.8158,\n",
      "        0.7275, 0.6521, 0.5824, 0.5196, 0.4612, 0.4141, 0.3739, 0.3366, 0.3052,\n",
      "        0.2773, 0.2547, 0.2330, 0.2151, 0.1980, 0.1815, 0.1647, 0.1475, 0.1293,\n",
      "        0.1160], grad_fn=<AddBackward0>) tensor([ 5.3299,  5.3379,  5.3412,  5.3297,  5.1869,  5.3049,  5.3026,  5.2390,\n",
      "         5.2537,  5.2457,  5.2857,  5.2342,  5.1503,  5.2567,  5.2609,  5.2349,\n",
      "         5.2142,  5.1911,  5.0672,  4.9545,  4.8910,  4.6586,  4.5451,  4.3225,\n",
      "         4.1672,  3.8774,  3.7233,  3.4896,  3.2460,  3.0494,  2.9227,  2.7093,\n",
      "         2.6217,  2.3940,  2.2596,  2.0992,  2.0247,  1.7590,  1.5918,  1.4637,\n",
      "         1.5015,  1.3553,  1.2361,  1.1463,  1.0917,  1.0718,  0.9903,  1.0266,\n",
      "         1.0280,  1.0896,  1.2353,  1.4420,  1.8803,  2.8387, 24.6269],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5398, 6.5309, 6.5181, 6.5442, 6.5171, 6.4974, 6.4828, 6.4420, 6.4049,\n",
      "        6.3099, 6.2077, 6.0084, 5.7193, 5.2556, 4.7978, 4.3337, 3.8601, 3.4111,\n",
      "        2.9752, 2.5614, 2.1758, 1.8541, 1.5518, 1.3104, 1.1027, 0.9349, 0.8005,\n",
      "        0.6942, 0.6191, 0.5681, 0.5347, 0.5154, 0.5069, 0.5038, 0.5081, 0.5176,\n",
      "        0.5277, 0.5425, 0.5593, 0.5743, 0.5890, 0.6014, 0.6064, 0.6045, 0.5959,\n",
      "        0.5852, 0.5704, 0.5479, 0.5100, 0.4596, 0.3952, 0.3337, 0.2850, 0.2441,\n",
      "        0.2045], grad_fn=<AddBackward0>) tensor([7.8734, 7.8530, 7.8563, 7.8247, 7.8877, 7.8774, 7.8174, 7.8163, 7.7662,\n",
      "        7.6420, 7.4971, 7.3008, 6.9524, 6.4902, 5.9219, 5.4204, 4.9616, 4.4447,\n",
      "        3.9246, 3.4722, 3.0357, 2.6095, 2.3424, 2.0441, 1.7740, 1.4873, 1.3193,\n",
      "        1.1746, 1.0773, 0.9759, 0.9203, 0.9141, 0.8887, 0.9073, 0.9037, 0.9105,\n",
      "        0.9633, 0.9804, 1.0037, 1.0597, 1.1083, 1.0898, 1.1236, 1.1113, 1.1445,\n",
      "        1.1366, 1.1385, 1.1036, 1.0977, 1.0478, 1.0055, 0.9500, 1.0299, 1.2871,\n",
      "        8.8732], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6401, 3.6353, 3.6320, 3.6332, 3.6487, 3.6175, 3.6256, 3.6366, 3.6355,\n",
      "        3.6226, 3.6093, 3.6085, 3.6074, 3.6096, 3.5900, 3.5626, 3.5206, 3.4615,\n",
      "        3.3926, 3.3043, 3.1620, 3.0354, 2.8747, 2.6946, 2.5078, 2.3287, 2.1281,\n",
      "        1.9414, 1.7707, 1.5986, 1.4346, 1.2888, 1.1508, 1.0307, 0.9184, 0.8218,\n",
      "        0.7322, 0.6560, 0.5858, 0.5222, 0.4632, 0.4155, 0.3750, 0.3372, 0.3054,\n",
      "        0.2773, 0.2545, 0.2326, 0.2145, 0.1972, 0.1807, 0.1638, 0.1465, 0.1283,\n",
      "        0.1149], grad_fn=<AddBackward0>) tensor([ 5.3543,  5.3640,  5.3620,  5.3574,  5.2056,  5.3244,  5.3226,  5.2538,\n",
      "         5.2723,  5.2680,  5.3108,  5.2619,  5.1797,  5.2887,  5.2868,  5.2709,\n",
      "         5.2429,  5.2207,  5.1009,  4.9771,  4.9170,  4.6858,  4.5751,  4.3499,\n",
      "         4.1941,  3.8986,  3.7461,  3.5086,  3.2559,  3.0669,  2.9415,  2.7199,\n",
      "         2.6302,  2.3994,  2.2662,  2.1058,  2.0410,  1.7765,  1.5987,  1.4744,\n",
      "         1.5091,  1.3617,  1.2349,  1.1514,  1.0977,  1.0739,  0.9898,  1.0279,\n",
      "         1.0332,  1.0975,  1.2497,  1.4520,  1.8979,  2.8584, 25.0111],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.4907, 6.4800, 6.4683, 6.4940, 6.4664, 6.4493, 6.4326, 6.3918, 6.3549,\n",
      "        6.2620, 6.1607, 5.9622, 5.6740, 5.2142, 4.7593, 4.2999, 3.8297, 3.3863,\n",
      "        2.9543, 2.5431, 2.1619, 1.8417, 1.5410, 1.3013, 1.0946, 0.9273, 0.7933,\n",
      "        0.6876, 0.6128, 0.5621, 0.5288, 0.5097, 0.5013, 0.4982, 0.5027, 0.5122,\n",
      "        0.5224, 0.5372, 0.5542, 0.5694, 0.5842, 0.5966, 0.6017, 0.5998, 0.5909,\n",
      "        0.5802, 0.5651, 0.5423, 0.5039, 0.4531, 0.3883, 0.3268, 0.2783, 0.2377,\n",
      "        0.1985], grad_fn=<AddBackward0>) tensor([7.8022, 7.7851, 7.7859, 7.7531, 7.8199, 7.8023, 7.7521, 7.7492, 7.7017,\n",
      "        7.5705, 7.4289, 7.2349, 6.8929, 6.4293, 5.8721, 5.3704, 4.9184, 4.4049,\n",
      "        3.8878, 3.4445, 3.0024, 2.5890, 2.3269, 2.0257, 1.7576, 1.4770, 1.3092,\n",
      "        1.1633, 1.0663, 0.9643, 0.9113, 0.9013, 0.8766, 0.9001, 0.8916, 0.9026,\n",
      "        0.9548, 0.9725, 0.9970, 1.0494, 1.0974, 1.0803, 1.1155, 1.0999, 1.1361,\n",
      "        1.1277, 1.1291, 1.0924, 1.0866, 1.0357, 0.9922, 0.9336, 1.0137, 1.2754,\n",
      "        8.7870], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6188, 3.6174, 3.6123, 3.6129, 3.6268, 3.5993, 3.6058, 3.6173, 3.6172,\n",
      "        3.6020, 3.5913, 3.5904, 3.5910, 3.5920, 3.5723, 3.5470, 3.5024, 3.4475,\n",
      "        3.3795, 3.2912, 3.1479, 3.0235, 2.8631, 2.6838, 2.4980, 2.3187, 2.1188,\n",
      "        1.9336, 1.7637, 1.5917, 1.4280, 1.2827, 1.1451, 1.0257, 0.9141, 0.8170,\n",
      "        0.7277, 0.6517, 0.5816, 0.5183, 0.4593, 0.4118, 0.3714, 0.3337, 0.3021,\n",
      "        0.2740, 0.2514, 0.2296, 0.2115, 0.1943, 0.1779, 0.1610, 0.1439, 0.1258,\n",
      "        0.1125], grad_fn=<AddBackward0>) tensor([ 5.3221,  5.3172,  5.3234,  5.3222,  5.1788,  5.2798,  5.2874,  5.2165,\n",
      "         5.2268,  5.2379,  5.2740,  5.2236,  5.1352,  5.2524,  5.2557,  5.2318,\n",
      "         5.2211,  5.1790,  5.0585,  4.9428,  4.8941,  4.6532,  4.5503,  4.3214,\n",
      "         4.1660,  3.8779,  3.7278,  3.4865,  3.2305,  3.0477,  2.9205,  2.7028,\n",
      "         2.6115,  2.3753,  2.2350,  2.0931,  2.0302,  1.7647,  1.5911,  1.4599,\n",
      "         1.4990,  1.3536,  1.2287,  1.1443,  1.0869,  1.0627,  0.9761,  1.0149,\n",
      "         1.0315,  1.0899,  1.2376,  1.4437,  1.8772,  2.8556, 24.9831],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5178, 6.5055, 6.4932, 6.5184, 6.4960, 6.4759, 6.4601, 6.4171, 6.3818,\n",
      "        6.2840, 6.1844, 5.9854, 5.6982, 5.2317, 4.7766, 4.3155, 3.8458, 3.4011,\n",
      "        2.9667, 2.5565, 2.1741, 1.8519, 1.5498, 1.3084, 1.1002, 0.9311, 0.7961,\n",
      "        0.6895, 0.6141, 0.5630, 0.5294, 0.5102, 0.5018, 0.4990, 0.5037, 0.5135,\n",
      "        0.5240, 0.5391, 0.5565, 0.5723, 0.5874, 0.6003, 0.6054, 0.6035, 0.5945,\n",
      "        0.5834, 0.5679, 0.5444, 0.5051, 0.4531, 0.3869, 0.3242, 0.2751, 0.2343,\n",
      "        0.1949], grad_fn=<AddBackward0>) tensor([7.8159, 7.8014, 7.8033, 7.7679, 7.8250, 7.8157, 7.7619, 7.7663, 7.7115,\n",
      "        7.5959, 7.4435, 7.2497, 6.8980, 6.4455, 5.8819, 5.3821, 4.9298, 4.4147,\n",
      "        3.9051, 3.4508, 3.0078, 2.5967, 2.3345, 2.0324, 1.7583, 1.4820, 1.3119,\n",
      "        1.1653, 1.0674, 0.9637, 0.9136, 0.9021, 0.8772, 0.8979, 0.8938, 0.9046,\n",
      "        0.9548, 0.9752, 1.0024, 1.0544, 1.1052, 1.0859, 1.1224, 1.1052, 1.1403,\n",
      "        1.1311, 1.1363, 1.1001, 1.0904, 1.0360, 0.9930, 0.9357, 1.0160, 1.2789,\n",
      "        8.8775], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6307, 3.6280, 3.6244, 3.6246, 3.6387, 3.6091, 3.6185, 3.6308, 3.6309,\n",
      "        3.6122, 3.6017, 3.6037, 3.6045, 3.6050, 3.5852, 3.5627, 3.5170, 3.4629,\n",
      "        3.3944, 3.3054, 3.1640, 3.0355, 2.8758, 2.6947, 2.5093, 2.3295, 2.1263,\n",
      "        1.9410, 1.7708, 1.5973, 1.4333, 1.2867, 1.1485, 1.0282, 0.9163, 0.8185,\n",
      "        0.7285, 0.6524, 0.5815, 0.5180, 0.4587, 0.4109, 0.3702, 0.3324, 0.3007,\n",
      "        0.2725, 0.2498, 0.2279, 0.2098, 0.1926, 0.1762, 0.1593, 0.1422, 0.1243,\n",
      "        0.1109], grad_fn=<AddBackward0>) tensor([ 5.3188,  5.3202,  5.3217,  5.3209,  5.1797,  5.2898,  5.2850,  5.2114,\n",
      "         5.2203,  5.2501,  5.2889,  5.2226,  5.1376,  5.2621,  5.2629,  5.2257,\n",
      "         5.2234,  5.1767,  5.0623,  4.9519,  4.8857,  4.6660,  4.5568,  4.3320,\n",
      "         4.1674,  3.8710,  3.7436,  3.4931,  3.2318,  3.0531,  2.9184,  2.7071,\n",
      "         2.6084,  2.3788,  2.2304,  2.0928,  2.0312,  1.7548,  1.5947,  1.4558,\n",
      "         1.4982,  1.3524,  1.2236,  1.1373,  1.0808,  1.0593,  0.9677,  1.0159,\n",
      "         1.0310,  1.0929,  1.2294,  1.4451,  1.8938,  2.8789, 25.2820],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5165, 6.5046, 6.4903, 6.5150, 6.4961, 6.4761, 6.4556, 6.4166, 6.3800,\n",
      "        6.2825, 6.1806, 5.9841, 5.6941, 5.2296, 4.7753, 4.3144, 3.8437, 3.4009,\n",
      "        2.9677, 2.5580, 2.1757, 1.8537, 1.5510, 1.3097, 1.1003, 0.9306, 0.7951,\n",
      "        0.6879, 0.6122, 0.5609, 0.5273, 0.5082, 0.4998, 0.4970, 0.5019, 0.5117,\n",
      "        0.5222, 0.5378, 0.5554, 0.5713, 0.5867, 0.5999, 0.6050, 0.6030, 0.5936,\n",
      "        0.5825, 0.5667, 0.5426, 0.5026, 0.4498, 0.3827, 0.3196, 0.2702, 0.2295,\n",
      "        0.1903], grad_fn=<AddBackward0>) tensor([7.7994, 7.7862, 7.7930, 7.7590, 7.8090, 7.7955, 7.7529, 7.7489, 7.7005,\n",
      "        7.5825, 7.4357, 7.2360, 6.8937, 6.4300, 5.8652, 5.3654, 4.9275, 4.4066,\n",
      "        3.8978, 3.4486, 3.0095, 2.5932, 2.3333, 2.0263, 1.7583, 1.4784, 1.3055,\n",
      "        1.1633, 1.0635, 0.9609, 0.9110, 0.8987, 0.8736, 0.8955, 0.8907, 0.9018,\n",
      "        0.9573, 0.9706, 1.0005, 1.0520, 1.1032, 1.0813, 1.1214, 1.1049, 1.1435,\n",
      "        1.1291, 1.1352, 1.1005, 1.0886, 1.0339, 0.9894, 0.9257, 1.0157, 1.2836,\n",
      "        8.8539], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6297, 3.6259, 3.6228, 3.6250, 3.6373, 3.6095, 3.6202, 3.6311, 3.6315,\n",
      "        3.6133, 3.6010, 3.6045, 3.6044, 3.6063, 3.5867, 3.5654, 3.5208, 3.4654,\n",
      "        3.3985, 3.3086, 3.1684, 3.0402, 2.8797, 2.6996, 2.5131, 2.3337, 2.1292,\n",
      "        1.9449, 1.7733, 1.6001, 1.4354, 1.2892, 1.1505, 1.0298, 0.9172, 0.8188,\n",
      "        0.7290, 0.6526, 0.5814, 0.5175, 0.4581, 0.4099, 0.3693, 0.3313, 0.2994,\n",
      "        0.2711, 0.2483, 0.2264, 0.2082, 0.1910, 0.1745, 0.1576, 0.1405, 0.1225,\n",
      "        0.1093], grad_fn=<AddBackward0>) tensor([ 5.3023,  5.3138,  5.3126,  5.3011,  5.1700,  5.2709,  5.2640,  5.2002,\n",
      "         5.1996,  5.2322,  5.2817,  5.2102,  5.1303,  5.2543,  5.2567,  5.2178,\n",
      "         5.2078,  5.1749,  5.0549,  4.9552,  4.8792,  4.6627,  4.5566,  4.3240,\n",
      "         4.1656,  3.8672,  3.7503,  3.4875,  3.2384,  3.0515,  2.9239,  2.7000,\n",
      "         2.6027,  2.3751,  2.2323,  2.1057,  2.0280,  1.7531,  1.5875,  1.4596,\n",
      "         1.4912,  1.3586,  1.2182,  1.1358,  1.0827,  1.0563,  0.9644,  1.0167,\n",
      "         1.0310,  1.0948,  1.2379,  1.4564,  1.9002,  2.8908, 25.2864],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5369, 6.5246, 6.5114, 6.5365, 6.5200, 6.4989, 6.4764, 6.4390, 6.4000,\n",
      "        6.3015, 6.2005, 6.0045, 5.7119, 5.2436, 4.7896, 4.3273, 3.8564, 3.4130,\n",
      "        2.9795, 2.5691, 2.1845, 1.8613, 1.5575, 1.3149, 1.1041, 0.9332, 0.7966,\n",
      "        0.6886, 0.6121, 0.5605, 0.5269, 0.5077, 0.4993, 0.4966, 0.5017, 0.5117,\n",
      "        0.5224, 0.5383, 0.5563, 0.5726, 0.5884, 0.6016, 0.6071, 0.6047, 0.5952,\n",
      "        0.5840, 0.5677, 0.5431, 0.5021, 0.4480, 0.3799, 0.3161, 0.2663, 0.2254,\n",
      "        0.1862], grad_fn=<AddBackward0>) tensor([7.8146, 7.8040, 7.8106, 7.7731, 7.8159, 7.8063, 7.7711, 7.7598, 7.7190,\n",
      "        7.6050, 7.4524, 7.2456, 6.9069, 6.4457, 5.8738, 5.3740, 4.9339, 4.4148,\n",
      "        3.9022, 3.4494, 3.0221, 2.6025, 2.3362, 2.0268, 1.7596, 1.4778, 1.3007,\n",
      "        1.1579, 1.0651, 0.9618, 0.9090, 0.8966, 0.8727, 0.8937, 0.8866, 0.9007,\n",
      "        0.9596, 0.9707, 1.0011, 1.0531, 1.1046, 1.0844, 1.1238, 1.1090, 1.1508,\n",
      "        1.1292, 1.1377, 1.0990, 1.0879, 1.0402, 0.9854, 0.9227, 1.0172, 1.2966,\n",
      "        8.8495], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6207, 3.6158, 3.6130, 3.6156, 3.6282, 3.6011, 3.6105, 3.6212, 3.6233,\n",
      "        3.6055, 3.5940, 3.5950, 3.5973, 3.6010, 3.5790, 3.5598, 3.5150, 3.4606,\n",
      "        3.3935, 3.3045, 3.1637, 3.0384, 2.8780, 2.6977, 2.5117, 2.3319, 2.1277,\n",
      "        1.9443, 1.7718, 1.5988, 1.4341, 1.2881, 1.1490, 1.0289, 0.9159, 0.8177,\n",
      "        0.7275, 0.6510, 0.5798, 0.5157, 0.4562, 0.4079, 0.3671, 0.3293, 0.2973,\n",
      "        0.2689, 0.2462, 0.2243, 0.2061, 0.1890, 0.1724, 0.1556, 0.1385, 0.1206,\n",
      "        0.1074], grad_fn=<AddBackward0>) tensor([ 5.2763,  5.2952,  5.2872,  5.2764,  5.1470,  5.2396,  5.2417,  5.1796,\n",
      "         5.1746,  5.2019,  5.2554,  5.1952,  5.1065,  5.2222,  5.2420,  5.1956,\n",
      "         5.1907,  5.1594,  5.0412,  4.9354,  4.8716,  4.6463,  4.5371,  4.3058,\n",
      "         4.1466,  3.8535,  3.7346,  3.4647,  3.2287,  3.0459,  2.9142,  2.6934,\n",
      "         2.6052,  2.3643,  2.2236,  2.0922,  2.0247,  1.7479,  1.5770,  1.4552,\n",
      "         1.4871,  1.3517,  1.2181,  1.1242,  1.0770,  1.0516,  0.9577,  1.0098,\n",
      "         1.0239,  1.0948,  1.2431,  1.4580,  1.9121,  2.9037, 25.3048],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.5404, 6.5288, 6.5174, 6.5398, 6.5232, 6.5031, 6.4785, 6.4418, 6.4035,\n",
      "        6.3054, 6.2023, 6.0080, 5.7139, 5.2448, 4.7942, 4.3302, 3.8588, 3.4171,\n",
      "        2.9835, 2.5729, 2.1888, 1.8654, 1.5605, 1.3176, 1.1055, 0.9340, 0.7967,\n",
      "        0.6879, 0.6112, 0.5594, 0.5257, 0.5064, 0.4980, 0.4955, 0.5007, 0.5110,\n",
      "        0.5219, 0.5381, 0.5564, 0.5732, 0.5893, 0.6027, 0.6083, 0.6059, 0.5965,\n",
      "        0.5849, 0.5682, 0.5432, 0.5012, 0.4463, 0.3771, 0.3125, 0.2624, 0.2214,\n",
      "        0.1823], grad_fn=<AddBackward0>) tensor([7.8103, 7.7962, 7.7989, 7.7664, 7.8105, 7.8007, 7.7684, 7.7531, 7.7127,\n",
      "        7.5981, 7.4509, 7.2368, 6.9032, 6.4412, 5.8567, 5.3648, 4.9300, 4.4085,\n",
      "        3.9032, 3.4521, 3.0203, 2.6034, 2.3402, 2.0248, 1.7608, 1.4730, 1.2982,\n",
      "        1.1591, 1.0608, 0.9571, 0.9052, 0.8962, 0.8732, 0.8893, 0.8862, 0.8964,\n",
      "        0.9576, 0.9710, 1.0003, 1.0530, 1.1043, 1.0850, 1.1281, 1.1099, 1.1480,\n",
      "        1.1291, 1.1392, 1.1019, 1.0940, 1.0395, 0.9849, 0.9218, 1.0175, 1.2951,\n",
      "        8.8461], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6149, 3.6090, 3.6057, 3.6080, 3.6207, 3.5940, 3.6035, 3.6153, 3.6165,\n",
      "        3.5995, 3.5882, 3.5886, 3.5913, 3.5962, 3.5757, 3.5556, 3.5113, 3.4562,\n",
      "        3.3916, 3.3039, 3.1631, 3.0370, 2.8776, 2.6972, 2.5109, 2.3321, 2.1272,\n",
      "        1.9432, 1.7713, 1.5987, 1.4337, 1.2874, 1.1487, 1.0281, 0.9148, 0.8168,\n",
      "        0.7263, 0.6499, 0.5781, 0.5141, 0.4544, 0.4061, 0.3652, 0.3274, 0.2953,\n",
      "        0.2670, 0.2442, 0.2224, 0.2041, 0.1870, 0.1705, 0.1537, 0.1366, 0.1189,\n",
      "        0.1057], grad_fn=<AddBackward0>) tensor([ 5.2462,  5.2760,  5.2655,  5.2584,  5.1304,  5.2226,  5.2250,  5.1573,\n",
      "         5.1584,  5.1843,  5.2361,  5.1799,  5.0959,  5.2059,  5.2224,  5.1845,\n",
      "         5.1788,  5.1539,  5.0275,  4.9175,  4.8545,  4.6362,  4.5242,  4.2920,\n",
      "         4.1408,  3.8389,  3.7269,  3.4640,  3.2230,  3.0353,  2.9049,  2.6898,\n",
      "         2.5903,  2.3541,  2.2204,  2.0826,  2.0188,  1.7342,  1.5805,  1.4513,\n",
      "         1.4870,  1.3490,  1.2162,  1.1162,  1.0703,  1.0443,  0.9561,  1.0011,\n",
      "         1.0265,  1.0977,  1.2455,  1.4635,  1.9226,  2.9017, 25.4704],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5679, 6.5569, 6.5458, 6.5680, 6.5524, 6.5306, 6.5067, 6.4687, 6.4287,\n",
      "        6.3323, 6.2270, 6.0315, 5.7372, 5.2642, 4.8137, 4.3464, 3.8747, 3.4325,\n",
      "        2.9977, 2.5864, 2.2009, 1.8757, 1.5691, 1.3250, 1.1107, 0.9381, 0.7995,\n",
      "        0.6898, 0.6125, 0.5603, 0.5265, 0.5072, 0.4987, 0.4965, 0.5018, 0.5125,\n",
      "        0.5239, 0.5404, 0.5592, 0.5764, 0.5930, 0.6068, 0.6126, 0.6103, 0.6004,\n",
      "        0.5885, 0.5715, 0.5457, 0.5027, 0.4464, 0.3756, 0.3100, 0.2593, 0.2180,\n",
      "        0.1787], grad_fn=<AddBackward0>) tensor([7.8286, 7.8125, 7.8102, 7.7808, 7.8241, 7.8130, 7.7830, 7.7678, 7.7304,\n",
      "        7.6118, 7.4686, 7.2549, 6.9139, 6.4581, 5.8634, 5.3803, 4.9405, 4.4190,\n",
      "        3.9147, 3.4621, 3.0252, 2.6121, 2.3480, 2.0246, 1.7699, 1.4775, 1.3020,\n",
      "        1.1592, 1.0606, 0.9594, 0.9044, 0.8964, 0.8761, 0.8895, 0.8888, 0.9001,\n",
      "        0.9570, 0.9751, 1.0038, 1.0615, 1.1084, 1.0931, 1.1347, 1.1161, 1.1555,\n",
      "        1.1389, 1.1452, 1.1075, 1.1017, 1.0407, 0.9895, 0.9215, 1.0217, 1.3003,\n",
      "        8.8692], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6122, 3.6063, 3.6028, 3.6050, 3.6156, 3.5907, 3.5997, 3.6119, 3.6127,\n",
      "        3.5963, 3.5860, 3.5871, 3.5903, 3.5939, 3.5742, 3.5545, 3.5131, 3.4572,\n",
      "        3.3928, 3.3041, 3.1646, 3.0394, 2.8794, 2.6993, 2.5128, 2.3331, 2.1281,\n",
      "        1.9446, 1.7727, 1.5994, 1.4341, 1.2875, 1.1494, 1.0284, 0.9140, 0.8163,\n",
      "        0.7255, 0.6491, 0.5770, 0.5127, 0.4529, 0.4046, 0.3634, 0.3257, 0.2935,\n",
      "        0.2651, 0.2422, 0.2204, 0.2021, 0.1850, 0.1684, 0.1516, 0.1345, 0.1170,\n",
      "        0.1037], grad_fn=<AddBackward0>) tensor([ 5.2273,  5.2552,  5.2447,  5.2382,  5.1205,  5.2061,  5.2107,  5.1431,\n",
      "         5.1501,  5.1724,  5.2169,  5.1642,  5.0768,  5.1988,  5.2132,  5.1768,\n",
      "         5.1581,  5.1427,  5.0150,  4.9101,  4.8444,  4.6248,  4.5157,  4.2791,\n",
      "         4.1305,  3.8344,  3.7265,  3.4549,  3.2108,  3.0316,  2.9000,  2.6869,\n",
      "         2.5778,  2.3410,  2.2283,  2.0766,  2.0153,  1.7247,  1.5751,  1.4484,\n",
      "         1.4888,  1.3448,  1.2166,  1.1099,  1.0601,  1.0386,  0.9463,  0.9957,\n",
      "         1.0238,  1.0913,  1.2447,  1.4678,  1.9257,  2.8760, 25.4280],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5133, 6.5028, 6.4887, 6.5117, 6.4991, 6.4764, 6.4535, 6.4153, 6.3757,\n",
      "        6.2788, 6.1736, 5.9811, 5.6875, 5.2183, 4.7740, 4.3097, 3.8437, 3.4055,\n",
      "        2.9753, 2.5675, 2.1862, 1.8631, 1.5593, 1.3162, 1.1030, 0.9310, 0.7930,\n",
      "        0.6837, 0.6068, 0.5548, 0.5213, 0.5022, 0.4940, 0.4918, 0.4973, 0.5080,\n",
      "        0.5195, 0.5363, 0.5553, 0.5728, 0.5895, 0.6034, 0.6093, 0.6069, 0.5969,\n",
      "        0.5847, 0.5677, 0.5415, 0.4981, 0.4411, 0.3700, 0.3042, 0.2537, 0.2128,\n",
      "        0.1739], grad_fn=<AddBackward0>) tensor([7.7539, 7.7379, 7.7453, 7.7112, 7.7504, 7.7375, 7.7102, 7.6916, 7.6566,\n",
      "        7.5429, 7.4015, 7.1847, 6.8530, 6.3995, 5.8028, 5.3303, 4.8931, 4.3809,\n",
      "        3.8797, 3.4355, 2.9970, 2.5919, 2.3235, 2.0082, 1.7541, 1.4655, 1.2902,\n",
      "        1.1487, 1.0485, 0.9539, 0.8947, 0.8867, 0.8679, 0.8806, 0.8806, 0.8933,\n",
      "        0.9512, 0.9662, 0.9985, 1.0555, 1.1012, 1.0881, 1.1263, 1.1140, 1.1510,\n",
      "        1.1322, 1.1365, 1.0977, 1.0903, 1.0315, 0.9794, 0.9181, 1.0173, 1.2930,\n",
      "        8.8067], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6365, 3.6321, 3.6281, 3.6309, 3.6416, 3.6148, 3.6263, 3.6378, 3.6390,\n",
      "        3.6227, 3.6130, 3.6137, 3.6168, 3.6209, 3.6008, 3.5817, 3.5424, 3.4848,\n",
      "        3.4204, 3.3328, 3.1928, 3.0656, 2.9045, 2.7222, 2.5341, 2.3526, 2.1460,\n",
      "        1.9618, 1.7875, 1.6121, 1.4462, 1.2971, 1.1585, 1.0356, 0.9209, 0.8215,\n",
      "        0.7303, 0.6530, 0.5801, 0.5150, 0.4546, 0.4059, 0.3643, 0.3262, 0.2937,\n",
      "        0.2651, 0.2420, 0.2200, 0.2016, 0.1843, 0.1677, 0.1507, 0.1336, 0.1158,\n",
      "        0.1027], grad_fn=<AddBackward0>) tensor([ 5.2524,  5.2728,  5.2678,  5.2541,  5.1369,  5.2351,  5.2267,  5.1650,\n",
      "         5.1727,  5.1945,  5.2361,  5.1887,  5.1003,  5.2275,  5.2432,  5.2067,\n",
      "         5.1744,  5.1689,  5.0453,  4.9291,  4.8597,  4.6433,  4.5357,  4.3006,\n",
      "         4.1506,  3.8540,  3.7436,  3.4584,  3.2224,  3.0479,  2.9054,  2.7096,\n",
      "         2.5816,  2.3571,  2.2293,  2.0899,  2.0197,  1.7261,  1.5769,  1.4567,\n",
      "         1.4935,  1.3478,  1.2222,  1.1125,  1.0595,  1.0382,  0.9528,  0.9984,\n",
      "         1.0259,  1.1015,  1.2546,  1.4899,  1.9343,  2.9217, 25.5960],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5584, 6.5482, 6.5346, 6.5578, 6.5453, 6.5205, 6.5001, 6.4610, 6.4203,\n",
      "        6.3234, 6.2159, 6.0236, 5.7277, 5.2539, 4.8071, 4.3401, 3.8710, 3.4327,\n",
      "        3.0006, 2.5894, 2.2058, 1.8800, 1.5741, 1.3285, 1.1127, 0.9387, 0.7992,\n",
      "        0.6883, 0.6107, 0.5580, 0.5242, 0.5049, 0.4969, 0.4949, 0.5005, 0.5116,\n",
      "        0.5235, 0.5409, 0.5604, 0.5786, 0.5958, 0.6100, 0.6161, 0.6137, 0.6035,\n",
      "        0.5908, 0.5732, 0.5460, 0.5015, 0.4428, 0.3699, 0.3028, 0.2516, 0.2103,\n",
      "        0.1711], grad_fn=<AddBackward0>) tensor([7.8017, 7.7804, 7.7885, 7.7543, 7.7919, 7.7837, 7.7507, 7.7346, 7.6994,\n",
      "        7.5847, 7.4468, 7.2258, 6.8894, 6.4333, 5.8301, 5.3595, 4.9250, 4.4014,\n",
      "        3.8987, 3.4572, 3.0160, 2.6139, 2.3371, 2.0215, 1.7697, 1.4756, 1.2960,\n",
      "        1.1541, 1.0497, 0.9570, 0.8958, 0.8923, 0.8726, 0.8840, 0.8861, 0.9011,\n",
      "        0.9581, 0.9727, 1.0084, 1.0644, 1.1114, 1.0989, 1.1400, 1.1256, 1.1613,\n",
      "        1.1464, 1.1470, 1.1110, 1.1007, 1.0376, 0.9850, 0.9223, 1.0224, 1.3125,\n",
      "        8.9106], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6636, 3.6576, 3.6529, 3.6562, 3.6665, 3.6400, 3.6537, 3.6636, 3.6656,\n",
      "        3.6482, 3.6393, 3.6415, 3.6449, 3.6490, 3.6294, 3.6090, 3.5704, 3.5126,\n",
      "        3.4480, 3.3622, 3.2201, 3.0946, 2.9294, 2.7470, 2.5560, 2.3726, 2.1646,\n",
      "        1.9788, 1.8031, 1.6257, 1.4583, 1.3074, 1.1677, 1.0433, 0.9279, 0.8273,\n",
      "        0.7348, 0.6568, 0.5833, 0.5173, 0.4564, 0.4072, 0.3651, 0.3266, 0.2938,\n",
      "        0.2650, 0.2416, 0.2196, 0.2010, 0.1836, 0.1668, 0.1498, 0.1326, 0.1147,\n",
      "        0.1016], grad_fn=<AddBackward0>) tensor([ 5.2666,  5.2959,  5.2943,  5.2801,  5.1613,  5.2609,  5.2421,  5.1901,\n",
      "         5.1958,  5.2225,  5.2623,  5.2091,  5.1211,  5.2528,  5.2664,  5.2431,\n",
      "         5.2063,  5.2035,  5.0792,  4.9515,  4.8877,  4.6546,  4.5616,  4.3166,\n",
      "         4.1732,  3.8765,  3.7655,  3.4785,  3.2371,  3.0654,  2.9204,  2.7267,\n",
      "         2.5965,  2.3723,  2.2343,  2.0986,  2.0370,  1.7387,  1.5809,  1.4648,\n",
      "         1.4923,  1.3483,  1.2212,  1.1161,  1.0667,  1.0344,  0.9588,  0.9989,\n",
      "         1.0358,  1.1173,  1.2753,  1.5008,  1.9467,  2.9621, 25.8589],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.5503, 6.5435, 6.5283, 6.5522, 6.5406, 6.5152, 6.4920, 6.4568, 6.4147,\n",
      "        6.3167, 6.2114, 6.0195, 5.7223, 5.2495, 4.8031, 4.3358, 3.8675, 3.4312,\n",
      "        3.0004, 2.5897, 2.2068, 1.8806, 1.5744, 1.3288, 1.1125, 0.9379, 0.7978,\n",
      "        0.6866, 0.6087, 0.5559, 0.5220, 0.5028, 0.4948, 0.4930, 0.4988, 0.5099,\n",
      "        0.5221, 0.5396, 0.5595, 0.5780, 0.5954, 0.6099, 0.6161, 0.6136, 0.6030,\n",
      "        0.5901, 0.5723, 0.5445, 0.4995, 0.4398, 0.3660, 0.2985, 0.2472, 0.2060,\n",
      "        0.1670], grad_fn=<AddBackward0>) tensor([7.7934, 7.7626, 7.7741, 7.7407, 7.7733, 7.7665, 7.7427, 7.7136, 7.6822,\n",
      "        7.5711, 7.4254, 7.2083, 6.8718, 6.4128, 5.8084, 5.3456, 4.9142, 4.3933,\n",
      "        3.8916, 3.4516, 3.0105, 2.6132, 2.3401, 2.0187, 1.7636, 1.4710, 1.2931,\n",
      "        1.1496, 1.0438, 0.9535, 0.8928, 0.8894, 0.8689, 0.8799, 0.8821, 0.8949,\n",
      "        0.9536, 0.9715, 1.0053, 1.0589, 1.1063, 1.0976, 1.1385, 1.1266, 1.1625,\n",
      "        1.1452, 1.1469, 1.1126, 1.0919, 1.0344, 0.9830, 0.9199, 1.0163, 1.3087,\n",
      "        8.9022], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6251, 3.6201, 3.6157, 3.6185, 3.6283, 3.6049, 3.6151, 3.6258, 3.6288,\n",
      "        3.6123, 3.6024, 3.6042, 3.6084, 3.6131, 3.5950, 3.5734, 3.5392, 3.4786,\n",
      "        3.4152, 3.3303, 3.1914, 3.0668, 2.9032, 2.7234, 2.5319, 2.3496, 2.1451,\n",
      "        1.9586, 1.7855, 1.6107, 1.4447, 1.2943, 1.1561, 1.0329, 0.9179, 0.8186,\n",
      "        0.7270, 0.6490, 0.5764, 0.5110, 0.4504, 0.4018, 0.3599, 0.3217, 0.2894,\n",
      "        0.2607, 0.2376, 0.2158, 0.1973, 0.1802, 0.1636, 0.1467, 0.1298, 0.1123,\n",
      "        0.0992], grad_fn=<AddBackward0>) tensor([ 5.2052,  5.2294,  5.2268,  5.2136,  5.0989,  5.1833,  5.1826,  5.1297,\n",
      "         5.1276,  5.1538,  5.1978,  5.1494,  5.0607,  5.1891,  5.1999,  5.1861,\n",
      "         5.1338,  5.1478,  5.0259,  4.8990,  4.8250,  4.5970,  4.5057,  4.2568,\n",
      "         4.1285,  3.8410,  3.7180,  3.4528,  3.2058,  3.0239,  2.8820,  2.7013,\n",
      "         2.5671,  2.3377,  2.2183,  2.0701,  2.0091,  1.7249,  1.5665,  1.4443,\n",
      "         1.4813,  1.3293,  1.2064,  1.1075,  1.0410,  1.0224,  0.9524,  0.9854,\n",
      "         1.0288,  1.1068,  1.2636,  1.4953,  1.9448,  2.9182, 25.8172],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5687, 6.5600, 6.5469, 6.5706, 6.5576, 6.5308, 6.5087, 6.4714, 6.4330,\n",
      "        6.3344, 6.2277, 6.0336, 5.7363, 5.2605, 4.8147, 4.3464, 3.8769, 3.4405,\n",
      "        3.0090, 2.5976, 2.2141, 1.8872, 1.5798, 1.3327, 1.1153, 0.9392, 0.7981,\n",
      "        0.6861, 0.6080, 0.5547, 0.5206, 0.5014, 0.4934, 0.4916, 0.4975, 0.5087,\n",
      "        0.5211, 0.5387, 0.5589, 0.5776, 0.5952, 0.6097, 0.6162, 0.6134, 0.6026,\n",
      "        0.5893, 0.5711, 0.5427, 0.4969, 0.4363, 0.3618, 0.2938, 0.2425, 0.2015,\n",
      "        0.1628], grad_fn=<AddBackward0>) tensor([7.8008, 7.7749, 7.7811, 7.7467, 7.7860, 7.7803, 7.7528, 7.7314, 7.6879,\n",
      "        7.5786, 7.4341, 7.2211, 6.8790, 6.4212, 5.8108, 5.3478, 4.9217, 4.4006,\n",
      "        3.9013, 3.4613, 3.0158, 2.6172, 2.3372, 2.0189, 1.7611, 1.4700, 1.2953,\n",
      "        1.1473, 1.0384, 0.9528, 0.8901, 0.8843, 0.8657, 0.8775, 0.8802, 0.8909,\n",
      "        0.9516, 0.9708, 1.0019, 1.0563, 1.1048, 1.0985, 1.1347, 1.1229, 1.1616,\n",
      "        1.1429, 1.1444, 1.1102, 1.0873, 1.0313, 0.9784, 0.9157, 1.0057, 1.3004,\n",
      "        8.8348], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6374, 3.6283, 3.6280, 3.6267, 3.6382, 3.6152, 3.6249, 3.6371, 3.6396,\n",
      "        3.6228, 3.6142, 3.6157, 3.6195, 3.6270, 3.6074, 3.5873, 3.5525, 3.4912,\n",
      "        3.4276, 3.3446, 3.2055, 3.0799, 2.9152, 2.7359, 2.5423, 2.3583, 2.1547,\n",
      "        1.9667, 1.7926, 1.6174, 1.4504, 1.2988, 1.1602, 1.0364, 0.9207, 0.8209,\n",
      "        0.7288, 0.6500, 0.5770, 0.5112, 0.4504, 0.4015, 0.3592, 0.3209, 0.2884,\n",
      "        0.2596, 0.2364, 0.2145, 0.1960, 0.1788, 0.1622, 0.1454, 0.1284, 0.1109,\n",
      "        0.0977], grad_fn=<AddBackward0>) tensor([ 5.1913,  5.2381,  5.2173,  5.2251,  5.0986,  5.1855,  5.1883,  5.1305,\n",
      "         5.1305,  5.1575,  5.1990,  5.1511,  5.0653,  5.1843,  5.2084,  5.1869,\n",
      "         5.1422,  5.1580,  5.0387,  4.9013,  4.8282,  4.6039,  4.5155,  4.2592,\n",
      "         4.1394,  3.8588,  3.7183,  3.4579,  3.2163,  3.0282,  2.8864,  2.7124,\n",
      "         2.5757,  2.3392,  2.2218,  2.0696,  2.0013,  1.7293,  1.5661,  1.4464,\n",
      "         1.4788,  1.3264,  1.2072,  1.1046,  1.0422,  1.0215,  0.9522,  0.9837,\n",
      "         1.0315,  1.1037,  1.2650,  1.4915,  1.9550,  2.9339, 26.0295],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5558, 6.5450, 6.5291, 6.5560, 6.5445, 6.5168, 6.4959, 6.4577, 6.4210,\n",
      "        6.3223, 6.2143, 6.0195, 5.7238, 5.2469, 4.8034, 4.3378, 3.8699, 3.4347,\n",
      "        3.0042, 2.5950, 2.2122, 1.8858, 1.5789, 1.3314, 1.1137, 0.9372, 0.7959,\n",
      "        0.6836, 0.6054, 0.5519, 0.5179, 0.4987, 0.4909, 0.4891, 0.4952, 0.5066,\n",
      "        0.5192, 0.5369, 0.5573, 0.5763, 0.5942, 0.6088, 0.6154, 0.6125, 0.6014,\n",
      "        0.5879, 0.5693, 0.5404, 0.4940, 0.4326, 0.3574, 0.2892, 0.2379, 0.1971,\n",
      "        0.1587], grad_fn=<AddBackward0>) tensor([7.7733, 7.7514, 7.7638, 7.7216, 7.7577, 7.7575, 7.7237, 7.7052, 7.6584,\n",
      "        7.5483, 7.4095, 7.2023, 6.8547, 6.4032, 5.7890, 5.3256, 4.9022, 4.3872,\n",
      "        3.8923, 3.4471, 3.0094, 2.6083, 2.3296, 2.0130, 1.7564, 1.4671, 1.2908,\n",
      "        1.1407, 1.0335, 0.9492, 0.8850, 0.8811, 0.8602, 0.8735, 0.8743, 0.8867,\n",
      "        0.9498, 0.9681, 1.0008, 1.0558, 1.1031, 1.0950, 1.1296, 1.1211, 1.1552,\n",
      "        1.1376, 1.1415, 1.1061, 1.0829, 1.0255, 0.9726, 0.9109, 1.0043, 1.2990,\n",
      "        8.8367], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6585, 3.6492, 3.6491, 3.6476, 3.6583, 3.6349, 3.6455, 3.6556, 3.6602,\n",
      "        3.6425, 3.6365, 3.6365, 3.6409, 3.6500, 3.6316, 3.6089, 3.5764, 3.5133,\n",
      "        3.4498, 3.3682, 3.2284, 3.1021, 2.9372, 2.7552, 2.5599, 2.3749, 2.1698,\n",
      "        1.9810, 1.8057, 1.6277, 1.4609, 1.3070, 1.1673, 1.0430, 0.9261, 0.8253,\n",
      "        0.7325, 0.6531, 0.5793, 0.5127, 0.4515, 0.4021, 0.3595, 0.3209, 0.2881,\n",
      "        0.2591, 0.2357, 0.2138, 0.1951, 0.1779, 0.1612, 0.1443, 0.1273, 0.1099,\n",
      "        0.0965], grad_fn=<AddBackward0>) tensor([ 5.2004,  5.2487,  5.2285,  5.2352,  5.1130,  5.2030,  5.2039,  5.1578,\n",
      "         5.1475,  5.1808,  5.2106,  5.1710,  5.0853,  5.2015,  5.2214,  5.2149,\n",
      "         5.1604,  5.1857,  5.0638,  4.9205,  4.8484,  4.6184,  4.5272,  4.2799,\n",
      "         4.1622,  3.8750,  3.7379,  3.4700,  3.2256,  3.0515,  2.8924,  2.7320,\n",
      "         2.5929,  2.3477,  2.2296,  2.0820,  2.0086,  1.7315,  1.5678,  1.4589,\n",
      "         1.4800,  1.3288,  1.2096,  1.1027,  1.0386,  1.0239,  0.9574,  0.9857,\n",
      "         1.0397,  1.1094,  1.2788,  1.5044,  1.9754,  2.9550, 26.3500],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5684, 6.5563, 6.5399, 6.5673, 6.5584, 6.5284, 6.5058, 6.4691, 6.4317,\n",
      "        6.3336, 6.2243, 6.0293, 5.7333, 5.2559, 4.8107, 4.3451, 3.8768, 3.4436,\n",
      "        3.0131, 2.6022, 2.2193, 1.8928, 1.5850, 1.3367, 1.1173, 0.9395, 0.7976,\n",
      "        0.6844, 0.6057, 0.5520, 0.5177, 0.4986, 0.4910, 0.4893, 0.4956, 0.5073,\n",
      "        0.5202, 0.5382, 0.5591, 0.5787, 0.5968, 0.6117, 0.6186, 0.6156, 0.6042,\n",
      "        0.5903, 0.5714, 0.5417, 0.4943, 0.4317, 0.3552, 0.2863, 0.2345, 0.1937,\n",
      "        0.1554], grad_fn=<AddBackward0>) tensor([7.7705, 7.7561, 7.7674, 7.7236, 7.7531, 7.7595, 7.7298, 7.7058, 7.6617,\n",
      "        7.5496, 7.4141, 7.2053, 6.8529, 6.3980, 5.7871, 5.3245, 4.9051, 4.3840,\n",
      "        3.8918, 3.4568, 3.0130, 2.6105, 2.3304, 2.0130, 1.7602, 1.4702, 1.2896,\n",
      "        1.1412, 1.0309, 0.9482, 0.8845, 0.8801, 0.8590, 0.8746, 0.8759, 0.8868,\n",
      "        0.9527, 0.9733, 1.0028, 1.0583, 1.1087, 1.1011, 1.1327, 1.1280, 1.1604,\n",
      "        1.1431, 1.1449, 1.1157, 1.0883, 1.0260, 0.9731, 0.9046, 1.0039, 1.2905,\n",
      "        8.8195], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6524, 3.6428, 3.6442, 3.6433, 3.6521, 3.6300, 3.6417, 3.6501, 3.6558,\n",
      "        3.6381, 3.6308, 3.6318, 3.6372, 3.6458, 3.6268, 3.6066, 3.5747, 3.5119,\n",
      "        3.4495, 3.3669, 3.2290, 3.1014, 2.9370, 2.7543, 2.5600, 2.3747, 2.1697,\n",
      "        1.9803, 1.8057, 1.6267, 1.4598, 1.3062, 1.1660, 1.0416, 0.9245, 0.8233,\n",
      "        0.7310, 0.6513, 0.5772, 0.5105, 0.4493, 0.3998, 0.3571, 0.3186, 0.2857,\n",
      "        0.2569, 0.2335, 0.2116, 0.1930, 0.1758, 0.1592, 0.1424, 0.1256, 0.1084,\n",
      "        0.0949], grad_fn=<AddBackward0>) tensor([ 5.1849,  5.2360,  5.2075,  5.2100,  5.0965,  5.1850,  5.1789,  5.1441,\n",
      "         5.1278,  5.1611,  5.2010,  5.1581,  5.0707,  5.1927,  5.2183,  5.2020,\n",
      "         5.1476,  5.1723,  5.0498,  4.9124,  4.8324,  4.6110,  4.5203,  4.2755,\n",
      "         4.1529,  3.8658,  3.7255,  3.4613,  3.2097,  3.0478,  2.8891,  2.7207,\n",
      "         2.5858,  2.3401,  2.2233,  2.0855,  1.9920,  1.7193,  1.5619,  1.4522,\n",
      "         1.4688,  1.3220,  1.2046,  1.0999,  1.0323,  1.0176,  0.9512,  0.9799,\n",
      "         1.0375,  1.1061,  1.2776,  1.5017,  1.9743,  2.9718, 26.6119],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.5721, 6.5601, 6.5435, 6.5714, 6.5631, 6.5318, 6.5107, 6.4733, 6.4337,\n",
      "        6.3366, 6.2293, 6.0325, 5.7354, 5.2567, 4.8127, 4.3468, 3.8796, 3.4469,\n",
      "        3.0175, 2.6067, 2.2244, 1.8975, 1.5886, 1.3397, 1.1191, 0.9405, 0.7977,\n",
      "        0.6840, 0.6049, 0.5511, 0.5166, 0.4976, 0.4899, 0.4885, 0.4948, 0.5067,\n",
      "        0.5199, 0.5382, 0.5595, 0.5794, 0.5980, 0.6130, 0.6202, 0.6170, 0.6054,\n",
      "        0.5912, 0.5719, 0.5416, 0.4934, 0.4297, 0.3523, 0.2827, 0.2309, 0.1901,\n",
      "        0.1519], grad_fn=<AddBackward0>) tensor([7.7674, 7.7508, 7.7636, 7.7191, 7.7487, 7.7534, 7.7230, 7.7009, 7.6617,\n",
      "        7.5464, 7.4044, 7.1981, 6.8520, 6.3955, 5.7805, 5.3218, 4.9043, 4.3852,\n",
      "        3.8916, 3.4613, 3.0124, 2.6092, 2.3330, 2.0132, 1.7631, 1.4666, 1.2884,\n",
      "        1.1380, 1.0295, 0.9438, 0.8843, 0.8754, 0.8579, 0.8696, 0.8745, 0.8865,\n",
      "        0.9508, 0.9721, 1.0044, 1.0624, 1.1102, 1.1052, 1.1368, 1.1326, 1.1624,\n",
      "        1.1452, 1.1507, 1.1168, 1.0859, 1.0242, 0.9746, 0.9043, 0.9968, 1.2897,\n",
      "        8.8207], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6800, 3.6710, 3.6733, 3.6716, 3.6796, 3.6566, 3.6707, 3.6784, 3.6831,\n",
      "        3.6668, 3.6586, 3.6610, 3.6659, 3.6779, 3.6566, 3.6359, 3.6070, 3.5434,\n",
      "        3.4799, 3.3972, 3.2582, 3.1316, 2.9641, 2.7811, 2.5847, 2.3973, 2.1897,\n",
      "        1.9993, 1.8226, 1.6419, 1.4729, 1.3182, 1.1761, 1.0503, 0.9322, 0.8299,\n",
      "        0.7366, 0.6558, 0.5809, 0.5133, 0.4516, 0.4015, 0.3584, 0.3194, 0.2862,\n",
      "        0.2571, 0.2334, 0.2114, 0.1926, 0.1753, 0.1585, 0.1416, 0.1247, 0.1075,\n",
      "        0.0939], grad_fn=<AddBackward0>) tensor([ 5.2118,  5.2604,  5.2281,  5.2342,  5.1216,  5.2192,  5.2002,  5.1704,\n",
      "         5.1609,  5.1885,  5.2315,  5.1845,  5.1047,  5.2113,  5.2560,  5.2433,\n",
      "         5.1725,  5.2021,  5.0858,  4.9491,  4.8684,  4.6343,  4.5519,  4.2954,\n",
      "         4.1738,  3.8855,  3.7495,  3.4786,  3.2263,  3.0628,  2.9107,  2.7321,\n",
      "         2.6018,  2.3581,  2.2359,  2.0903,  1.9971,  1.7305,  1.5702,  1.4626,\n",
      "         1.4761,  1.3289,  1.2081,  1.1041,  1.0339,  1.0203,  0.9558,  0.9804,\n",
      "         1.0505,  1.1123,  1.2829,  1.5136,  1.9915,  2.9678, 26.9103],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5615, 6.5504, 6.5326, 6.5623, 6.5537, 6.5239, 6.4995, 6.4625, 6.4242,\n",
      "        6.3274, 6.2193, 6.0243, 5.7260, 5.2476, 4.8027, 4.3390, 3.8741, 3.4423,\n",
      "        3.0144, 2.6055, 2.2240, 1.8970, 1.5887, 1.3392, 1.1179, 0.9390, 0.7960,\n",
      "        0.6818, 0.6024, 0.5487, 0.5141, 0.4952, 0.4876, 0.4862, 0.4928, 0.5049,\n",
      "        0.5182, 0.5368, 0.5584, 0.5788, 0.5975, 0.6128, 0.6203, 0.6170, 0.6053,\n",
      "        0.5911, 0.5714, 0.5407, 0.4918, 0.4273, 0.3491, 0.2791, 0.2271, 0.1864,\n",
      "        0.1485], grad_fn=<AddBackward0>) tensor([7.7496, 7.7293, 7.7434, 7.6943, 7.7256, 7.7249, 7.7056, 7.6814, 7.6379,\n",
      "        7.5217, 7.3835, 7.1719, 6.8331, 6.3738, 5.7666, 5.3094, 4.8898, 4.3770,\n",
      "        3.8838, 3.4557, 3.0061, 2.6055, 2.3250, 2.0084, 1.7629, 1.4632, 1.2836,\n",
      "        1.1358, 1.0278, 0.9382, 0.8810, 0.8705, 0.8529, 0.8644, 0.8690, 0.8819,\n",
      "        0.9482, 0.9656, 1.0010, 1.0586, 1.1116, 1.1091, 1.1363, 1.1321, 1.1645,\n",
      "        1.1393, 1.1516, 1.1176, 1.0864, 1.0244, 0.9738, 0.9009, 0.9987, 1.2874,\n",
      "        8.7631], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6615, 3.6531, 3.6548, 3.6541, 3.6606, 3.6375, 3.6538, 3.6591, 3.6644,\n",
      "        3.6464, 3.6403, 3.6434, 3.6500, 3.6623, 3.6417, 3.6207, 3.5915, 3.5297,\n",
      "        3.4673, 3.3847, 3.2477, 3.1215, 2.9527, 2.7712, 2.5766, 2.3886, 2.1819,\n",
      "        1.9930, 1.8158, 1.6356, 1.4671, 1.3129, 1.1712, 1.0457, 0.9273, 0.8257,\n",
      "        0.7329, 0.6516, 0.5770, 0.5095, 0.4480, 0.3981, 0.3549, 0.3160, 0.2830,\n",
      "        0.2540, 0.2304, 0.2085, 0.1898, 0.1725, 0.1559, 0.1391, 0.1222, 0.1052,\n",
      "        0.0919], grad_fn=<AddBackward0>) tensor([ 5.1795,  5.2231,  5.1924,  5.1956,  5.0908,  5.1911,  5.1601,  5.1447,\n",
      "         5.1336,  5.1699,  5.2046,  5.1542,  5.0692,  5.1760,  5.2200,  5.2134,\n",
      "         5.1481,  5.1713,  5.0556,  4.9225,  4.8355,  4.6034,  4.5363,  4.2719,\n",
      "         4.1453,  3.8662,  3.7301,  3.4521,  3.2091,  3.0460,  2.8940,  2.7125,\n",
      "         2.5853,  2.3416,  2.2298,  2.0713,  1.9706,  1.7229,  1.5605,  1.4532,\n",
      "         1.4642,  1.3084,  1.1981,  1.0935,  1.0271,  1.0106,  0.9457,  0.9743,\n",
      "         1.0411,  1.1019,  1.2724,  1.5000,  1.9786,  2.9466, 26.7085],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5753, 6.5648, 6.5454, 6.5770, 6.5678, 6.5400, 6.5130, 6.4771, 6.4384,\n",
      "        6.3425, 6.2343, 6.0375, 5.7370, 5.2579, 4.8129, 4.3491, 3.8843, 3.4509,\n",
      "        3.0241, 2.6146, 2.2326, 1.9047, 1.5951, 1.3443, 1.1217, 0.9419, 0.7976,\n",
      "        0.6827, 0.6029, 0.5490, 0.5140, 0.4953, 0.4877, 0.4866, 0.4933, 0.5056,\n",
      "        0.5194, 0.5382, 0.5603, 0.5812, 0.6004, 0.6160, 0.6238, 0.6204, 0.6085,\n",
      "        0.5940, 0.5737, 0.5424, 0.4925, 0.4267, 0.3472, 0.2765, 0.2241, 0.1833,\n",
      "        0.1455], grad_fn=<AddBackward0>) tensor([7.7598, 7.7379, 7.7539, 7.7011, 7.7343, 7.7300, 7.7144, 7.6878, 7.6419,\n",
      "        7.5233, 7.3881, 7.1763, 6.8407, 6.3768, 5.7662, 5.3108, 4.8913, 4.3845,\n",
      "        3.8844, 3.4600, 3.0122, 2.6104, 2.3289, 2.0171, 1.7711, 1.4653, 1.2862,\n",
      "        1.1357, 1.0256, 0.9366, 0.8835, 0.8686, 0.8516, 0.8623, 0.8673, 0.8838,\n",
      "        0.9472, 0.9683, 1.0042, 1.0638, 1.1159, 1.1125, 1.1391, 1.1374, 1.1663,\n",
      "        1.1407, 1.1549, 1.1188, 1.0918, 1.0302, 0.9754, 0.9019, 1.0034, 1.2941,\n",
      "        8.7472], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6511, 3.6435, 3.6459, 3.6462, 3.6527, 3.6291, 3.6459, 3.6507, 3.6546,\n",
      "        3.6377, 3.6321, 3.6338, 3.6441, 3.6546, 3.6334, 3.6159, 3.5857, 3.5237,\n",
      "        3.4631, 3.3828, 3.2449, 3.1180, 2.9482, 2.7689, 2.5750, 2.3863, 2.1790,\n",
      "        1.9905, 1.8141, 1.6334, 1.4655, 1.3113, 1.1696, 1.0435, 0.9253, 0.8241,\n",
      "        0.7311, 0.6497, 0.5749, 0.5074, 0.4458, 0.3960, 0.3527, 0.3138, 0.2808,\n",
      "        0.2518, 0.2282, 0.2063, 0.1876, 0.1705, 0.1538, 0.1371, 0.1203, 0.1034,\n",
      "        0.0902], grad_fn=<AddBackward0>) tensor([ 5.1562,  5.1986,  5.1630,  5.1630,  5.0599,  5.1625,  5.1293,  5.1203,\n",
      "         5.1140,  5.1478,  5.1778,  5.1392,  5.0396,  5.1556,  5.2061,  5.1844,\n",
      "         5.1282,  5.1557,  5.0328,  4.8939,  4.8094,  4.5878,  4.5295,  4.2511,\n",
      "         4.1227,  3.8474,  3.7217,  3.4425,  3.1933,  3.0398,  2.8781,  2.6946,\n",
      "         2.5732,  2.3426,  2.2305,  2.0619,  1.9637,  1.7172,  1.5620,  1.4513,\n",
      "         1.4592,  1.2980,  1.1901,  1.0907,  1.0200,  1.0054,  0.9410,  0.9688,\n",
      "         1.0352,  1.0901,  1.2711,  1.4929,  1.9815,  2.9616, 26.8292],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6055, 6.5943, 6.5750, 6.6062, 6.5962, 6.5701, 6.5414, 6.5082, 6.4675,\n",
      "        6.3708, 6.2619, 6.0629, 5.7618, 5.2806, 4.8319, 4.3672, 3.9028, 3.4676,\n",
      "        3.0399, 2.6288, 2.2455, 1.9155, 1.6046, 1.3521, 1.1279, 0.9462, 0.8006,\n",
      "        0.6847, 0.6042, 0.5500, 0.5147, 0.4959, 0.4883, 0.4874, 0.4943, 0.5068,\n",
      "        0.5207, 0.5400, 0.5625, 0.5837, 0.6032, 0.6191, 0.6270, 0.6235, 0.6112,\n",
      "        0.5962, 0.5754, 0.5433, 0.4924, 0.4253, 0.3447, 0.2732, 0.2207, 0.1798,\n",
      "        0.1422], grad_fn=<AddBackward0>) tensor([7.7799, 7.7586, 7.7743, 7.7228, 7.7574, 7.7470, 7.7384, 7.7010, 7.6590,\n",
      "        7.5454, 7.4093, 7.1976, 6.8607, 6.3885, 5.7828, 5.3254, 4.9001, 4.3933,\n",
      "        3.8949, 3.4702, 3.0228, 2.6244, 2.3389, 2.0271, 1.7762, 1.4736, 1.2898,\n",
      "        1.1382, 1.0296, 0.9371, 0.8858, 0.8681, 0.8541, 0.8613, 0.8667, 0.8838,\n",
      "        0.9508, 0.9697, 1.0061, 1.0687, 1.1245, 1.1198, 1.1453, 1.1444, 1.1698,\n",
      "        1.1484, 1.1596, 1.1250, 1.0936, 1.0283, 0.9759, 0.9026, 0.9980, 1.3006,\n",
      "        8.7438], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6648, 3.6596, 3.6616, 3.6619, 3.6684, 3.6459, 3.6630, 3.6675, 3.6711,\n",
      "        3.6545, 3.6500, 3.6504, 3.6614, 3.6729, 3.6519, 3.6342, 3.6050, 3.5445,\n",
      "        3.4842, 3.4037, 3.2642, 3.1371, 2.9675, 2.7857, 2.5921, 2.4012, 2.1931,\n",
      "        2.0033, 1.8261, 1.6440, 1.4751, 1.3191, 1.1769, 1.0498, 0.9305, 0.8285,\n",
      "        0.7348, 0.6528, 0.5773, 0.5091, 0.4470, 0.3969, 0.3530, 0.3139, 0.2806,\n",
      "        0.2514, 0.2277, 0.2057, 0.1868, 0.1696, 0.1529, 0.1362, 0.1193, 0.1024,\n",
      "        0.0892], grad_fn=<AddBackward0>) tensor([ 5.1785,  5.2079,  5.1762,  5.1751,  5.0709,  5.1663,  5.1347,  5.1276,\n",
      "         5.1270,  5.1578,  5.1833,  5.1546,  5.0565,  5.1693,  5.2221,  5.2023,\n",
      "         5.1468,  5.1674,  5.0433,  4.9065,  4.8276,  4.6059,  4.5402,  4.2669,\n",
      "         4.1336,  3.8642,  3.7320,  3.4535,  3.2010,  3.0501,  2.8865,  2.7111,\n",
      "         2.5829,  2.3521,  2.2418,  2.0687,  1.9675,  1.7175,  1.5621,  1.4560,\n",
      "         1.4593,  1.2959,  1.1988,  1.0944,  1.0211,  1.0039,  0.9414,  0.9695,\n",
      "         1.0428,  1.0952,  1.2786,  1.4960,  1.9983,  3.0067, 27.2084],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.5766, 6.5662, 6.5471, 6.5790, 6.5686, 6.5426, 6.5126, 6.4817, 6.4405,\n",
      "        6.3405, 6.2348, 6.0355, 5.7367, 5.2572, 4.8089, 4.3476, 3.8849, 3.4544,\n",
      "        3.0287, 2.6197, 2.2376, 1.9093, 1.5995, 1.3475, 1.1235, 0.9417, 0.7962,\n",
      "        0.6804, 0.6002, 0.5459, 0.5106, 0.4920, 0.4845, 0.4837, 0.4907, 0.5032,\n",
      "        0.5174, 0.5367, 0.5596, 0.5809, 0.6006, 0.6165, 0.6245, 0.6208, 0.6085,\n",
      "        0.5930, 0.5722, 0.5397, 0.4882, 0.4208, 0.3397, 0.2684, 0.2161, 0.1755,\n",
      "        0.1385], grad_fn=<AddBackward0>) tensor([7.7386, 7.7158, 7.7293, 7.6779, 7.7094, 7.7045, 7.6967, 7.6528, 7.6159,\n",
      "        7.5131, 7.3665, 7.1590, 6.8202, 6.3456, 5.7510, 5.2944, 4.8789, 4.3648,\n",
      "        3.8700, 3.4501, 3.0124, 2.6120, 2.3266, 2.0139, 1.7660, 1.4672, 1.2818,\n",
      "        1.1281, 1.0179, 0.9308, 0.8804, 0.8599, 0.8474, 0.8536, 0.8592, 0.8792,\n",
      "        0.9447, 0.9660, 0.9987, 1.0626, 1.1217, 1.1165, 1.1392, 1.1426, 1.1596,\n",
      "        1.1456, 1.1509, 1.1160, 1.0914, 1.0182, 0.9721, 0.8896, 0.9893, 1.2948,\n",
      "        8.6866], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6567, 3.6527, 3.6571, 3.6568, 3.6616, 3.6409, 3.6553, 3.6613, 3.6649,\n",
      "        3.6481, 3.6446, 3.6448, 3.6555, 3.6682, 3.6485, 3.6312, 3.6020, 3.5423,\n",
      "        3.4826, 3.4022, 3.2621, 3.1337, 2.9654, 2.7853, 2.5909, 2.3990, 2.1916,\n",
      "        2.0014, 1.8241, 1.6419, 1.4725, 1.3174, 1.1740, 1.0470, 0.9279, 0.8259,\n",
      "        0.7323, 0.6503, 0.5746, 0.5062, 0.4441, 0.3941, 0.3504, 0.3111, 0.2780,\n",
      "        0.2489, 0.2252, 0.2032, 0.1845, 0.1674, 0.1508, 0.1342, 0.1176, 0.1008,\n",
      "        0.0875], grad_fn=<AddBackward0>) tensor([ 5.1649,  5.1846,  5.1446,  5.1495,  5.0496,  5.1381,  5.1189,  5.1072,\n",
      "         5.1063,  5.1432,  5.1621,  5.1372,  5.0434,  5.1510,  5.2031,  5.1822,\n",
      "         5.1271,  5.1487,  5.0234,  4.8891,  4.8096,  4.6028,  4.5283,  4.2436,\n",
      "         4.1126,  3.8518,  3.7100,  3.4374,  3.1839,  3.0383,  2.8799,  2.6889,\n",
      "         2.5775,  2.3474,  2.2317,  2.0580,  1.9520,  1.6994,  1.5488,  1.4454,\n",
      "         1.4567,  1.2898,  1.1847,  1.0886,  1.0100,  0.9923,  0.9372,  0.9652,\n",
      "         1.0362,  1.0945,  1.2691,  1.4870,  1.9823,  3.0347, 27.4443],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6134, 6.6033, 6.5840, 6.6137, 6.6037, 6.5773, 6.5509, 6.5178, 6.4753,\n",
      "        6.3758, 6.2679, 6.0681, 5.7669, 5.2857, 4.8345, 4.3719, 3.9070, 3.4752,\n",
      "        3.0488, 2.6375, 2.2538, 1.9239, 1.6114, 1.3578, 1.1315, 0.9476, 0.8009,\n",
      "        0.6838, 0.6028, 0.5480, 0.5124, 0.4939, 0.4865, 0.4859, 0.4930, 0.5059,\n",
      "        0.5205, 0.5404, 0.5637, 0.5856, 0.6059, 0.6223, 0.6305, 0.6266, 0.6140,\n",
      "        0.5981, 0.5767, 0.5434, 0.4906, 0.4217, 0.3390, 0.2666, 0.2139, 0.1731,\n",
      "        0.1361], grad_fn=<AddBackward0>) tensor([7.7696, 7.7484, 7.7601, 7.7152, 7.7467, 7.7399, 7.7232, 7.6858, 7.6512,\n",
      "        7.5463, 7.3988, 7.1907, 6.8530, 6.3666, 5.7702, 5.3144, 4.8990, 4.3864,\n",
      "        3.8870, 3.4697, 3.0302, 2.6264, 2.3433, 2.0206, 1.7754, 1.4800, 1.2873,\n",
      "        1.1319, 1.0204, 0.9351, 0.8841, 0.8625, 0.8470, 0.8561, 0.8632, 0.8835,\n",
      "        0.9491, 0.9717, 1.0058, 1.0683, 1.1307, 1.1274, 1.1497, 1.1548, 1.1698,\n",
      "        1.1551, 1.1623, 1.1264, 1.0984, 1.0220, 0.9760, 0.8938, 0.9890, 1.3088,\n",
      "        8.7371], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6577, 3.6549, 3.6595, 3.6579, 3.6635, 3.6441, 3.6573, 3.6633, 3.6672,\n",
      "        3.6503, 3.6472, 3.6485, 3.6594, 3.6736, 3.6526, 3.6365, 3.6081, 3.5481,\n",
      "        3.4888, 3.4081, 3.2681, 3.1413, 2.9712, 2.7913, 2.5951, 2.4042, 2.1957,\n",
      "        2.0057, 1.8273, 1.6440, 1.4747, 1.3191, 1.1749, 1.0477, 0.9284, 0.8257,\n",
      "        0.7317, 0.6493, 0.5734, 0.5049, 0.4425, 0.3923, 0.3486, 0.3092, 0.2761,\n",
      "        0.2469, 0.2232, 0.2012, 0.1826, 0.1654, 0.1488, 0.1323, 0.1157, 0.0989,\n",
      "        0.0858], grad_fn=<AddBackward0>) tensor([ 5.1596,  5.1757,  5.1359,  5.1459,  5.0458,  5.1258,  5.1131,  5.1029,\n",
      "         5.0998,  5.1406,  5.1593,  5.1293,  5.0386,  5.1407,  5.2041,  5.1794,\n",
      "         5.1230,  5.1477,  5.0234,  4.8882,  4.8095,  4.5927,  4.5282,  4.2417,\n",
      "         4.1191,  3.8458,  3.7078,  3.4281,  3.1771,  3.0387,  2.8729,  2.6786,\n",
      "         2.5715,  2.3386,  2.2180,  2.0512,  1.9433,  1.6974,  1.5437,  1.4342,\n",
      "         1.4489,  1.2832,  1.1734,  1.0831,  1.0021,  0.9844,  0.9298,  0.9617,\n",
      "         1.0339,  1.0991,  1.2760,  1.4882,  1.9836,  3.0426, 27.2848],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5710, 6.5626, 6.5438, 6.5738, 6.5645, 6.5378, 6.5116, 6.4793, 6.4364,\n",
      "        6.3359, 6.2290, 6.0300, 5.7308, 5.2530, 4.8028, 4.3458, 3.8841, 3.4558,\n",
      "        3.0330, 2.6257, 2.2445, 1.9157, 1.6051, 1.3519, 1.1264, 0.9431, 0.7964,\n",
      "        0.6794, 0.5986, 0.5439, 0.5086, 0.4902, 0.4830, 0.4825, 0.4898, 0.5029,\n",
      "        0.5177, 0.5378, 0.5614, 0.5836, 0.6042, 0.6206, 0.6289, 0.6249, 0.6123,\n",
      "        0.5961, 0.5744, 0.5406, 0.4871, 0.4176, 0.3345, 0.2621, 0.2094, 0.1690,\n",
      "        0.1325], grad_fn=<AddBackward0>) tensor([7.7249, 7.6973, 7.7089, 7.6630, 7.6898, 7.6860, 7.6689, 7.6307, 7.5973,\n",
      "        7.4981, 7.3492, 7.1433, 6.8079, 6.3202, 5.7340, 5.2738, 4.8672, 4.3597,\n",
      "        3.8653, 3.4456, 3.0117, 2.6125, 2.3300, 2.0109, 1.7665, 1.4679, 1.2769,\n",
      "        1.1225, 1.0142, 0.9260, 0.8774, 0.8565, 0.8394, 0.8499, 0.8588, 0.8767,\n",
      "        0.9445, 0.9672, 1.0015, 1.0635, 1.1255, 1.1246, 1.1507, 1.1519, 1.1647,\n",
      "        1.1467, 1.1556, 1.1208, 1.0951, 1.0218, 0.9698, 0.8846, 0.9818, 1.3044,\n",
      "        8.6432], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6810, 3.6813, 3.6832, 3.6820, 3.6874, 3.6697, 3.6818, 3.6875, 3.6914,\n",
      "        3.6752, 3.6753, 3.6747, 3.6860, 3.6999, 3.6797, 3.6656, 3.6369, 3.5782,\n",
      "        3.5161, 3.4363, 3.2958, 3.1680, 2.9965, 2.8148, 2.6164, 2.4239, 2.2148,\n",
      "        2.0236, 1.8425, 1.6578, 1.4871, 1.3296, 1.1839, 1.0560, 0.9358, 0.8317,\n",
      "        0.7367, 0.6534, 0.5766, 0.5074, 0.4445, 0.3937, 0.3496, 0.3097, 0.2762,\n",
      "        0.2470, 0.2231, 0.2009, 0.1821, 0.1648, 0.1482, 0.1316, 0.1149, 0.0980,\n",
      "        0.0849], grad_fn=<AddBackward0>) tensor([ 5.1812,  5.1871,  5.1586,  5.1689,  5.0702,  5.1426,  5.1354,  5.1300,\n",
      "         5.1258,  5.1638,  5.1718,  5.1524,  5.0584,  5.1691,  5.2302,  5.1987,\n",
      "         5.1471,  5.1643,  5.0509,  4.9126,  4.8310,  4.6154,  4.5515,  4.2638,\n",
      "         4.1484,  3.8707,  3.7248,  3.4390,  3.1988,  3.0573,  2.8866,  2.6991,\n",
      "         2.5965,  2.3499,  2.2227,  2.0579,  1.9501,  1.7002,  1.5528,  1.4425,\n",
      "         1.4488,  1.2865,  1.1763,  1.0857,  1.0101,  0.9882,  0.9311,  0.9632,\n",
      "         1.0404,  1.1108,  1.2829,  1.4987,  2.0138,  3.0911, 27.5403],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.5995, 6.5891, 6.5724, 6.5999, 6.5920, 6.5675, 6.5382, 6.5078, 6.4632,\n",
      "        6.3631, 6.2553, 6.0548, 5.7534, 5.2747, 4.8205, 4.3634, 3.9008, 3.4716,\n",
      "        3.0485, 2.6405, 2.2575, 1.9269, 1.6143, 1.3598, 1.1322, 0.9474, 0.7994,\n",
      "        0.6814, 0.5998, 0.5447, 0.5092, 0.4908, 0.4836, 0.4833, 0.4908, 0.5041,\n",
      "        0.5192, 0.5396, 0.5637, 0.5863, 0.6072, 0.6239, 0.6323, 0.6281, 0.6150,\n",
      "        0.5985, 0.5762, 0.5416, 0.4869, 0.4163, 0.3321, 0.2591, 0.2063, 0.1659,\n",
      "        0.1296], grad_fn=<AddBackward0>) tensor([7.7468, 7.7238, 7.7306, 7.6925, 7.7180, 7.7031, 7.6945, 7.6523, 7.6227,\n",
      "        7.5183, 7.3701, 7.1644, 6.8305, 6.3332, 5.7546, 5.2893, 4.8830, 4.3770,\n",
      "        3.8770, 3.4570, 3.0217, 2.6230, 2.3425, 2.0137, 1.7731, 1.4712, 1.2786,\n",
      "        1.1242, 1.0169, 0.9267, 0.8763, 0.8569, 0.8411, 0.8485, 0.8610, 0.8779,\n",
      "        0.9463, 0.9700, 1.0043, 1.0666, 1.1305, 1.1323, 1.1561, 1.1577, 1.1709,\n",
      "        1.1499, 1.1530, 1.1270, 1.1010, 1.0253, 0.9702, 0.8889, 0.9812, 1.3100,\n",
      "        8.6547], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6599, 3.6612, 3.6629, 3.6598, 3.6665, 3.6498, 3.6615, 3.6659, 3.6691,\n",
      "        3.6556, 3.6569, 3.6558, 3.6666, 3.6803, 3.6622, 3.6482, 3.6201, 3.5615,\n",
      "        3.5007, 3.4219, 3.2815, 3.1537, 2.9842, 2.8027, 2.6050, 2.4127, 2.2053,\n",
      "        2.0138, 1.8347, 1.6501, 1.4800, 1.3231, 1.1779, 1.0504, 0.9305, 0.8271,\n",
      "        0.7319, 0.6491, 0.5725, 0.5034, 0.4408, 0.3901, 0.3460, 0.3064, 0.2731,\n",
      "        0.2439, 0.2201, 0.1981, 0.1794, 0.1622, 0.1457, 0.1292, 0.1126, 0.0959,\n",
      "        0.0830], grad_fn=<AddBackward0>) tensor([ 5.1430,  5.1429,  5.1179,  5.1359,  5.0278,  5.0999,  5.0960,  5.0982,\n",
      "         5.0993,  5.1254,  5.1269,  5.1126,  5.0206,  5.1367,  5.1921,  5.1618,\n",
      "         5.1098,  5.1313,  5.0156,  4.8769,  4.7998,  4.5909,  4.5211,  4.2375,\n",
      "         4.1252,  3.8520,  3.6996,  3.4245,  3.1748,  3.0359,  2.8682,  2.6832,\n",
      "         2.5815,  2.3340,  2.2111,  2.0380,  1.9417,  1.6834,  1.5371,  1.4285,\n",
      "         1.4373,  1.2775,  1.1732,  1.0750,  0.9979,  0.9778,  0.9214,  0.9544,\n",
      "         1.0307,  1.1013,  1.2727,  1.4875,  2.0034,  3.0816, 27.3977],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.6327, 6.6238, 6.6059, 6.6333, 6.6246, 6.6009, 6.5698, 6.5402, 6.4967,\n",
      "        6.3945, 6.2865, 6.0855, 5.7795, 5.2993, 4.8428, 4.3838, 3.9205, 3.4925,\n",
      "        3.0664, 2.6575, 2.2728, 1.9408, 1.6256, 1.3696, 1.1398, 0.9532, 0.8036,\n",
      "        0.6845, 0.6021, 0.5464, 0.5108, 0.4922, 0.4851, 0.4850, 0.4927, 0.5063,\n",
      "        0.5219, 0.5425, 0.5672, 0.5904, 0.6116, 0.6286, 0.6372, 0.6325, 0.6191,\n",
      "        0.6021, 0.5791, 0.5437, 0.4877, 0.4157, 0.3303, 0.2564, 0.2035, 0.1632,\n",
      "        0.1269], grad_fn=<AddBackward0>) tensor([7.7750, 7.7501, 7.7545, 7.7185, 7.7453, 7.7280, 7.7278, 7.6835, 7.6457,\n",
      "        7.5469, 7.3942, 7.1860, 6.8584, 6.3599, 5.7740, 5.3079, 4.9028, 4.3851,\n",
      "        3.8921, 3.4721, 3.0354, 2.6321, 2.3577, 2.0222, 1.7811, 1.4771, 1.2838,\n",
      "        1.1276, 1.0171, 0.9273, 0.8782, 0.8595, 0.8422, 0.8512, 0.8621, 0.8836,\n",
      "        0.9503, 0.9762, 1.0116, 1.0693, 1.1362, 1.1421, 1.1612, 1.1706, 1.1755,\n",
      "        1.1562, 1.1592, 1.1304, 1.1044, 1.0274, 0.9664, 0.8932, 0.9817, 1.3076,\n",
      "        8.7052], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6624, 3.6620, 3.6623, 3.6604, 3.6659, 3.6490, 3.6631, 3.6674, 3.6704,\n",
      "        3.6575, 3.6560, 3.6571, 3.6682, 3.6818, 3.6659, 3.6513, 3.6243, 3.5657,\n",
      "        3.5044, 3.4248, 3.2851, 3.1580, 2.9884, 2.8060, 2.6091, 2.4158, 2.2080,\n",
      "        2.0161, 1.8362, 1.6511, 1.4807, 1.3238, 1.1778, 1.0508, 0.9301, 0.8263,\n",
      "        0.7308, 0.6478, 0.5712, 0.5020, 0.4391, 0.3883, 0.3443, 0.3046, 0.2713,\n",
      "        0.2421, 0.2183, 0.1963, 0.1776, 0.1605, 0.1439, 0.1274, 0.1110, 0.0944,\n",
      "        0.0815], grad_fn=<AddBackward0>) tensor([ 5.1209,  5.1294,  5.1080,  5.1234,  5.0210,  5.0933,  5.0786,  5.0820,\n",
      "         5.0873,  5.1120,  5.1284,  5.1023,  5.0121,  5.1311,  5.1794,  5.1555,\n",
      "         5.1016,  5.1260,  5.0142,  4.8828,  4.7939,  4.5880,  4.5172,  4.2345,\n",
      "         4.1131,  3.8407,  3.6913,  3.4189,  3.1715,  3.0339,  2.8639,  2.6727,\n",
      "         2.5771,  2.3179,  2.2003,  2.0367,  1.9377,  1.6819,  1.5274,  1.4186,\n",
      "         1.4336,  1.2768,  1.1673,  1.0706,  0.9967,  0.9732,  0.9191,  0.9551,\n",
      "         1.0216,  1.0968,  1.2740,  1.5005,  2.0037,  3.0849, 27.3653],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6160, 6.6062, 6.5875, 6.6148, 6.6072, 6.5831, 6.5519, 6.5217, 6.4786,\n",
      "        6.3760, 6.2658, 6.0692, 5.7627, 5.2846, 4.8260, 4.3706, 3.9094, 3.4840,\n",
      "        3.0605, 2.6533, 2.2697, 1.9386, 1.6239, 1.3682, 1.1385, 0.9513, 0.8011,\n",
      "        0.6821, 0.5997, 0.5439, 0.5083, 0.4899, 0.4829, 0.4829, 0.4909, 0.5047,\n",
      "        0.5204, 0.5413, 0.5663, 0.5899, 0.6113, 0.6286, 0.6372, 0.6324, 0.6187,\n",
      "        0.6013, 0.5781, 0.5420, 0.4854, 0.4126, 0.3266, 0.2525, 0.1997, 0.1597,\n",
      "        0.1238], grad_fn=<AddBackward0>) tensor([7.7388, 7.7198, 7.7287, 7.6878, 7.7140, 7.6978, 7.6972, 7.6559, 7.6169,\n",
      "        7.5196, 7.3728, 7.1542, 6.8321, 6.3273, 5.7582, 5.2883, 4.8877, 4.3715,\n",
      "        3.8789, 3.4604, 3.0298, 2.6259, 2.3509, 2.0159, 1.7706, 1.4722, 1.2835,\n",
      "        1.1234, 1.0118, 0.9221, 0.8753, 0.8556, 0.8395, 0.8499, 0.8590, 0.8805,\n",
      "        0.9463, 0.9725, 1.0115, 1.0665, 1.1324, 1.1417, 1.1620, 1.1679, 1.1714,\n",
      "        1.1541, 1.1590, 1.1327, 1.1034, 1.0268, 0.9650, 0.8917, 0.9832, 1.3040,\n",
      "        8.6825], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6798, 3.6788, 3.6806, 3.6770, 3.6855, 3.6666, 3.6820, 3.6852, 3.6894,\n",
      "        3.6761, 3.6755, 3.6767, 3.6884, 3.7024, 3.6855, 3.6735, 3.6473, 3.5887,\n",
      "        3.5258, 3.4472, 3.3071, 3.1805, 3.0098, 2.8240, 2.6275, 2.4321, 2.2242,\n",
      "        2.0314, 1.8493, 1.6631, 1.4909, 1.3329, 1.1859, 1.0574, 0.9362, 0.8316,\n",
      "        0.7352, 0.6511, 0.5740, 0.5043, 0.4407, 0.3895, 0.3449, 0.3050, 0.2715,\n",
      "        0.2421, 0.2181, 0.1959, 0.1771, 0.1598, 0.1432, 0.1266, 0.1101, 0.0934,\n",
      "        0.0806], grad_fn=<AddBackward0>) tensor([ 5.1380,  5.1519,  5.1229,  5.1462,  5.0307,  5.1115,  5.0935,  5.0998,\n",
      "         5.1020,  5.1314,  5.1466,  5.1214,  5.0277,  5.1505,  5.2088,  5.1752,\n",
      "         5.1156,  5.1452,  5.0431,  4.9037,  4.8166,  4.6016,  4.5301,  4.2634,\n",
      "         4.1316,  3.8611,  3.7010,  3.4222,  3.1829,  3.0429,  2.8767,  2.6844,\n",
      "         2.5859,  2.3323,  2.2075,  2.0410,  1.9462,  1.6932,  1.5346,  1.4220,\n",
      "         1.4398,  1.2795,  1.1785,  1.0735,  1.0021,  0.9742,  0.9210,  0.9587,\n",
      "         1.0240,  1.1046,  1.2803,  1.5089,  2.0213,  3.1213, 27.5271],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6323, 6.6205, 6.6021, 6.6294, 6.6241, 6.5991, 6.5652, 6.5371, 6.4943,\n",
      "        6.3907, 6.2808, 6.0832, 5.7757, 5.2967, 4.8348, 4.3819, 3.9185, 3.4937,\n",
      "        3.0693, 2.6627, 2.2778, 1.9467, 1.6308, 1.3732, 1.1422, 0.9538, 0.8026,\n",
      "        0.6827, 0.5996, 0.5437, 0.5079, 0.4895, 0.4825, 0.4827, 0.4908, 0.5048,\n",
      "        0.5207, 0.5421, 0.5673, 0.5914, 0.6131, 0.6306, 0.6392, 0.6342, 0.6201,\n",
      "        0.6023, 0.5786, 0.5418, 0.4842, 0.4103, 0.3235, 0.2491, 0.1962, 0.1565,\n",
      "        0.1208], grad_fn=<AddBackward0>) tensor([7.7484, 7.7344, 7.7397, 7.7002, 7.7181, 7.7084, 7.7122, 7.6640, 7.6262,\n",
      "        7.5303, 7.3803, 7.1608, 6.8366, 6.3281, 5.7675, 5.2880, 4.8949, 4.3743,\n",
      "        3.8907, 3.4668, 3.0423, 2.6290, 2.3539, 2.0228, 1.7731, 1.4722, 1.2829,\n",
      "        1.1238, 1.0128, 0.9207, 0.8731, 0.8531, 0.8405, 0.8498, 0.8581, 0.8821,\n",
      "        0.9491, 0.9740, 1.0169, 1.0677, 1.1333, 1.1398, 1.1646, 1.1698, 1.1769,\n",
      "        1.1566, 1.1599, 1.1340, 1.1022, 1.0278, 0.9604, 0.8898, 0.9792, 1.2987,\n",
      "        8.6705], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6684, 3.6675, 3.6680, 3.6659, 3.6739, 3.6536, 3.6715, 3.6739, 3.6800,\n",
      "        3.6671, 3.6657, 3.6664, 3.6782, 3.6935, 3.6760, 3.6660, 3.6385, 3.5836,\n",
      "        3.5198, 3.4420, 3.3014, 3.1761, 3.0070, 2.8192, 2.6246, 2.4288, 2.2218,\n",
      "        2.0289, 1.8471, 1.6606, 1.4892, 1.3313, 1.1837, 1.0558, 0.9345, 0.8299,\n",
      "        0.7334, 0.6494, 0.5724, 0.5023, 0.4388, 0.3875, 0.3429, 0.3031, 0.2695,\n",
      "        0.2401, 0.2161, 0.1940, 0.1753, 0.1580, 0.1414, 0.1249, 0.1085, 0.0920,\n",
      "        0.0792], grad_fn=<AddBackward0>) tensor([ 5.1109,  5.1265,  5.0996,  5.1210,  5.0079,  5.0951,  5.0671,  5.0792,\n",
      "         5.0723,  5.0988,  5.1204,  5.0987,  5.0094,  5.1288,  5.1937,  5.1532,\n",
      "         5.1051,  5.1176,  5.0255,  4.8819,  4.8028,  4.5816,  4.5009,  4.2559,\n",
      "         4.1123,  3.8479,  3.6827,  3.4104,  3.1709,  3.0345,  2.8634,  2.6743,\n",
      "         2.5856,  2.3233,  2.2020,  2.0342,  1.9438,  1.6904,  1.5243,  1.4210,\n",
      "         1.4391,  1.2767,  1.1777,  1.0642,  0.9954,  0.9689,  0.9175,  0.9498,\n",
      "         1.0159,  1.1072,  1.2793,  1.5176,  2.0212,  3.1089, 27.6982],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6118, 6.5994, 6.5819, 6.6086, 6.6045, 6.5793, 6.5463, 6.5172, 6.4728,\n",
      "        6.3708, 6.2612, 6.0642, 5.7576, 5.2785, 4.8169, 4.3675, 3.9061, 3.4829,\n",
      "        3.0618, 2.6572, 2.2735, 1.9432, 1.6278, 1.3700, 1.1390, 0.9506, 0.7990,\n",
      "        0.6793, 0.5960, 0.5402, 0.5044, 0.4861, 0.4791, 0.4793, 0.4876, 0.5016,\n",
      "        0.5178, 0.5392, 0.5647, 0.5889, 0.6106, 0.6283, 0.6370, 0.6319, 0.6174,\n",
      "        0.5993, 0.5753, 0.5383, 0.4801, 0.4057, 0.3188, 0.2445, 0.1919, 0.1527,\n",
      "        0.1175], grad_fn=<AddBackward0>) tensor([7.7172, 7.7055, 7.7085, 7.6692, 7.6878, 7.6777, 7.6791, 7.6345, 7.5993,\n",
      "        7.5009, 7.3515, 7.1313, 6.8059, 6.3017, 5.7457, 5.2638, 4.8747, 4.3610,\n",
      "        3.8756, 3.4537, 3.0323, 2.6197, 2.3471, 2.0196, 1.7681, 1.4656, 1.2773,\n",
      "        1.1166, 1.0086, 0.9122, 0.8670, 0.8460, 0.8356, 0.8420, 0.8517, 0.8789,\n",
      "        0.9439, 0.9697, 1.0119, 1.0630, 1.1320, 1.1391, 1.1604, 1.1653, 1.1743,\n",
      "        1.1556, 1.1537, 1.1254, 1.1003, 1.0234, 0.9516, 0.8808, 0.9776, 1.2828,\n",
      "        8.6359], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6795, 3.6779, 3.6782, 3.6748, 3.6844, 3.6640, 3.6815, 3.6846, 3.6929,\n",
      "        3.6789, 3.6770, 3.6795, 3.6894, 3.7074, 3.6900, 3.6795, 3.6527, 3.5976,\n",
      "        3.5355, 3.4559, 3.3166, 3.1895, 3.0209, 2.8315, 2.6376, 2.4400, 2.2315,\n",
      "        2.0384, 1.8542, 1.6676, 1.4960, 1.3364, 1.1884, 1.0594, 0.9375, 0.8324,\n",
      "        0.7351, 0.6507, 0.5732, 0.5027, 0.4388, 0.3873, 0.3424, 0.3024, 0.2686,\n",
      "        0.2392, 0.2151, 0.1930, 0.1742, 0.1568, 0.1402, 0.1237, 0.1073, 0.0910,\n",
      "        0.0781], grad_fn=<AddBackward0>) tensor([ 5.1118,  5.1337,  5.1080,  5.1336,  5.0130,  5.1004,  5.0776,  5.0862,\n",
      "         5.0662,  5.1041,  5.1284,  5.1004,  5.0236,  5.1324,  5.1989,  5.1630,\n",
      "         5.1153,  5.1324,  5.0324,  4.8974,  4.8099,  4.5957,  4.5105,  4.2664,\n",
      "         4.1127,  3.8522,  3.6917,  3.4114,  3.1849,  3.0400,  2.8573,  2.6778,\n",
      "         2.5827,  2.3249,  2.2018,  2.0333,  1.9443,  1.6891,  1.5255,  1.4192,\n",
      "         1.4381,  1.2737,  1.1735,  1.0661,  0.9941,  0.9714,  0.9208,  0.9494,\n",
      "         1.0163,  1.1097,  1.2856,  1.5238,  2.0503,  3.1324, 28.0077],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.6238, 6.6112, 6.5959, 6.6219, 6.6183, 6.5919, 6.5593, 6.5296, 6.4866,\n",
      "        6.3828, 6.2717, 6.0765, 5.7680, 5.2889, 4.8236, 4.3755, 3.9144, 3.4909,\n",
      "        3.0698, 2.6652, 2.2817, 1.9501, 1.6337, 1.3747, 1.1428, 0.9527, 0.8004,\n",
      "        0.6798, 0.5960, 0.5400, 0.5040, 0.4858, 0.4789, 0.4791, 0.4876, 0.5020,\n",
      "        0.5183, 0.5402, 0.5660, 0.5905, 0.6127, 0.6306, 0.6394, 0.6341, 0.6193,\n",
      "        0.6005, 0.5761, 0.5383, 0.4791, 0.4037, 0.3159, 0.2411, 0.1886, 0.1496,\n",
      "        0.1147], grad_fn=<AddBackward0>) tensor([7.7236, 7.7134, 7.7106, 7.6727, 7.6932, 7.6841, 7.6842, 7.6391, 7.6013,\n",
      "        7.5073, 7.3613, 7.1325, 6.8080, 6.2992, 5.7509, 5.2642, 4.8749, 4.3645,\n",
      "        3.8817, 3.4587, 3.0351, 2.6259, 2.3522, 2.0290, 1.7701, 1.4728, 1.2771,\n",
      "        1.1153, 1.0100, 0.9110, 0.8683, 0.8447, 0.8362, 0.8427, 0.8500, 0.8751,\n",
      "        0.9454, 0.9670, 1.0121, 1.0644, 1.1337, 1.1404, 1.1596, 1.1687, 1.1746,\n",
      "        1.1604, 1.1547, 1.1284, 1.1041, 1.0253, 0.9448, 0.8819, 0.9799, 1.2743,\n",
      "        8.6199], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6774, 3.6744, 3.6738, 3.6720, 3.6823, 3.6632, 3.6774, 3.6815, 3.6923,\n",
      "        3.6768, 3.6743, 3.6789, 3.6897, 3.7068, 3.6916, 3.6790, 3.6524, 3.5998,\n",
      "        3.5386, 3.4573, 3.3198, 3.1935, 3.0239, 2.8337, 2.6408, 2.4422, 2.2346,\n",
      "        2.0410, 1.8554, 1.6686, 1.4969, 1.3370, 1.1893, 1.0600, 0.9370, 0.8320,\n",
      "        0.7344, 0.6498, 0.5721, 0.5013, 0.4374, 0.3856, 0.3407, 0.3006, 0.2670,\n",
      "        0.2374, 0.2133, 0.1912, 0.1724, 0.1551, 0.1385, 0.1221, 0.1056, 0.0893,\n",
      "        0.0766], grad_fn=<AddBackward0>) tensor([ 5.0922,  5.1226,  5.1028,  5.1181,  4.9972,  5.0795,  5.0731,  5.0769,\n",
      "         5.0466,  5.0927,  5.1216,  5.0809,  5.0079,  5.1255,  5.1800,  5.1617,\n",
      "         5.1134,  5.1190,  5.0171,  4.8977,  4.7991,  4.5828,  4.5027,  4.2619,\n",
      "         4.1011,  3.8461,  3.6764,  3.3953,  3.1826,  3.0384,  2.8546,  2.6744,\n",
      "         2.5643,  2.3108,  2.2013,  2.0310,  1.9364,  1.6822,  1.5139,  1.4142,\n",
      "         1.4283,  1.2721,  1.1719,  1.0688,  0.9851,  0.9684,  0.9171,  0.9512,\n",
      "         1.0179,  1.0996,  1.2901,  1.5138,  2.0426,  3.1573, 27.8908],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6025, 6.5884, 6.5743, 6.5989, 6.5940, 6.5700, 6.5377, 6.5076, 6.4652,\n",
      "        6.3594, 6.2504, 6.0528, 5.7450, 5.2700, 4.8055, 4.3575, 3.9015, 3.4781,\n",
      "        3.0607, 2.6583, 2.2763, 1.9453, 1.6302, 1.3719, 1.1400, 0.9495, 0.7970,\n",
      "        0.6764, 0.5927, 0.5367, 0.5010, 0.4828, 0.4761, 0.4763, 0.4849, 0.4997,\n",
      "        0.5161, 0.5381, 0.5644, 0.5892, 0.6116, 0.6296, 0.6385, 0.6332, 0.6179,\n",
      "        0.5990, 0.5743, 0.5361, 0.4761, 0.4001, 0.3120, 0.2372, 0.1850, 0.1463,\n",
      "        0.1118], grad_fn=<AddBackward0>) tensor([7.6800, 7.6745, 7.6671, 7.6352, 7.6588, 7.6416, 7.6417, 7.5954, 7.5577,\n",
      "        7.4710, 7.3191, 7.1012, 6.7779, 6.2631, 5.7184, 5.2417, 4.8457, 4.3500,\n",
      "        3.8671, 3.4429, 3.0204, 2.6200, 2.3409, 2.0150, 1.7600, 1.4670, 1.2742,\n",
      "        1.1093, 1.0023, 0.9055, 0.8592, 0.8381, 0.8300, 0.8393, 0.8489, 0.8688,\n",
      "        0.9430, 0.9653, 1.0090, 1.0590, 1.1306, 1.1424, 1.1625, 1.1699, 1.1799,\n",
      "        1.1612, 1.1529, 1.1250, 1.1052, 1.0276, 0.9407, 0.8763, 0.9733, 1.2740,\n",
      "        8.6713], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6738, 3.6737, 3.6710, 3.6699, 3.6811, 3.6611, 3.6759, 3.6797, 3.6909,\n",
      "        3.6764, 3.6749, 3.6785, 3.6910, 3.7095, 3.6938, 3.6807, 3.6558, 3.6025,\n",
      "        3.5425, 3.4606, 3.3236, 3.1974, 3.0268, 2.8380, 2.6442, 2.4443, 2.2373,\n",
      "        2.0443, 1.8574, 1.6706, 1.4994, 1.3380, 1.1898, 1.0611, 0.9375, 0.8325,\n",
      "        0.7344, 0.6496, 0.5714, 0.5005, 0.4365, 0.3845, 0.3396, 0.2993, 0.2657,\n",
      "        0.2360, 0.2119, 0.1898, 0.1710, 0.1538, 0.1371, 0.1207, 0.1044, 0.0881,\n",
      "        0.0755], grad_fn=<AddBackward0>) tensor([ 5.0866,  5.1041,  5.0956,  5.1066,  4.9814,  5.0705,  5.0615,  5.0678,\n",
      "         5.0348,  5.0815,  5.1030,  5.0694,  4.9940,  5.1047,  5.1669,  5.1527,\n",
      "         5.0990,  5.1098,  5.0074,  4.8920,  4.7918,  4.5757,  4.5005,  4.2501,\n",
      "         4.0996,  3.8452,  3.6713,  3.3835,  3.1805,  3.0327,  2.8430,  2.6779,\n",
      "         2.5722,  2.3008,  2.1976,  2.0183,  1.9334,  1.6742,  1.5200,  1.4150,\n",
      "         1.4256,  1.2734,  1.1658,  1.0704,  0.9841,  0.9759,  0.9115,  0.9466,\n",
      "         1.0173,  1.0921,  1.2920,  1.5190,  2.0441,  3.1847, 28.1266],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6191, 6.6037, 6.5905, 6.6144, 6.6108, 6.5850, 6.5537, 6.5221, 6.4775,\n",
      "        6.3742, 6.2657, 6.0652, 5.7583, 5.2811, 4.8159, 4.3671, 3.9105, 3.4882,\n",
      "        3.0708, 2.6678, 2.2853, 1.9541, 1.6377, 1.3777, 1.1451, 0.9531, 0.7994,\n",
      "        0.6781, 0.5938, 0.5376, 0.5016, 0.4835, 0.4770, 0.4774, 0.4864, 0.5015,\n",
      "        0.5183, 0.5409, 0.5676, 0.5931, 0.6161, 0.6345, 0.6435, 0.6382, 0.6225,\n",
      "        0.6028, 0.5778, 0.5385, 0.4774, 0.4000, 0.3106, 0.2351, 0.1826, 0.1440,\n",
      "        0.1096], grad_fn=<AddBackward0>) tensor([7.6832, 7.6840, 7.6735, 7.6431, 7.6653, 7.6488, 7.6462, 7.6051, 7.5711,\n",
      "        7.4771, 7.3217, 7.1108, 6.7825, 6.2673, 5.7180, 5.2465, 4.8524, 4.3545,\n",
      "        3.8711, 3.4519, 3.0324, 2.6270, 2.3456, 2.0261, 1.7624, 1.4677, 1.2758,\n",
      "        1.1096, 1.0003, 0.9043, 0.8588, 0.8386, 0.8311, 0.8417, 0.8496, 0.8732,\n",
      "        0.9465, 0.9702, 1.0154, 1.0657, 1.1366, 1.1502, 1.1709, 1.1754, 1.1892,\n",
      "        1.1731, 1.1606, 1.1376, 1.1115, 1.0329, 0.9403, 0.8744, 0.9777, 1.2775,\n",
      "        8.7315], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6732, 3.6724, 3.6688, 3.6680, 3.6797, 3.6594, 3.6747, 3.6787, 3.6889,\n",
      "        3.6758, 3.6724, 3.6775, 3.6896, 3.7095, 3.6933, 3.6822, 3.6576, 3.6060,\n",
      "        3.5444, 3.4647, 3.3270, 3.1988, 3.0293, 2.8392, 2.6463, 2.4463, 2.2384,\n",
      "        2.0460, 1.8590, 1.6712, 1.4997, 1.3384, 1.1893, 1.0609, 0.9371, 0.8318,\n",
      "        0.7331, 0.6483, 0.5698, 0.4990, 0.4348, 0.3828, 0.3378, 0.2974, 0.2637,\n",
      "        0.2340, 0.2100, 0.1879, 0.1691, 0.1518, 0.1352, 0.1188, 0.1026, 0.0863,\n",
      "        0.0739], grad_fn=<AddBackward0>) tensor([ 5.0664,  5.0882,  5.0834,  5.0934,  4.9653,  5.0565,  5.0445,  5.0553,\n",
      "         5.0245,  5.0654,  5.0997,  5.0564,  4.9905,  5.0952,  5.1605,  5.1432,\n",
      "         5.0905,  5.0944,  5.0028,  4.8768,  4.7815,  4.5777,  4.4965,  4.2501,\n",
      "         4.0987,  3.8361,  3.6705,  3.3720,  3.1663,  3.0292,  2.8355,  2.6628,\n",
      "         2.5702,  2.2886,  2.1867,  2.0075,  1.9314,  1.6704,  1.5224,  1.4098,\n",
      "         1.4256,  1.2672,  1.1548,  1.0647,  0.9830,  0.9758,  0.9076,  0.9434,\n",
      "         1.0136,  1.0879,  1.2860,  1.5029,  2.0371,  3.1819, 27.9794],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6289, 6.6133, 6.6001, 6.6234, 6.6201, 6.5942, 6.5614, 6.5301, 6.4868,\n",
      "        6.3831, 6.2749, 6.0726, 5.7652, 5.2871, 4.8189, 4.3717, 3.9154, 3.4943,\n",
      "        3.0776, 2.6748, 2.2925, 1.9601, 1.6431, 1.3822, 1.1488, 0.9552, 0.8007,\n",
      "        0.6786, 0.5940, 0.5375, 0.5014, 0.4833, 0.4770, 0.4775, 0.4869, 0.5022,\n",
      "        0.5194, 0.5424, 0.5697, 0.5956, 0.6191, 0.6379, 0.6472, 0.6416, 0.6255,\n",
      "        0.6052, 0.5798, 0.5397, 0.4775, 0.3988, 0.3083, 0.2323, 0.1797, 0.1413,\n",
      "        0.1070], grad_fn=<AddBackward0>) tensor([7.6813, 7.6839, 7.6714, 7.6427, 7.6648, 7.6508, 7.6491, 7.6066, 7.5677,\n",
      "        7.4759, 7.3180, 7.1094, 6.7784, 6.2650, 5.7214, 5.2441, 4.8522, 4.3558,\n",
      "        3.8728, 3.4552, 3.0311, 2.6338, 2.3521, 2.0290, 1.7601, 1.4707, 1.2773,\n",
      "        1.1070, 0.9976, 0.9023, 0.8593, 0.8379, 0.8297, 0.8416, 0.8479, 0.8747,\n",
      "        0.9453, 0.9731, 1.0149, 1.0717, 1.1394, 1.1557, 1.1709, 1.1826, 1.1976,\n",
      "        1.1864, 1.1669, 1.1430, 1.1152, 1.0363, 0.9419, 0.8767, 0.9835, 1.2694,\n",
      "        8.7202], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.7100, 3.7091, 3.7056, 3.7049, 3.7163, 3.6952, 3.7114, 3.7158, 3.7253,\n",
      "        3.7119, 3.7110, 3.7145, 3.7276, 3.7476, 3.7336, 3.7220, 3.6983, 3.6468,\n",
      "        3.5842, 3.5051, 3.3657, 3.2357, 3.0635, 2.8713, 2.6759, 2.4743, 2.2639,\n",
      "        2.0693, 1.8801, 1.6897, 1.5155, 1.3529, 1.2016, 1.0716, 0.9464, 0.8396,\n",
      "        0.7396, 0.6539, 0.5741, 0.5025, 0.4374, 0.3849, 0.3392, 0.2985, 0.2644,\n",
      "        0.2343, 0.2101, 0.1878, 0.1689, 0.1515, 0.1347, 0.1183, 0.1020, 0.0857,\n",
      "        0.0732], grad_fn=<AddBackward0>) tensor([ 5.1021,  5.1241,  5.1192,  5.1277,  5.0008,  5.0981,  5.0844,  5.0922,\n",
      "         5.0661,  5.1119,  5.1351,  5.1020,  5.0312,  5.1462,  5.1961,  5.1871,\n",
      "         5.1296,  5.1384,  5.0461,  4.9118,  4.8185,  4.6166,  4.5384,  4.2825,\n",
      "         4.1368,  3.8635,  3.6976,  3.3980,  3.1884,  3.0498,  2.8628,  2.6801,\n",
      "         2.5912,  2.3067,  2.1988,  2.0214,  1.9440,  1.6762,  1.5332,  1.4161,\n",
      "         1.4372,  1.2687,  1.1668,  1.0677,  0.9870,  0.9849,  0.9166,  0.9470,\n",
      "         1.0184,  1.0972,  1.3001,  1.5212,  2.0528,  3.2201, 28.4102],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.6371, 6.6219, 6.6104, 6.6334, 6.6298, 6.6044, 6.5716, 6.5385, 6.4976,\n",
      "        6.3912, 6.2840, 6.0793, 5.7722, 5.2929, 4.8233, 4.3768, 3.9195, 3.5000,\n",
      "        3.0832, 2.6811, 2.2982, 1.9652, 1.6478, 1.3859, 1.1510, 0.9562, 0.8010,\n",
      "        0.6784, 0.5932, 0.5365, 0.5002, 0.4822, 0.4758, 0.4765, 0.4860, 0.5015,\n",
      "        0.5187, 0.5418, 0.5695, 0.5957, 0.6191, 0.6381, 0.6472, 0.6415, 0.6248,\n",
      "        0.6041, 0.5781, 0.5375, 0.4745, 0.3951, 0.3042, 0.2282, 0.1759, 0.1378,\n",
      "        0.1041], grad_fn=<AddBackward0>) tensor([7.6860, 7.6868, 7.6698, 7.6426, 7.6652, 7.6492, 7.6487, 7.6109, 7.5643,\n",
      "        7.4762, 7.3153, 7.1140, 6.7775, 6.2661, 5.7249, 5.2437, 4.8559, 4.3545,\n",
      "        3.8768, 3.4563, 3.0325, 2.6364, 2.3488, 2.0299, 1.7600, 1.4726, 1.2765,\n",
      "        1.1007, 0.9962, 0.9014, 0.8591, 0.8363, 0.8281, 0.8398, 0.8443, 0.8724,\n",
      "        0.9452, 0.9757, 1.0140, 1.0689, 1.1397, 1.1582, 1.1743, 1.1818, 1.1984,\n",
      "        1.1843, 1.1689, 1.1398, 1.1108, 1.0315, 0.9346, 0.8736, 0.9804, 1.2674,\n",
      "        8.6250], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.7111, 3.7105, 3.7074, 3.7069, 3.7176, 3.6964, 3.7127, 3.7157, 3.7276,\n",
      "        3.7134, 3.7142, 3.7177, 3.7308, 3.7508, 3.7390, 3.7273, 3.7040, 3.6510,\n",
      "        3.5900, 3.5124, 3.3708, 3.2408, 3.0704, 2.8776, 2.6804, 2.4795, 2.2699,\n",
      "        2.0720, 1.8825, 1.6930, 1.5179, 1.3551, 1.2036, 1.0728, 0.9476, 0.8398,\n",
      "        0.7398, 0.6536, 0.5736, 0.5017, 0.4364, 0.3837, 0.3379, 0.2971, 0.2628,\n",
      "        0.2328, 0.2085, 0.1862, 0.1672, 0.1499, 0.1331, 0.1167, 0.1005, 0.0842,\n",
      "        0.0718], grad_fn=<AddBackward0>) tensor([ 5.0908,  5.1145,  5.1078,  5.1176,  4.9913,  5.0930,  5.0795,  5.0940,\n",
      "         5.0563,  5.1084,  5.1245,  5.0946,  5.0271,  5.1427,  5.1860,  5.1845,\n",
      "         5.1222,  5.1429,  5.0476,  4.9058,  4.8234,  4.6205,  4.5324,  4.2749,\n",
      "         4.1419,  3.8616,  3.6839,  3.4094,  3.1975,  3.0508,  2.8641,  2.6814,\n",
      "         2.5854,  2.3064,  2.1901,  2.0281,  1.9428,  1.6816,  1.5325,  1.4205,\n",
      "         1.4389,  1.2660,  1.1628,  1.0620,  0.9859,  0.9789,  0.9093,  0.9483,\n",
      "         1.0150,  1.0969,  1.2970,  1.5263,  2.0507,  3.2374, 28.3309],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6369, 6.6231, 6.6124, 6.6341, 6.6306, 6.6047, 6.5714, 6.5384, 6.4968,\n",
      "        6.3922, 6.2837, 6.0785, 5.7697, 5.2915, 4.8217, 4.3753, 3.9191, 3.5007,\n",
      "        3.0850, 2.6838, 2.3008, 1.9675, 1.6505, 1.3875, 1.1520, 0.9564, 0.8003,\n",
      "        0.6776, 0.5918, 0.5349, 0.4987, 0.4806, 0.4744, 0.4751, 0.4848, 0.5004,\n",
      "        0.5179, 0.5412, 0.5691, 0.5956, 0.6193, 0.6384, 0.6475, 0.6416, 0.6245,\n",
      "        0.6034, 0.5768, 0.5356, 0.4720, 0.3919, 0.3006, 0.2245, 0.1725, 0.1347,\n",
      "        0.1014], grad_fn=<AddBackward0>) tensor([7.6792, 7.6769, 7.6569, 7.6341, 7.6564, 7.6412, 7.6421, 7.6043, 7.5590,\n",
      "        7.4651, 7.3066, 7.1071, 6.7751, 6.2544, 5.7142, 5.2363, 4.8539, 4.3515,\n",
      "        3.8731, 3.4552, 3.0322, 2.6383, 2.3453, 2.0302, 1.7548, 1.4702, 1.2763,\n",
      "        1.0946, 0.9934, 0.8996, 0.8552, 0.8340, 0.8243, 0.8375, 0.8415, 0.8689,\n",
      "        0.9419, 0.9731, 1.0142, 1.0671, 1.1367, 1.1589, 1.1717, 1.1794, 1.1949,\n",
      "        1.1768, 1.1688, 1.1400, 1.1049, 1.0271, 0.9274, 0.8687, 0.9821, 1.2572,\n",
      "        8.6386], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6995, 3.6983, 3.6942, 3.6929, 3.7047, 3.6838, 3.7001, 3.7033, 3.7166,\n",
      "        3.7021, 3.7017, 3.7065, 3.7187, 3.7389, 3.7282, 3.7182, 3.6951, 3.6411,\n",
      "        3.5821, 3.5058, 3.3659, 3.2341, 3.0647, 2.8728, 2.6764, 2.4753, 2.2651,\n",
      "        2.0674, 1.8774, 1.6896, 1.5149, 1.3519, 1.2005, 1.0699, 0.9447, 0.8370,\n",
      "        0.7373, 0.6509, 0.5710, 0.4991, 0.4338, 0.3813, 0.3354, 0.2947, 0.2605,\n",
      "        0.2305, 0.2063, 0.1840, 0.1652, 0.1479, 0.1312, 0.1148, 0.0987, 0.0825,\n",
      "        0.0703], grad_fn=<AddBackward0>) tensor([ 5.0548,  5.0848,  5.0852,  5.0954,  4.9653,  5.0660,  5.0540,  5.0712,\n",
      "         5.0265,  5.0814,  5.1047,  5.0692,  5.0077,  5.1232,  5.1645,  5.1606,\n",
      "         5.0970,  5.1284,  5.0262,  4.8787,  4.7919,  4.6012,  4.5094,  4.2480,\n",
      "         4.1115,  3.8357,  3.6682,  3.3972,  3.1948,  3.0291,  2.8437,  2.6661,\n",
      "         2.5730,  2.2944,  2.1815,  2.0192,  1.9263,  1.6742,  1.5217,  1.4116,\n",
      "         1.4351,  1.2524,  1.1566,  1.0553,  0.9813,  0.9678,  0.9038,  0.9440,\n",
      "         1.0090,  1.0909,  1.2846,  1.5284,  2.0344,  3.2327, 28.1335],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6495, 6.6352, 6.6265, 6.6462, 6.6442, 6.6192, 6.5854, 6.5516, 6.5113,\n",
      "        6.4050, 6.2948, 6.0900, 5.7806, 5.2996, 4.8299, 4.3821, 3.9248, 3.5076,\n",
      "        3.0925, 2.6916, 2.3079, 1.9729, 1.6555, 1.3912, 1.1549, 0.9574, 0.8009,\n",
      "        0.6773, 0.5911, 0.5338, 0.4976, 0.4795, 0.4733, 0.4741, 0.4839, 0.4997,\n",
      "        0.5175, 0.5411, 0.5693, 0.5960, 0.6199, 0.6392, 0.6483, 0.6421, 0.6245,\n",
      "        0.6031, 0.5761, 0.5341, 0.4698, 0.3889, 0.2971, 0.2211, 0.1692, 0.1318,\n",
      "        0.0989], grad_fn=<AddBackward0>) tensor([7.6877, 7.6869, 7.6608, 7.6434, 7.6618, 7.6443, 7.6453, 7.6100, 7.5610,\n",
      "        7.4702, 7.3131, 7.1112, 6.7773, 6.2583, 5.7156, 5.2402, 4.8644, 4.3575,\n",
      "        3.8761, 3.4538, 3.0341, 2.6476, 2.3470, 2.0347, 1.7522, 1.4716, 1.2727,\n",
      "        1.0923, 0.9914, 0.8968, 0.8529, 0.8310, 0.8208, 0.8344, 0.8389, 0.8686,\n",
      "        0.9360, 0.9697, 1.0125, 1.0675, 1.1380, 1.1596, 1.1720, 1.1838, 1.2005,\n",
      "        1.1786, 1.1689, 1.1416, 1.1049, 1.0237, 0.9220, 0.8622, 0.9768, 1.2563,\n",
      "        8.6501], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6980, 3.6980, 3.6946, 3.6924, 3.7035, 3.6838, 3.7006, 3.7027, 3.7168,\n",
      "        3.7034, 3.7025, 3.7070, 3.7181, 3.7405, 3.7296, 3.7212, 3.6985, 3.6451,\n",
      "        3.5860, 3.5088, 3.3704, 3.2390, 3.0695, 2.8763, 2.6797, 2.4782, 2.2683,\n",
      "        2.0686, 1.8794, 1.6912, 1.5164, 1.3528, 1.2012, 1.0701, 0.9446, 0.8366,\n",
      "        0.7369, 0.6499, 0.5700, 0.4980, 0.4325, 0.3797, 0.3339, 0.2932, 0.2588,\n",
      "        0.2289, 0.2046, 0.1823, 0.1635, 0.1462, 0.1296, 0.1132, 0.0972, 0.0811,\n",
      "        0.0689], grad_fn=<AddBackward0>) tensor([ 5.0468,  5.0692,  5.0690,  5.0817,  4.9528,  5.0524,  5.0404,  5.0619,\n",
      "         5.0140,  5.0636,  5.0943,  5.0604,  5.0113,  5.1175,  5.1604,  5.1540,\n",
      "         5.0912,  5.1209,  5.0200,  4.8787,  4.7854,  4.5893,  4.4975,  4.2394,\n",
      "         4.1044,  3.8294,  3.6599,  3.3999,  3.1862,  3.0206,  2.8347,  2.6588,\n",
      "         2.5618,  2.2875,  2.1762,  2.0163,  1.9138,  1.6765,  1.5218,  1.4085,\n",
      "         1.4299,  1.2540,  1.1539,  1.0437,  0.9796,  0.9632,  0.8981,  0.9425,\n",
      "         1.0036,  1.0962,  1.2788,  1.5313,  2.0430,  3.2200, 28.1013],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6812, 6.6667, 6.6582, 6.6765, 6.6763, 6.6495, 6.6158, 6.5830, 6.5413,\n",
      "        6.4369, 6.3221, 6.1168, 5.8076, 5.3224, 4.8515, 4.4025, 3.9452, 3.5264,\n",
      "        3.1107, 2.7096, 2.3236, 1.9867, 1.6685, 1.4020, 1.1635, 0.9640, 0.8063,\n",
      "        0.6813, 0.5943, 0.5366, 0.5002, 0.4822, 0.4762, 0.4773, 0.4876, 0.5038,\n",
      "        0.5223, 0.5465, 0.5755, 0.6031, 0.6277, 0.6477, 0.6572, 0.6507, 0.6327,\n",
      "        0.6108, 0.5829, 0.5399, 0.4739, 0.3910, 0.2974, 0.2203, 0.1679, 0.1304,\n",
      "        0.0973], grad_fn=<AddBackward0>) tensor([7.7129, 7.7130, 7.6860, 7.6723, 7.6875, 7.6760, 7.6712, 7.6380, 7.5911,\n",
      "        7.4912, 7.3443, 7.1407, 6.7972, 6.2828, 5.7353, 5.2575, 4.8788, 4.3726,\n",
      "        3.8935, 3.4655, 3.0505, 2.6656, 2.3577, 2.0441, 1.7638, 1.4797, 1.2753,\n",
      "        1.0963, 0.9955, 0.9008, 0.8549, 0.8361, 0.8257, 0.8401, 0.8411, 0.8750,\n",
      "        0.9425, 0.9768, 1.0229, 1.0776, 1.1511, 1.1746, 1.1851, 1.2000, 1.2156,\n",
      "        1.1884, 1.1829, 1.1544, 1.1198, 1.0355, 0.9329, 0.8699, 0.9866, 1.2691,\n",
      "        8.7911], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6900, 3.6898, 3.6861, 3.6827, 3.6953, 3.6773, 3.6941, 3.6940, 3.7095,\n",
      "        3.6955, 3.6943, 3.7015, 3.7125, 3.7338, 3.7256, 3.7167, 3.6936, 3.6432,\n",
      "        3.5837, 3.5051, 3.3675, 3.2358, 3.0671, 2.8724, 2.6775, 2.4759, 2.2668,\n",
      "        2.0662, 1.8774, 1.6885, 1.5151, 1.3508, 1.1986, 1.0685, 0.9425, 0.8344,\n",
      "        0.7347, 0.6478, 0.5678, 0.4957, 0.4302, 0.3774, 0.3317, 0.2911, 0.2567,\n",
      "        0.2270, 0.2027, 0.1805, 0.1618, 0.1446, 0.1280, 0.1118, 0.0959, 0.0801,\n",
      "        0.0678], grad_fn=<AddBackward0>) tensor([ 5.0250,  5.0477,  5.0486,  5.0702,  4.9305,  5.0256,  5.0154,  5.0461,\n",
      "         4.9916,  5.0488,  5.0796,  5.0345,  4.9903,  5.1029,  5.1338,  5.1379,\n",
      "         5.0757,  5.0955,  4.9965,  4.8672,  4.7702,  4.5771,  4.4843,  4.2363,\n",
      "         4.0901,  3.8148,  3.6430,  3.3892,  3.1713,  3.0144,  2.8146,  2.6442,\n",
      "         2.5603,  2.2683,  2.1638,  2.0071,  1.9035,  1.6611,  1.5069,  1.4011,\n",
      "         1.4205,  1.2533,  1.1518,  1.0379,  0.9741,  0.9539,  0.8935,  0.9424,\n",
      "         1.0019,  1.0948,  1.2839,  1.5501,  2.0506,  3.2438, 28.4290],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0 before lock-down  tensor([6.6588, 6.6423, 6.6344, 6.6526, 6.6540, 6.6260, 6.5921, 6.5597, 6.5181,\n",
      "        6.4140, 6.3004, 6.0950, 5.7853, 5.3009, 4.8319, 4.3861, 3.9304, 3.5146,\n",
      "        3.1011, 2.7020, 2.3171, 1.9819, 1.6649, 1.3987, 1.1597, 0.9607, 0.8029,\n",
      "        0.6777, 0.5908, 0.5331, 0.4969, 0.4790, 0.4731, 0.4742, 0.4848, 0.5011,\n",
      "        0.5199, 0.5441, 0.5733, 0.6011, 0.6259, 0.6461, 0.6555, 0.6487, 0.6305,\n",
      "        0.6083, 0.5799, 0.5364, 0.4699, 0.3867, 0.2929, 0.2160, 0.1641, 0.1270,\n",
      "        0.0945], grad_fn=<AddBackward0>) tensor([7.6737, 7.6787, 7.6499, 7.6368, 7.6487, 7.6378, 7.6338, 7.6032, 7.5558,\n",
      "        7.4551, 7.3039, 7.1058, 6.7656, 6.2532, 5.7085, 5.2279, 4.8553, 4.3506,\n",
      "        3.8742, 3.4511, 3.0444, 2.6544, 2.3436, 2.0328, 1.7618, 1.4710, 1.2668,\n",
      "        1.0925, 0.9892, 0.8972, 0.8486, 0.8306, 0.8191, 0.8393, 0.8328, 0.8680,\n",
      "        0.9362, 0.9749, 1.0223, 1.0754, 1.1479, 1.1712, 1.1808, 1.1966, 1.2134,\n",
      "        1.1834, 1.1794, 1.1523, 1.1169, 1.0262, 0.9254, 0.8652, 0.9809, 1.2611,\n",
      "        8.7128], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.7041, 3.7046, 3.7002, 3.6992, 3.7109, 3.6937, 3.7103, 3.7101, 3.7283,\n",
      "        3.7134, 3.7134, 3.7184, 3.7314, 3.7525, 3.7448, 3.7367, 3.7152, 3.6650,\n",
      "        3.6054, 3.5252, 3.3875, 3.2546, 3.0868, 2.8916, 2.6947, 2.4914, 2.2815,\n",
      "        2.0789, 1.8889, 1.6992, 1.5244, 1.3586, 1.2058, 1.0747, 0.9480, 0.8387,\n",
      "        0.7382, 0.6506, 0.5701, 0.4972, 0.4312, 0.3782, 0.3319, 0.2911, 0.2565,\n",
      "        0.2265, 0.2021, 0.1799, 0.1610, 0.1437, 0.1272, 0.1108, 0.0950, 0.0792,\n",
      "        0.0669], grad_fn=<AddBackward0>) tensor([ 5.0467,  5.0658,  5.0677,  5.0820,  4.9467,  5.0385,  5.0283,  5.0605,\n",
      "         4.9960,  5.0572,  5.0862,  5.0530,  5.0026,  5.1181,  5.1496,  5.1542,\n",
      "         5.0826,  5.1073,  5.0123,  4.8893,  4.7908,  4.5974,  4.4972,  4.2404,\n",
      "         4.1045,  3.8229,  3.6506,  3.4039,  3.1843,  3.0228,  2.8274,  2.6596,\n",
      "         2.5684,  2.2755,  2.1679,  2.0139,  1.9089,  1.6659,  1.5064,  1.4047,\n",
      "         1.4285,  1.2508,  1.1538,  1.0394,  0.9730,  0.9531,  0.8904,  0.9417,\n",
      "         1.0086,  1.1014,  1.2856,  1.5639,  2.0673,  3.2511, 28.6722],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6728, 6.6585, 6.6469, 6.6652, 6.6669, 6.6375, 6.6074, 6.5742, 6.5316,\n",
      "        6.4282, 6.3121, 6.1052, 5.7979, 5.3099, 4.8398, 4.3919, 3.9371, 3.5216,\n",
      "        3.1101, 2.7093, 2.3243, 1.9886, 1.6704, 1.4031, 1.1628, 0.9626, 0.8039,\n",
      "        0.6779, 0.5904, 0.5324, 0.4962, 0.4784, 0.4725, 0.4739, 0.4845, 0.5010,\n",
      "        0.5200, 0.5444, 0.5741, 0.6019, 0.6272, 0.6475, 0.6567, 0.6497, 0.6310,\n",
      "        0.6083, 0.5794, 0.5353, 0.4677, 0.3839, 0.2895, 0.2126, 0.1608, 0.1241,\n",
      "        0.0920], grad_fn=<AddBackward0>) tensor([7.6791, 7.6801, 7.6608, 7.6478, 7.6581, 7.6502, 7.6384, 7.6080, 7.5621,\n",
      "        7.4582, 7.3136, 7.1134, 6.7652, 6.2567, 5.7083, 5.2349, 4.8635, 4.3593,\n",
      "        3.8711, 3.4540, 3.0475, 2.6581, 2.3445, 2.0316, 1.7626, 1.4695, 1.2649,\n",
      "        1.0917, 0.9913, 0.8992, 0.8466, 0.8299, 0.8168, 0.8345, 0.8324, 0.8676,\n",
      "        0.9351, 0.9761, 1.0202, 1.0798, 1.1489, 1.1714, 1.1861, 1.1960, 1.2130,\n",
      "        1.1856, 1.1733, 1.1447, 1.1230, 1.0185, 0.9238, 0.8562, 0.9812, 1.2647,\n",
      "        8.6616], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6947, 3.6955, 3.6921, 3.6896, 3.7009, 3.6850, 3.7019, 3.7013, 3.7202,\n",
      "        3.7050, 3.7053, 3.7117, 3.7246, 3.7457, 3.7392, 3.7321, 3.7092, 3.6627,\n",
      "        3.6008, 3.5214, 3.3848, 3.2534, 3.0843, 2.8899, 2.6940, 2.4884, 2.2802,\n",
      "        2.0782, 1.8880, 1.6978, 1.5233, 1.3581, 1.2049, 1.0738, 0.9473, 0.8378,\n",
      "        0.7371, 0.6495, 0.5688, 0.4958, 0.4298, 0.3767, 0.3303, 0.2895, 0.2549,\n",
      "        0.2248, 0.2005, 0.1783, 0.1594, 0.1422, 0.1256, 0.1092, 0.0935, 0.0778,\n",
      "        0.0656], grad_fn=<AddBackward0>) tensor([ 5.0289,  5.0467,  5.0415,  5.0662,  4.9358,  5.0162,  5.0071,  5.0415,\n",
      "         4.9753,  5.0415,  5.0726,  5.0310,  4.9826,  5.1005,  5.1315,  5.1318,\n",
      "         5.0696,  5.0838,  5.0007,  4.8770,  4.7755,  4.5761,  4.4852,  4.2269,\n",
      "         4.0865,  3.8215,  3.6375,  3.3892,  3.1750,  3.0169,  2.8192,  2.6495,\n",
      "         2.5628,  2.2718,  2.1588,  2.0074,  1.9053,  1.6615,  1.5035,  1.4021,\n",
      "         1.4208,  1.2417,  1.1531,  1.0315,  0.9692,  0.9537,  0.8904,  0.9401,\n",
      "         1.0075,  1.0980,  1.2798,  1.5807,  2.0748,  3.2210, 28.5109],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6695, 6.6571, 6.6437, 6.6616, 6.6627, 6.6338, 6.6062, 6.5718, 6.5268,\n",
      "        6.4236, 6.3080, 6.1028, 5.7938, 5.3047, 4.8350, 4.3889, 3.9332, 3.5198,\n",
      "        3.1103, 2.7102, 2.3253, 1.9900, 1.6718, 1.4039, 1.1628, 0.9619, 0.8027,\n",
      "        0.6763, 0.5888, 0.5304, 0.4943, 0.4765, 0.4708, 0.4722, 0.4830, 0.4996,\n",
      "        0.5189, 0.5435, 0.5734, 0.6015, 0.6271, 0.6475, 0.6567, 0.6496, 0.6303,\n",
      "        0.6072, 0.5781, 0.5334, 0.4650, 0.3806, 0.2859, 0.2091, 0.1577, 0.1213,\n",
      "        0.0897], grad_fn=<AddBackward0>) tensor([7.6692, 7.6634, 7.6487, 7.6370, 7.6489, 7.6394, 7.6229, 7.5946, 7.5548,\n",
      "        7.4479, 7.3005, 7.0963, 6.7522, 6.2443, 5.6956, 5.2222, 4.8601, 4.3525,\n",
      "        3.8642, 3.4463, 3.0429, 2.6538, 2.3371, 2.0284, 1.7589, 1.4669, 1.2610,\n",
      "        1.0879, 0.9848, 0.8977, 0.8450, 0.8266, 0.8115, 0.8307, 0.8323, 0.8657,\n",
      "        0.9336, 0.9699, 1.0178, 1.0752, 1.1470, 1.1704, 1.1867, 1.1937, 1.2130,\n",
      "        1.1862, 1.1680, 1.1376, 1.1209, 1.0124, 0.9260, 0.8580, 0.9759, 1.2652,\n",
      "        8.6343], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6959, 3.6991, 3.6921, 3.6918, 3.7041, 3.6876, 3.7052, 3.7042, 3.7231,\n",
      "        3.7067, 3.7094, 3.7165, 3.7275, 3.7503, 3.7437, 3.7382, 3.7153, 3.6686,\n",
      "        3.6081, 3.5274, 3.3912, 3.2594, 3.0898, 2.8974, 2.6992, 2.4929, 2.2837,\n",
      "        2.0813, 1.8912, 1.7009, 1.5257, 1.3596, 1.2065, 1.0751, 0.9478, 0.8382,\n",
      "        0.7371, 0.6493, 0.5683, 0.4949, 0.4287, 0.3756, 0.3290, 0.2881, 0.2534,\n",
      "        0.2234, 0.1990, 0.1768, 0.1580, 0.1407, 0.1242, 0.1079, 0.0922, 0.0767,\n",
      "        0.0645], grad_fn=<AddBackward0>) tensor([ 5.0264,  5.0321,  5.0436,  5.0578,  4.9238,  5.0095,  4.9950,  5.0322,\n",
      "         4.9683,  5.0401,  5.0637,  5.0178,  4.9797,  5.0918,  5.1284,  5.1243,\n",
      "         5.0669,  5.0809,  4.9925,  4.8778,  4.7757,  4.5759,  4.4888,  4.2158,\n",
      "         4.0822,  3.8168,  3.6393,  3.3903,  3.1732,  3.0086,  2.8150,  2.6489,\n",
      "         2.5548,  2.2643,  2.1578,  2.0058,  1.9034,  1.6575,  1.5012,  1.4060,\n",
      "         1.4204,  1.2351,  1.1468,  1.0247,  0.9633,  0.9543,  0.8823,  0.9389,\n",
      "         1.0044,  1.0979,  1.2903,  1.5911,  2.0750,  3.2331, 28.6261],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n",
      "r0 before lock-down  tensor([6.6800, 6.6684, 6.6532, 6.6740, 6.6715, 6.6452, 6.6150, 6.5813, 6.5374,\n",
      "        6.4351, 6.3181, 6.1126, 5.8006, 5.3115, 4.8410, 4.3941, 3.9391, 3.5266,\n",
      "        3.1169, 2.7172, 2.3316, 1.9960, 1.6769, 1.4081, 1.1656, 0.9637, 0.8031,\n",
      "        0.6763, 0.5883, 0.5297, 0.4934, 0.4757, 0.4700, 0.4714, 0.4825, 0.4993,\n",
      "        0.5188, 0.5437, 0.5740, 0.6025, 0.6284, 0.6490, 0.6582, 0.6510, 0.6314,\n",
      "        0.6078, 0.5781, 0.5330, 0.4637, 0.3785, 0.2831, 0.2063, 0.1550, 0.1189,\n",
      "        0.0876], grad_fn=<AddBackward0>) tensor([7.6738, 7.6652, 7.6519, 7.6371, 7.6577, 7.6383, 7.6313, 7.6023, 7.5579,\n",
      "        7.4462, 7.3036, 7.0991, 6.7595, 6.2428, 5.6947, 5.2222, 4.8620, 4.3532,\n",
      "        3.8654, 3.4494, 3.0509, 2.6584, 2.3391, 2.0302, 1.7621, 1.4660, 1.2645,\n",
      "        1.0873, 0.9803, 0.8939, 0.8421, 0.8229, 0.8098, 0.8296, 0.8299, 0.8634,\n",
      "        0.9335, 0.9694, 1.0205, 1.0743, 1.1493, 1.1718, 1.1912, 1.1974, 1.2161,\n",
      "        1.1891, 1.1732, 1.1365, 1.1212, 1.0126, 0.9241, 0.8580, 0.9768, 1.2538,\n",
      "        8.6562], grad_fn=<AddBackward0>)\n",
      "r0 mrs before lock-down  tensor([3.6994, 3.7023, 3.6951, 3.6944, 3.7064, 3.6897, 3.7074, 3.7085, 3.7287,\n",
      "        3.7107, 3.7152, 3.7216, 3.7330, 3.7562, 3.7506, 3.7452, 3.7233, 3.6776,\n",
      "        3.6164, 3.5368, 3.3992, 3.2667, 3.0972, 2.9054, 2.7060, 2.4999, 2.2892,\n",
      "        2.0865, 1.8963, 1.7052, 1.5295, 1.3622, 1.2093, 1.0769, 0.9494, 0.8391,\n",
      "        0.7376, 0.6494, 0.5682, 0.4943, 0.4278, 0.3746, 0.3278, 0.2869, 0.2520,\n",
      "        0.2219, 0.1975, 0.1753, 0.1565, 0.1392, 0.1227, 0.1064, 0.0908, 0.0753,\n",
      "        0.0633], grad_fn=<AddBackward0>) tensor([ 5.0223,  5.0304,  5.0414,  5.0589,  4.9262,  5.0120,  4.9959,  5.0277,\n",
      "         4.9591,  5.0365,  5.0549,  5.0148,  4.9798,  5.0904,  5.1215,  5.1255,\n",
      "         5.0674,  5.0799,  4.9928,  4.8752,  4.7814,  4.5850,  4.4948,  4.2164,\n",
      "         4.0880,  3.8160,  3.6400,  3.3932,  3.1689,  3.0039,  2.8136,  2.6535,\n",
      "         2.5450,  2.2636,  2.1520,  2.0044,  1.9025,  1.6537,  1.4942,  1.4020,\n",
      "         1.4189,  1.2322,  1.1402,  1.0170,  0.9591,  0.9512,  0.8839,  0.9362,\n",
      "         1.0020,  1.0926,  1.2852,  1.5808,  2.0756,  3.2258, 28.4619],\n",
      "       grad_fn=<AddBackward0>)\n",
      "inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min 30s, sys: 18 s, total: 34min 48s\n",
      "Wall time: 34min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "losses, a,b  = [], [], []\n",
    "num_steps = 20000\n",
    "for t in range(num_steps):\n",
    "    #print(svi.step(guess_R0, guess_R0_RMS))\n",
    "    #print('r0 = ',pyro.param(\"a_r0\"), pyro.param(\"b_r0\"))\n",
    "    losses.append(svi.step())\n",
    "    if t % 100 == 0:\n",
    "        print('r0 before lock-down ',pyro.param(\"a_r0_1\"), pyro.param(\"a_r0_1\") + pyro.param(\"b_r0_1\"))\n",
    "        print('r0 mrs before lock-down ',pyro.param(\"a_r0_mrs_1\"), pyro.param(\"a_r0_mrs_1\") + pyro.param(\"b_r0_mrs_1\"))\n",
    "        print(losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_points = 100\n",
    "for i in range(n_points):\n",
    "    if mrs:\n",
    "        s_T, e_T, i_T, h_T, l_T, m_T, m_mrs_T, r_T, r0_T, r0_mrs_T = svi.guide(True)\n",
    "    else:\n",
    "        s_T, e_T, i_T, h_T, l_T, m_T, r_T, r0_T = svi.guide(True)\n",
    "    hospi_T = np.array(list(map(lambda x: (x[0] + x[1]).detach().numpy(), zip(h_T, l_T)))).reshape(-1, 1)\n",
    "    l_T = np.array(list(map(lambda x: x.detach().numpy(), l_T))).reshape(-1, 1)\n",
    "    m_T = np.array(list(map(lambda x: x.detach().numpy(), m_T))).reshape(-1, 1)\n",
    "    m_mrs_T = np.array(list(map(lambda x: x.detach().numpy(), m_mrs_T))).reshape(-1, 1)\n",
    "    r0_T = np.array(list(map(lambda x: x.detach().numpy(), r0_T))).reshape(-1, 1)\n",
    "    r0_mrs_T = np.array(list(map(lambda x: x.detach().numpy(), r0_mrs_T))).reshape(-1, 1)\n",
    "\n",
    "    if i == 0:\n",
    "        h = hospi_T\n",
    "        l = l_T\n",
    "        m = m_T\n",
    "        m_mrs = m_mrs_T\n",
    "        r0, r0_mrs = r0_T, r0_mrs_T\n",
    "    else:\n",
    "        h = np.append(h, hospi_T, axis=1)\n",
    "        l = np.append(l, l_T, axis=1)\n",
    "        m = np.append(m, m_T, axis=1)\n",
    "        m_mrs = np.append(m_mrs, m_mrs_T, axis=1)\n",
    "        r0_mrs = np.append(r0_mrs, r0_mrs_T, axis=1)\n",
    "        r0 = np.append(r0, r0_T, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_percentiles(arr, color=None,ax=None, label=None):\n",
    "    arr_50 = np.percentile(arr, 50, axis=1)\n",
    "    arr_5 = np.percentile(arr, 5, axis=1)\n",
    "    arr_95 = np.percentile(arr, 95, axis=1)\n",
    "    if color is not None:\n",
    "        ax.plot(data_df['date'][:len(arr)], arr_50, c=color, label=label)\n",
    "        ax.fill_between(data_df['date'][:len(arr)], arr_5, arr_95, color=color, alpha=0.2)\n",
    "    return arr_50, arr_5, arr_95\n",
    "\n",
    "seaborn.set()\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10), sharex=True, gridspec_kw={\"height_ratios\": (4, 1)})\n",
    "\n",
    "ax[0].plot(data_df['date'], data_df['n_hospitalized'], 'x', color='b', label='Hospitalized')\n",
    "\n",
    "ax[0].plot(data_df['date'], data_df['n_icu'], 'x', color='g', label='ICUs')\n",
    "ax[0].plot(data_df['date'], data_df['n_deaths'] * frac_dh().item(), 'x', color='r', label='Deaths in hospital')\n",
    "ax[0].plot(data_df['date'], data_df['n_deaths']*(1-frac_dh().item()), 'x', color='orange', label='Deaths in MRS')\n",
    "\n",
    "get_percentiles(h, 'b', ax[0])\n",
    "get_percentiles(l, 'g', ax[0])\n",
    "get_percentiles(m, 'r', ax[0])\n",
    "get_percentiles(m_mrs, 'orange', ax[0])\n",
    "\n",
    "get_percentiles(r0_mrs[:-n_unpredictable_days-1], 'yellow', ax[1], \"R0 in mrs\")\n",
    "get_percentiles(r0[:-n_unpredictable_days-1], 'brown', ax[1], 'R0')\n",
    "\n",
    "ax[0].axvline(data_df['date'][date_r0_switch], 0, 8500, label='Lockdown', c='black', alpha=.8, linestyle ='--')\n",
    "ax[0].axvline(data_df['date'][date_r0_switch_mrs], 0, 8500, label='MRS forbidden', c='black', alpha=.8, linestyle=':')\n",
    "ax[1].axvline(data_df['date'][date_r0_switch], 0, 8500, label='Lockdown', c='black', alpha=.8, linestyle ='--')\n",
    "ax[1].axvline(data_df['date'][date_r0_switch_mrs], 0, 8500, label='MRS forbidden', c='black', alpha=.8, linestyle=':')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.savefig('pyro_SEIR_manyR0.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc_seir_full_model_bis(data):\n",
    "    return pyro.condition(SEIR_full_model_bis, data=data)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nuts_kernel = NUTS(mcmc_seir_full_model_bis, jit_compile=False, ignore_jit_warnings=True)\n",
    "pyro.set_rng_seed(1)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=100)\n",
    "mcmc.run(data)\n",
    "mcmc.summary(prob=.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
